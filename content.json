{"pages":[{"title":"","text":"个人简介 道可道，非常道；名可名，非常名。 无名，天地之始，有名，万物之母。 故常无欲，以观其妙，常有欲，以观其徼。 此两者，同出而异名，同谓之玄，玄之又玄，众妙之门。 博客信息 网站采用amazing主题 使用Hexo渲染 更新日志：–2020.05.09：使用amazing主题–2020.04.15：使用next主题 推荐阅读 博客主题 github Issue 作为博客微型数据库的应用 amazing作者博客源码分享 Hexo 博客提交百度、谷歌搜索引擎收录 游戏服务器架构 游戏服务器架构演进(完整版) 游戏服务器引擎 GSE C++ C++那些事 Golang Golang实现软件设计模式 Golang学习室 Golang channel 源码深度剖析 golang-101-hacks Linux网络 源码解读epoll内核机制 STL STL 容器底层实现总结 muduo muduo 源码剖析 软件开发底层知识 底层知识学习记录目录表 技术博客 酷 壳 – COOLSHELL 纯洁的微笑 廖雪峰的官方网站 美团技术团队 时间轴","link":"/about/index.html"},{"title":"","text":"不是每一种声音都叫音乐，不是每一个乐队都叫BEYOND","link":"/album/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://beyondhxl.github.io/img/avatar.png 网站名称：宇宙の騎士 网站地址：https://beyondhxl.github.io 网站简介：在路上 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"&nbsp;&nbsp;聆听 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;观影 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"The Wall 那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程…可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。","link":"/message/index.html"},{"title":"","text":"滚石杂志--史上最伟大的500首歌曲 --- 中国摇滚二十年--经典100首歌曲 温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"说说 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址…「+99次查看」 说说加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '6e19ff696a6246d4da8b', clientSecret: '1518ab0356e2eeaecbdbd5efd9b654cd5c224c93', id: '666666', repo: 'blogcomment', owner: 'beyondhxl', admin: \"beyondhxl\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"C++游戏服务器知识点散记","text":"C++ 游戏服务器知识点零散记录 Static1、声明为 static 的对象2、global scope3、namespace scope 多态非自然多态 unnatural polymorphism 对象涉及多重继承或虚拟继承的基类，会拥有多个地址 C++ 以下列方法支持多态: 1、隐式的转化把一个 derived class 指针转化为一个指向其 public base type 的指针2、经由 virtual function 机制3、经由 dynamic-cast 和 typeid 运算法 多态的主要用途 经由一个共同的接口来影响类型的封装，这个接口通常被定义在一个抽象的 base class 中。这个接口是以 virtual function 机制引发的，它可以在执行期根据 object 的真正类型解析出到底是哪一个函数实体被调用。 抽象混合式基类 abstract base class 不能被实例化的 base class 至少有一个纯虚函数 转型1、dynamic_cast 只适用于那种”所指对象至少有一个虚函数” C++ 隐式类型转换和关键字 explicit1、explicit 制止单一参数的 constructor 被当做一个 conversion 运算符2、conversion 运算符即类型转换运算符，这是类的一种特殊成员函数，它负责将一个类类型的值转换成其他类型，一般形式为：operator type() const，其中 type 表示被转换成的某种类型。3、《C++ Primer》中讲到了一个规定：如果构造函数只接受一个实参，则它实际上定义了转换为此类类型的隐式转换机制（关键字 explicit 出现的原因就是在 C++ 这个规定的基础上）。 1234567891011121314151617class Test{ public: Test(int num);}Test obj = 10； // 编译器自动将整型“隐式转换”为Test类对象 // 在这种情况下，该语句等同于 Test temp(10); Test obj = temp;隐式类型转换中，编译器只会自动地执行一步类型转换（只允许一步类类型转换）。我们可以通过将构造函数声明为 explicit 从而抑制构造函数定义的隐式转换。class Test{ public: explicit Test(int num);}Test obj = 10; // error! explicit 构造函数只能用于直接初始化，不能用于拷贝形式的初始化过程。 编译Java 生成的是字节码，没有链接的过程。比如修改一个函数，Java 添加完成，可以直接启动测试，但是 C++ 可能会因为一行代码的修改，导致无数 cpp 文件的编译。 为什么 C/C++ 要分为头文件和源文件？ 因为编译出来的二进制码（比如 .o、.obj、.lib、.dll）不包含自我描述的信息，要复用这种可行码的话得另外的文件。C# 和 Java 的可执行码自带元数据信息，但是这也意味着运行时的内存需求增加，毕竟自我描述的数据对最终用户来说是无用的。 cdecl、stdcall、fastcall、pascal __cdecl 是 C Declaration 的缩写（declaration 声明），表示 C 语言默认的函数调用方法：所有参数从右到左依次入栈，这些参数由调用者清除，称为手动清栈。被调用函数不会要求调用者传递多少参数，调用者传递过多或者过少的参数，甚至完全不同的参数都不会产生编译阶段的错误。 __stdcall 调用规则使得被调用者来执行清栈操作（由被调用者函数自身将 ESP 拉高以维持堆栈平衡） __fastcall 调用规则使得被调用者负责清理栈的操作（由被调用者函数自身将 ESP 拉高以维持堆栈平衡） __pascal 则是从左到右依次入栈。并且，被调用者（函数自身）将自行完成清栈操作 调用规则 入栈顺序 清栈责任 __cdecl 从右到左 调用者 __stdcall 从右到左 被调用者 __fastcall 从右到左（先 EDX、ECX，再到堆栈） 被调用者 __pascal 从左到右 被调用者 GatewayServer也称之为连接服务器，网络游戏的客户端一般是连接到这里，然后再由该连接服务器根据不同的需要，把游戏消息转发给其它相应的服务器（逻辑和地图服务器）。也因为它是客户端直接连接的对象，它同时也承担了验证客户身份的工作。 Q&amp;&amp;A1、Gateway 上的客户端连接类有多个连接的原因？2、Scene 只有一个 SessionClient？ 游戏网关服务器GatewayServer的作用： 游戏网关服务器可以作为客户端与 game server 的隔离作用 消息解析 与客户端保持连接，作为广播作用 消息合法性验证 转发消息到业务服务，针对不同的客户端消息分发到相应的服务处理 流量限制，消息分流作用 版本验证等 可扩展性、动态拓展 英语1、技术 : Techniques2、Idioms : 习语3、Patterns : 模式4、stumble[st^mbl] : 蹒跚、结巴、失足、绊脚、过失5、aggregation[ˌæɡrɪˈɡeɪʃn] 聚集、集合、聚集体；集合体；聚合作用；凝聚；聚集作用；总量；6、reconcile[ˈrekənsaɪl] 使和谐一致; 调和; 使配合; 使和解; 使和好如初; 将就; 妥协;7、reduction[rɪˈdʌkʃn] 减少; 缩小; 降低; 减价; 折扣; (照片、地图、图片等的) 缩图，缩版;8、preemptive[priˈɛmptɪv] 先发制人的; 先买的，有先买权的;9、restore[rɪˈstɔː(r)] 恢复(某种情况或感受); 使复原; 使复位; 使复职; 修复; 整修;10、immutable[ɪˈmjuːtəbl] 不可改变的; 永恒不变的;11、stale[steɪl] adj. 不新鲜的; (空气) 污浊的; (烟味) 难闻的; 陈腐的; 没有新意的; 老掉牙的; n.(牛马、骆驼的)尿;12、cancellation[ˌkænsəˈleɪʃn] 取消; 撤销; 被取消了的事物; 作废; 废除; 中止;13、ephemeral[ɪˈfemərəl] 短暂的; 瞬息的; Effective C++条款25 C++ swap 函数 1、标准库 swap 函数定义在 std 命名空间的函数模板： 12345678namespace std { template&lt;typename T&gt; void swap(T&amp; a, T&amp; b) { T temp(a); a = b; b = temp; }} 标准库的 swap 实现调用了拷贝构造函数（对于非内置类型），并且有两次赋值运算，这在很多情况下是不满足我们的效率需求的（大型对象的拷贝是毫无必要的操作，我们仅需要交换指针，若存在容器类型，调用容器类的 swap 明显是更加正确的操作）。在 C++11 中，我们有如下的优化： 123456template&lt;typename T&gt;void swap(T&amp; a, T&amp; b) { T temp(std::move(a)); a = std::move(b); b = std::move(temp);} 移动方式的本质就是移交临时对象对资源的控制权，通常就是指针的替换，因此上述操作对存在移动构造和移动赋值运算的类来讲，已经可以基本满足要求，但是，对于未定义上述操作的类来讲，改进版本的 swap 操作并未有任何效率上的提升，因此，有必要定义类类型的 swap。 2、copy and swap 中的 swap 操作 1234567891011class A { private: int *a; public: void swap(A&amp; rhs) { using std::swap; swap(this-&gt;a, rhs.a); // 我们简单地交换了指针 }}; 上述操作并没有解决问题，我们希望能够像调用普通 swap 函数操作一样调用 swap(A&amp; a, A&amp; b)，因此，我们下一步的操作就是在 std 命名空间内特化 swap 版本： 123456namespace std { template&lt;&gt; void swap&lt;A&gt;(A&amp; a, A&amp; b) { a.swap(b); }} 在 std 空间内的特化版本满足 C++ 标准的规定，这种扩充操作使得我们的特化版本对包含了 std 空间的文件都处于可见状态，因此，我们可以像以前一样使用 swap 进行交换： 123using std::swap;A a, b;swap(a, b); 我们知道，C++ 允许对类模板全特化，但是对函数模板不允许全特化： 12345template&lt;typename T&gt;// 以下定义不允许！void swap&lt;A&lt;T&gt;&gt; (A&lt;T&gt;&amp; a, A&lt;T&gt;&amp; b) { a.swap(b); } 同样的，std 内对 swap 的重载也不符合规定，我们的解决方案就是，在自定义的命名空间内定义 swap 函数： 1234567891011namespace Astuff { template&lt;typename T&gt; class A { ... ... }; template&lt;typename T&gt; void swap(A&lt;T&gt;&amp; a, A&lt;T&gt;&amp; b) { a.swap(b); }}; 这样，我们在当前的命名空间内就拥有了 swap 的完整定义，那么为什么在使用时要加 using std::swap 呢？这句声明会使 std 命名空间的 swap 暴露出来，编译器会自动在当前命名空间和 std 空间内寻找最符合当前函数调用的 swap 版本，因此，以下的写法完全错误： 12A a, b;std::swap(a, b); 这种写法直接调用了 std 空间内的 swap 函数，因此并不符合大多数情况下的需求，using 版本才是最准确的版本： 12using std::swap;swap(a, b); More Effective C++条款25：将 constructor 和 non-member function 虚化1、virtual constructor 是某种函数，视其获得的输入，可产生不同类型的对象。2、copy-on-write 写入时才复制3、子类写父类的函数时，虚函数的返回值可以与父类的不一样，子类返回一个引用或者指针。 结构体 Struct1、C 中的 Struct 一个用途一个复杂的 class object 的全部或部分到某个 C 函数去时，可以将数据封装起来。并保证拥有与 C 兼容的空间布局。 2、把单一元素的数组放在一个 struct 的尾端。每个 struct object 可以拥有可变大小的数组。(柔性数组) 字节对齐要判断一个结构体所占的空间大小，大体来说分三步走： 先确定实际对齐单位，其由以下三个因素决定(1) cpu 周期win、vs、qt 默认8字节对齐，linux 32位，默认4字节对齐，linux 64位默认8字节对齐。(2) 结构体最大成员(基本数据类型变量)(3) 预编译指令 #pragma pack(n) 手动设置（n 只能填1 2 4 8 16）上面三者取最小的。 除结构体的第一个成员外，其他所有的成员的地址相对于结构体地址（即它首个成员的地址）的偏移量必须为实际对齐单位或自身大小的整数倍（取两者中小的那个） 结构体的整体大小必须为实际对齐单位的整数倍 123456789101112131415#include&lt;stdio.h&gt;typedef struct _nums{ char a; short b; int c; double d;}nums;int main(void){ printf(\"%lu\\n\", sizeof(nums)); return 0;} 上面 nums 中，没有手动设置对齐单位，linux 64位系统的默认对齐单位是8字节，结构体 nums 的最大成员 double d 占8个字节，故实际对齐字节是二者最小，即8字节。 char a 放在结构体的起始地址; short b 占2个字节，2小于实际对齐字节8，故 b 的起始地址相对于 a 的起始地址的偏移量必须为2的整数倍个字节; int c 占4个字节，4小于实际对齐字节8，故 c 起始地址相对于 a 的起始地址的偏移量必须为4的整数倍个字节； double d 占8个字节，8与实际对齐字节8相等，故 d 的起始地址相对于 a 的起始地址的偏移量须为8的整数倍个字节； 所以 nums 所占空间如下：1(a)+1(浪费的空间，由 b 的起始地址决定这1字节必须腾出)+2(b)+4(c)+8(d)=16个字节 12ubuntu@VM-0-9-ubuntu:~$ ./stru 16 在结构体最后添加一个 char 数组 12345678910111213141516#include&lt;stdio.h&gt;typedef struct _nums{ char a; short b; int c; double d; char arr[13];}nums;int main(void){ printf(\"%lu\\n\", sizeof(nums)); return 0;} 数组的类型是 char[13]，并不是基本数据类型，这里仍然当做13个 char 型变量来处理，char 占1个字节，小于实际对齐字节8，所以这13个 char 型变量可以直接挨着 double d 后面放（最后结果看起来也就相当于整个数组挨着 double d 放置）。所以总的空间情况是：1(a)+1(浪费空间)+2(b)+4(c)+8(d)+13(arr)=29，但29并不满足上面三步走的最后一步：“整个结构体的大小必须是实际对齐单位的整数倍”，所以29+3(浪费空间)=32，所以最后nums 的空间情况是：1(a)+1(浪费空间)+2(b)+4(c)+8(d)+13(arr)+3(浪费空间)=32字节。 12ubuntu@VM-0-9-ubuntu:~$ ./stru32 结构体嵌套结构体的字节对齐和上面原理一样，唯一要注意的是子结构体的起始地址与母结构体的起地址之间的距离必须是子结构体最大成员或者实际对齐单位（还是取两者小的那个）的整数倍。 12345678910111213141516171819202122#include&lt;stdio.h&gt;typedef struct _parent{ int a; // 4 char b; // 2 short c; // 2}parent;typedef struct _child{ char a; // 4 int b; // 4 parent p; // 8 long c; // 8}child;int main(void){ printf(\"parent:%ld\\n child:%ld\\n\", sizeof(parent), sizeof(child)); return 0;} 输出如下： 123ubuntu@VM-0-9-ubuntu:~$ ./struparent:8child:24 对齐的作用和原因：各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。比如有些架构的 CPU 在访问一个没有进行对齐的变量的时候会发生错误，那么在这种架构下编程必须保证字节对齐。其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台要求对数据存放进行对齐，会在存取效率上带来损失。比如有些平台每次读都是从偶地址开始，如果一个 int 型（假设为 32 位系统）如果存放在偶地址开始的地方，那么一个读周期就可以读出这 32bit，而如果存放在奇地址开始的地方，就需要2个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该32bit数据。显然在读取效率上下降很多。 结构体内部存在 static 类型的变量 123456struct S4{ char a; long b; static long c; //静态 }; 静态变量存放在全局数据区内，而 sizeof 计算栈中分配的空间的大小，故不计算在内，S4 的大小为 4+4=8。（在自然对齐的结构体中，在 32 位系统内，对于某一个成员变量，如果前面的变量所占空间比自身小，那么前面的空间填充为满 4 字节，使得这个成员的地址从 4 字节整数倍开始，最后结构体的总体字节调整为 4 字节的整数倍即可） 12345678910struct test{ char a; short b; int c; double d; char e; // char f; // char g;} sizeof(struct test) = 20。如果将最后两行注释去掉，仍然是 20 字节。规则是这样的，假设从 0x00000000 地址开始存储成员，那么 a 偏移为 1，但是 b 必须从 2 的地址开始，那么 a 就必须填充一个字节，那么 a、b 共占用 4 个字节，c 需要从 4 字节的整数倍开始，现在正好，上述不用填充，d 也从可以被 4 整除的字节数开始存储（现在正好，其实也是 8 字节的整数倍，这是凑巧了），连续填充 8 个字节，现在变成 0x0000010（16 进制），那么 e 的地址为 0x00000011，但是整个结构体的大小不是 4 字节的整数倍，最后需要填充 3 个字节，整体是 0x00000014，如果将最后两行注释去掉，那么仍然是 20 字节，需要填充的就是 g，填充 1 个字节。 范式C++ 支持三种范式：1、程序模型(procedural model)2、抽象数据类型模型(abstract data type model ADT)3、面向对象模型(object-oriented model) inline1、一个 inline 函数有静态链接、不会被文件以外者看到。2、每一个 non-inline member function 只会诞生一个函数实例。 STLSTL find 函数用类指针的一个原因是可以应用到链表的 next 1、lower_bound 和 upper_bound 实现lower_bound 算法返回第一个大于等于给定值所在的位置。设置两个指针 start 和 last，其中 start 指向数组的起始位置，last 指向数组末尾位置之后的位置。当 start 和 last 指向相同位置时循环结束。mid 指向 [start, last) 区间的中间位置，当中间位置元素值大于等于给定 val 时，说明第一个大于等于 val 值在 mid 位置的左边，更新 last 为 mid。当中间位置元素值小于给定的 val 时，说明第一个大于等于 val 值在 mid 右边，不包括 mid 所在的位置，更新 start 为 mid+1。 1、在从小到大的排序数组中 lower_bound(begin, end, num) 从数组的 begin 位置到 end-1 位置二分查找第一个大于或等于 num 的数字，找到返回该数字的地址，不存在则返回 end。通过返回的地址减去起始地址 begin，得到找到数字在数组中的下标。 upper_bound(begin, end, num) 从数组的 begin 位置到 end-1 位置二分查找第一个大于 num 的数字，找到返回该数字的地址，不存在则返回 end。通过返回的地址减去起始地址 begin，得到找到数字在数组中的下标。 2、在从大到小的排序数组中 重载 lower_bound() 和 upper_bound() lower_bound(begin, end, num, greater()) 从数组的 begin 位置到 end-1 位置二分查找第一个小于或等于 num 的数字，找到返回该数字的地址，不存在则返回 end。通过返回的地址减去起始地址 begin，得到找到数字在数组中的下标。 upper_bound( begin,end,num,greater() ) 从数组的 begin 位置到 end-1 位置二分查找第一个小于 num 的数字，找到返回该数字的地址，不存在则返回 end。通过返回的地址减去起始地址 begin，得到找到数字在数组中的下标。 1234567891011121314151617int lower_bound(vector&lt;int&gt;&amp; nums, int target){ int lo = 0, hi = nums.size() - 1; while (lo &lt;= hi) // equal { int mid = lo + (hi - lo) / 2; if (target &gt; nums[mid]) { lo = mid + 1; } else { hi = mid - 1; // mid - 1 } } return lo;} upper_bound 算法返回第一个大于给定元素值所在的位置，设置两个指针 start 和 last，其中 start 指向数组的起始位置，last 指向数组末尾位置之后的位置，当 start 和 last 指向相同位置时循环结束，mid 指向 [start, last) 区间的中间位置，当中间位置元素值小于等于给定 val 时，说明第一个大于 val 值在 mid 位置的右边，更新 start 为 mid+1。当中间位置元素值大于给定元素时，说明第一大于在 mid 左边，包括 mid 所在位置，所以更新 last 为 mid。 1234567891011121314151617int upper_bound(vector&lt;int&gt;&amp; nums, int target) { int lo = 0, hi = nums.size() - 1; while (lo &lt;= hi) // equal !! { int mid = lo + (hi - lo) / 2; if (target &gt;= nums[mid]) { lo = mid + 1; } else { hi = mid - 1; // mid - 1 } } return lo;} lower_bound、upper_bound 例子 11 2 2 3 4 5 target = 2，则 lower_bound 返回的位置是 第 1 个位置，upper_bound 返回的位置是第 3 个位置。(从第 0 个位置开始) upper_bound - lower_bound = 数组中 target 的个数。 12345678910111213141516171819202122#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn=100000+10;const int INF=2*int(1e9)+10;#define LL long longint cmd(int a,int b){ return a&gt;b;}int main(){ int num[6]={1,2,4,7,15,34}; sort(num,num+6); //按从小到大排序 int pos1=lower_bound(num,num+6,7)-num; //返回数组中第一个大于或等于被查数的值 int pos2=upper_bound(num,num+6,7)-num; //返回数组中第一个大于被查数的值 cout&lt;&lt;pos1&lt;&lt;\" \"&lt;&lt;num[pos1]&lt;&lt;endl; cout&lt;&lt;pos2&lt;&lt;\" \"&lt;&lt;num[pos2]&lt;&lt;endl; sort(num,num+6,cmd); //按从大到小排序 int pos3=lower_bound(num,num+6,7,greater&lt;int&gt;())-num; //返回数组中第一个小于或等于被查数的值 int pos4=upper_bound(num,num+6,7,greater&lt;int&gt;())-num; //返回数组中第一个小于被查数的值 cout&lt;&lt;pos3&lt;&lt;\" \"&lt;&lt;num[pos3]&lt;&lt;endl; cout&lt;&lt;pos4&lt;&lt;\" \"&lt;&lt;num[pos4]&lt;&lt;endl; return 0; } SessionServerSession 服务器上有所有的玩家(RelationUser) 游戏服务器中的数据库异步操作技术和游戏数据的保存机制1、在游戏服务器中，处理玩家登陆需要向数据库查询玩家的账号和密码，玩家上线和下线需要对玩家的角色数据从数据库中读取和保存。2、为了不阻塞逻辑线程，可以采用异步数据库访问的方式，即数据库操作请求提交给专门的数据库处理线程池，然后逻辑线程不再等待数据库处理结果，继续处理其他，不再阻塞在这里。3、改成数据库异步处理后，为了保障数据安全，我们希望不只是玩家下线的时候才会保存玩家数据，同时也希望每隔一段时间统一保存所有在线玩家的数据，可以考虑这样的思路：假设我们有一个 GAMEDB 服务器，GAMEDB 缓存了所有在线玩家的角色数据，每次到保存时间，GAMEDB 就将所有在线玩家的数据（DBO）的副本都统一提交给 DB 线程池，让它保存数据，提交的过程很快，提交完后，GAMEDB 的逻辑线程仍能继续处理游戏服务器的更新和读取 CACHE 的请求。为什么要保存副本呢，DB 线程的执行保存队列的过程也许很耗时，但是队列中的数据都是 GAMEDB 提交 DBO 那个时刻的数据，这样就能保证玩家的游戏数据的完整性。4、为提高性能，网络游戏服务器程序启动后一般都会把事先需要的数据从数据库提取到内存供使用，以减少读数据库的频率。5、当然，网游开发中，遇到需要立即写库或者更新库的内容时，我们会立即向数据库服务器发送 insert、delete、update 等以期望数据库能立即更新我们的数据，比如玩家切换到新地图，这种数据就有必要立即提交到数据库： 写到数据服务(这个数据服务器就是程序中缓存，用来缓存一些所要提交的数据)中，并不直接写库，因为数据库不是你想象的那么高效； 业务服务实时写数据库，数据服务定时存盘，比如5分钟保存一次； 6、数据服务中心负责所有数据统一管理，提供实时的数据读写，多服务器环境下数据服务中心的处理能力直接关系到整个集群系统的性能，所有的关键数据库访问都它包装。一般对内存需求会很大，因为有大量数据要在内存缓存。7、一般场景服务器 SceneServer 是没有数据库连接池的，存档的数据，都是通过档案服务器客户端 RecordClient 发送到 RecordServer(DBServer) 上的。 服务器传输层在异步模型下的基本使用序列1、在主循环（TimeTick）中，不断尝试读取，看是否有什么数据可读2、如果上一步返回有数据到达了，则读取数据3、读取数据处理后，需要发送数据，则向网络写入数据（写的话，可以先发送到写的缓冲buffer、多缓存一些，然后::send() 出去）网游比较特殊，最大的特点在于客户端和服务器端是要进行长连接的，客户端和服务器端基本上一直要保持连接，不是典型的 Request-Response 模式，Client 会主动给 Server 发送数据，Server 也可能主动往 Client 发送数据，生命周期比较长，一次发送的数据量比较小，但是数据交互发送比较频繁。由于要进行长连接，服务器端的 socket 就不能进行复用，单台服务器处理请求是有限的。 RAII在编写 C++ 程序的时候，总是设法保证对象的构造和析构是成对出现的。 生命期和程序一样长的对象，直接使用全局对象(或 scope_ptr)或者做成 main() 的栈上对象。有如下发生串话场景：从某个 TCP 连接 A 收到了一个 request，程序开始处理这个 request；处理可能要花一定的时间，为了避免耽误(阻塞)处理其他 request，程序记住了发来 request 的 TCP 连接，在某个线程池中处理这个请求；在处理完之后，会把 response 发回 TCP 连接 A。但是，在处理 request 的过程中，客户端断开了 TCP 连接 A，而另一个客户端刚好创建了新连接 B。程序不能只记住 TCP 连接 A 的文件描述符，而应该持有封装 socket 连接的 TcpConnection 对象，保证在处理 request 期间 TCP 连接 A 的文件描述符不会被关闭。或者持有 TcpConnection 对象的弱引用(week_ptr)，这样能知道 socket 连接在处理 request 期间是否已经关闭了，fd=8 的文件描述符到底是“前世”还是“今生”。 在 C++ 项目中，自己写个 File Class，把项目用到的文件 IO 功能简单封装一下(以 RAII 手法封装 File* 或者 file descriptor 都可以)，通常就能满足需要。记得把拷贝构造和赋值操作符禁用，在析构函数里释放资源，避免泄露内部的 handle。 如果要用 stream 方式做 logging，可以抛开繁重的 iostream，自己写一个简单的 LogStream，重载几个 operate&lt;&lt; 操作符，而且可以用 stack buffer，轻松做到线程安全与高效。 fork()1234567int main(){ Foo foo; // 调用构造函数 fork(); // fork 为两个进程 foo.doit(); // 在父子进程中都使用 foo // 析构函数会被调用两次，父进程和子进程各一次} fork() 之后，子进程继承了父进程的几乎全部状态。子进程会继承地址空间和文件描述符，因此用于管理动态内存和文件描述符的 RAII class 都能正常工作。但子进程不会继承：1、父进程的内存锁，mlock()、mlockall()2、父进程的文件锁，fcntl()3、父进程的某些定时器，settimer()、alarm()、timer_create()等等 fork() 一般不能在多线程程序中调用，因为 Linux 的 fork() 只克隆当前线程的 thread of control，不克隆其他线程。不能一下子 fork() 出一个和父进程一样的多线程子进程。Linux 没有 forkall() 这样的系统调用。因为其他线程可能等在 condition variable 上，可能阻塞在系统调用上，可能等着 mutex 以跨入临界区，还可能在密集的计算中，这些都不好全盘搬到子进程里。 其他线程可能正好位于临界区之内，持有了某个锁，而它突然死亡，再也没有机会去解锁了。如果子进程试图再对同一个 mutex 加锁，就会立刻死锁。在 fork() 之后，子进程就相当于处于 signal handler 之中，不能调用线程安全的函数(除非它是可重入的)，而只能调用异步信号安全(async-signal-safe)函数。子进程不能调用：1、malloc()。因为 malloc() 在访问全局状态时几乎肯定会加锁。2、任何可能分配或释放内存的函数，包括 new、map::insert()、snprintf…..3、任何 Pthreads 函数。不能用 pthread_cond_signal() 去通知父进程，只能通过读写 pipe() 来同步。4、printf() 系列函数，因为其他线程可能恰好持有 stdout/stderr 的锁。5、除了 man 7 signal 中明确列出的 “signal 安全” 函数之外的任何函数。 唯一安全的做法是在 fork() 之后立即调用 exec() 执行另一个程序，彻底隔断子进程与父进程的联系。 Signal信号在多线程程序中，使用 signal 的第一原则是不要使用 signal1、不要使用 signal 作为 IPC 的手段，包括不要使用 SIGUSR1 等信号来触发服务端的行为。可以采取增加监听端口的方式来实现双向的、可远程访问的进程控制。2、不要使用基于 signal 实现的定时函数，包括 alarm/ualarm/settitimer/timer_create、sleep/usleep 等等。3、不主动处理各种异常信号(SIGTERM、SIGINT 等等)，只用默认语义：结束进程。有一个例外 SIGPIPE，服务器程序通常的做法是忽略此信号，否则如果对方断开连接，而本机继续 write 的话，会导致程序意外终止。4、在没有别的替代方法的情况下(比如需要处理 SIGCHILD 信号)，把异步信号转换为同步的文件描述符事件。传统的做法是在 signal handler 里往一个特定的 pipe() 写一个字节，在主程序中从这个 pipe 读取，从而纳入统一的 IO 事件处理框架中去。现代 Linux 的做法是采用 signalfd() 把信号直接转换为文件描述符事件，从根本上避免使用 signal handler。 文件描述符fdO_NONBLOCK 的功能是开启非阻塞 IO，而文件描述符默认是阻塞的。FD_CLOEXEC 的功能是让程序 exec() 时，进程会自动关闭这个文件描述符。而文件描述默认是被子进程继承的(这是传统 Unix 的一种典型 IPC，比如用 pipe() 在父子进程间单向通信)。 MySQLMySQL 的客户端只支持同步操作，对于 UPDATE/INSERT/DELETE 之类只要行为不管结果的操作，可以用一个单独的线程来做，以降低服务线程的延迟。 Mysql 联合索引最左匹配原则最左前缀匹配原则 在 mysql 建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例： 对列 col1、列 col2 和列 col3 建一个联合索引 1KEY test_col1_col2_col3 on test(col1, col2, col3); 联合索引 test_col1_col2_col3 实际建立了 (col1)、(col1, col2)、(col1, col2, col3) 三个索引。 1SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4” 上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引 (col1, col2) 进行数据匹配。 索引的字段可以是任意顺序的，如： 12SELECT * FROM test WHERE col1=“1” AND clo2=“2”SELECT * FROM test WHERE col2=“2” AND clo1=“1” 这两个查询语句都会用到索引 (col1, col2)，mysql 创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段 col1 的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段 col2 进行排序。其实就相当于实现了类似 order by col1 col2 这样一种排序规则。 有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引 (col1, col2) 中的 col1、col2 两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助 mysql 查询优化器 explain，explain 会纠正 sql 语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。 为什么要使用联合索引 减少开销。建一个联合索引 (col1, col2, col3)，实际相当于建了 (col1)、(col1, col2)、(col1, col2, col3) 三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引。对联合索引 (col1, col2, col3)，如果有如下的 sql: select col1,col2,col3 from test where col1=1 and col2=2。那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。减少 io 操作，特别是随机 io，其实是 dba 主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。 效率高。索引列越多，通过索引筛选出的数据越少。有 1000W 条数据的表，有如下 sql:select from table where col1=1 and col2=2 and col3=3，假设每个条件可以筛选出 10% 的数据，如果只有单值索引，那么通过该索引能筛选出 1000W * 10% = 100w 条数据，然后再回表从 100W 条数据中找到符合 col2=2 and col3=3 的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出 1000W * 10% * 10% * 10% = 1W，效率提升可想而知！ 引申 对于联合索引 (col1, col2, col3)，查询语句 SELECT * FROM test WHERE col2=2；是否能够触发索引？大多数人都会说 NO，实际上却是 YES。 12EXPLAIN SELECT * FROM test WHERE col2=2;EXPLAIN SELECT * FROM test WHERE col1=1; 观察上述两个 explain 结果中的 type 字段。查询中分别是： type: index type: ref index：这种类型表示 mysql 会对整个该索引进行扫描。要想用到这种类型的索引，对这个索引并无特别要求，只要是索引，或者某个联合索引的一部分，mysql 都可能会采用 index 类型的方式扫描。但是呢，缺点是效率不高，mysql 会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。所以，上述语句会触发索引。 ref：这种类型表示 mysql 会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。简单说，也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。 HTTP一次 HTTP proxy 的请求如果没有命中本地 cache：1、解析域名2、建立连接3、发送 HTTP 请求4、等待对方回应5、把结果返回给客户这5步中和2个 sever 发生了3次 round-trip：1、向 DNS 问域名，等待回复2、向对方的 HTTP 服务器发起连接，等待 TCP 三路握手完成3、向对方发送 HTTP request，等待对方 response 网络同步网络同步 = 数据同步 + 表现同步，数据同步是后端操作，表现同步就是让前端对后端同步过来的数据进行进一步的处理从而达到表现上的一致。一般的 Web 服务器只是单纯的从服务器向客户端进行数据同步，不会把其他客户端的数据都发给你。游戏服务器对实时性要求比较高(尤其是 MMORPG、FPS 类型的网游)。综上 网络同步 = 实时的多端数据同步 + 实时的多端表现同步。网络同步是一个网络 IO 与 CPU 计算同样密集的游戏功能。 游戏服务器基础组件(Java)1、网络组件包括内网通信模块和外网通信模块、协议2、数据库组件玩家数据和全局数据的持久化3、日志组件异常日志(代码异常打印日志)、行为日志(为运营平台提供的行为日志)4、配置组件程序启动配置(如 ip、port、连接关系)和游戏相关配置(各种数据表格) 游戏逻辑模块(Java)1、系统服务线程组登录系统服务、好友系统服务、帮派系统服务…，可以将一个或者多服务挂载一个线程，也可以分别挂载不同线程 2、场景逻辑线程组玩家的行走、战斗、道具获得、使用，系统服务线程组提供的系统服务基本都是通过 RPC 调用的方式为场景逻辑组线程提供服务。比如添加好友、场景逻辑线程上的玩家收到添加好友消息，然后通过 RPC 调用系统服务线程组的好友服务实现添加好友功能。登录服务做了特殊处理，登录消息会直接分发到登录服务，登录服务进行验证，验证通过后会在场景服务线程组创建对应的角色通信对象与客户端进行通信。 进程和线程资源 堆是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。 栈是线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立。因此，栈是 thread safe 的。操作系统在切换线程的时候会自动的切换栈，就是切换 ss/esp 寄存器。栈空间不需要在高级语言里面显式的分配和释放。 进程占有的资源 线程占有的资源 地址空间 栈 全局变量 寄存器 打开的文件 状态 子进程 程序计数器 信号量 账户信息 程序计数器是用来存放下一条指令的地址的。当执行一条指令时，首先需要根据 PC 中存放的指令地址，将指令由内存取到指令寄存器中，此过程称为“取指令”。与此同时，PC 中的地址或自动加1或由转移指针给出下一条指今的地址。此后经过分析指令、执行指令、完成第一条指令的执行，而后根据 PC 取出第二条指令的地址，如此循环，执行每一条指令。 进程和线程区别程序并不能单独运行，只有将程序装载到内存中，系统为它分配资源才能运行，而这种执行的程序就称之为进程。程序和进程的区别就在于：程序是指令的集合，它是进程运行的静态描述文本；进程是程序的一次执行活动，属于动态概念。 在多道编程中，我们允许多个程序同时加载到内存中，在操作系统的调度下，可以实现并发地执行。正是这样的设计，大大提高了 CPU 的利用率。进程的出现让每个用户感觉到自己独享 CPU，因此，进程就是为了在 CPU 上实现多道编程而提出的。 进程的不足： 进程只能在一个时间干一件事，如果想同时干两件事或多件事，进程就无能为力了。 进程在执行的过程中如果阻塞，例如等待输入，整个进程就会挂起，即使进程中有些工作不依赖于输入的数据，也将无法执行。 举个现实的例子：如果把我们上课的过程看成一个进程的话，那么我们要做的是耳朵听老师讲课，手上还要记笔记，脑子还要思考问题，这样才能高效的完成听课的任务。而如果只提供进程这个机制的话，上面这三件事将不能同时执行，同一时间只能做一件事，听的时候就不能记笔记，也不能用脑子思考，这是其一；如果老师在黑板上写演算过程，我们开始记笔记，而老师突然有一步推不下去了，阻塞住了，他在那边思考着，而我们呢，也不能干其他事，即使你想趁此时思考一下刚才没听懂的一个问题都不行，这是其二。 现在你应该明白了进程的缺陷了，而解决的办法很简单，我们完全可以让听、写、思三个独立的过程，并行起来，这样很明显可以提高听课的效率。而实际的操作系统中，也同样引入了这种类似的机制——线程。 进程属于在处理器这一层上提供的抽象；线程则属于在进程这个层次上再提供了一层并发的抽象。如果我们进入计算机体系结构里，就会发现，流水线提供的也是一种并发，不过是指令级的并发。这样，流水线、线程、进程就从低到高在三个层次上提供我们所迫切需要的并发。 区别： 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。 线程是进程的一个实体，是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器、一组寄存器和栈），但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行。 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 用户级线程与核心级线程（线程的切换）1、为什么要说线程的切换 操作系统是多进程的，我们关注的应该是进程之间的切换，那为什么关注线程的切换呢？因为理解了线程的切换之后可以更好的理解进程的切换，换句话说线程的切换是进程切换的基础。 每一个进程都包含一个映射表，如果进程切换了，那么程序选择的映射表肯定也不一样；进程的切换其实是包含两个部分的，第一个指令的切换，第二个映射表的切换。指令的切换就是从这段程序跳到另外一段程序执行，映射表切换就是执行不同的进程，所选择的映射表不一样。线程的切换只有指令的切换，同处于一个进程里面，不存在映射表的切换。进程的切换就是在线程切换的基础上加上映射表的切换。 2、线程的引入 多个进程可以“同时”执行，其实也就是换着执行，那么在同一个进程里面，不同的代码段能不能换着执行呢？比如在进程 A 里面有代码段 1、代码段 2、代码段 3；能不能先执行一下代码段 1，然后执行一下代码段 3，再执行一下代码段 2 呢？答案是可以的。进程的切换包括指令的切换和映射表的切换，那么同一个进程里面就没必要进行映射表的切换了，即只需要切换指令就可以了。上面所说的代码段其实就称为“线程”。 前面说了多线程只需要进行指令的切换就可以了；这样相对于进程来说，多线程保留了多进程的优点：并发。避免了进程切换的代价（切换映射表需要耗费比较多的时间）。如果能够将多线程的切换弄明白，那么多进程的切换其实也就直剩下了映射表的切换，这是典型的“分而治之”。 3、用户级线程 以前网速比较慢的时候，打开浏览器访问一个网页，首先弹出来的是网页的文字部分，然后是一些图片，最后才是一些小视频之类的。为什么呢？浏览器向服务器发起访问的程序是一个进程，它包含若干线程，比如：一个线程用来从服务器接收数据，一个线程用来显示文本，一个线程用来显示视频，一个线程用来显示图片等等。在网速比较慢的时候用来从服务器接收数据的线程要执行的时间比较长，因为一些图片和视频都比较大。如果要等这个线程运行完了之后再显示，那么电脑屏幕就会有一段时间什么东西都没有，这样用户体验就会比较差；一个比较合理的办法是：接受数据的线程接受完文本东西之后，就调用显示文本的线程将数据显示出来，然后再接受图片再显示，再接受视频再显示；这样至少可以保证电脑屏幕上始终有东西；相比前面的方法好很多，当然最根本的办法还是提高网速。 为什么浏览器向服务器请求数据的程序是一个进程，而不是多个？浏览器接受服务器的数据肯定都是存储在一个缓冲区里面的，并且这个缓冲区是共享的，如果是多个进程，那么肯定有多个映射表，也就是说如果程序里面存储数据的地址是连续的，经过不同的映射表之后，就会分布在内存的不同区域，这样肯定没有在一块地方好处理。 1、两个线程与一个栈 线程一 12345678910100 : A(){ B(); 104:}200 : B(){ Yield1(); // 切换线程 204:} 线程二 12345678910300 : C(){ D(); 304:}400 : D(){ Yield2(); 404:} 按照这个执行一下，首先从线程一的 A 函数开始，调用 B 函数，将 B 函数的返回地址 104 压栈，然后进入 B 函数；在 B 函数内部使用Yield1 切换到线程二的 C() 函数里面去，同时将 Yield1 的返回地址压栈，此时栈中的数据如下： 1104 204 Yield1 的伪代码应该是： 12345void Yield1(){ find 300; jmp 300;} 现在执行到了线程二，计划是在 D 函数里面通过 Yield2 跳到线程一的 204 这个地址，完成线程的切换。调用 C 函数，同时将 304 这个地址压栈，跳到 D 函数里面执行，在 D 函数里面调用 Yield2，同时将 404 压栈。Yield2 的伪代码应该是： 12345void Yield2(){ find 204; jmp 204;} 目前栈里面的数据应该是： 1104 204 304 404 跳到 204 之后，接着执行 B 函数剩下的内容，执行完内容之后，执行函数 B 的 “}” 相当于 ret，弹栈，此时栈顶的地址是 404，B 函数应该是返回到 104 处，而不是 404 处；这里就出现了问题。怎么处理？ 2、从一个栈到两个栈 处理方法是使用两个栈，在不同的线程里面使用不同的栈。在线程一中使用栈一，线程二中使用栈二。 重新执行一下上面那个程序，从 A 函数开始执行，在 B 函数里面调用 Yield1 进入线程二的 C 函数之后，线程一对应的栈一中的内容应该是： 1104 204 执行到 D 函数的 Yield2 之后，线程二对应的栈二的内容应该是： 1304 404 在 Yield2 里面做的第一件事就应该是切换栈，如何切换？肯定需要一个数据结构将原来栈一的地址保存起来，这个数据结构就是 TCB（Thread control block）；当前栈的栈顶地址是存放在 cpu 里面的 esp 寄存器里面的，因此只需要改变 esp 的值就可以切换栈了。 123456void Yield2(){ TCB2.esp = esp; // 保存当前栈顶地址 esp = TCB1.esp; // 切换栈 jmp 204; } jmp 到 204 之后，执行完 B 函数剩下的代码之后执行 B 函数的 “}”，即弹栈，这时栈顶是 204，也就是又跳到 204 去了，显然有问题，但是比前面已经好很多了，因为不会跳到另外一个线程里去。那现在为什么会这样呢？原因是 Yield2() 直接跳到 204 之后，而没有将栈中的 204 弹出去，如果 Yield2 跳到 204 这个位置，同时将栈中的 204 弹出去就好了。其实这个可以实现，修改 Yield2 如下： 12345void Yield2(){ TCB2.esp = esp; // 保存当前栈顶地址 esp = TCB1.esp; // 切换栈} 没错，就是将 jmp 204 去掉就可以了，利用 Yield2 的 “}” 弹栈同时跳到 204 地址处，执行完 B 函数之后，通过 B 函数的 “}” 再次弹栈到 104 处。 4、核心级线程 1、多处理器和多核的区别 多处理器每一个 CPU 都有一套自己的 MMU。多核是所有的 CPU 共用一套 MMU，也就是多个 CPU 的内存映射关系是一致的。 多核就有种单个进程的概念，在这个进程内部所有的线程都是共用一套 MMU 的。多处理器就有种多进程的概念，每个 CPU 的 MMU 都不一样。因此对于同一个进程来说，多核可以同时执行这个进程里面的线程，但是多处理器不行，只有多线程才能将多核利用起来，因为现在电脑都是多核的，所以这是多线程的一大用处。这里的线程指的是核心级线程。核心级线程可以将每一个线程对应到具体的 CPU 上。 2、核心级线程与用户级线程有什么区别呢？ 核心级线程需要在用户态和核心态里面跑，在用户态里跑需要一个用户栈，在核心态里面跑需要一个核心栈。用户栈和核心栈合起来称为一套栈，这就是核心级线程与用户级线程一个很重要的区别，从一个栈变成了一套栈。用户级线程用 TCB 切换栈的时候是在一个栈与另外一个栈之间切换，核心级线程就是在一套栈与另外一套栈之间的切换（核心级线程切换），核心级线程的 TCB 应该是在内核态里面。 3、用户栈与内核栈之间的关联 内核栈什么时候出现？当线程进入内核的时候就应该建立一个属于这个线程的内核栈，那么线程是如何进入系统内核的？通过 INT 中断。当线程下一次进入内核的时候，操作系统可以根据一些硬件寄存器来知道这是哪个线程，它对应的内核栈在哪里。同时会将用户态的栈的位置（SS、SP）和程序执行到哪个地方了（CS、IP）都压入内核栈。等线程在内核里面执行完（也就是 IRET 指令）之后就根据进入时存入的 SS、SP 的值找到用户态中对应栈的位置，根据存入的 CS、IP 的值找到程序执行到哪个地方。 123456789101112131415161718192021222324100:A(){ B(); 104:}200:B(){ read(); 204:}300:read(){ int 0x80; 304:}---------------------------------system_call: call sys_read;1000:2000:sys_read(){} 上面的 “- - - - -” 表示用户态和核心态的分界；首先该线程调用 B 函数，将 104 压栈（用户栈），进入 B 函数之后调用 read() 这个系统调用，同时将 204 压栈（用户栈），进入 read() 系统调用通过 int0x80 这个中断号进入内核态，执行到 1234567sys_read(){ 读磁盘； 将自己变成阻塞状态； 找到 next （下一个执行的线程）； 调用 switch_to(cur, next);} switch_to() 方法就是切换线程，形参 cur 表示当前线程的 TCB，next 表示下一个执行线程的 TCB。这个函数首先将目前 esp 寄存器的值存入 cur.TCB.esp，将 next.TCB.esp 放入 esp 寄存器里面；其实就是从当前线程的内核栈切换到 next 线程的内核栈。这里要明白一件事，内核级线程自己的代码还是在用户态的，只是进入内核态完成系统调用，也就是逛一圈之后还是要回去执行的。因此切换到 next 线程就是要根据 next 线程的内核栈找到这个线程阻塞前执行到的位置，并接着执行。所以切换到 next 线程的内核栈之后应该通过一条包含 IRET 指令的语句进入到用户态执行这个线程的代码。这样就从 cur 线程切换到 next 线程。 Redis如果 CPU 成为 Redis 瓶颈，或者不想让服务器其他 CUP 核闲置，可以考虑多起几个 Redis 进程，Redis 是 key-value 数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些 key 放在哪个 Redis 进程上就可以了。 分布式事务假如数据库在提交事务的时候突然断电，那么它是怎么样恢复的呢？因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的 TCP、存储数据丢失、其他异常等等。 constconst 只修饰离它最近的类型符号 1、const 修饰的一级指针 12345678910111213#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int a = 10; int b = 20; const int* p = &amp;a; //*p = 30; //error:表达式必须是可修改的左值 p = &amp;b; //ok printf(\"%d \", *p); //20 system(\"pause\"); return 0;} 上述代码证明出 const int * p 中 const 修饰的是 int，则 const int * p 指的是：*p 所代表的整形值是常量，不能被直接修改，而指针 p 本身是变量，可以被修改。（不能通过修改 p 指针指向地址 a 的数据来修改 *p 的值，但可以通过修改 p 指针本身所储存的地址来修改 p 的值。）另外 const int * p 和 int const * p 是一样的，因为与int const * p 中与 const 相邻的类型只有 int，const 修饰的还是 int。 12345678910111213#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(){ int a = 10; int b = 20; int *const p = &amp;a; *p = 30; //ok //p = &amp;b; //error:表达式必须是可修改的左值 printf(\"%d \", *p); //20 system(\"pause\"); return 0;} 从上述代码可以看出，int * const p 中 const 修饰的是 int *，int * const p 指的是：指针 p 本身是常量，不能被修改。而 *p 所代表的是整形变量，可以被直接修改。（指针 p 本身存储的地址不能被修改，而指针 p 指向地址 a 的值可以被修改。） 2、const 修饰的二级指针 const int ** pconst int ** p 表示 ** p 代表的整形内存放的是常量，不能够被修改。而指针 p 本身是变量，可以被修改。（const 修饰的是 int） int ** const pint ** const p 表示指针 p 本身是常量，不能被修改。而 ** p 代表的整形内存放的值是变量，可以被修改。（const 修饰 的是int **） int * const * pint * const * p 是一个二级指针，const 修饰的是 int * ，代表指针 * p 的值是常量，不能被修改。而 ** p 所代表的整形内存放的是变量，可以被修改。指针 p 本身是变量，也可以被修改。（通俗来说，就是二级指针 p 所指向的一级指针 * p 不能被修改，而 ** p 所代表的整形，可以被修改。指针 p 本身，也可以被修改。） 重载为什么函数重载不可以根据返回类型区分？12float max(int a, int b);int max(int a, int b); 当调用 max(1, 2) 时，无法确定调用的是哪个，单从这一点上来说，仅返回值类型不同的重载是不应该允许的。 函数的返回值只是作为函数运行之后的一个状态，它是保持方法的调用者与被调用者进行通信的关键。并不能作为某个方法的标识。 sizeofsizeof 实际上是获取了数据在内存中所占用的存储空间，以字节为单位来计数。 C 语言会自动在在双引号 “” 括起来的内容的末尾补上 “\\0” 代表结束，ASCII 中的0号位也占用一个字符。 123456789101112131415161718192021#include&lt;stdio.h&gt; void main(){ int a = 10; char b = 'b'; short c = 2; long d = 9; float e = 6.29f; double f = 95.0629; int arr[] = { 1,2,3 }; char str[] = \"hello\"; double *p = &amp;f; int *i = &amp;a; //分别对各个变量使用sizeof运算 printf(\"a=%d,b=%d,c=%d,d=%d,e=%d,f=%d,arr=%d,str=%d point_p=%d,point_i=%d\\n\", sizeof(a), sizeof(b), sizeof(c), sizeof(d), sizeof(e), sizeof(f), sizeof(arr), sizeof(str), sizeof(p), sizeof(i)); system(\"pause\");}输出的结果是:a=4,b=1,c=2,d=4,e=4,f=8,arr=12,str=6 point_p=4,point_i=4 C/C++ 中，sizeof() 只是运算符号，是编译的时候确定大小的。动态分配是运行过程中得到大小的，也就是说 C++ 中 new 出来的内存，sizeof 都无法统计的，退一步说，即使是 new 出来的空间也有可能失败，所以 sizeof 无法统计动态分配的内存大小。 123456//使用new关键字，在堆区开辟一个int数组int* arr = new int[5]{1,2,3,4,5}; //统计一个指针的大小，32位系统指针占4字节，64位系统指针占8字节cout &lt;&lt; sizeof(arr) &lt;&lt; endl;//解指针，32位系统下，结果和上面一样，因为arr指针指向的时数组的首元素，int类型占4字节cout &lt;&lt; sizeof(*arr) &lt;&lt; endl; sizeof() 为物理存储大小，strlen() 为除去 \\0 后逻辑字符串长度。 Socketsocket 选项1、SO_REUSEADDR 一般来说，一个端口释放后会等待两分钟之后才能再被使用，SO_REUSEADDR 是让端口释放后立即就可以被再次使用。 SO_REUSEADDR 用于对 TCP 套接字处于 TIME_WAIT 状态下的 socket，才可以重复绑定使用。 server 程序总是应该在调用 bind() 之前设置 SO_REUSEADDR 套接字选项 TCP，先调用 close() 的一方会进入 TIME_WAIT 状态。 SO_REUSEADDR 提供如下四个功能： 允许启动一个监听服务器并捆绑其众所周知端口，即使以前建立的将此端口用做他们的本地端口的连接仍存在。这通常是重启监听服务器时出现，若不设置此选项，则 bind 时将出错。 允许在同一端口上启动同一服务器的多个实例，只要每个实例捆绑一个不同的本地 IP 地址即可。对于 TCP，我们根本不可能启动捆绑相同 IP 地址和相同端口号的多个服务器。 允许单个进程捆绑同一端口到多个套接口上，只要每个捆绑指定不同的本地 IP 地址即可，这一般不用于 TCP 服务器。 SO_REUSEADDR 允许完全重复的捆绑： 当一个 IP 地址和端口绑定到某个套接口上时，还允许此 IP 地址和端口捆绑到另一个套接口上。一般来说，这个特性仅在支持多播的系统上才有，而且只对 UDP 套接口而言（TCP 不支持多播）。 SO_REUSEPORT 选项有如下语义： 此选项允许完全重复捆绑，但仅在想捆绑相同 IP 地址和端口的套接口都指定了此套接口选项才行。 如果被捆绑的 IP 地址是一个多播地址，则 SO_REUSEADDR 和 SO_REUSEPORT 等效。 使用这两个套接口选项的建议： 在所有 TCP 服务器中，在调用 bind 之前设置 SO_REUSEADDR 套接口选项； 当编写一个同一时刻在同一主机上可运行多次的多播应用程序时，设置 SO_REUSEADDR 选项，并将本组的多播地址作为本地 IP 地址捆绑。 2、SO_REUSEPORT 目前常见的网络编程模型就是多进程或多线程，根据accpet的位置，分为如下场景2种场景 单进程或线程创建 socket，并进行 listen 和 accept，接收到连接后创建进程和线程处理连接 单进程或线程创建 socket，并进行 listen，预先创建好多个工作进程或线程 accept() 在同一个服务器套接字 这两种模型解充分发挥了多核 CPU 的优势，虽然可以做到线程和 CPU 核绑定，但都会存在： 单一 listener 工作进程或线程在高速的连接接入处理时会成为瓶颈 多个线程之间竞争获取服务套接字 缓存行跳跃 很难做到 CPU 之间的负载均衡 随着核数的扩展，性能并没有随着提升 SO_REUSEPORT 支持多个进程或者线程绑定到同一端口，提高服务器程序的性能，解决的问题： 允许多个套接字 bind()/listen() 同一个 TCP/UDP 端口 每一个线程拥有自己的服务器套接字 在服务器套接字上没有了锁的竞争 内核层面实现负载均衡 安全层面，监听同一个端口的套接字只能位于同一个用户下面 其核心的实现主要有三点： 扩展 socket option，增加 SO_REUSEPORT 选项，用来设置 reuseport 修改 bind 系统调用实现，以便支持可以绑定到相同的 IP 和端口 修改处理新建连接的实现，查找 listener 的时候，能够支持在监听相同 IP 和端口的多个 sock 之间均衡选择 有了 SO_RESUEPORT 后，每个进程可以自己创建 socket、bind、listen、accept 相同的地址和端口，各自是独立平等的 让多进程监听同一个端口，各个进程中 accept socket fd 不一样，有新连接建立时，内核只会唤醒一个进程来 accept，并且保证唤醒的均衡性 Accept 发生在三次握手的哪个阶段？ accept 过程发生在三次握手之后，三次握手完成后，客户端和服务器就建立了 tcp 连接并可以进行数据交互了。这时可以调用 accept 函数获得此连接。 客户端调用 connect 的时候，就是发一个 syn，服务端 accept 的时候，实际上是从内核的 accept 队列里面取一个连接，如果这个队列为空，则进程阻塞（阻塞模式下）。如果 accept 返回则说明成功取到一个连接，返回到应用层。大致的过程是客户端发一个 syn 之后，服务端将这个连接放入到 backlog 队列，在收到客户端的 ack 之后将这个请求移到 accept 队列。所以 accept 一定是发生在三次握手之后，connect只是发一个 syn 而已。 socket 分为两种，一种套接字正如 accept 的参数 sockfd，它是 listen socket，在调用 listen 函数之后，一个 socket 会从主动连接的套接字变为 listen 套接字；而 accept 返回是一个连接套接字，它代表着一个网络已经存在的点对点连接。以后的数据交互就是基于这个连接socket，而之前的那个 listen socket 可以继续工作，从而接收更多的连接。 connect() 在第二次握手返回。 惊群惊群效应就是当一个 fd 的事件被触发时，所有等待这个 fd 的线程或进程都被唤醒。一般都是 socket 的 accept() 会导致惊群（当然也可以弄成一堆线程/进程阻塞 read 一个 fd），很多个进程都 block 在 server socket 的 accept()，一但有客户端进来，所有进程的 accept() 都会返回，但是只有一个进程会读到数据，就是惊群。实际上现在的 Linux 内核实现中不会出现惊群了，只会有一个进程被唤醒（Linux2.6内核）。使用 mutex 锁住多个线程是不会惊群的，在某个线程解锁后，只会有一个线程会获得锁，其它的继续等待。 指针为什么 C++ 调用空指针对象的成员函数可以运行通过？ 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class B {public: void foo() { cout &lt;&lt; \"B foo \" &lt;&lt; endl; } void pp() { cout &lt;&lt; \"B pp\" &lt;&lt; endl; } void FunctionB() { cout &lt;&lt; \"funB\" &lt;&lt; endl; }};int main(){ B *somenull = NULL; somenull-&gt;foo(); somenull-&gt;pp(); somenull-&gt;FunctionB(); return 0;} 这个问题可以阐明“静态绑定”和“动态绑定”的区别。真正的原因是：因为对于非虚成员函数，Ｃ++ 这门语言是静态绑定的。这也是 Ｃ++ 语言和其它语言 Java, Python 的一个显著区别。以此下面的语句为例： 1somenull-&gt;foo(); 这语句的意图是：调用对象 somenull 的 foo 成员函数。如果这句话在 Java 或 Python 等动态绑定的语言之中，编译器生成的代码大概是：找到 somenull 的 foo 成员函数，调用它。（注意，这里的找到是程序运行的时候才找的，这也是所谓动态绑定的含义：运行时才绑定这个函数名与其对应的实际代码。有些地方也称这种机制为迟绑定，晚绑定。） 但是对于 C++。为了保证程序的运行时效率，Ｃ++ 的设计者认为凡是编译时能确定的事情，就不要拖到运行时再查找了。所以 C++ 的编译器看到这句话会这么做：１：查找 somenull 的类型，发现它有一个非虚的成员函数叫 foo。（编译器处理）２：找到了，在这里生成一个函数调用，直接调 B::foo(somenull)。所以到了运行时，由于 foo() 函数里面并没有任何需要解引用 somenull 指针的代码，所以真实情况下也不会引发 segment fault。这里对成员函数的解析，和查找其对应的代码的工作都是在编译阶段完成而非运行时完成的，这就是所谓的静态绑定，也叫早绑定。正确理解 C++ 的静态绑定可以理解一些特殊情况下 C++ 的行为。 mutableC++ 中的 mutable 有两种作用。 1、类中的 mutable 可变的只能用来形容变量，而不可能是函数或者类本身。然而，既然是变量，那么它本来就是可变的，也没必要使用 mutable 来修饰。那么，mutable 就只能用来形容某种不变的东西了。 C++ 中，不可变的变量，称之为常量，使用 const 修饰。 事实上，mutable 是用来修饰一个 const 示例的部分可变的数据成员的。如果说得更清晰一点，就是说 mutable 的出现，将 C++ 中的 const 的概念分成了两种。 二进制层面的 const，也就是绝对的常量，在任何情况下都不可修改（除非用 const_cast）。 引入 mutable 之后，C++ 可以有逻辑层面的 const，也就是对一个常量实例来说，从外部观察，它是常量不可修改，但是内部可以有非常量的状态。 显而易见，mutable 只能用来修饰类的数据成员，而被 mutable 修饰的数据成员，可以在 const 成员函数中修改。 12345678910111213141516171819202122class HashTable{ public: std::string lookup(const std::string&amp; key) const { if(key == last_key_) { return last_value_; } std::string value{this-&gt;lookupInternal(key)}; last_key_ = key; last_value_ = value; return value; } private: mutable std::string last_key_; mutable std::string last_value_;}; 对哈希表的查询操作，在逻辑上不应该修改哈希表本身。因此，HashTable::lookup 是一个 const 成员函数。在 HashTable::lookup 中，我们使用了 last_key_ 和 last_value_ 实现了一个简单的缓存逻辑。当传入的 key 与前次查询的 last_key_ 一致时，直接返回 last_value_; 否则，则返回实际查询得到的 value 并更新 last_key_ 和 last_value_。 在这里，last_key_ 和 last_value_ 是 HashTable 的数据成员。按照一般的理解，const 成员函数是不允许修改数据成员的。但是，另一方面，last_key_ 和 last_value_ 在类的外部是看不到的，从逻辑上说，修改它们的值，外部是没有感知的，因此也就不会破坏逻辑上的 const。为了解决这一矛盾，我们用 mutable 来修饰 last_key_ 和 last_value_，以便在 lookup 函数中更新缓存的键值。 2、Lambda 表达式中的 mutable C++11 引入了 Lambda 表达式，程序员可以凭此创建匿名函数。在 Lambda 表达式的设计中，捕获变量有几种方式；其中按值捕获（Caputre by Value）的方式不允许程序员在 Lambda 函数的函数体中修改捕获的变量。而以 mutable 修饰 Lambda 函数，则可以打破这种限制。 123int x{0};auto f1 = [=]() mutable {x = 42;}; // okay, 创建了一个函数类型的实例auto f2 = [=]() {x = 42;}; // error, 不允许修改按值捕获的外部变量的值 需要注意的是，上述 f1 的函数体中，虽然我们给 x 做了赋值操作，但是这一操作仅只在函数内部生效。即，实际是给拷贝至函数内部的 x 进行赋值，而外部的 x 的值依旧是 0。 函数为什么要在 C++ 函数中最后添加默认参数？ 在参数列表中的任何位置都可能具有默认参数，但这会增加函数调用的复杂性和歧义性（对于编译器，可能更重要的是对于函数用户）。 如果要在各个参数位置使用默认参数，则几乎可以肯定地做到这一点，方法是编写重载，然后简单地转过来并调用内联完全参数化的函数： 12345int foo(int x, int y);int foo(int y){ return foo(0, y);} 相当于： 1int foo(int x = 0, int y); 通常，函数参数由编译器处理，并以从右到左的顺序放置在堆栈中。因此，应该首先评估具有默认值的任何参数。（这适用于 __cdecl，它通常是 VC++ 和 __stdcall 函数声明的默认值。） C++111、default_random_engine 以前获取伪随机数都是用的 rand，想要获取两个数之间的伪随机数，方法如下： 12345678int min,max;//定义上下边界 int range=max-min;//获取中间的范围 int randNum = rand() % range + min;//生成介于min和max之间的伪随机数 《C++ Primer 5th Edition》里面介绍了使用 default_random_engine 来获取随机数，并且指出“C++ 程序不应该使用库函数 rand，而应使用 default_random_engine 类来恰当的分布类对象。”用这种新方法获取两个数之间的伪随机数的方法如下： 1234567891011int min,max;//定义上下边界 default_random_engine e;//创建引擎 uniform_int_distribution&lt;unsigned&gt; u(min,max);//创建取值范围 int randNum=u(e);//获取伪随机数 有一个问题，就是多次调用同一对范围和引擎时，每次生成的数都是一样的。为了避免这个情况，需要在定义范围和引擎时，将其定义为 static的： 12static default_random_engine e;static uniform_int_distribution&lt;unsigned&gt; u(min,max); 关于设置种子，既可以在定义时设置种子，也可以创建完成后再设置种子，方法如下： 123456default_random_engine e1(32767);//创建引擎时设置种子 default_random_engine e2;e2.seed(32767);//创建后再设置种子 如果要设置时间为种子，方法如下： 12default_random_engine e(time(0));//设置当前时间为引擎种子 time 返回时间的单位是秒，所以如果是自动过程的一部分反复运行，比如用在循环中，那么因为间隔时间不够，所以设置的种子其实是一样的。 enable_shared_from_thisenable_shared_from_this 是一个模板类，定义于头文件 &lt; memory &gt; 12template&lt;class T&gt; class enable_shared_from_this; std::enable_shared_from_this 能让一个对象（假设其名为 t ，且已被一个 std::shared_ptr 对象 pt 管理）安全地生成其他额外的 std::shared_ptr 实例（假设名为 pt1, pt2, … ），它们与 pt 共享对象 t 的所有权。 若一个类 T 继承 std::enable_shared_from_this ，则会为该类 T 提供成员函数 shared_from_this。当 T 类型对象 t 被一个为名为 pt 的 std::shared_ptr 类对象管理时，调用 T::shared_from_this 成员函数，将会返回一个新的 std::shared_ptr 对象，它与 pt 共享 t 的所有权。 1、使用场合 当类 A 被 share_ptr 管理，且在类 A 的成员函数里需要把当前类对象作为参数传给其他函数时，就需要传递一个指向自身的 share_ptr。 为何不直接传递this指针使用智能指针的初衷就是为了方便资源管理，如果在某些地方使用智能指针，某些地方使用原始指针，很容易破坏智能指针的语义，从而产生各种错误。 可以直接传递 share_ptr 么？答案是不能，因为这样会造成2个非共享的 share_ptr 指向同一个对象，未增加引用计数导对象被析构两次。 123456789101112131415161718192021#include &lt;memory&gt;#include &lt;iostream&gt; class Bad{public: std::shared_ptr&lt;Bad&gt; getptr() { return std::shared_ptr&lt;Bad&gt;(this); } ~Bad() { std::cout &lt;&lt; \"Bad::~Bad() called\" &lt;&lt; std::endl; }}; int main(){ // 错误的示例，每个shared_ptr都认为自己是对象仅有的所有者 std::shared_ptr&lt;Bad&gt; bp1(new Bad()); std::shared_ptr&lt;Bad&gt; bp2 = bp1-&gt;getptr(); // 打印bp1和bp2的引用计数 std::cout &lt;&lt; \"bp1.use_count() = \" &lt;&lt; bp1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; \"bp2.use_count() = \" &lt;&lt; bp2.use_count() &lt;&lt; std::endl;} // Bad 对象将会被删除两次 正确的实现如下： 123456789101112131415161718192021222324#include &lt;memory&gt;#include &lt;iostream&gt; struct Good : std::enable_shared_from_this&lt;Good&gt; // 注意：继承{public: std::shared_ptr&lt;Good&gt; getptr() { return shared_from_this(); } ~Good() { std::cout &lt;&lt; \"Good::~Good() called\" &lt;&lt; std::endl; }}; int main(){ // 大括号用于限制作用域，这样智能指针就能在system(\"pause\")之前析构 { std::shared_ptr&lt;Good&gt; gp1(new Good()); std::shared_ptr&lt;Good&gt; gp2 = gp1-&gt;getptr(); // 打印gp1和gp2的引用计数 std::cout &lt;&lt; \"gp1.use_count() = \" &lt;&lt; gp1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; \"gp2.use_count() = \" &lt;&lt; gp2.use_count() &lt;&lt; std::endl; } system(\"pause\");} 2、为何会出现这种使用场合 因为在异步调用中，存在一个保活机制，异步函数执行的时间点我们是无法确定的，然而异步函数可能会使用到异步调用之前就存在的变量。为了保证该变量在异步函数执期间一直有效，我们可以传递一个指向自身的 share_ptr 给异步函数，这样在异步函数执行期间 share_ptr 所管理的对象就不会析构，所使用的变量也会一直有效了（保活）。 类 Class实现一个不能被继承的类1、方法一 最直观的解决方法就是将其构造函数声明为私有的，这样就可以阻止子类构造对象了。但是这样的话，就无法构造本身的对象了，就无法利用了。既然这样，我们又可以想定义一个静态方法来构造类和释放类。 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;using namespace std;class A{ public: static A* Construct(int n) { A *pa = new A; pa-&gt;num = n; cout&lt;&lt;\"num is:\"&lt;&lt;pa-&gt;num&lt;&lt;endl; return pa; } static void Destruct(A * pIntance) { delete pIntance; pIntance = NULL; } private: A(){} ~A(){} public: int num;};int main(){ A *f = A::Construct(9); cout&lt;&lt;f-&gt;num&lt;&lt;endl; A::Destruct(f); return 0;} 但是这样只能在堆上创建，无法再栈上实现创建类。这就是私有的构造函数的局限性。 2、方法二 利用友元不能被继承的特性，可以实现这样的类。 设计一个模板辅助类 Base，将构造函数声明为私有的；再设计一个不能继承的类 FinalClass，将 FinalClass 作为 Base 的友元类。FinalClass 虚继承 Base。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Base{ friend T;private: Base(){ cout &lt;&lt; \"base\" &lt;&lt; endl; } ~Base(){}};class FinalClass : virtual public Base&lt;FinalClass&gt;{ //一定注意 必须是虚继承public: FinalClass(){ cout &lt;&lt; \"FinalClass()\" &lt;&lt; endl; }};class C : public FinalClass {public: C(){} //继承时报错，无法通过编译};int main(){ FinalClass b; //B类无法被继承 //C c; return 0;} 类 Base 的构造函数和析构函数因为是私有的，只有 Base 类的友元可以访问，FinalClass 类在继承时将模板的参数设置为了 FinalClass 类，所以构造 FinalClass 类对象时们可以直接访问父类（Base）的构造函数。 为什么必须是虚继承呢？ 虚继承的功能是：当出现了菱形继承体系的时候，使用虚继承可以防止二义性，即子孙类不会继承多个原始祖先类。 那么虚继承如何解决这种二义性的呢？从具有虚基类的类继承的类在初始化时进行了特殊处理，在虚派生中，由最低层次的派生类的构造函数初始化虚基类。 结合上面的代码来解释：C 在调用构造函数时，不会先调用 FinalClass 的构造函数，而是直接调用 Base 的构造函数，C 不是 Base 的友元类，所以无法访问。这样的话 C 就不能继承 FinalClass。 注 C++11 的已经加入了 final 关键字，直接在类后面加上 final 关键字，就可以防止该类被继承。 操作系统死锁是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 死锁发生的条件 互斥条件：线程对资源的访问是排他性的，如果一个线程占用了某资源，那么其他线程必须处于等待状态，直到资源被释放。 请求和保持条件：线程 T1 至少已经保持了对一个资源 R1 的占用，但又提出对另一个资源 R2 的请求，而此时，资源 R2 被其他线程 T2 占用，于是该线程 T1 也必须等待，但又对自己保持的资源 R1 不释放。 不剥夺条件：线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。 环路等待条件：在死锁发生时，必然存在一个“进程-资源环形链”，即 {p0,p1,p2,…pn}，进程 p0（或线程）等待 p1 占用的资源，p1 等待 p2 占用的资源，pn 等待 p0 占用的资源。（最直观的理解是，p0 等待 p1 占用的资源，而 p1 在等待 p0 占用的资源，于是两个进程就相互等待）。 活锁是指线程 1 可以使用资源，但它很礼貌，让其他线程先使用资源，线程 2 也可以使用资源，但它很绅士，也让其他线程先使用资源。这样你让我，我让你，最后两个线程都无法使用资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/************************ * 活锁例子 * 创建一个勺子类，有且只有一个。 * 丈夫和妻子用餐时，需要使用勺子，这时只能有一人持有，也就是说同一时刻只有一个人能够进餐。 * 但是丈夫和妻子互相谦让，都想让对方先吃，所以勺子一直传递来传递去，谁都没法用餐。 * */public class LiveLockTest { //定义一个勺子，ower 表示这个勺子的拥有者 static class Spoon { Diner owner;//勺子的拥有者 //获取拥有者 public String getOwnerName() { return owner.getName(); } //设置拥有者 public void setOwner(Diner diner) { this.owner = diner; } public Spoon(Diner diner) { this.owner = diner; } //表示正在用餐 public void use() { System.out.println(owner.getName() + \" use this spoon and finish eat.\"); } } //定义一个晚餐类 static class Diner { public Diner(boolean isHungry, String name) { this.isHungry = isHungry; this.name = name; } private boolean isHungry;//是否饿了 private String name;//定义当前用餐者的名字 public String getName() {//获取当前用餐者 return name; } //可以理解为和某人吃饭 public void eatWith(Diner spouse, Spoon sharedSpoon) { try { synchronized (sharedSpoon) { while (isHungry) { //当前用餐者和勺子拥有者不是同一个人，则进行等待 while (!sharedSpoon.getOwnerName().equals(name)) { sharedSpoon.wait(); //System.out.println(\"sharedSpoon belongs to\" + sharedSpoon.getOwnerName()) } //spouse此时是饿了，把勺子分给他，并通知他可以用餐 if (spouse.isHungry) { System.out.println(\"I am \" + name + \", and my \" + spouse.getName() + \" is hungry, I should give it to him(her).\\n\"); sharedSpoon.setOwner(spouse); sharedSpoon.notifyAll(); } else { //用餐 sharedSpoon.use(); sharedSpoon.setOwner(spouse); isHungry = false; } Thread.sleep(500); } } } catch (InterruptedException e) { System.out.println(name + \" is interrupted.\"); } } } public static void main(String[] args) { final Diner husband = new Diner(true, \"husband\");//创建一个丈夫用餐类 final Diner wife = new Diner(true, \"wife\");//创建一个妻子用餐类 final Spoon sharedSpoon = new Spoon(wife);//创建一个勺子，初始状态并由妻子持有 //创建一个 线程，由丈夫进行用餐 Thread h = new Thread() { @Override public void run() { //表示和妻子用餐，这个过程判断妻子是否饿了，如果是，则会把勺子分给妻子，并通知她 husband.eatWith(wife, sharedSpoon); } }; h.start(); //创建一个 线程，由妻子进行用餐 Thread w = new Thread() { @Override public void run() { //表示和妻子用餐，这个过程判断丈夫是否饿了，如果是，则会把勺子分给丈夫，并通知他 wife.eatWith(husband, sharedSpoon); } }; w.start(); try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } h.interrupt(); w.interrupt(); try { h.join();//join()方法阻塞调用此方法的线程(calling thread)，直到线程t完成，此线程再继续；通常用于在main()主线程内，等待其它线程完成再结束main()主线程。 w.join(); } catch (InterruptedException e) { e.printStackTrace(); } }} 饥饿是指如果线程 T1 占用了资源 R，线程 T2 又请求封锁 R，于是 T2 等待。T3 也请求资源 R，当 T1 释放了 R上 的封锁后，系统首先批准了T3 的请求，T2 仍然等待。然后 T4 又请求封锁 R，当 T3 释放了 R 上的封锁之后，系统又批准了 T4 的请求…，T2 可能永远等待。 StringC 语言实现 itoa 函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/* A C++ program to implement itoa() */#include &lt;iostream&gt; using namespace std; /* A utility function to reverse a string */void reverse(char str[], int length) { int start = 0; int end = length -1; while (start &lt; end) { swap(*(str+start), *(str+end)); start++; end--; } } // Implementation of itoa() char* itoa(int num, char* str, int base) { int i = 0; bool isNegative = false; /* Handle 0 explicitely, otherwise empty string is printed for 0 */ if (num == 0) { str[i++] = '0'; str[i] = '\\0'; return str; } // In standard itoa(), negative numbers are handled only with // base 10. Otherwise numbers are considered unsigned. if (num &lt; 0 &amp;&amp; base == 10) { isNegative = true; num = -num; } // Process individual digits while (num != 0) { int rem = num % base; str[i++] = (rem &gt; 9) ? (rem-10) + 'a' : rem + '0'; num = num/base; } // If number is negative, append '-' if (isNegative) str[i++] = '-'; str[i] = '\\0'; // Append string terminator // Reverse the string reverse(str, i); return str; } // Driver program to test implementation of itoa() int main() { char str[100]; cout &lt;&lt; \"Base:10 \" &lt;&lt; itoa(1567, str, 10) &lt;&lt; endl; cout &lt;&lt; \"Base:10 \" &lt;&lt; itoa(-1567, str, 10) &lt;&lt; endl; cout &lt;&lt; \"Base:2 \" &lt;&lt; itoa(1567, str, 2) &lt;&lt; endl; cout &lt;&lt; \"Base:8 \" &lt;&lt; itoa(1567, str, 8) &lt;&lt; endl; cout &lt;&lt; \"Base:16 \" &lt;&lt; itoa(1567, str, 16) &lt;&lt; endl; return 0; } 参考原文1、C++内存对象布局2、C++对象模型3、网络同步在游戏历史中的发展变化（一）—— 网络同步与网络架构4、C++11新特性之十：enable_shared_from_this","link":"/post/70ae5d6.html"},{"title":"游戏服务器端开发要点","text":"本文作为游戏服务端开发的基本大纲，是游戏实践开发中的总结。第一部分专业基础，列举部分游戏开发理论知识点，第二部分游戏开发入门，讲述游戏服务器端开发的基本要点，第三部分服务端架构，介绍架构设计中的一些基本原则。 一、专业基础1.1、网络1.1.1、理解 TCP/IP 协议 网络传输模型 滑动窗口技术 建立连接的三次握手与断开连接的四次挥手 连接建立与断开过程中的各种状态 TCP/IP 协议的传输效率 思考 1、TIME_WAIT 状态怎么解释？ 1.1.2、掌握常用的网络通信 IO 模型 select、poll、epoll epoll，边缘触发 ET 与水平触发 LT 的区别与应用 1.2、存储 计算机系统存储体系 程序运行时的内存结构 计算机文件系统，页表结构 内存池与对象池的实现原理，应用场景与区别 关系数据库 MySQL 的使用 共享内存 1.3、程序 对 C/C++ 语言有较深的理解 深刻理解接口，封装与多态，并且有实践经验 深刻理解常用的数据结构：数组、链表、二叉树、哈希表 熟悉常用的算法及相关复杂度：冒泡排序、快速排序、堆排序 二、游戏开发入门2.1、防御式编程 不要相信客户端数据，一定要检验。作为服务器端你无法确定你的客户端是谁，你也不能假定它是善意的，请做好自我保护。(这是判断一个服务器端程序员是否入门的基本标准) 务必对于函数的传人参数和返回值进行合法性判断，内部子系统，功能模块之间不要太过信任，要求低耦合，高内聚 插件式的模块设计，模块功能的健壮性应该是内建的，尽量减少模块间耦合 2.2、设计模式 道法自然。不要迷信，迷恋设计模式，更不要生搬硬套 简化，简化，再简化，用最简单的办法解决问题 2.3、网络模型 自造轮子: select, epoll， epoll 一定比 select 高效吗？ 开源框架: libevent、libev、ACE、muduo、skynet 2.4、数据持久化 自定义文件存储，如《梦幻西游》 关系数据库: MySQL NO-SQL 数据库: MongoDB、Redis 选择存储系统要考虑的因素：稳定性，性能，可扩展性 2.5、内存管理 使用内存池和对象池，禁止运行期间动态分配内存 对于输入输出的指针参数，严格检查，宁滥勿缺 写内存保护。使用带内存保护的函数 (strncpy、memcpy、snprintf、vsnprintf 等)，严防数组下标越界 防止读内存溢出，确保字符串以“\\0”结束 2.6、日志系统 简单高效，大量日志操作不应该影响程序性能 稳定，做到服务器崩溃时日志不丢失 完备，玩家关键操作一定要记日志，理想的情况是通过日志能重建任何时刻的玩家数据 开关，开发日志要加级别开关控制 2.7、通信协议 采用 PDL(Protocol Design Language)， 如 Protobuf，可以同时生成前后端代码，减少前后端协议联调成本，扩展性好 JSON，文本协议简单、自解释、无联调成本、扩展性好，也很方便进行包过滤以及写日志 自定义二进制协议，精简，有高效的传输性能，完全可控，几乎无扩展性 2.8、全局唯一 Key(GUID) 为合服做准备 方便追踪道具，装备流向 每个角色，装备，道具都应对应有全局唯一 Key 2.9、多线程与同步 消息队列进行同步化处理 2.10、状态机 强化角色的状态 前置状态的检查校验 2.11、数据包操作 合并，同一帧内的数据包进行合并，减少 IO 操作次数 单副本，用一个包尽量只保存一份，减少内存复制次数 AOI 同步中减少中间过程无用数据包 2.12、状态监控 随时监控服务器内部状态 内存池，对象池使用情况 帧处理时间 网络 IO 包处理性能 各种业务逻辑的处理次数 2.13、包频率控制 基于每个玩家每条协议的包频率控制，瘫痪变速齿轮 2.14、开关控制 每个模块都有开关，可以紧急关闭任何出问题的功能模块 包频率控制可以消灭变速齿轮 包 id 自增校验，可以消灭 WPE 包校验码可以消灭包拦截篡改 图形识别码，可以踢掉99%非人的操作 2.15、热更新 核心配置逻辑的热更新，如防沉迷系统，包频率控制，开关控制等 代码脚本热更新，如 Erlang，Lua 等 2.16、防刷 关键系统资源（如元宝，精力值，道具，装备等）的产出记日志 资源的产出和消耗尽量依赖两个或以上的独立条件的检测 严格检查各项操作的前置条件 校验参数合法性 2.17、防崩溃 系统底层与具体业务逻辑无关，可以用大量的机器人压力测试暴露各种 bug，确保稳定 业务逻辑建议使用脚本 系统性的保证游戏不会崩溃 2.18、性能优化 IO 操作异步化 IO 操作合并缓写 （事务性的提交 db 操作，包合并，文件日志缓写） Cache 机制 减少竞态条件 (避免频繁进出切换，尽量减少锁定使用），多线程不一定优于单线程，多线程不一定比单线程快 减少内存复制 测试，用数据说话 2.19、运营支持 接口支持：实时查询，控制指令，数据监控，客服处理等 实现考虑提供 Http 接口 2.20、容灾与故障预案三、服务器端架构3.1、什么是好的架构 满足业务要求 能迅速的实现策划需求，响应需求变更 系统级的稳定性保障 简化开发。将复杂性控制在架构底层，降低对开发人员的技术要求，逻辑开发不依赖于开发人员本身强大的技术实力，提高开发效率 完善的运营支撑体系 3.2、架构实践的思考 简单，满足需求的架构就是好架构 设计性能，抓住重要的20%， 没必要从程序代码里面去抠性能 热更新是必须的 人难免会犯错，尽可能的用一套机制去保障逻辑的健壮性 3.3、架构分层一般地，会把游戏服务器的架构划分如下三层：网络接入层、游戏逻辑层、数据存储层，这样划分的主要目的是：1、将底层通信与业务逻辑处理解耦合；2、将业务逻辑处理与数据存储解耦合；3、有利于运营部署与扩展； 3.3.1、网络接入层网络接入层主要任务是解决来自客户端大量并发请求和负载均衡的处理，考量该层的主要性能指标是：高吞吐、低延迟、均负载，即既能同一时刻处理大批量的客户端请求（每秒至少1万个请求以上），又能快速响应，并且均负载的分布处理这些请求。 高并发处理1、http 接入基于 web 的应用，玩家无需下载客户端，也不用担心防火墙等问题2、socket 接入二进制协议较文本协议能大幅度节省带宽，并且通信包可做组播等处理，以有效降低流量 IP 路由与负载均衡这块跟服务器集群和 IDC 部署密切相关，主要是为了让整个服务器集群能最大化其处理能力，尤其是在业务高峰时期，整个服务器集群能均衡平滑的应对客户端请求，不至于出现某个单点服务器出现很高负载时，其它同层服务器较空闲的情况。 3.3.2、游戏逻辑层游戏逻辑层主要是处理游戏的具体业务逻辑，根据游戏类型和部署的不同，它会由一个或多个进程组成。 基础系统1、游戏对象内存管理：这是业务系统中最基本也是最重要的系统之一，目前，我们采用基于共享内存的预分配机制，来管理游戏中各个对象所需内存的分配与回收。这样的好处是，当游戏服务器进程 Crash 时，配合运营的实时监测机制，系统自动拉取进程，在线玩家的状态数据可以无损恢复，并且在线玩家不会感觉到服务器宕机；2、消息分发管理：集中处理 C-&gt;S 消息和 S-&gt;S 消息，设计时重点考虑程序的可扩展性；3、系统与运营日志管理：分别用来监控服务器状态和玩家的各种行为；4、游戏商城管理：对付费物品的上架、扣除、计费等处理；5、玩家登录管理：玩家登录游戏时的流程统一处理； 业务系统业务系统主要是说明游戏的主体内容是由哪些子模块组成，这跟具体的游戏类型关系较大。 1、地图与副本管理：游戏各公共场景和玩家独自的副本地图的处理，包括 Npc 与怪物分布、传送点分布、地图阻挡数据等的解析，以及地图实例和副本实例的抽象等；2、移动管理：主要是实现游戏对象（玩家角色、怪物等）的地图寻路、障碍物检测，以及动态碰撞处理等功能。3、装备与道具管理：主要包括装备的合成、拆分、打造、镶嵌、升星等，以及道具的获取、交易、使用等功能；4、任务与事件管理：主要包括任务的领取、任务节点的更新、任务的完成和失败处理等，以及系统随机事件的产生等内容；5、游戏世界状态管理：可将整个游戏世界各游戏对象的状态分成几大类与几小类，如：玩家角色的状态、技能 Buff 的状态等，然后对各状态之间关系进行统一管理；6、战斗与技能管理：处理 PVE、PVP 战斗流程、伤害计算，以及各个技能、Buff、Debuff 的业务规则处理；7、Npc 与怪物 AI 管理：包括 Npc 在场景中的分布规则和本身的功能处理，以及怪物的分布、刷新、各类 AI 行为的处理；8、视野管理：包括玩家的视野、Npc 和怪物的视野等，设计时需要特别注意考虑各个不同场景中玩家的视野大小和视野搜索网格大小这两个重要参数，因为，它们对服务器的性能（CPU 和流量）影响很大；9、宠物与坐骑管理：包括宠物和坐骑的养成、交易、附带技能和装备等功能；10、社会关系管理：包括玩家组队、玩家好友、玩家交易、家族、公会、阵营、国家等社会关系功能的处理；11、邮件管理：通过邮件可实现发送系统消息、发放系统道具，玩家道具交易等功能；12、聊天管理：包括玩家点对点聊天、群聊等功能； 3.3.3、数据存储层数据存储层是整个服务器的关键基础系统之一，因为游戏服务器的核心功能之一就是存取玩家数据。游戏类型不同，对数据的存取需求也不一样，对于传统客户端 MMORPG 而言，一般采用 Mysql 作数据持久化，然后在 Mysql 与 GameSvr 中间实现一个 ORM 的服务提供数据的代理或缓存即可。而新兴的 Social Game 和强交互的 WebGame，则选择用 NoSql 来替代 Mysql，以满足其超大规模 IO 并发的需求。 网络游戏服务器与数据库的关系 一般就是每个区服对应一个数据库，比如合服就是在合并数据库，有时候两个区因为版本问题、数据库架构不同，也可能会有细微不同。访问方面一般实时数据都在内存里，通过缓存和日志的方式每隔一段时间持久化一次，同时保证数据完整性。 而所谓服务器就是一组程序，用来响应来自客户端的消息。平衡负载可以简单让不同的程序负责处理不同的消息，比如一个负责战斗、一个负责聊天等，或者每个程序负责不同的地图区域之类的，这个取决于架构师的设计。不过大部分的运算都只访问内存中的数据，数据库只负责保证数据持久和完整。 一般有两种库保存玩家的不同信息 玩家登录账号的资料信息、账号内的余额，一般保存在一个库中。这个库在该公司内是通用的，登录官网可以登录查询充值，在每个游戏登录的时候都会访问，在游戏过程中的消费可以回馈到这个库里。 每个游戏的每个大区的每个服还会对应一个数据库。在这个库里，会保存玩家的角色信息（等级，装备，金钱……），玩家的社交关系，拍卖行，任务等一切在游戏里的数据。 ORMORM 即为对象关系映射，可以这样来简单的理解：我们平时操作关系型数据库，需要业务自己编写许多数据访问的代码，这样会把许多 SQL 语句直接暴露在业务代码里，十分不利于维护。利用 ORM 技术，可以避免这个问题，即业务逻辑不会直接对 DB 进行操作，而改由 ORM 来完成，业务逻辑与 ORM 服务之间约定相关协议和 API 接口，来完成对数据的增、删、改、查等功能。 NoSqlNoSql，指的是非关系型的数据库，它可以满足对数据库的高并发读写、对海量数据的高效率存储和访问，以及对数据库的高可扩展性和高可用性等需求，它是随着 SNS 和 Web2.0 的兴起而产生的新兴存储技术。对于游戏而言，目前它主要应用于 Social Game 和强交互的 WebGame 中。 3.3.4、通用组件层通用组件库是指那些与具体业务无关的，能应用于所有服务器开发的组件库。 后台服务应用框架后台服务应用框架规范了进程的起停方式、信号处理、命令行参数等操作，框架本身实现了一个 daemon 服务所必备的消息主循环、reload 机制，以及定时器处理等功能。 日志组件日志是服务器调试和定位 Bug 的主要手段之一，日志组件一般需要实现日志分级、异步写磁盘、以及按日期时间分类等功能。 进程间通讯组件进程间的通讯也是服务器的核心基础功能之一，高效的进程间通讯是服务器性能的基本保障，进程间通讯组件需要实现同机器与跨机器的进程高效通讯。 进程内线程之间的通信 指令消息消息解包后，可以采取无锁的消息队列，然后工作线程进行业务处理。 连接转移连接验证、同步、加入 IO 主线程，这些需要互斥加锁处理。 进程之间的通信 传统的 TCP 连接 绑定在 TCP 上的 RPC 连接 消息打包组件在许多通信程序中，需要定义一套网络协议，并需要根据网络协议对协议数据单元（PDU）进行 Pack/Unpack，以实现可移植性和网络传输的可靠性及效率。但是对协议数据单元进行 Pack/Unpack 是一个重复性很强的操作，繁琐而且容易出错（Pack 和 Unpack 容易不匹配）。而消息打包组件则简化了网络协议的制定，使得业务应用不用关心协议的 Pack/Unpack 操作，并且支持良好的数据扩展和协议版本兼容。 四、服务器系统设计服务器主要关注的点有：安全、性能、容灾、扩展。1、安全：就是玩家用外挂伪造客户端发包怎么办？答案就是加上一堆检验。但是怎么检验才合理高效，这个就需要好好考虑了。2、性能：就是你这个服务器撑不了几个人，很卡怎么办？答案就是各种优化，多线程、缓存、负载均衡、排队、异步，能用上的都用上。3、容灾：就是万一你的服务器挂了怎么办？答案就是需要支持快速切换、拉起，隔离灾难，非核心进程挂掉不影响核心进程。另外怎么监控服务器，自动化处理也有需要考虑的。4、扩展：就是如果玩家突然多了，服务器可以动态扩展吗？如果服务器需要修复 Bug，可以动态更新吗(热更新)？这就需要有对应的状态管理和更新机制。 4.1、3DMMORPG 技能战斗系统1、技能施法时，client 只有一个上行的请求施法包，后续施法的过程全由 server 来驱动下发施法各阶段的结果信息，如吟唱、效果伤害、命中信息等等； 2、弹道类技能是由 server 计算飞行时间，并不考虑飞行后的轨迹，若此时目标有移动，则 client 会做目标跟随的处理； 3、技能学习：由秘籍来获得技能，一本秘籍包含多个技能，被动技能不影响主动技能的属性； 4、Buff 系统与技能系统是相互独立的，相互之间有各自的接口进行访问； 5、玩家施法作群攻目标选定时，也是由 server 来完成，这时是从玩家自己的视野里搜索，而无需再搜一次动态区域（格子32*32）； 6、技能效果由一个主效果 +N 个 Buff 效果组成； 7、Buff 对象区分玩家和怪物，其存储结构独立出来放在内存池中，在施法者需要时再根据目标类型来添加； 8、在作技能效果计算时，尽量避免有轮循的处理，因为这样很耗 CPU。 关于技能引发的位置同步问题1、对于改变目标(玩家)移动速度的技能，可能会带来位置不同步的问题，即 server 下发速度改变的包时，目标玩家可能正在移动，从而导致 server 和 client 的位置不一致？答：对于这个问题，一般是通过移动系统自身的位置同步策略来解决的，即移动系统发现 client 和 server 位置不一致时，通过一定的策略来补偿速度慢的一方，从而使目标玩家在接下来的一定时间内达到位置平衡。 2、类似性质的问题还有给目标加冰冻、定身等 Buff，也可能带来位置不同步的问题？答：这个问题暂也还没有好的解决方案，目前的做法是当目标中定身 Buff 时，client 立即表现定身，即定在原地，并将此时的位置信息带给 server，server 检验合法后设置这个位置，解冻后 client 继续让玩家移动(若玩家是移动中被定身住的话)。 冲锋技能1、在 MMORPG 游戏中，对于那些同时拥有近攻和远程系等多种职业的游戏，策划一般都会对近攻类的职业，加上冲锋类的技能，以便平衡远程类职业在攻击距离上的优势。在 client 看到的效果，是玩家边播放冲锋动作，然后快速接近目标，并对目标一个伤害，而对 server 而言，该技能与其它技能在处理的不同之处在于，施法玩家在施法的同时，也作一个位置的变更。一般 server 的处理流程是，先检查冲锋直线路径是否合法（有无阻挡）和其它施法条件，若通过，则告诉 client 可以施法，并同时设置当前玩家坐标为冲锋后的坐标（该坐标由 client 带上来）。 2、由于 server 移动系统在对 client 发过来的移动数据作检验时，需要检查本次移动的起步点，是否为上次移动的结束点，即作线段端点合法检查，而冲锋到达的目标点并未在上次移动的路径栈信息中，所以，server 技能系统在设置冲锋位置时，需要先清除原路径栈信息（如调用 MoveStop 接口），以便确认本次冲锋为一次全新的移动。 3、两个玩家同时使用冲锋技能时（目前 client 在做技能时，采用先表现的方式），出现一个玩家（冲锋目标 client）停在冲锋途中的现象，原因为 server 广播技能施法时，没有带目标主动位移的信息（client 在处理冲锋位置时，对于使用冲锋技能的 client，因为它知道冲锋到达的位置，所以它的处理没有问题，而另一个冲锋目标 client，由于它不知道对方要冲到哪里，则 client 处理时就是选择冲锋路径上的一点，这样就会看到停在冲锋途中了）所致。解决办法是，要么在协议中下发目标位移信息，要么在策划规则上，只允许同一时刻一个玩家冲锋，如冲锋加晕眩 debuff 等。 4.2、Social Game 与 MMORPG 在服务器架构上的差异协议通信 Socail Game 为了快速开发，在通信协议的选择上均会选择 http 作为底层通信协议，这样选择的好处大致有：1、方便客户端编程：http 为一应一答的同步模型；2、可以选择成熟的开源 http 服务器，如：apache、nginx； RPG选择的是基于 socket 的 TCP 通信，这是由游戏本身的特点所决定的，如：聊天、多人视野、服务器主动通知事件等需求 游戏逻辑服务器的承受能力1、RPG 的游戏逻辑服务器（地图服务器）所能承载的最高在线（PCU）是在3000-5000不等； 2、Social Game 由于没有 RPG 复杂的移动、战斗、视野管理等需求，逻辑服务器承受的在线一般都是比较高的，如10000-30000不等 游戏逻辑服务器的 Cache 和回写机制1、RPG 的游戏逻辑服务器一般都需要 Cache 玩家数据，并且采取定时回写的策略，如根据数据重要程度分别作 5min-15min 不等的定时回写； 2、Social Game 的游戏逻辑服务器一般都无需 Cache 玩家数据，玩家的每次请求都是即时读即时写（这样会涉及到另外一个问题，即 DB 读写的性能问题，见下一条）； DB 存储模型的选择1、RPG 存储服务器常用的还是 MySQL（Innodb 存储引擎），中间还由业务自己写一个 Cache 代理服务器，以 Cache 热点数据； 2、Social Game 则会选用 TC、MemCached 等所谓 Key-Value 全内存数据存储，有实力的公司会自己实现一个类似这种机制的存储系统，它可以无源，也可以是有源，并且还可以选择用 MySQL 作数据落地，毕竟 MySQL 作为互联网业务 DB 的成熟解决方案已毋庸置疑； 交互数据的一致性1、在 SNS Game 中，会经常出现同一个玩家在某一个时刻同时被多个好友访问和修改数据的情况，这时就需要保证，每次数据的更新都是正常有序进行的，而不能被写脏数据。一般地，都会使用一个类似全局锁服务的设计来解决这个问题； 2、RPG 不会存在这样的问题，类似的需求是：玩家可能会跨地图服务器，即所谓的跳线或跨服，这个问题的通常解决方案是服务器重新作一次下线、重登录的处理，当然，玩家是感觉不到的； IDC 部署1、RPG 一般是分区分服部署；2、Social Game 则是全区全服部署； 4.3、游戏排行榜的实现游戏开发中排行榜经常出现，实际开发端游项目遇到的排行榜是根据玩家的某种特征对所有玩家进行排序(装备评分、人物等级…等)。排行榜需求不是实时显示，而且客户端也只显示 TopK(K=10、50、100) 的排名玩家。 排行榜的主要作用： 1、排行榜内容是部分有序的玩家信息(以等级为例)2、玩家等级变化后，需更新排行榜3、根据玩家 ID 获取其在排行榜中的排名4、获取排行榜中特定排名的玩家 4.4、卡牌游戏和弱连接随着游戏类型复杂度提升，在一种游戏里，以某一种核心内容为主(卡牌)，其他内容为辅(横版、PVP 等)的做法比较常见。但并非百分百的卡牌游戏都固定地使用弱连接模式，可以通过游戏的表现来判断是否使用弱连接。基于 PVP 的判断方式有如下两种： 第一种1、战斗过程中，选择的内容偏多，且时间偏长(如放牌)2、战斗允许预先放置卡牌和预先连锁判断3、客户端使用网页形式来制作 第二种1、没有即时交互的过程，玩家和玩家之间的对战摆完道具就自动进行计算和战斗2、刷新排行榜3、买卖道具 安全性在服务器登录的时候，进行一下简单的校验，比如使用时间戳或者预定随机值或者预定好的 counting 值来进行哈希，哈希后的值用作双方通信的 key 来进行加密通信，这样以后每次通信都不需要再次加密，时间戳或者随机值加上哈希可以保证每次登录的 key 不同。 排行榜的推送和积分，购买道具的选择和下单购买，这些都基本使用弱连接。 4.5、地图的无缝连接所谓的无缝，最大的难点就是连接点，只要解决了连接点之间的通信和客户端之间的交互，就解决了无缝问题。 4.6、帧同步中如何做移动预测王者荣耀，采用的是帧同步方案。不存在预测的情况，都是得在相应帧做相应的输入操作。如果到了相应帧，因为网络过卡，没有及时收到输入数据，则会锁帧等待，表现出来就是网络差时，会卡住，后来收到包时，再追帧。但是不影响其它玩家。 一般做预测都是用在状态同步里面，帧同步讲究的是根据操作得出确定的结果，如果网络出现问题有可能会进行等待的情况。 4.7、包裹系统包裹中增加道具道具如果是不能叠加的 1、往包裹中添加道具，主要是往空位置上插入2、有空位置，则加入到道具管理器中3、道具有耐久度，且有扣耐久类型，比如是根据游戏时间或者物理时间，设置是时限道具 参考文章：1、游戏服务器端开发要点2、游戏服务器开发技术小结","link":"/post/a9472e98.html"},{"title":"Golang游戏服务器知识点散记","text":"Golang游戏服务器知识点零散记录 一、使用Go语言开发大型MMORPG游戏服务器语言、库、第三方库 1、Golang 语言特性和 C 语言很像。2、Golang 用组合+接口，C++ 则更多是继承。3、Golang 服务器如何保证解决游戏服务器存盘一致性问题？stop the world 是需要的，但是 Golang 可以从语言层并发序列化玩家数据，再通过后台存盘。4、channel 和 goroutine 虽然是 Golang 的语言特性。但是在编写服务器时，其实只有底层用的比较多。5、Golang 的第三方库很多。6、Golang 用 interface{}/反射做泛型。 运行期 runtime 1、Go1.6 版后的 GC 优化的已经很好了，如果不是高性能、高并发Web应用，只用 Golang 写游戏服务器，GC 损耗可以忽略不计。2、崩溃捕捉是标配功能。3、热更新：官方已经有 plugin 系统，plugin 跨平台。可以告别手动 cgo 做 so 热更新。 开发、部署、调试、优化 1、Jetbrains 的 Goland 是一把利器。2、Golang 自带性能调优工具，从内存、CPU、阻塞点等几个方面直接出图进行分析，非常直观。3、Golang 支持交叉编译、跨平台部署，在 windows 上编译输出一个 elf，到 Linux 服务器上直接开跑。 二、Goroutine1、goroutine 的目的是描述并发编程模型。并发与并行不同，它并不需要多核的硬件支持，它不是一种物理运行状态，而是一种程序逻辑流程。它的主要目的不是利用多核提高运行效率，而是提供一种更容易理解、不容易出错的语言来描述问题。2、实际上 golang 默认就是运行在单 OS 进程上面的，通过指定环境变量 GOMAXPROCS 才能转身跑在多 OS 进程上面。3、coroutine 本质上是语言开发者自己实现的、处于 user space 内的线程，无论是 erlang、还是 golang 都是这样。需要解决没有时钟中断，碰着阻塞式 IO，整个进程都会被操作系统主动挂起，需要自己拥有调度控制能力（放在并行环境下面还是挺麻烦的一件事）等等问题。4、把线程放到 user space 的可以避免陷入 system call 进行上下文切换以及高速缓冲更新，线程本身以及切换等操作可以做得非常的轻量。这也就是 golang 这类语言反复提及的超高并发能力，分分钟给你开上几千个线程不费力。5、golang 的并发调度在 IO 等易发阻塞的时候才会发生，一般是内封在库函数内；erlang 则更夸张，对每个 coroutine 维持一个计数器，常用语句都会导致这个计数器进行 reduction，一旦到点，立即切换调度函数。6、中断介入程度的不同，导致 erlang 看上去拥有了 preemptive scheduling(抢先调度) 的能力，而 golang 则是 cooperative scheduling 的。golang 一旦写出纯计算死循环，进程内所有会话必死无疑；要有计算量大，少 IO 的函数还得自己主动叫 runtime.Sched() 来进行调度切换。 三、架构3.1、一种 bigworld 手游架构设计进程划分 Gate首先要有一个 Gate（网关）服务器，负责客户端连接及消息转发到 Game（游戏服），保持客户端到服务端的连接。没有任何逻辑，只做消息加密和解密，以及客户端和服务器消息的转发（相当于两者之间的桥梁）。 GameServerGameServer 是游戏进程，提供游戏逻辑功能（采用单进程（或者单线程）模型，游戏服务器的瓶颈从来不在 CPU，所以只做逻辑功能的话单线程足够了，在这里没必要用多线程或多进程）。 DBManager实现数据库的读写，方便 Game 服务器异步读写数据库的数据（有些把数据库读写放在游戏服，没有单独的服务器，那恐怕游戏服单进程就不够用了）。 GameManager负责管理所有的 GameServer，GameServer 之间消息转发，提供广播到所有 Game 的功能。 协议 客户端与服务器之间协议通信，可以用 tcp 或者 http。主要看游戏模型，如果是那种弱联网单机玩法，用 http 足够了，像天天酷跑之类，只在需要的时候处理一条 http 请求响应。 不过 tcp 用的比较还是比较多的。现在的网络游戏大多数都是 tcp，像 MMORPG 类游戏。我们现在的游戏就是同时用了 http 和 tcp，客户端和游戏服采用 http 协议。只有多人战斗转向战斗服才采用 tcp 长链接。 其实游戏是有 udp 的，在一些高效率的场景下比如 pvp 即时战斗，tcp 的拥塞控制和超时重传并不适合，有些就用的 udp，然后自己做丢包重发，拿网络公平性换游戏局部的效率。 存盘 有数据库就肯定有数据库读写操作，最主要的还是存盘（save），周期存盘还是即时存盘。 即时存盘就是每一次操作数据都存到数据库，当然这样会导致对数据库的操作过于频繁，这是效率的瓶颈之一。 周期存盘也叫固定存盘，就是每隔固定时间存盘一次，比如 10 秒或者 15 秒，这样数据库的压力就会小很多，当然自己就要在内存中做好数据操作，防止数据污染或者存盘不上导致回档。 开源技术 protobuf全称 Google Protocol Buffers，是 google 开发的的一套用于数据存储，网络通信时用于协议编解码的工具库。它和 XML 或者 JSON 差不多，也就是把某种数据结构的信息，以某种格式（XML、JSON）保存起来。protobuf 与 XML 和 JSON 不同在于，protobuf 是基于二进制的，主要用于数据存储、传输协议格式等场合。 zeromq消息队列，一个稳健、简洁的多进程通讯方案的基础。ZeroMQ 并不是一个对 socket 的封装，不能用它去实现已有的网络协议。它有自己的模式，不同于更底层的点对点通讯模式。它有比 tcp 协议更高一级的协议。（当然 ZeroMQ 不一定基于 TCP 协议，它也可以用于进程间和进程内通讯。）它改变了通讯都基于一对一的连接这个假设。在这里它更适合服务器与服务器之间的通信，比如逻辑服和战斗服之间进行通信。 memcached一个高性能的分布式内存对象缓存系统，用于动态 Web 应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。可以用来做缓存，比如客户端本来每次操作都需要操作数据库，会严重影响效率，这时在中间加一层缓存系统，就提升了性能。基于 http 协议的通信用 memcached 是一个不错的选择，如果是 tcp 长链接，直接维护一个在线的内存对象就可以了。类似的技术还有 redis 等。 tcmalloc内存性能分析 distcc分布式编译工具，之前每次修改代码都要 make 半个小时，用 distcc 多台电脑同时帮你编译，速度快很多。 3.2、为什么像王者荣耀这样的游戏 Server 不愿意使用微服务？1、回答一 比如 moba 类游戏/王者荣耀/LOL，就看王者荣耀的客户端吧，想象一下。 账号系统，符文系统，英雄系统，皮肤系统，好友系统，好友之间 messaging，这些都是常规操作，如果流量足够大，当然可以用微服务的架构去做。 不过这不是这个游戏的核心，核心是 MOBA：Multiplayer online battle arena。特性是什么？ 10 个人之间各种游戏事件的高速多向通讯 streaming/broadcast/multicast/pubsub 各种通讯模式。 所以游戏的核心在于小规模群体之间的高速网络通信。就是对方说的 realtime。多了一个 10ms 的延迟玩家就接受不了了。 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。更别说什么 service mesh，各种 gateway，proxy，sidecar，简直就是担心延迟太低。 微服务基本只有 request/response 的模式。做不了 streaming？微服务通常要求应用是无状态的才能做到水平扩展。streaming 本身就是加入了状态。 我可以想像，为了提高通讯的性能，一场英雄联盟游戏很可能会使用同一个服务器负责这 10 个玩家之间的通讯，这样就使得数据可以在本地交换，性能最大化。这对客户端或者说服务端统一网关的要求是必须支持 sticky routing。假设客户端连接断了，接下来的必须重连之前的同一个服务器。微服务的 stateless，水平扩展要求本身就是反 sticky routing 的，因为 sticky routing 本身就是状态。 对服务端集群来说，同时有无数个王者荣耀的比赛在进行，每个都可以看成一个沙盒，每个沙盒都处于一个不同的状态：塔被推了几个了，你被杀了几次了，对面几个超神了，20 分钟到了没。这些都是长时间存在的状态，直到游戏结束，服务端才可以清理一场游戏的状态。所以虽然不用把这些状态写进持久性存储，但是必然会在内存中存在很长时间，都是状态，反正有状态，就别想用微服务。除非你说把这些状态都移到 redis 里去，那么在服务器在信息流传输到一半还要做一个 remote request，一来一回，延迟就上升了，总之怎样都不好。（比如想象对方在 A 你的水晶，每一次 A 的操作都是一个 event，被 streaming 到服务端的沙盒中，沙盒中有一个流处理器，每次接收到一个你水晶被 A 的 event 都会计算一下你水晶爆了没。这个计算需要极快，你是不可能把你水晶生命值的数据存在远端的。） 像这类游戏，都是对网络，内存，CPU 的优化需求很高，整个游戏进行过程中，几乎不存在什么 RPC call，真的需要 remote data，也应该是prefetch，就是在游戏刚开始的时候加载好。 微服务不是什么银弹，也就是方便拆解一下原来的 CRUD 应用罢了而已，一没触及高级的交互方式，二没触及分布式系统真正的难点：状态，其实没有大家想的那么有用。之所以感觉上好像微服务改变了互联网，只不过 90% 的互联网应用都只是简单小规模的 CRUD 而已。 对方没有听说过微服务完全没有问题，因为这本身就不是什么高深的概念，反而对方听你说一下就知道微服务不适合游戏，说明对方理解能力很强，对游戏系统设计也了解足够深。 2、回答二 微服务本身是为了应对业务逻辑的复杂，需要新的组织接口的方式。游戏本身逻辑其实没有这么复杂，比如大厅就是一些基本功能，修改帐号，登录等。游戏本身就是游戏本身的逻辑。 游戏逻辑服务器本身（比如斗地主等棋牌）因为网络响应性能要求问题（玩家对每个操作的反馈时长敏感度远高于业务系统），所以游戏服务器都是有状态的，状态就存在内存，偶尔会接受 redis，mysql 等是绝对不可以的接受的，关系型数据库仅用来定时异步持久化数据，仅游戏服务器而言持久化在 redis 即可。 游戏服务器一般需要主动推送，所以第一代微服务网关就没办法满足需求，tcp 的没有网关用，spring cloud gateway 的 web socket 也许可以用（但是从防攻击角度讲端游用 TCP 绝对比 web socket 合理）。 服务间通信 rpc 首先 ribbon、feign 等并不是合适，因为都是基于 http 的，用 http 存在一个消息乱序问题，比如玩家出牌两次，在http 就可能出现次序不一致。游戏服务器集群一般使用长连接互联。 游戏逻辑服务器（比如斗地主服务器），一般是不能用 spring mvc 做的，因为线程模型完全不同。多线程模型处理游戏性能差还非常复杂，一般都是使用单进程/线程驱动固定数量房间的方式（这也是为何服务器一定有状态，一定不能直接读写 mysql）。一般就直接 netty 了。 自动扩容在游戏这边叫做开服，早就有固定流程和工具和限流方式了。 游戏很多操作不存在服务降级熔断，不行就要直接报错给用户。 大厅服务器登录注册等的确可以做微服务，但是其实也不是做微服务，就是几个接口有自动水平扩容的方案即可。服务注册发现用处不大，开服都是确定的事情，还有一系列运营手段配合，关服也是绝对不能随便关的。 游戏处理的流量真的不算多，你在线 1 万的棋牌游戏已经很赚钱了，10W 就是个特别厉害的产品了。 一些独立的服务器比如充值之类的需要微服务化么？只能说这种服务器都需要微服务处理了，项目组做梦都能笑醒。 虽然上面说了很多点，但是其实也是可以考虑用 spring cloud 改造的，因为游戏集群一样有注册中心，需要服务发现，需要编排启动顺序，只是spring cloud 没有为了游戏设计而已，比如至少要完全支持 webflux吧，需要一个单线程的长连接最好支持 protobuf rpc 框架吧（集成服务发现相关功能与接口），网关支持 tcp 或者至少封装或者暴露一些 netty 的 decoder encoder（或者允许注入）等等。 3.3、游戏中排行榜的实现游戏开发中排行榜经常出现，接触过的排行榜有两种。一种是由玩家挑战排名比自己靠前的其他玩家，胜利后交换位置；另一种是根据玩家的某特性对所有玩家进行排序。第一种只涉及到两个玩家数据的变化，实现起来比较简单，因此只记录第二种情况。 1、需求 排行榜内容是有序的所有玩家信息（以等级为例） 玩家等级变化后，更新排行榜 根据玩家 id 获取在排行榜中的排名 获取排行榜中特定排名的玩家 2、思路 思路一如果用关系型数据库的话，实现排行版比较简单，一条 SQL 即可。由于游戏服务器并发量大、排行榜数据变化频繁，用 SQL 显然不合适。 思路二用数组作为排行榜存放玩家信息并对其进行排序。有新玩家加入或玩家等级变化时，重新排序。这样的好处是获取特定排名的玩家时很快，时间复杂度仅仅是 O(1)。但是获取某玩家的排名时需要遍历整个数组，时间复杂度是 O(n)。有新玩家加入或玩家信息有变化时，需要重新排序，以归并排序为例，其平均时间复杂度为 O(nlogn)。每次更新排行榜都需要排序，不断地排序似乎并不优雅。于是考虑定期排序，如每分钟排一次序。 思路三思路二的情况下，如果某玩家的排名上升了 1000 名，操作数组就要把被他超越的 1000 个玩家数据都向后移动。于是考虑了使用链表替代数组。但是这就带来了新的问题，通过排名获取玩家时，就要遍历链表，思路二中这个操作的时间复杂度为 O(1)，现在就变成了 O(n)。故不能使用链表，或者说不能直接使用普通的链表。 思路四借助 Redis。用 Redis 的 zset 来处理排行榜。 思路五用 ssdb，是兼容 Redis 的 api。 3、zset 的 golang 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622package zsetimport ( \"math/rand\")const zSkiplistMaxlevel = 32type ( skipListLevel struct { forward *skipListNode span uint64 } skipListNode struct { objID int64 score float64 backward *skipListNode level []*skipListLevel } obj struct { key int64 attachment interface{} score float64 } skipList struct { header *skipListNode tail *skipListNode length int64 level int16 } // SortedSet is the final exported sorted set we can use SortedSet struct { dict map[int64]*obj zsl *skipList } zrangespec struct { min float64 max float64 minex int32 maxex int32 } zlexrangespec struct { minKey int64 maxKey int64 minex int maxex int })func zslCreateNode(level int16, score float64, id int64) *skipListNode { n := &amp;skipListNode{ score: score, objID: id, level: make([]*skipListLevel, level), } for i := range n.level { n.level[i] = new(skipListLevel) } return n}func zslCreate() *skipList { return &amp;skipList{ level: 1, header: zslCreateNode(zSkiplistMaxlevel, 0, 0), }}const zSkiplistP = 0.25 /* Skiplist P = 1/4 *//* Returns a random level for the new skiplist node we are going to create. * The return value of this function is between 1 and _ZSKIPLIST_MAXLEVEL * (both inclusive), with a powerlaw-alike distribution where higher * levels are less likely to be returned. */func randomLevel() int16 { level := int16(1) for float32(rand.Int31()&amp;0xFFFF) &lt; (zSkiplistP * 0xFFFF) { level++ } if level &lt; zSkiplistMaxlevel { return level } return zSkiplistMaxlevel}/* zslInsert a new node in the skiplist. Assumes the element does not already * exist (up to the caller to enforce that). The skiplist takes ownership * of the passed SDS string 'obj'. */func (zsl *skipList) zslInsert(score float64, id int64) *skipListNode { update := make([]*skipListNode, zSkiplistMaxlevel) rank := make([]uint64, zSkiplistMaxlevel) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { /* store rank that is crossed to reach the insert position */ if i == zsl.level-1 { rank[i] = 0 } else { rank[i] = rank[i+1] } if x.level[i] != nil { for x.level[i].forward != nil &amp;&amp; (x.level[i].forward.score &lt; score || (x.level[i].forward.score == score &amp;&amp; x.level[i].forward.objID &lt; id)) { rank[i] += x.level[i].span x = x.level[i].forward } } update[i] = x } /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ level := randomLevel() if level &gt; zsl.level { for i := zsl.level; i &lt; level; i++ { rank[i] = 0 update[i] = zsl.header update[i].level[i].span = uint64(zsl.length) } zsl.level = level } x = zslCreateNode(level, score, id) for i := int16(0); i &lt; level; i++ { x.level[i].forward = update[i].level[i].forward update[i].level[i].forward = x /* update span covered by update[i] as x is inserted here */ x.level[i].span = update[i].level[i].span - (rank[0] - rank[i]) update[i].level[i].span = (rank[0] - rank[i]) + 1 } /* increment span for untouched levels */ for i := level; i &lt; zsl.level; i++ { update[i].level[i].span++ } if update[0] == zsl.header { x.backward = nil } else { x.backward = update[0] } if x.level[0].forward != nil { x.level[0].forward.backward = x } else { zsl.tail = x } zsl.length++ return x}/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank */func (zsl *skipList) zslDeleteNode(x *skipListNode, update []*skipListNode) { for i := int16(0); i &lt; zsl.level; i++ { if update[i].level[i].forward == x { update[i].level[i].span += x.level[i].span - 1 update[i].level[i].forward = x.level[i].forward } else { update[i].level[i].span-- } } if x.level[0].forward != nil { x.level[0].forward.backward = x.backward } else { zsl.tail = x.backward } for zsl.level &gt; 1 &amp;&amp; zsl.header.level[zsl.level-1].forward == nil { zsl.level-- } zsl.length--}/* Delete an element with matching score/element from the skiplist. * The function returns 1 if the node was found and deleted, otherwise * 0 is returned. * * If 'node' is NULL the deleted node is freed by zslFreeNode(), otherwise * it is not freed (but just unlinked) and *node is set to the node pointer, * so that it is possible for the caller to reuse the node (including the * referenced SDS string at node-&gt;obj). */func (zsl *skipList) zslDelete(score float64, id int64) int { update := make([]*skipListNode, zSkiplistMaxlevel) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil &amp;&amp; (x.level[i].forward.score &lt; score || (x.level[i].forward.score == score &amp;&amp; x.level[i].forward.objID &lt; id)) { x = x.level[i].forward } update[i] = x } /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. */ x = x.level[0].forward if x != nil &amp;&amp; score == x.score &amp;&amp; x.objID == id { zsl.zslDeleteNode(x, update) return 1 } return 0 /* not found */}func zslValueGteMin(value float64, spec *zrangespec) bool { if spec.minex != 0 { return value &gt; spec.min } return value &gt;= spec.min}func zslValueLteMax(value float64, spec *zrangespec) bool { if spec.maxex != 0 { return value &lt; spec.max } return value &lt;= spec.max}/* Returns if there is a part of the zset is in range. */func (zsl *skipList) zslIsInRange(ran *zrangespec) bool { /* Test for ranges that will always be empty. */ if ran.min &gt; ran.max || (ran.min == ran.max &amp;&amp; (ran.minex != 0 || ran.maxex != 0)) { return false } x := zsl.tail if x == nil || !zslValueGteMin(x.score, ran) { return false } x = zsl.header.level[0].forward if x == nil || !zslValueLteMax(x.score, ran) { return false } return true}/* Find the first node that is contained in the specified range. * Returns NULL when no element is contained in the range. */func (zsl *skipList) zslFirstInRange(ran *zrangespec) *skipListNode { /* If everything is out of range, return early. */ if !zsl.zslIsInRange(ran) { return nil } x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { /* Go forward while *OUT* of range. */ for x.level[i].forward != nil &amp;&amp; !zslValueGteMin(x.level[i].forward.score, ran) { x = x.level[i].forward } } /* This is an inner range, so the next node cannot be NULL. */ x = x.level[0].forward //serverAssert(x != NULL); /* Check if score &lt;= max. */ if !zslValueLteMax(x.score, ran) { return nil } return x}/* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. */func (zsl *skipList) zslLastInRange(ran *zrangespec) *skipListNode { /* If everything is out of range, return early. */ if !zsl.zslIsInRange(ran) { return nil } x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { /* Go forward while *IN* range. */ for x.level[i].forward != nil &amp;&amp; zslValueLteMax(x.level[i].forward.score, ran) { x = x.level[i].forward } } /* This is an inner range, so this node cannot be NULL. */ //serverAssert(x != NULL); /* Check if score &gt;= min. */ if !zslValueGteMin(x.score, ran) { return nil } return x}/* Delete all the elements with score between min and max from the skiplist. * Min and max are inclusive, so a score &gt;= min || score &lt;= max is deleted. * Note that this function takes the reference to the hash table view of the * sorted set, in order to remove the elements from the hash table too. */func (zsl *skipList) zslDeleteRangeByScore(ran *zrangespec, dict map[int64]*obj) uint64 { removed := uint64(0) update := make([]*skipListNode, zSkiplistMaxlevel) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil { var condition bool if ran.minex != 0 { condition = x.level[i].forward.score &lt;= ran.min } else { condition = x.level[i].forward.score &lt; ran.min } if !condition { break } x = x.level[i].forward } update[i] = x } /* Current node is the last with score &lt; or &lt;= min. */ x = x.level[0].forward /* Delete nodes while in range. */ for x != nil { var condition bool if ran.maxex != 0 { condition = x.score &lt; ran.max } else { condition = x.score &lt;= ran.max } if !condition { break } next := x.level[0].forward zsl.zslDeleteNode(x, update) delete(dict, x.objID) // Here is where x-&gt;obj is actually released. // And golang has GC, don't need to free manually anymore //zslFreeNode(x) removed++ x = next } return removed}func (zsl *skipList) zslDeleteRangeByLex(ran *zlexrangespec, dict map[int64]*obj) uint64 { removed := uint64(0) update := make([]*skipListNode, zSkiplistMaxlevel) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil &amp;&amp; !zslLexValueGteMin(x.level[i].forward.objID, ran) { x = x.level[i].forward } update[i] = x } /* Current node is the last with score &lt; or &lt;= min. */ x = x.level[0].forward /* Delete nodes while in range. */ for x != nil &amp;&amp; zslLexValueLteMax(x.objID, ran) { next := x.level[0].forward zsl.zslDeleteNode(x, update) delete(dict, x.objID) removed++ x = next } return removed}func zslLexValueGteMin(id int64, spec *zlexrangespec) bool { if spec.minex != 0 { return compareKey(id, spec.minKey) &gt; 0 } return compareKey(id, spec.minKey) &gt;= 0}func compareKey(a, b int64) int8 { if a == b { return 0 } else if a &gt; b { return 1 } return -1}func zslLexValueLteMax(id int64, spec *zlexrangespec) bool { if spec.maxex != 0 { return compareKey(id, spec.maxKey) &lt; 0 } return compareKey(id, spec.maxKey) &lt;= 0}/* Delete all the elements with rank between start and end from the skiplist. * Start and end are inclusive. Note that start and end need to be 1-based */func (zsl *skipList) zslDeleteRangeByRank(start, end uint64, dict map[int64]*obj) uint64 { update := make([]*skipListNode, zSkiplistMaxlevel) var traversed, removed uint64 x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil &amp;&amp; (traversed+x.level[i].span) &lt; start { traversed += x.level[i].span x = x.level[i].forward } update[i] = x } traversed++ x = x.level[0].forward for x != nil &amp;&amp; traversed &lt;= end { next := x.level[0].forward zsl.zslDeleteNode(x, update) delete(dict, x.objID) removed++ traversed++ x = next } return removed}/* Find the rank for an element by both score and obj. * Returns 0 when the element cannot be found, rank otherwise. * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. */func (zsl *skipList) zslGetRank(score float64, key int64) int64 { rank := uint64(0) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil &amp;&amp; (x.level[i].forward.score &lt; score || (x.level[i].forward.score == score &amp;&amp; x.level[i].forward.objID &lt;= key)) { rank += x.level[i].span x = x.level[i].forward } /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ if x.objID == key { return int64(rank) } } return 0}/* Finds an element by its rank. The rank argument needs to be 1-based. */func (zsl *skipList) zslGetElementByRank(rank uint64) *skipListNode { traversed := uint64(0) x := zsl.header for i := zsl.level - 1; i &gt;= 0; i-- { for x.level[i].forward != nil &amp;&amp; (traversed+x.level[i].span) &lt;= rank { traversed += x.level[i].span x = x.level[i].forward } if traversed == rank { return x } } return nil}/*----------------------------------------------------------------------------- * Common sorted set API *----------------------------------------------------------------------------*/// New creates a new SortedSet and return its pointerfunc New() *SortedSet { s := &amp;SortedSet{ dict: make(map[int64]*obj), zsl: zslCreate(), } return s}// Length returns counts of elementsfunc (z *SortedSet) Length() int64 { return z.zsl.length}// Set is used to add or update an elementfunc (z *SortedSet) Set(score float64, key int64, dat interface{}) { v, ok := z.dict[key] z.dict[key] = &amp;obj{attachment: dat, key: key, score: score} if ok { /* Remove and re-insert when score changes. */ if score != v.score { z.zsl.zslDelete(v.score, key) z.zsl.zslInsert(score, key) } } else { z.zsl.zslInsert(score, key) }}// IncrBy ..func (z *SortedSet) IncrBy(score float64, key int64) (float64, interface{}) { v, ok := z.dict[key] if !ok { // use negative infinity ? return 0, nil } if score != 0 { z.zsl.zslDelete(v.score, key) v.score += score z.zsl.zslInsert(v.score, key) } return v.score, v.attachment}// Delete removes an element from the SortedSet// by its key.func (z *SortedSet) Delete(key int64) (ok bool) { v, ok := z.dict[key] if ok { z.zsl.zslDelete(v.score, key) delete(z.dict, key) return true } return false}// GetRank returns position,score and extra data of an element which// found by the parameter key.// The parameter reverse determines the rank is descent or ascend，// true means descend and false means ascend.func (z *SortedSet) GetRank(key int64, reverse bool) (rank int64, score float64, data interface{}) { v, ok := z.dict[key] if !ok { return -1, 0, nil } r := z.zsl.zslGetRank(v.score, key) if reverse { r = z.zsl.length - r } else { r-- } return int64(r), v.score, v.attachment}// GetData returns data stored in the map by its keyfunc (z *SortedSet) GetData(key int64) (data interface{}, ok bool) { o, ok := z.dict[key] if !ok { return nil, false } return o.attachment, true}// GetDataByRank returns the id,score and extra data of an element which// found by position in the rank.// The parameter rank is the position, reverse says if in the descend rank.func (z *SortedSet) GetDataByRank(rank int64, reverse bool) (key int64, score float64, data interface{}) { if rank &lt; 0 || rank &gt; z.zsl.length { return 0, 0, nil } if reverse { rank = z.zsl.length - rank } else { rank++ } n := z.zsl.zslGetElementByRank(uint64(rank)) if n == nil { return 0, 0, nil } dat, _ := z.dict[n.objID] if dat == nil { return 0, 0, nil } return dat.key, dat.score, dat.attachment}// Range implements ZRANGEfunc (z *SortedSet) Range(start, end int64, f func(float64, int64, interface{})) { z.commonRange(start, end, false, f)}// RevRange implements ZREVRANGEfunc (z *SortedSet) RevRange(start, end int64, f func(float64, int64, interface{})) { z.commonRange(start, end, true, f)}func (z *SortedSet) commonRange(start, end int64, reverse bool, f func(float64, int64, interface{})) { l := z.zsl.length if start &lt; 0 { start += l if start &lt; 0 { start = 0 } } if end &lt; 0 { end += l } if start &gt; end || start &gt;= l { return } if end &gt;= l { end = l - 1 } span := (end - start) + 1 var node *skipListNode if reverse { node = z.zsl.tail if start &gt; 0 { node = z.zsl.zslGetElementByRank(uint64(l - start)) } } else { node = z.zsl.header.level[0].forward if start &gt; 0 { node = z.zsl.zslGetElementByRank(uint64(start + 1)) } } for span &gt; 0 { span-- k := node.objID s := node.score f(s, k, z.dict[k].attachment) if reverse { node = node.backward } else { node = node.level[0].forward } }} 参考文章:1、使用 Go 语言开发大型 MMORPG 游戏服务器怎么样？2、手游服务器开发技术详解3、golang笔记：游戏中排行榜的实现","link":"/post/1c48c532.html"},{"title":"Linux的epoll使用LT+非阻塞IO和ET+非阻塞IO的区别(转载)","text":"综合 select 和 poll 的一些优缺点，Linux 从内核2.6版本开始引入了更高效的 epoll 模型。 与 poll 的事件宏相比，epoll 新增了一个事件宏 EPOLLET，这就是所谓的边缘触发模式（Edge Trigger，ET），而默认的模式我们称为 水平触发模式（Level Trigger，LT）。这两种模式的区别在于： 对于水平触发模式，一个事件只要有，就会一直触发； 对于边缘触发模式，只有一个事件从无到有才会触发。 这两个词汇来自电学术语，你可以将 fd 上有数据认为是高电平，没有数据认为是低电平，将 fd 可写认为是高电平，fd 不可写认为是低电平。那么水平模式的触发条件是状态处于高电平，而边缘模式的触发条件是新来一次电信号将当前状态变为高电平，即： 水平模式的触发条件 121. 低电平 =&gt; 高电平2. 处于高电平状态 边缘模式的触发条件 11. 低电平 =&gt; 高电平 说的有点抽象，以 socket 的读事件为例，对于水平模式，只要 socket 上有未读完的数据，就会一直产生 EPOLLIN 事件；而对于边缘模式，socket 上每新来一次数据就会触发一次，如果上一次触发后，未将 socket 上的数据读完，也不会再触发，除非再新来一次数据。对于 socket 写事件，如果 socket 的 TCP 窗口一直不饱和，会一直触发 EPOLLOUT 事件；而对于边缘模式，只会触发一次，除非 TCP 窗口由不饱和变成饱和再一次变成不饱和，才会再次触发 EPOLLOUT 事件。 socket 可读事件水平模式触发条件： 121. socket上无数据 =&gt; socket上有数据2. socket处于有数据状态 socket 可读事件边缘模式触发条件： 121. socket上无数据 =&gt; socket上有数据2. socket又新来一次数据 socket 可写事件水平模式触发条件： 121. socket可写 =&gt; socket可写2. socket不可写 =&gt; socket可写 socket 可写事件边缘模式触发条件： 11. socket不可写 =&gt; socket可写 也就是说，如果对于一个非阻塞 socket，如果使用 epoll 边缘模式去检测数据是否可读，触发可读事件以后，一定要一次性把 socket 上的数据收取干净才行，也就是说一定要循环调用 recv 函数直到 recv 出错，错误码是 EWOULDBLOCK（EAGAIN 一样）（此时表示 socket 上本次数据已经读完）；如果使用水平模式，则不用，你可以根据业务一次性收取固定的字节数，或者收完为止。边缘模式下收取数据的代码写法示例如下： 1234567891011121314151617181920212223242526bool TcpSession::RecvEtMode(){ //每次只收取256个字节 char buff[256]; while (true) { int nRecv = ::recv(clientfd_, buff, 256, 0); if (nRecv == -1) { if (errno == EWOULDBLOCK) return true; else if (errno == EINTR) continue; return false; } //对端关闭了socket else if (nRecv == 0) return false; inputBuffer_.add(buff, (size_t)nRecv); } return true;} 下面我们来看几个具体的例子来比较一下 LT 模式与 ET 模式的区别。 先来测试一下 LT 模式 与 ET 模式在处理读事件上的区别。 代码如下： >folded epoll_server.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190/** * 验证epoll的LT与ET模式的区别, epoll_server.cpp */#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;unistd.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/epoll.h&gt;#include&lt;poll.h&gt;#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;vector&gt;#include&lt;errno.h&gt;#include&lt;iostream&gt;int main(){ //创建一个监听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout &lt;&lt; \"create listen socket error\" &lt;&lt; std::endl; return -1; } //设置重用ip地址和端口号 int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, (char*)&amp;on, sizeof(on)); setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT, (char*)&amp;on, sizeof(on)); //将监听socker设置为非阻塞的 int oldSocketFlag = fcntl(listenfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(listenfd, F_SETFL, newSocketFlag) == -1) { close(listenfd); std::cout &lt;&lt; \"set listenfd to nonblock error\" &lt;&lt; std::endl; return -1; } //初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr*)&amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout &lt;&lt; \"bind listen socker error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //启动监听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout &lt;&lt; \"listen error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //创建epollfd int epollfd = epoll_create(1); if (epollfd == -1) { std::cout &lt;&lt; \"create epollfd error.\" &lt;&lt; std::endl; close(listenfd); return -1; } epoll_event listen_fd_event; listen_fd_event.data.fd = listenfd; listen_fd_event.events = EPOLLIN; //取消注释掉这一行，则使用ET模式 //listen_fd_event.events |= EPOLLET; //将监听sokcet绑定到epollfd上去 if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listenfd, &amp;listen_fd_event) == -1) { std::cout &lt;&lt; \"epoll_ctl error\" &lt;&lt; std::endl; close(listenfd); return -1; } int n; while (true) { epoll_event epoll_events[1024]; n = epoll_wait(epollfd, epoll_events, 1024, 1000); if (n &lt; 0) { //被信号中断 if (errno == EINTR) continue; //出错,退出 break; } else if (n == 0) { //超时,继续 continue; } for (size_t i = 0; i &lt; n; ++i) { //事件可读 if (epoll_events[i].events &amp; EPOLLIN) { if (epoll_events[i].data.fd == listenfd) { //侦听socket,接受新连接 struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); int clientfd = accept(listenfd, (struct sockaddr*)&amp;clientaddr, &amp;clientaddrlen); if (clientfd != -1) { int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFD, newSocketFlag) == -1) { close(clientfd); std::cout &lt;&lt; \"set clientfd to nonblocking error.\" &lt;&lt; std::endl; } else { epoll_event client_fd_event; client_fd_event.data.fd = clientfd; client_fd_event.events = EPOLLIN; //取消注释这一行，则使用ET模式 //client_fd_event.events |= EPOLLET; if (epoll_ctl(epollfd, EPOLL_CTL_ADD, clientfd, &amp;client_fd_event) != -1) { std::cout &lt;&lt; \"new client accepted,clientfd: \" &lt;&lt; clientfd &lt;&lt; std::endl; } else { std::cout &lt;&lt; \"add client fd to epollfd error\" &lt;&lt; std::endl; close(clientfd); } } } } else { std::cout &lt;&lt; \"client fd: \" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \" recv data.\" &lt;&lt; std::endl; //普通clientfd char ch; //每次只收一个字节 int m = recv(epoll_events[i].data.fd, &amp;ch, 1, 0); if (m == 0) { //对端关闭了连接，从epollfd上移除clientfd if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } else if (m &lt; 0) { //出错 if (errno != EWOULDBLOCK &amp;&amp; errno != EINTR) { if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } } else { //正常收到数据 std::cout &lt;&lt; \"recv from client:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \", \" &lt;&lt; ch &lt;&lt; std::endl; } } } else if (epoll_events[i].events &amp; EPOLLERR) { // TODO 暂不处理 } } } close(listenfd); return 0;} 我们先来看水平模式的行为，将代码 79 行和 134 行注释掉则使用 LT 模式，我们编译下程序并运行： 12345ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ vim epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ g++ -g -o epoll_server epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ lsepoll_server epoll_server.cppubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server 然后再另外开启一个 shell 窗口，使用 nc 命令模拟一个客户端，连接服务器成功后，我们给服务器发送一个消息“abcef”： 123ubuntu@VM-0-9-ubuntu:~$ nc -v 127.0.0.1 3000Connection to 127.0.0.1 3000 port [tcp/*] succeeded!abdcef 此时服务器端输出： 12345678910111213141516ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server new client accepted,clientfd: 5client fd: 5 recv data.recv from client:5, aclient fd: 5 recv data.recv from client:5, bclient fd: 5 recv data.recv from client:5, dclient fd: 5 recv data.recv from client:5, cclient fd: 5 recv data.recv from client:5, eclient fd: 5 recv data.recv from client:5, fclient fd: 5 recv data.recv from client:5, nc 命令实际发送了 a、b、c、d、e、f 和 \\n 七个字符，由于服务器端使用的是 LT 模式，每次接收一个字符，只要 socket 接收缓冲区中仍有数据可读，POLLIN 事件就会一直触发，所以服务器一共有 7 次输出，直到 socket 接收缓冲区没有数据为止。 我们将代码 79 行和 134 行注释取消掉，使用 ET 模式再试一下，修改代码并重新编译，然后重新运行一下。再次使用 nc 命令模拟一个客户端连接后发送”abcef”，服务器只会有一次输出，效果如下： 123456ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ vim epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ g++ -g -o epoll_server epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server new client accepted,clientfd: 5client fd: 5 recv data.recv from client:5, a 由于使用了 ET 模式，只会触发一次 POLLIN 事件，如果此时没有新数据到来，就再也不会触发。所以，如果我们继续给服务器发送一条新数据，如 123，服务器将再次触发一次 POLLIN 事件，然后打印出字母 b，效果如下： 1234ubuntu@VM-0-9-ubuntu:~$ nc -v 127.0.0.1 3000Connection to 127.0.0.1 3000 port [tcp/*] succeeded!abdcef123 12345678ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ vim epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ g++ -g -o epoll_server epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server new client accepted,clientfd: 5client fd: 5 recv data.recv from client:5, aclient fd: 5 recv data.recv from client:5, b 所以如果使用 ET 模式 处理读事件，切记要将该次 socket 上的数据收完。 再来测试一下 LT 模式 与 ET 模式在处理写事件上的区别。 修改上述代码如下： >folded 点击>查看 epoll_server.cpp(EPOLLOUT LT)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200/** * 验证epoll的LT与ET模式的区别, epoll_server.cpp */#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;unistd.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/epoll.h&gt;#include&lt;poll.h&gt;#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;vector&gt;#include&lt;errno.h&gt;#include&lt;iostream&gt;int main(){ //创建一个监听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout &lt;&lt; \"create listen socket error\" &lt;&lt; std::endl; return -1; } //设置重用ip地址和端口号 int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, (char*)&amp;on, sizeof(on)); setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT, (char*)&amp;on, sizeof(on)); //将监听socker设置为非阻塞的 int oldSocketFlag = fcntl(listenfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(listenfd, F_SETFL, newSocketFlag) == -1) { close(listenfd); std::cout &lt;&lt; \"set listenfd to nonblock error\" &lt;&lt; std::endl; return -1; } //初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr*)&amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout &lt;&lt; \"bind listen socker error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //启动监听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout &lt;&lt; \"listen error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //创建epollfd int epollfd = epoll_create(1); if (epollfd == -1) { std::cout &lt;&lt; \"create epollfd error.\" &lt;&lt; std::endl; close(listenfd); return -1; } epoll_event listen_fd_event; listen_fd_event.data.fd = listenfd; listen_fd_event.events = EPOLLIN; //取消注释掉这一行，则使用ET模式 //listen_fd_event.events |= EPOLLET; //将监听sokcet绑定到epollfd上去 if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listenfd, &amp;listen_fd_event) == -1) { std::cout &lt;&lt; \"epoll_ctl error\" &lt;&lt; std::endl; close(listenfd); return -1; } int n; while (true) { epoll_event epoll_events[1024]; n = epoll_wait(epollfd, epoll_events, 1024, 1000); if (n &lt; 0) { //被信号中断 if (errno == EINTR) continue; //出错,退出 break; } else if (n == 0) { //超时,继续 continue; } for (size_t i = 0; i &lt; n; ++i) { //事件可读 if (epoll_events[i].events &amp; EPOLLIN) { if (epoll_events[i].data.fd == listenfd) { //侦听socket,接受新连接 struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); int clientfd = accept(listenfd, (struct sockaddr*)&amp;clientaddr, &amp;clientaddrlen); if (clientfd != -1) { int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFD, newSocketFlag) == -1) { close(clientfd); std::cout &lt;&lt; \"set clientfd to nonblocking error.\" &lt;&lt; std::endl; } else { epoll_event client_fd_event; client_fd_event.data.fd = clientfd; //同时侦听新来连接socket的读和写事件 client_fd_event.events = EPOLLIN | EPOLLOUT; //取消注释这一行，则使用ET模式 //client_fd_event.events |= EPOLLET; if (epoll_ctl(epollfd, EPOLL_CTL_ADD, clientfd, &amp;client_fd_event) != -1) { std::cout &lt;&lt; \"new client accepted,clientfd: \" &lt;&lt; clientfd &lt;&lt; std::endl; } else { std::cout &lt;&lt; \"add client fd to epollfd error\" &lt;&lt; std::endl; close(clientfd); } } } } else { std::cout &lt;&lt; \"client fd: \" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \" recv data.\" &lt;&lt; std::endl; //普通clientfd char ch; //每次只收一个字节 int m = recv(epoll_events[i].data.fd, &amp;ch, 1, 0); if (m == 0) { //对端关闭了连接，从epollfd上移除clientfd if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } else if (m &lt; 0) { //出错 if (errno != EWOULDBLOCK &amp;&amp; errno != EINTR) { if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } } else { //正常收到数据 std::cout &lt;&lt; \"recv from client:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \", \" &lt;&lt; ch &lt;&lt; std::endl; } } } else if (epoll_events[i].events &amp; EPOLLOUT) { //只处理客户端fd的可写事件 if (epoll_events[i].data.fd != listenfd) { //打印结果 std::cout &lt;&lt; \"EPOLLOUT triggered,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } } else if (epoll_events[i].events &amp; EPOLLERR) { // TODO 暂不处理 } } } close(listenfd); return 0;} 上述代码中，我们对新来的连接 fd 同时注册读和写事件（代码 133 行），再次编译程序执行： 123ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ vim epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ g++ -g -o epoll_server epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server 然后使用 nc 命令模拟一个客户端去连接 epoll_server： 12ubuntu@VM-0-9-ubuntu:~$ nc -v 127.0.0.1 3000Connection to 127.0.0.1 3000 port [tcp/*] succeeded! 此时服务器端（epoll_server）会疯狂的输出可写事件触发消息： 123456789101112131415161718192021222324252627282930313233EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5EPOLLOUT triggered,clientfd:5E^Cubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ 之所以是这样，是因为我们注册了可写事件且使用的是 LT 模式，LT 模式下，由于这里的服务器端对应的客户端 fd 一直是可写的，有写事件一直触发，所以看到屏幕不断输出。 我们再将服务器端与客户端建立连接时新建的 fd 设置为 ET 模式再实验一下： >folded 点击>查看 epoll_server.cpp(EPOLLOUT ET)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208/** * 验证epoll的LT与ET模式的区别, epoll_server.cpp */#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;unistd.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/epoll.h&gt;#include&lt;poll.h&gt;#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;vector&gt;#include&lt;errno.h&gt;#include&lt;iostream&gt;int main(){ //创建一个监听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout &lt;&lt; \"create listen socket error\" &lt;&lt; std::endl; return -1; } //设置重用ip地址和端口号 int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, (char*)&amp;on, sizeof(on)); setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT, (char*)&amp;on, sizeof(on)); //将监听socker设置为非阻塞的 int oldSocketFlag = fcntl(listenfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(listenfd, F_SETFL, newSocketFlag) == -1) { close(listenfd); std::cout &lt;&lt; \"set listenfd to nonblock error\" &lt;&lt; std::endl; return -1; } //初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr*)&amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout &lt;&lt; \"bind listen socker error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //启动监听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout &lt;&lt; \"listen error.\" &lt;&lt; std::endl; close(listenfd); return -1; } //创建epollfd int epollfd = epoll_create(1); if (epollfd == -1) { std::cout &lt;&lt; \"create epollfd error.\" &lt;&lt; std::endl; close(listenfd); return -1; } epoll_event listen_fd_event; listen_fd_event.data.fd = listenfd; listen_fd_event.events = EPOLLIN; //取消注释掉这一行，则使用ET模式 //listen_fd_event.events |= EPOLLET; //将监听sokcet绑定到epollfd上去 if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listenfd, &amp;listen_fd_event) == -1) { std::cout &lt;&lt; \"epoll_ctl error\" &lt;&lt; std::endl; close(listenfd); return -1; } int n; while (true) { epoll_event epoll_events[1024]; n = epoll_wait(epollfd, epoll_events, 1024, 1000); if (n &lt; 0) { //被信号中断 if (errno == EINTR) continue; //出错,退出 break; } else if (n == 0) { //超时,继续 continue; } for (size_t i = 0; i &lt; n; ++i) { //事件可读 if (epoll_events[i].events &amp; EPOLLIN) { if (epoll_events[i].data.fd == listenfd) { //侦听socket,接受新连接 struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); int clientfd = accept(listenfd, (struct sockaddr*)&amp;clientaddr, &amp;clientaddrlen); if (clientfd != -1) { int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFD, newSocketFlag) == -1) { close(clientfd); std::cout &lt;&lt; \"set clientfd to nonblocking error.\" &lt;&lt; std::endl; } else { epoll_event client_fd_event; client_fd_event.data.fd = clientfd; //同时侦听新来连接socket的读和写事件 client_fd_event.events = EPOLLIN | EPOLLOUT; //取消注释这一行，则使用ET模式 client_fd_event.events |= EPOLLET; if (epoll_ctl(epollfd, EPOLL_CTL_ADD, clientfd, &amp;client_fd_event) != -1) { std::cout &lt;&lt; \"new client accepted,clientfd: \" &lt;&lt; clientfd &lt;&lt; std::endl; } else { std::cout &lt;&lt; \"add client fd to epollfd error\" &lt;&lt; std::endl; close(clientfd); } } } } else { std::cout &lt;&lt; \"client fd: \" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \" recv data.\" &lt;&lt; std::endl; //普通clientfd char recvbuf[1024] = { 0 }; int m = recv(epoll_events[i].data.fd, recvbuf, 1024, 0); if (m == 0) { //对端关闭了连接，从epollfd上移除clientfd if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } else if (m &lt; 0) { //出错 if (errno != EWOULDBLOCK &amp;&amp; errno != EINTR) { if (epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout &lt;&lt; \"client disconnected,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } close(epoll_events[i].data.fd); } } else { //正常收到数据 std::cout &lt;&lt; \"recv from client:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; \", \" &lt;&lt; ch &lt;&lt; std::endl; epoll_event client_fd_event; client_fd_event.data.fd = epoll_events[i].data.fd; //再次给clientfd注册检测可写事件 client_fd_event.events = EPOLLIN | EPOLLOUT | EPOLLET; if (epoll_ctl(epollfd, EPOLL_CTL_MOD, epoll_events[i].data.fd, &amp;client_fd_event) != -1) { std::cout &lt;&lt; \"epoll_ctl successfully, mode: EPOLL_CTL_MOD, clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } } } } else if (epoll_events[i].events &amp; EPOLLOUT) { //只处理客户端fd的可写事件 if (epoll_events[i].data.fd != listenfd) { //打印结果 std::cout &lt;&lt; \"EPOLLOUT triggered,clientfd:\" &lt;&lt; epoll_events[i].data.fd &lt;&lt; std::endl; } } else if (epoll_events[i].events &amp; EPOLLERR) { // TODO 暂不处理 } } } close(listenfd); return 0;} 上述逻辑中，服务器端在每次收到客户端消息时会重新给客户端 fd 注册检测可写事件（EPOLLOUT），重新编译代码，启动 epoll_server，再次使用 nc 命令模拟客户端给 epoll_server 发送几条消息，结果如下： 1234567891011121314151617181920ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ vim epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ g++ -g -o epoll_server epoll_server.cpp ubuntu@VM-0-9-ubuntu:~/recipes/epoll_server$ ./epoll_server new client accepted,clientfd: 5EPOLLOUT triggered,clientfd:5client fd: 5 recv data.recv from client:5, helloepoll_ctl successfully, mode: EPOLL_CTL_MOD, clientfd:5EPOLLOUT triggered,clientfd:5client fd: 5 recv data.recv from client:5, worldepoll_ctl successfully, mode: EPOLL_CTL_MOD, clientfd:5EPOLLOUT triggered,clientfd:5client fd: 5 recv data.recv from client:5, !!!epoll_ctl successfully, mode: EPOLL_CTL_MOD, clientfd:5EPOLLOUT triggered,clientfd:5 12345ubuntu@VM-0-9-ubuntu:~$ nc -v 127.0.0.1 3000Connection to 127.0.0.1 3000 port [tcp/*] succeeded!helloworld!!! 通过上述输出，我们可以发现，epoll_server 使用 ET 模式下即使给客户端 fd 注册了检测可写事件不会一直触发，只会触发一次，触发完后只有再次注册检测可写事件才会继续触发，这里是靠客户端来新消息驱动再次注册检测可写事件。也就是说，如果我们使用 ET 模式去处理可写事件时不必像 LT 模式那样为了避免不必要的可写触发在触发后需要立即移除检测可写事件。 这就意味着，使用 LT 模式，如果你的实现依赖于可写事件触发去发送数据，那么你一定要在数据发送完之后移除检测可写事件，避免没有数据发送时无意义的触发；使用 ET 模式时，如果你的实现也依赖于可写事件触发去发送数据，可写事件触发后，你调用 send 函数（Linux 平台也可以使用 write）去发送数据，如果数据本次不能全部发送完（对于非阻塞的 socket，此时 send 函数返回 -1，错误码为 EAGAIN 或 EWOULDBLOCK），你一定要继续注册检测可写事件，否则你剩余的数据就再也没有机会发送了，因为 ET 模式的可写事件再也不会触发。 最后容我再啰嗦几句，总结起来： LT 模式下，读事件触发后，可以按需收取想要的字节数，不用把本次接收到的数据收取干净（即不用循环到 recv 或者 read 函数返回 -1，错误码为 EWOULDBLOCK 或 EAGAIN）；ET 模式下，读事件必须把数据收取干净，因为你不一定有下一次机会再收取数据了，即使有机会，也可能存在上次没读完的数据没有及时处理，造成客户端响应延迟。 LT 模式下，不需要写事件一定要及时移除，避免不必要的触发，浪费 CPU 资源；ET 模式下，写事件触发后，如果还需要下一次的写事件触发来驱动任务（例如发上次剩余的数据），你需要继续注册一次检测可写事件。 LT 模式和 ET 模式各有优缺点，无所谓孰优孰劣。使用 LT 模式，我们可以自由决定每次收取多少字节（对于普通 socket）或何时接收连接（对于侦听 socket），但是可能会导致多次触发；使用 ET 模式，我们必须每次都要将数据收完（对于普通 socket）或必须立即调用 accept 接收连接（对于侦听socket），其优点是触发次数少。 原文链接:epoll LT 模式和 ET 模式详解","link":"/post/baad55eb.html"},{"title":"博客-Markdown使用笔记","text":"markdown写作中有一些小技巧，或者规范，值得记录一下，方便以后查阅使用。 一、技巧1.1、转义字符的使用有时文章里引用了一段名言，署名作者时，会用到”---“这种分割符号，直接加在名句后是不生效的，需要使用”\\“进行转义。如下所示： 123**转眼就是夏天了，野蔷薇快要绿叶满枝，遮掩了它周身的棘刺；苦尽之后会有甘来。****---莎士比亚** 输出如下： 转眼就是夏天了，野蔷薇快要绿叶满枝，遮掩了它周身的棘刺；苦尽之后会有甘来。 -莎士比亚 需要对”-“进行如下的转义： 123**转眼就是夏天了，野蔷薇快要绿叶满枝，遮掩了它周身的棘刺；苦尽之后会有甘来。****\\-\\--莎士比亚** 最后才能正确输出： 转眼就是夏天了，野蔷薇快要绿叶满枝，遮掩了它周身的棘刺；苦尽之后会有甘来。 ---莎士比亚 1.2、使用Markdown输出LaTex数学公式之前使用用hexo的next主题编写数学公式时，是能够正常显示的。hexo clean &amp;&amp; hexo g &amp;&amp; hexo s测试，发现内容页面是公式的原始模样，并未转换。 12345678$$f(x) = \\left\\{ \\begin{array}{lr} 0 &amp; : n=0\\\\ [f(n-1,m)+m] \\%n &amp; : n &gt; 1 \\end{array}\\right.$$ 查看icarus主题的Issue问题记录，发现之前也有人遇到类似问题。 按照给出的建议，修改公式，加上了div标签。 12345678910&lt;div&gt;$$f(x) = \\left\\{ \\begin{array}{lr} 0 &amp; : n=0\\\\ [f(n-1,m)+m] \\%n &amp; : n &gt; 1 \\end{array}\\right.$$&lt;div/&gt; 修改后公式就能正常显示了。 $$ f(x) = \\left\\{ \\begin{array}{lr} 0 & : n=0\\\\ [f(n-1,m)+m] \\%n & : n > 1 \\end{array} \\right. $$ 最后记得在文章的头部mathJax: true设置使用数学公式mathjax插件。 1.3、导出cmd窗口指令日志1ping beyondhxl.com &gt; F:\\cmd.txt 二、规范2.1、设置图片的大小下图是原始图片 1&lt;img src=\"图片地址\" width = \"80%\" height = \"80%\" div align=center /&gt; 如上所示，通过设置图片的宽、高比列可用改变图片大小，align是图片的位置，除了左边、还有右边和居中显示。 2.2、设置文章字体的颜色1234567&lt;font face=\"微软雅黑\" &gt;微软雅黑字体&lt;/font&gt;&lt;font face=\"黑体\" &gt;黑体&lt;/font&gt;&lt;font size=3 &gt;3号字&lt;/font&gt;&lt;font size=4 &gt;4号字&lt;/font&gt;&lt;font color=#FF0000 &gt;红色&lt;/font&gt;&lt;font color=#008000 &gt;绿色&lt;/font&gt;&lt;font color=#0000FF &gt;蓝色&lt;/font&gt; color后面是RGB颜色十六进制颜色值 显示效果如下： 微软雅黑字体黑体3号字4号字红色绿色蓝色 2.3、设置字体居中显示123&lt;center&gt;&lt;font color=#0099ff size=3 face=\"黑体\"&gt;color=#0099ff size=72 face=\"黑体\"&lt;/font&gt;&lt;/center&gt; 效果如下： color=#0099ff size=72 face=\"黑体\" 2.4、Markdown代码高亮支持的语言 名称 关键字 AppleScript applescript ActionScript 3.0 actionscript3, as3 Shell bash, shell ColdFusion coldfusion, cf ActionScript 3.0 actionscript3, as3 C bash, shell AppleScript cpp, c C# c#, c-sharp, csharp CSS css Delphi delphi, pascal, pas diff&amp;patch diff patch Erlang erl, erlang Groovy groovy Java actionscript3, as3 JavaFX jfx, javafx Perl perl, pl, Perl PHP php text text, plain Python py, python Ruby ruby, rails, ror, rb SASS&amp;SCSS sass, scss Scala scala SQL sql Visual Basic vb, vbnet XML xml, xhtml, xslt, html Objective C objc, obj-c F# f#, f-sharp, fsharp R r, s, splus matlab matlab swift swift GO go, golang VS Code 中 Instant Markdown 不支持直接用 ```C#，而要用 csharp 才能高亮 C# 代码 参考文章:1、Markdown如何打出双下划线包含的内容？2、使用Markdown输出LaTex数学公式3、HTML 颜色名4、Markdown使用之语法字体、字号、颜色与居中（CSDN）","link":"/post/1d3a59e7.html"},{"title":"数据库系统概论","text":"事务、并发一致性、封锁、隔离级别、多版本并发控制、Next-Key Locks、关系数据库设计理论、ER图等概念简述。 一、事务概念事务指的是满足ACID特性的一组操作，可以通过Commit提交一个事务，也可以使用Rollback进行回滚。 ACID原子性(Atomicity)事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 一致性(Consistency)数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性(Isolation)一个事务所做的修改在最终提交以前，对其它事务是不可见的。类似于软件协同开发中，每个人在本地对代码仓库所做的修改，其他人是无法得知的，只有在提交之后。 持久性(Durability)一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢。 使用重做日志来保证持久性。 ACID之间的关系只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 二、并发一致性在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1和T2两个事务都对一个数据进行修改，T1先修改，T2随后修改，T2的修改覆盖了T1的修改。 读脏数据T1修改一个数据，T2随后读取这个数据。如果T1撤销了这次修改，那么T2读取的数据是脏数据。 不可重复读T2读取一个数据，T1对该数据做了修改。如果T2再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 总结产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 三、封锁封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 封锁类型读写锁 排它锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下： - X S X × × S × √ 意向锁使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 意向锁、排它锁、兼容锁的兼容关系如下： - X IX S IS X × × × × IX × √ × √ S × × √ √ IS × √ √ √ 任意 IS、IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； 意向锁相互兼容，因为 IX、IS 只是表明申请更低层次级别元素（比如page、记录）的X、S操作。 表级S锁和 X、IX 锁不兼容，因为上了表级 S 锁后，不允许其他事务再加 X 锁。 表级 X 锁和 IS、IX、S、X 不兼容，因为上了表级X锁后，会修改数据，即使是行级排他锁，因为表级锁定的行肯定包括行级锁定的行，所以表级X和IX、X都不兼容。 封锁协议三级封锁协议一级封锁协议事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 T1 T2 lock-x (A) read A=20 lock-x (A) wait write A=19 . commit . unlock-x (A) . obtain read A=19 write A=21 commit unlock-x (A) 二级封锁协议在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 T1 T2 lock-x (A) read A=20 write A=19 lock-s (A) wait rollback . A=20 . unlock-x (A) . obtain read A=20 unlock-s (A) commit 三级封锁协议在二级封锁协议的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 T1 T2 lock-s (A) read A=20 lock-x (A) wait read A=20 . commit . unlock-s (A) . obtain read A=20 write A=19 commit unlock-x (A) 两段锁协议加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 1lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL 隐式与显示锁定MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： 12SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE; 三、隔离级别未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化（SERIALIZABLE）强制事务串行执行。 需要加锁实现，而其它隔离级别通常不需要。 隔离级别 脏读 不可重复读 幻影读 未提交读 √ √ √ 提交读 × √ √ 可重复读 × × √ 可串行化 × × × 四、多版本并发控制多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo 日志MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程以下实现过程针对可重复读隔离级别。 当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号，理解这一点很关键。数据行快照的创建版本号是创建数据行快照时的系统版本号，系统版本号随着创建事务而递增，因此新创建一个事务时，这个事务的系统版本号比之前的系统版本号都大，也就是比所有数据行快照的创建版本号都大。 SELECT多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 INSERT将当前系统版本号作为数据行快照的创建版本号。 DELETE将当前系统版本号作为数据行快照的删除版本号。 UPDATE将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读快照读使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 1select * from table ...; 当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update;delete; 五、Next-Key LocksNext-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 Record Locks锁定一个记录上的索引，而不是记录本身。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 1SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： 12345(-∞, 10](10, 11](11, 13](13, 20](20, +∞) 六、关系数据库设计理论函数依赖记 A-&gt;B 表示 A 函数决定 B，也可以说 B 函数依赖于 A。 如果 {A1，A2，… ，An} 是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。 对于 A-&gt;B，如果能找到 A 的真子集 A’，使得 A’-&gt; B，那么 A-&gt;B 就是部分函数依赖，否则就是完全函数依赖。 对于 A-&gt;B，B-&gt;C，则 A-&gt;C 是一个传递函数依赖。 异常以下的学生课程关系的函数依赖为 {Sno, Cname} -&gt; {Sname, Sdept, Mname, Grade}，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 不符合范式的关系，会产生很多异常，主要有以下四种异常： 冗余数据：例如 学生-2 出现了两次。 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 课程-1 需要删除第一行和第三行，那么 学生-1 的信息就会丢失。 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。 范式范式理论是为了解决以上提到四种异常。 高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。 第一范式 (1NF)属性不可分。 第二范式 (2NF)每个非主属性完全函数依赖于键码。 可以通过分解来满足。 分解前 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 以上学生课程关系中，{Sno, Cname} 为键码，有如下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname Sno, Cname-&gt; Grade Grade 完全函数依赖于键码，它没有任何冗余数据，每个学生的每门课都有特定的成绩。 Sname, Sdept 和 Mname 都部分依赖于键码，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。 分解后 关系-1 Sno Sname Sdept Mname 1 学生-1 学院-1 院长-1 2 学生-2 学院-2 院长-2 3 学生-3 学院-2 院长-2 有以下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname 关系-2 Sno Cname Grade 1 课程-1 90 2 课程-2 80 2 课程-1 100 3 课程-2 95 有以下函数依赖： Sno, Cname -&gt; Grade 第三范式 (3NF)非主属性不传递函数依赖于键码。 上面的 关系-1 中存在以下传递函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname Sno -&gt; Mname 可以进行以下分解： 关系-11 Sno Sname Sdept 1 学生-1 学院-1 2 学生-2 学院-2 3 学生-3 学院-2 关系-12 Sdept Mname 学院-1 院长-1 学院-2 院长-2 七、ER 图Entity-Relationship，有三个组成部分：实体、属性、联系。 用来进行关系型数据库系统的概念设计。 实体的三种联系包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 下图的 Course 和 Student 是一对多的关系。 表示出现多次的关系一个实体在联系出现几次，就要用几条线连接。 下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。 联系的多向性虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。 表示子类用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 参考 AbrahamSilberschatz, HenryF.Korth, S.Sudarshan, 等. 数据库系统概念 [M]. 机械工业出版社, 2006. 施瓦茨. 高性能 MYSQL(第3版)[M]. 电子工业出版社, 2013. 史嘉权. 数据库系统概论[M]. 清华大学出版社有限公司, 2006. The InnoDB Storage Engine Transaction isolation levels Concurrency Control The Nightmare of Locking, Blocking and Isolation Levels! Database Normalization and Normal Forms with an Example The basics of the InnoDB undo logging and history system MySQL locking for the busy web developer 浅入浅出 MySQL 和 InnoDB Innodb 中的事务隔离级别和锁的关系","link":"/post/85be90d7.html"},{"title":"WSL-Windows上的Linux子系统","text":"对工作环境为 Windows，开发目标环境为 Linux 的人来说是比较合适的。 WSL 最大的好处就是整个工作环境可以无缝衔接，比如后台服务在 linux 下开发和部署，前端 app 项目在 win 下调试。 一、安装1.1、官方文档适用于 Linux 的 Windows 子系统文档 1.2、安装步骤1、打开控制面板——程序和功能——启用或关闭 Windows 功能——适用于 Linux 的 Windows 子系统——重启系统 2、打开 Microsoft Store —— 搜索并安装 Ubuntu ——启动 Ubuntu —— 输入用户名和两遍密码完成安装 1.3、root密码Ubuntu 的默认 root 密码是随机的，即每次开机都有一个新的 root 密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码，回车 Enter，终端会提示我们输入新的密码并确认，此时的密码就是 root 新密码。修改成功后，输入命令 su root，再输入新的密码就可以切换了。 二、问题2.1、Unable to locate package错误解决办法当用 apt-get 更新软件包时，常出现错误提示 Unable to locate package update，尤其是在 ubuntu server 上，解决方法是：先 sudo apt-get update 再 sudo apt-get install 就可以了。 参考文章:Windows10 Install WSL Ubuntu","link":"/post/784ee20b.html"},{"title":"TCP网络编程常用工具(转载)","text":"ping、ifconfig、netstat、lsof、tcpdump 其实在平常使用套接字开发和测试过程中，我们总会碰到这样或那样的问题。学会对这些问题进行诊断和分析，其实需要不断地积累经验。而 Linux 平台下提供的各种网络工具，则为我们进行诊断分析提供了很好的帮助。 一、ping这个命令我想大家都不陌生，“ping” 这个命名来自于声呐探测，在网络上用来完成对网络连通性的探测，这个命名可以说是恰如其分了。 123456789101112$ ping www.sina.com.cnPING www.sina.com.cn (202.102.94.124) 56(84) bytes of data.64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=1 ttl=63 time=8.64 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=2 ttl=63 time=11.3 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=3 ttl=63 time=8.66 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=4 ttl=63 time=13.7 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=5 ttl=63 time=8.22 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=6 ttl=63 time=7.99 ms^C--- www.sina.com.cn ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 5006msrtt min/avg/max/mdev = 7.997/9.782/13.795/2.112 ms 在上面的例子中，我使用 ping 命令探测了和新浪网的网络连通性。可以看到，每次显示是按照 sequence 序列号排序显示的，一并显示的，也包括 TTL（time to live），反映了两个 IP 地址之间传输的时间。最后还显示了 ping 命令的统计信息，如最小时间、平均时间等。 我们需要经常和 Linux 下的 ping 命令打交道，那么 ping 命令的原理到底是什么呢？它是基于 TCP 还是 UDP 开发的？ 其实，ping 是基于一种叫做 ICMP 的协议开发的，ICMP 又是一种基于 IP 协议的控制协议，翻译为网际控制协议，其报文格式如下图： ICMP 在 IP 报文后加入了新的内容，这些内容包括： 类型：即 ICMP 的类型，其中 ping 的请求类型为 0，应答为 8。 代码：进一步划分 ICMP 的类型, 用来查找产生错误的原因。 校验和：用于检查错误的数据。 标识符：通过标识符来确认是谁发送的控制协议，可以是进程 ID。 序列号：唯一确定的一个报文，前面 ping 名字执行后显示的 icmp_seq 就是这个值。 当我们发起 ping 命令时，ping 程序实际上会组装成如图的一个 IP 报文。报文的目的地址为 ping 的目标地址，源地址就是发送 ping 命令时的主机地址，同时按照 ICMP 报文格式填上数据，在可选数据上可以填上发送时的时间戳。 IP 报文通过 ARP 协议，源地址和目的地址被翻译成 MAC 地址，经过数据链路层后，报文被传输出去。当报文到达目的地址之后，目的地址所在的主机也按照 ICMP 协议进行应答。之所以叫做协议，是因为双方都会遵守这个报文格式，并且也会按照格式进行发送 - 应答。 应答数据到达源地址之后，ping 命令可以通过再次解析 ICMP 报文，对比序列号，计算时间戳等来完成每个发送 - 应答的显示，最终显示的格式就像前面的例子中展示的一样。 可以说，ICMP 协议为我们侦测网络问题提供了非常好的支持。另外一种对路由的检测命令 Traceroute 也是通过 ICMP 协议来完成的，这里就不展开讲了。 二、ifconfig很多熟悉 Windows 的同学都知道 Windows 有一个 ipconfig 命令，用来显示当前的网络设备列表。事实上，Linux 有一个对应的命令叫做 ifconfig，也用来显示当前系统中的所有网络设备，通俗一点的说，就是网卡列表。 123456789101112131415161718192021222324252627282930vagrant@ubuntu-xenial-01:~$ ifconfigcni0 Link encap:Ethernet HWaddr 0a:58:0a:f4:00:01 inet addr:10.244.0.1 Bcast:0.0.0.0 Mask:255.255.255.0 inet6 addr: fe80::401:b4ff:fe51:bcf9/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:2133 errors:0 dropped:0 overruns:0 frame:0 TX packets:2216 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:139381 (139.3 KB) TX bytes:853302 (853.3 KB)docker0 Link encap:Ethernet HWaddr 02:42:93:0f:f7:11 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:93ff:fe0f:f711/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:653 errors:0 dropped:0 overruns:0 frame:0 TX packets:685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:49542 (49.5 KB) TX bytes:430826 (430.8 KB)enp0s3 Link encap:Ethernet HWaddr 02:54:ad:ea:60:2e inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0 inet6 addr: fe80::54:adff:feea:602e/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:7951 errors:0 dropped:0 overruns:0 frame:0 TX packets:4123 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:5081047 (5.0 MB) TX bytes:385600 (385.6 KB) 我稍微解释一下这里面显示的数据。 1Link encap:Ethernet HWaddr 02:54:ad:ea:60:2e 上面这段表明这是一个以太网设备，MAC 地址为 02:54:ad:ea:60:2e。 12inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0inet6 addr: fe80::54:adff:feea:602e/64 Scope:Link 这里显示的是网卡的 IPv4 和 IPv6 地址，其中 IPv4 还显示了该网络的子网掩码以及广播地址。 在每个 IPv4 子网中，有一个特殊地址被保留作为子网广播地址，比如这里的 10.0.2.255 就是这个子网的广播地址。当向这个地址发送请求时，就会向以太网网络上的一组主机发送请求。 通常来说，这种被称作广播（broadcast）的技术，是用 UDP 来实现的。 1UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 这里显示的是网卡的状态，MTU 是最大传输单元的意思，表示的是链路层包的大小。1500 表示的是字节大小。 Metric 大家可能不知道是干啥用的，这里解释下，Linux 在一台主机上可以有多个网卡设备，很可能有这么一种情况，多个网卡可以路由到目的地。一个简单的例子是在同时有无线网卡和有线网卡的情况下，网络连接是从哪一个网卡设备上出去的？Metric 就是用来确定多块网卡的优先级的，数值越小，优先级越高，1 为最高级。 1234RX packets:7951 errors:0 dropped:0 overruns:0 frame:0TX packets:4123 errors:0 dropped:0 overruns:0 carrier:0collisions:0 txqueuelen:1000RX bytes:5081047 (5.0 MB) TX bytes:385600 (385.6 KB) 三、netstat 和 lsof在平时的工作中，我们最常碰到的问题就是某某进程对应的网络状况如何？是不是连接被打爆了？还是有大量的 TIME_WAIT 连接？ netstat 可以帮助我们了解当前的网络连接状况，比如我想知道当前所有的连接详情，就可以使用下面这行命令： 1netstat -alepn 可能的结果为： netstat 会把所有 IPv4 形态的 TCP，IPV6 形态的 TCP、UDP 以及 UNIX 域的套接字都显示出来。 对于 TCP 类型来说，最大的好处是可以清楚地看到一条 TCP 连接的四元组（源地址、源端口、目的地地址和目的端口）。 例如这里的一条信息： 1tcp 0 0 127.0.0.1:2379 127.0.0.1:52464 ESTABLISHED 0 27710 3496/etcd 它表达的意思是本地 127.0.0.1 的端口 52464 连上本地 127.0.0.1 的端口 2379，状态为 ESTABLISHED，本地进程为 etcd，进程为 3496。 这在实战分析的时候非常有用，比如你可以很方便地知道，在某个时候是不是有很多 TIME_WAIT 的 TCP 连接，导致端口号被占用光，以致新的连接分配不了。 当然，我们也可以只对 UNIX 套接字进行筛查。 1netstat Socket -x -alepn UNIX 套接字的结果稍有不同，最关键的信息是 Path，这个信息显示了本地套接字监听的文件路径，比如这条： 1unix 3 [ ] STREAM CONNECTED 23209 1400/dockerd /var/run/docker.sock 这其实就是大名鼎鼎的 Docker 在本地套接字的监听路径。/var/run/docker.sock 是本地套接字监听地址，dockerd 是进程名称，1400 是进程号。 netstat 命令可以选择的参数非常之多，这里只关注了几个简单的场景，你可以通过帮助命令或者查阅文档获得更多的信息。 lsof 的常见用途之一是帮助我们找出在指定的 IP 地址或者端口上打开套接字的进程，而 netstat 则告诉我们 IP 地址和端口使用的情况，以及各个 TCP 连接的状态。lsof 和 netstst 可以结合起来一起使用。 比如说，我们可以通过 lsof 查看到底是谁打开了这个文件： 1lsof /var/run/docker.sock 下面这张图显示了是 dockerd 打开了这个本地文件套接字： lsof 还有一个非常常见的用途。如果我们启动了一个服务器程序，发现这个服务器需要绑定的端口地址已经被占用，内核报出“该地址已在使用”的出错信息，我们可以使用 lsof 找出正在使用该端口的那个进程。比如下面这个代码，就帮我们找到了使用 8080 端口的那个进程，从而帮助我们定位问题。 1lsof -i :8080 四、tcpdumptcpdump 这样的抓包工具对于网络编程而言是非常有用的，特别是在一些“山重水复疑无路”的情形下，通过 tcpdump 这样的抓包工具，往往可以达到“柳暗花明又一村”的效果。 tcpdump 具有非常强大的过滤和匹配功能。 比如说指定网卡： 1tcpdump -i eth0 再比如说指定来源： 1tcpdump src host hostname 我们再来一个复杂一点的例子。这里抓的包是 TCP，且端口是 80，包来自 IP 地址为 192.168.1.25 的主机地址。 1tcpdump 'tcp and port 80 and src host 192.168.1.25' 如果我们对 TCP 协议非常熟悉，还可以写出这样的 tcpdump 命令： 1tcpdump 'tcp and port 80 and tcp[13:1]&amp;2 != 0' 这里 tcp[13:1] 表示的是 TCP 头部开始处偏移为 13 的字节，如果这个值为 2，说明设置了 SYN 分节，当然，我们也可以设置成其他值来获取希望类型的分节。注意，这里的偏移是从 0 开始算起的，tcp[13]其实是报文里的第 14 个字节。 tcpdump 在开启抓包的时候，会自动创建一个类型为 AF_PACKET 的网络套接口，并向系统内核注册。当网卡接收到一个网络报文之后，它会遍历系统中所有已经被注册的网络协议，包括其中已经注册了的 AF_PACKET 网络协议。系统内核接下来就会将网卡收到的报文发送给该协议的回调函数进行一次处理，回调函数可以把接收到的报文完完整整地复制一份，假装是自己接收到的报文，然后交给 tcpdump 程序，进行各种条件的过滤和判断，再对报文进行解析输出。 下面这张图显示的是 tcpdump 的输出格式： 首先我们看到的是时间戳，之后类似 192.168.33.11.41388 &gt; 192.168.33.11.6443 这样的，显示的是源地址（192.168.33.11.41388）到目的地址（192.168.33.11.6443）；然后 Flags [ ]是包的标志，[P]表示是数据推送，比较常见的包格式如下： [S]：SYN，表示开始连接 [.]：没有标记，一般是确认 [P]：PSH，表示数据推送 [F]：FIN，表示结束连接 [R] ：RST，表示重启连接 我们可以看到最后有几个数据，它们代表的含义如下： seq：包序号，就是 TCP 的确认分组 cksum：校验码 win：滑动窗口大小 length：承载的数据（payload）长度 length，如果没有数据则为 0 此外，tcpdump 还可以对每条 TCP 报文的细节进行显示，让我们可以看到每条报文的详细字节信息。这在对报文进行排查的时候很有用。 五、小结我再来总结一下这几个命令的作用： ping 可以用来帮助我们进行网络连通性的探测。 ifconfig，用来显示当前系统中的所有网络设备。 netstat 和 lsof 可以查看活动的连接状况。 tcpdump 可以对各种奇怪的环境进行抓包，进而帮我们了解报文，排查问题。 六、问答1、tcpdump 这个工具还可以对 UDP 包进行抓包处理吗？ tcpdump 可以抓 UDP，指定端口就可以。 tcpdump 还可以导出文件 pcap，放到 wireshark 中进一步分析。 2、Foreign Address 显示的 . 表示的是什么意思呢？ 这个套接字正在监听端口等待连接进来，允许任何地址、任何端口来建立连接。 参考文章:工欲善其事必先利其器：学会使用各种工具","link":"/post/977a8d62.html"},{"title":"数据结构与算法-二叉搜索树","text":"二叉搜索树 一、什么是二叉搜索树二叉搜索树（binary search tree, BST）也叫排序的二叉树，根节点比左边子树的所有节点都大，比右边子树上的所有节点都小，如下图就是一个二叉搜索树: 要实现一个二叉搜索树，我们需要实现节点的插入和删除，要实现节点的查找（搜索），要实现前序遍历、中序遍历和后序遍历，要实现最大节点和最小节点的查找。 二、定义基本数据结构常规地，我们定义节点的类型，每个节点包含它的值以及左右节点。因为目前 Go 泛型还没有发布，所以这里我们实现一个元素为 int 类型的具体的二叉搜索树，等泛型实现后可以改成抽象的二叉搜索树。 树只要包含根节点可以了。 1234567891011// Node 定义节点type Node struct { value int // 因为目前Go的泛型还没有发布，所以我们这里以一个int具体类型为例 left *Node // 左子节点 right *Node // 右子节点}// BST 是一个节点的值为int类型的二叉搜索树type BST struct { root *Node} 三、插入和删除既然是一棵树，就需要增加节点用来构造树，大部分情况下也需要删除节点。 增加节点的时候，需要判断应该往左边子树上添加，还是往右边子树上添加。天然地，既然二叉搜索树是一个有序的，那么我们就可以进行比较，然后递归的实现。 12345678910111213141516171819202122232425262728// Insert 插入一个元素.func (bst *BST) Insert(value int) { newNode := &amp;Node{value, nil, nil} // 如果二叉树为空，那么这个节点就当作跟节点 if bst.root == nil { bst.root = newNode } else { insertNode(bst.root, newNode) }}// 从根节点依次比较func insertNode(root, newNode *Node) { if newNode.value &lt; root.value { // 应该放到根节点的左边 if root.left == nil { root.left = newNode } else { insertNode(root.left, newNode) } } else if newNode.value &gt; root.value { // 应该放到根节点的右边 if root.right == nil { root.right = newNode } else { insertNode(root.right, newNode) } } // 否则等于根节点} 删除有些麻烦，如果是删除叶节点就比较容易，删除即可。但是如果不是删除叶节点，那么就需要将子节点提升。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// Remove 删除一个元素.func (bst *BST) Remove(value int) bool { _, existed := remove(bst.root, value) return existed}// 用来递归移除节点的辅助方法.// 返回替换root的新节点，以及元素是否存在func remove(root *Node, value int) (*Node, bool) { if root == nil { return nil, false } var existed bool // 从左边找 if value &lt; root.value { root.left, existed = remove(root.left, value) return root, existed } // 从右边找 if value &gt; root.value { root.right, existed = remove(root.right, value) return root, existed } // 如果此节点正是要移除的节点,那么返回此节点，同时返回之前可能需要调整. existed = true // 如果此节点没有孩子，直接返回即可 if root.left == nil &amp;&amp; root.right == nil { root = nil return root, existed } // 如果左子节点为空, 提升右子节点 if root.left == nil { root = root.right return root, existed } // 如果右子节点为空, 提升左子节点 if root.right == nil { root = root.left return root, existed } // 如果左右节点都存在,那么从右边节点找到一个最小的节点提升，这个节点肯定比左子树所有节点都大. // 也可以从左子树节点中找一个最大的提升，道理一样. smallestInRight, _ := min(root.right) // 提升 root.value = smallestInRight // 从右边子树中移除此节点 root.right, _ = remove(root.right, smallestInRight) return root, existed} 四、搜索检查一个节点是否存在比较简单，因为二叉搜索树是有序的。 12345678910111213141516// Search 搜索元素(检查元素是否存在)func (bst *BST) Search(value int) bool { return search(bst.root, value)}func search(n *Node, value int) bool { if n == nil { return false } if value &lt; n.value { return search(n.left, value) } if value &gt; n.value { return search(n.right, value) } return true} 同时，我们还可以实现查找一个二叉搜索树的最大最小值。 1234567891011121314151617181920212223242526272829303132333435363738// Min 二叉搜索树中的最小值func (bst *BST) Min() (int, bool) { return min(bst.root)}func min(node *Node) (int, bool) { if node == nil { return 0, false } n := node // 从左边找 for { if n.left == nil { return n.value, true } n = n.left }}// Max 二叉搜索树中的最大值func (bst *BST) Max() (int, bool) { return max(bst.root)}func max(node *Node) (int, bool) { if node == nil { return 0, false } n := node // 从右边找 for { if n.right == nil { return n.value, true } n = n.right }} 五、遍历可以实现先序遍历、中序遍历和后序遍历，先中后指的是根节点相对子节点的处理顺序。 12345678910111213141516171819202122232425// PreOrderTraverse 前序遍历func (bst *BST) PreOrderTraverse(f func(int)) { preOrderTraverse(bst.root, f)}func preOrderTraverse(n *Node, f func(int)) { if n != nil { f(n.value) // 前 preOrderTraverse(n.left, f) preOrderTraverse(n.right, f) }}// PostOrderTraverse 后序遍历func (bst *BST) PostOrderTraverse(f func(int)) { postOrderTraverse(bst.root, f)}func postOrderTraverse(n *Node, f func(int)) { if n != nil { postOrderTraverse(n.left, f) postOrderTraverse(n.right, f) f(n.value) // 后 }} 参考原文:用Go撸一个二叉搜索树","link":"/post/3294d6b6.html"},{"title":"如何优雅地关闭Go语言的通道channel","text":"Go channel的关闭 一、Go channel设计和规范的问题 在不能更改 channel 状态的情况下，没有简单普遍的方式来检查 channel 是否已经关闭了 关闭已经关闭的 channel 会导致 panic，所以在 closer（关闭者）不知道 channel 是否已经关闭的情况下去关闭 channel 是很危险的 发送值到已经关闭的 channel 会导致 panic，所以如果 sender（发送者）在不知道 channel 是否已经关闭的情况下去向 channel 发送值是很危险的 是的，没有一个内置函数可以检查一个 channel 是否已经关闭。如果你能确定不会向 channel 发送任何值，那么也确实需要一个简单的方法来检查 channel 是否已经关闭： 123456789101112131415161718192021package mainimport \"fmt\"type T intfunc IsClosed(ch &lt;-chan T) bool { select { case &lt;-ch: return true default: } return false}func main() { c := make(chan T) fmt.Println(IsClosed(c)) // false close(c) fmt.Println(IsClosed(c)) // true} 上面已经提到了，没有一种适用的方式来检查 channel 是否已经关闭了。但是，就算有一个简单的 closed(chan T) bool 函数来检查 channel 是否已经关闭，它的用处还是很有限的，就像内置的 len 函数用来检查缓冲 channel 中元素数量一样。原因就在于，已经检查过的 channel 的状态有可能在调用了类似的方法返回之后就修改了，因此返回来的值已经不能够反映刚才检查的 channel 的当前状态了。 尽管在调用 closed(ch) 返回 true 的情况下停止向 channel 发送值是可以的，但是如果调用 closed(ch) 返回 false，那么关闭 channel 或者继续向 channel 发送值就不安全了（会 panic）。 二、The Channel Closing Principle在使用 Go channel 的时候，一个适用的原则是不要从接收端关闭 channel，也不要关闭有多个并发发送者的 channel。换句话说，如果 sender（发送者）只是 channel 唯一的 sender 或者是 channel 最后一个活跃的 sender，那么你应该在 sender 的 goroutine 关闭 channel，从而通知 receiver(s)（接收者们）已经没有值可以读了。维持这条原则将保证永远不会发生向一个已经关闭的 channel 发送值或者关闭一个已经关闭的 channel。 三、打破 channel closing principle 的解决方案如果你因为某种原因从接收端（receiver side）关闭 channel 或者在多个发送者中的一个关闭 channel，那么你应该使用列在 Golang panic/recover Use Cases 的函数来安全地发送值到 channel 中（假设 channel 的元素类型是 T）。 123456789101112func SafeSend(ch chan T, value T) (closed bool) { defer func() { if recover() != nil { // the return result can be altered // in a defer function call closed = true } }() ch &lt;- value // panic if ch is closed return false // &lt;=&gt; closed = false; return} 如果 channel ch 没有被关闭的话，那么这个函数的性能将和 ch &lt;- value 接近。对于 channel 关闭的时候，SafeSend 函数只会在每个 sender goroutine 中调用一次，因此程序不会有太大的性能损失。 同样的想法也可以用在从多个 goroutine 关闭 channel 中： 1234567891011func SafeClose(ch chan T) (justClosed bool) { defer func() { if recover() != nil { justClosed = false } }() // assume ch != nil here. close(ch) // panic if ch is closed return true} 很多人喜欢用 sync.Once 来关闭 channel： 1234567891011121314type MyChannel struct { C chan T once sync.Once}func NewMyChannel() *MyChannel { return &amp;MyChannel{C: make(chan T)}}func (mc *MyChannel) SafeClose() { mc.once.Do(func(){ close(mc.C) })} 当然了，我们也可以用 sync.Mutex 来避免多次关闭 channel： 123456789101112131415161718192021222324type MyChannel struct { C chan T closed bool mutex sync.Mutex}func NewMyChannel() *MyChannel { return &amp;MyChannel{C: make(chan T)}}func (mc *MyChannel) SafeClose() { mc.mutex.Lock() if !mc.closed { close(mc.C) mc.closed = true } mc.mutex.Unlock()}func (mc *MyChannel) IsClosed() bool { mc.mutex.Lock() defer mc.mutex.Unlock() return mc.closed} 我们应该要理解为什么 Go 不支持内置 SafeSend 和 SafeClose 函数，原因就在于并不推荐从接收端或者多个并发发送端关闭 channel。Golang 甚至禁止关闭只接收（receive-only）的 channel。 四、保持 channel closing principle 的优雅方案上面的 SafeSend 函数有一个缺点，在 select 语句的 case 关键字后不能作为发送操作被调用（类似于 case SafeSend(ch, t):）。 M 个 receivers，一个 sender，sender 通过关闭 data channel 说“不再发送” 这是最简单的场景了，就只是当 sender 不想再发送的时候让 sender 关闭 data 来关闭 channel： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"log\" \"math/rand\" \"sync\" \"time\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumReceivers = 100 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int, 100) // the sender go func() { for { if value := rand.Intn(MaxRandomNumber); value == 0 { // the only sender can close the channel safely. close(dataCh) return } else { dataCh &lt;- value } } }() // receivers for i := 0; i &lt; NumReceivers; i++ { go func() { defer wgReceivers.Done() // receive values until dataCh is closed and // the value buffer queue of dataCh is empty. for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait()} 一个 receiver，N 个 sender，receiver 通过关闭一个额外的 signal channel 说“请停止发送” 这种场景比上一个要复杂一点。我们不能让 receiver 关闭 data channel，因为这么做将会打破 channel closing principle。但是我们可以让 receiver 关闭一个额外的 signal channel 来通知 sender 停止发送值： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport ( \"time\" \"math/rand\" \"sync\" \"log\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(1) // ... dataCh := make(chan int, 100) stopCh := make(chan struct{}) // stopCh is an additional signal channel. // Its sender is the receiver of channel dataCh. // Its reveivers are the senders of channel dataCh. // senders for i := 0; i &lt; NumSenders; i++ { go func() { for { value := rand.Intn(MaxRandomNumber) select { case &lt;- stopCh: return case dataCh &lt;- value: } } }() } // the receiver go func() { defer wgReceivers.Done() for value := range dataCh { if value == MaxRandomNumber-1 { // the receiver of the dataCh channel is // also the sender of the stopCh cahnnel. // It is safe to close the stop channel here. close(stopCh) return } log.Println(value) } }() // ... wgReceivers.Wait()} M 个 receiver，N 个 sender，它们当中任意一个通过通知一个 moderator（仲裁者）关闭额外的 signal channel 来说“让我们结束游戏吧” 这是最复杂的场景了。我们不能让任意的 receivers 和 senders 关闭 data channel，也不能让任何一个 receivers 通过关闭一个额外的 signal channel 来通知所有的 senders 和 receivers 退出游戏。这么做的话会打破 channel closing principle。但是，我们可以引入一个 moderator 来关闭一个额外的 signal channel。这个例子的一个技巧是怎么通知 moderator 去关闭额外的 signal channel： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package mainimport ( \"time\" \"math/rand\" \"sync\" \"log\" \"strconv\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumReceivers = 10 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int, 100) stopCh := make(chan struct{}) // stopCh is an additional signal channel. // Its sender is the moderator goroutine shown below. // Its reveivers are all senders and receivers of dataCh. toStop := make(chan string, 1) // the channel toStop is used to notify the moderator // to close the additional signal channel (stopCh). // Its senders are any senders and receivers of dataCh. // Its reveiver is the moderator goroutine shown below. var stoppedBy string // moderator go func() { stoppedBy = &lt;- toStop // part of the trick used to notify the moderator // to close the additional signal channel. close(stopCh) }() // senders for i := 0; i &lt; NumSenders; i++ { go func(id string) { for { value := rand.Intn(MaxRandomNumber) if value == 0 { // here, a trick is used to notify the moderator // to close the additional signal channel. select { case toStop &lt;- \"sender#\" + id: default: } return } // the first select here is to try to exit the // goroutine as early as possible. select { case &lt;- stopCh: return default: } select { case &lt;- stopCh: return case dataCh &lt;- value: } } }(strconv.Itoa(i)) } // receivers for i := 0; i &lt; NumReceivers; i++ { go func(id string) { defer wgReceivers.Done() for { // same as senders, the first select here is to // try to exit the goroutine as early as possible. select { case &lt;- stopCh: return default: } select { case &lt;- stopCh: return case value := &lt;-dataCh: if value == MaxRandomNumber-1 { // the same trick is used to notify the moderator // to close the additional signal channel. select { case toStop &lt;- \"receiver#\" + id: default: } return } log.Println(value) } } }(strconv.Itoa(i)) } // ... wgReceivers.Wait() log.Println(\"stopped by\", stoppedBy)} 在这个例子中，仍然遵守着 channel closing principle。请注意 channel toStop 的缓冲大小是1，这是为了避免当 mederator goroutine 准备好之前第一个通知就已经发送了，导致丢失。 参考文章:如何优雅地关闭Go channel","link":"/post/43ed0d63.html"},{"title":"深度探索C++对象模型（DataMember的布局）","text":"C++ 对象模型 DataMember 的布局 一、布局1234567891011class Point3d{ public: // ... private: float x; static list&lt;Point3d *&gt; *freeList; float y; static const int chunkSize = 0; float z;}; 我们可以知道 sizeof(Point3d) 为 12 bytes。一如之前的风格，我们来看一下 class Point3d 的对象模型，如下： C++ Standard 只要求在同一个 access section（也就是 private、public、proctected 等区段），data members 的排列只需要符合“较晚出现的 members 在 class object 中有较高的地址”，也就是说各个 member 并不一定是连续排列的，正如 class Point3d 一样，有可能被其他东西介入。C++ Standard 对布局持放任的态度，也就是说你你 class Point3d 写成下面这个样子，其对象布局也如上图（当然也看编译器，但一般都是相同的），即 access sections 的多少并不会导致额外的负担。 12345678910111213141516171819class Point3d { public: // ... private: float x; private: static list&lt;Point3d *&gt; *freeList; private: float y; private: static const int chunkSize = 0; private: float z;}; 二、存取再来看一段代码，如下： 1234567891011class Point3d { public: float x; static list&lt;Point3d *&gt; *freeList; float y; static int chunkSize; float z;};int Point3d::chunkSize = 0; 然后： 1234567891011int main() { Point3d origin; Point3d *pt = &amp;origin; // 下面这两天存取语句有什么差异？ origin.x = 0.0F; pt-&gt;x = 0.0F; system(\"pause\"); return 0;} 这里我们要分情况讨论，从之前的学习我们知道 class data member 是分为 static 和 nonstatic 两种，我们就此分别进行讨论。 2.1、static data member正如之前所说，static data member 被视为一个 global 的（但只在 class 声明范围内可见），而不论是存在多少的 class object，static data member 只存在一个实例，并且在没有任何 class object 的情况下，static data member 也是存在的。也就是说其实 static data member 的存取并不需要通过 class object 就可以完成，因为它并不在 class object 中。实际上，我们对 static data member 存取操作时，如： 12origin.chunkSize = 1; // 编译器会转化为 Point3d::chunkSize = 1;pt-&gt;chunkSize = 2; // 编译器会转化为 Point3d::chunkSize = 2; 因此，对于 static data members，这两种存取方式并无差异。 2.2、nonstatic data member根据对象模型，我们知道 nonstatic data members 的存取是通过 class object 的地址加上 nonstatic data members 的 offset（偏移）进行的。显然这个 offset 必须在编译期间就应该准备妥当，因此如下： 123// 通过寻址进行存取，因此下面两种操作并无差异origin.x = 0.0F; // 等价于 *(&amp;origin + (&amp;Point3d::x - 1)) = 0.0;pt-&gt;x = 0.0F; // 等价于 *(pt + (&amp;Point3d::x - 1)) = 0.0; 当然，对于那些单一继承、多重继承来的 data members 也是跟上面的一样，都是寻址+偏移完成。但是，有一个叫 virutal 关键字我们每次看到它的时候心里就应该知道要特殊对待，这就是下面要讲的内容。 三、继承与 Data member在 C++ 继承模型中，一个 derived class object 表现出来的东西，是自己的 members 与 base class(es) members 的总和。至于 derived class member 与 base(es) class members 的排列顺序，在 C++ Standard 中并未规定，由编译器自由安排之。但在大部分的编译器中，base class members 总是先出现，但属于 virtual base class 的除外。 123456789101112131415161718192021222324252627282930class Concrete1{ public: // ... private: int val; char bit1;}; class Concrete2 : public Concrete1 { public: // ... private: char bit2;}; class Concrete3 : public Concrete2 { public: // ... private: char bit3;}; 上面也是我们能够预料到的结果，这样的代码写法，造成许多的内存空间被浪费。 3.1、加上多态1234567891011121314151617181920class Point2d{ public: // has a virtual function // ... private: float _x; float _y;}; class Point3d : public Point2d { public: // override or hide the function private: float _z;}; 3.2、多重继承123456789101112131415161718192021222324252627282930313233343536373839404142class Point2d { public: // has virtual functions // ... private: float _x; float _y;}; class Point3d : public Point2d { public: // ... private: float _z;}; class Vertex { public: // has virtual functions // ... private: Vertex* next;}; class Vertex3d : public Point3d, public Vertex { public: // ... private: float mumble;}; 上图便是多重继承的 data members 的布局。 12345Vertex3d v3d;Vertex *pv;// 当发生这样的操作时pv = &amp;v3d;// 其内部发生的操作伪代码为：pv = (Vertex*) ( ((char*)&amp;v3d) + sizeof(Point3d) ); 由于 data members 的位置（offset）在编译时就已经准备妥当了，当我们要存取某个 base class 中的 data member 也就是计算 offset 这样简单的操作。 3.3、虚拟继承 再来看一段 virtual inheritance 的代码，如下： 123456789101112131415161718192021222324252627282930313233343536class Point2d { public: // has virtual functions // ... private: float _x; float _y;}; class Point3d : public virtual Point2d // virtual inheritance{ public: // ... private: float _z;}; class Vertex : public virtual Point2d // virtual inheritance{ public: // has virtual functions // ... private: Vertex *next;}; class Vertex3d : public Point3d, public Vertex { public: // ... private: float mumble;}; 对于 virtual inheritance，它的存在就必须要支持某种形式的 “shared subobject”，也就是说它只会存在一个 virtual base class subobject。一般来说其对象模型会划分成两个部分：不变区域部分、共享区域部分。 不变区域部分指的是，不管后继如何衍化，总是拥有固定的 offset，所以这一部分区域可以被直接存取；共享区域部分，很显然指的是 virtual base class subobject，这一部分其位置会因派生操作而有变化，所以只能被间接存取。 一般来说，各家编译器的差异就在于间接存取（共享部分）的策略不同。一般的布局策略是先安排好 derived class 的不变部分，然后再建立起共享部分。对于共享部分的存取策略，下面介绍两种策略：指针策略（pointer strategy）、虚表策略（virtual table offset strategy）。以上面 class 的虚拟继承关系，对于 pointer strategy 而言，它们的对象模型如下： 可以从上面的对象模型中看到，virtual base class subobject 部分在最后面，而 base class 根据继承的顺序依次排列，并且在每一个derived class object 中安插了一个指针，这个指针用来指向 virtual base class subobject（共享部分），因此要对共享部分进行存取，可以通过相关指针间接完成。 很明显，我们通过观察分析，发现这种 pointer strategy 对象模型存在缺点：对于每一个对象都会背负一个指向 virtual base class 的指针，这会导致 class object 的负担随着 virtual base class 的增加而真多，也就是说这些额外的负担是会变化的，我们并不能掌控其大小。 针对这个问题，一般而言有两种方法： 我们可以借鉴表格驱动模型来解决（即 Microsoft 编译器的方案），也就是说为有一个或多个 virtual base classes 的 class object 安插一个指针，指向 virtual base class table 表格，而表格中存放的是真正的 virtual base class 的地址。（注意也就是说，不论有多少个 virtual base class，都只安插一个指针）。 第二种办法也是建立 virtual base class table，但 table 中存放的不是地址，而是 virtual base class 的 offset（如下图）。 上面的每一种方法都是一种实现模型，而不是一种标准。 一般而言，virtual base class 最有效的一种运用形式就是：一个抽象的 virtual base class，没有任何的 data member。 参考原文:《深度探索C++对象模型》：Data member的布局","link":"/post/8ce5f219.html"},{"title":"《Go语言实战》阅读笔记再看看","text":"《Go语言实战》阅读笔记 一、关于Go语言的介绍1.1、Go解决现代编程难题Go 语言开发团队花了很长时间来解决当今软件开发人员面对的问题。开发人员在为项目选择语言时，不得不在快速开发和性能之间做出选择。C 和 C++ 这类语言提供了很快的执行速度，而 Ruby 和 Python 这类语言则擅长快速开发。Go 语言在这两者间架起了桥梁，不仅提供了高性能的语言，同时也让开发更快速。 Go 语言的编译器速度非常快，有时甚至会让人感觉不到在编译。所以，Go 开发者能显著减少等待项目构建的时间。 因为 Go 语言内置并发机制，所以不用被迫使用特定的线程库，就能让软件扩展，使用更多的资源。Go 语言的类型系统简单且高效，不需要为面向对象开发付出额外的心智，让开发者能专注于代码复用。Go 语言还自带垃圾回收器，不需要用户自己管理内存。 因为没有从编译代码到执行代码的中间过程，用动态语言编写应用程序可以快速看到输出。代价是，动态语言不提供静态语言提供的类型安全特性，不得不经常用大量的测试套件来避免在运行的时候出现类型错误这类 bug。 goroutine 使用的内存比线程更少，Go 语言运行时会自动在配置的一组逻辑处理器上调度执行 goroutine。每个逻辑处理器绑定到一个操作系统线程上。 通道是一种数据结构，可以让 goroutine 之间进行安全的数据通信。通道可以帮用户避免其他语言里常见的共享内存访问的问题。在其他语言中，如果使用全局变量或者共享内存，必须使用复杂的锁规则来防止对同一个变量的不同步修改。通道这一模式保证同一时刻只会有一个 goroutine 修改数据。 在两个 goroutine 间传输数据是同步的，一旦传输完成，两个 goroutine 都会知道数据已经完成传输。 需要强调的是，通道并不提供跨 goroutine 的数据访问保护机制。如果通过通道传输数据的一份副本，那么每个 goroutine 都持有一份副本，各自对自己的副本做修改是安全的。当传输的是指向数据的指针时，如果读和写是由不同的 goroutine 完成的，每个 goroutine 依旧需要额外的同步动作。 1.2、类型系统Go 开发者使用组合（composition）设计模式，只需简单地将一个类型嵌入到另一个类型，就能复用所有的功能。 在 Go 语言中，不需要声明某个类型实现了某个接口，编译器会判断一个类型的实例是否符合正在使用的接口。 在 Go 语言中，如果一个类型实现了一个接口的所有方法，那么这个类型的实例就可以存储在这个接口类型的实例中，不需要额外声明。 二、Go语言读取不同数据源实例main 函数保存在名为 main 的包里。如果 main 函数不在 main 包里，构建工具就不会生成可执行的文件。 一个包定义一组编译过的代码，包的名字类似命名空间，可以用来间接访问包内声明的标识符。这个特性可以把不同包中定义的同名标识符区别开。 关键字 import 就是导入一段代码，让用户可以访问其中的标识符，如类型、函数、常量和接口。 所有处于同一个文件夹里的代码文件，必须使用同一个包名。按照惯例，包和文件夹同名。 导入的路径前面有一个下划线，这个是为了让 Go 语言对包做初始化操作（即调用对应包内的所有代码文件里定义的 init() 函数），但是并不使用包里的标识符。程序中每个代码文件里定义的 init() 函数都会在 main() 函数执行之前调用。 从标准库中导入代码时，只需要提供包名。编译器总是从 GOROOT 和 GOPATH 环境变量引用的位置去查找。（目前最新的包管理是使用 go mod） 以小写字母开头的标识符是不公开的，不能被其他包中的代码直接访问。 1var matchers = make(map[string]Matcher) matchers 是包级变量。 在 Go 语言中，所有变量都被初始化为其零值。对于数值类型，零值是 0；对于字符串类型，零值是空字符串；对于布尔类型，零值是 false；对于指针，零值是 nil。对于引用类型来说，所引用的底层数据结构会被初始化为对应的零值。但是被声明为其零值的引用类型的变量，会返回 nil 作为其值。 切片是一种实现了一个动态数组的引用类型。 简化变量声明运算符（:=）声明一个变量，同时给这个变量赋予初始值。编译器使用函数返回值的类型来确定每个变量的类型。如果提供确切的非零值初始化变量或者使用函数返回值创建变量，应该使用简化变量声明运算符。 通道（channel）、映射（map）、切片（slice）都是引用类型。 在 main 函数返回前，清理并终止所有之前启动的 goroutine。编写启动和终止时的状态都很清晰的程序，有助减少 bug，防止资源异常。 WaitGroup 是一个计数信号量，我们可以利用它来统计所有的 goroutine 是不是都完成了工作。 关键字 range 可以用于迭代数组、字符串、切片、映射和通道。使用 for range 迭代切片时，每次迭代会返回两个值。第一个值是迭代的元素在切片里的索引位置，第二个值是元素值的一个副本。 下划线还有占位符的作用。 12for , _ := range feeds {} 查找 map 里的键时，有两个选择：要么赋值给一个变量，要么为了精确查找，赋值给两个变量。赋值给两个变量时，第一个值和赋值给一个变量时的值一样，是 map 查找的结果值。如果指定了第二个值，就会返回一个布尔标志，来表示查找的键是否存在于 map 里。如果这个键不存在，map 会返回其值类型的零值作为返回值，如果这个键存在，map 会返回键所对应值的副本。 一个 goroutine 是一个独立于其他函数运行的函数。使用关键字 go 启动一个 goroutine，并对这个 goroutine 做并发调度。 匿名函数是指没有明确声明名字的函数。匿名函数也可以接受声明时指定的参数。 指针变量可以方便地在函数之间共享数据。使用指针变量可以让函数访问并修改一个变量的状态，而这个变量可以在其他函数甚至是其他 goroutine 的作用域里声明。 在 Go 语言中，所有的变量都以值的方式传递。因为指针变量的值是所指向的内存地址，在函数间传递指针变量，是在传递这个地址值，所以依旧被看作以值的方式在传递。 Go 语言支持闭包，这里就应用了闭包。实际上，在匿名函数内访问 searchTerm 和 results 变量，也是通过闭包的形式访问的。因为有了闭包，函数可以直接访问到那些没有作为参数传入的变量。匿名函数并没有拿到这些变量的副本，而是直接访问外层函数作用域中声明的这些变量本身。因为 matcher 和 feed 变量每次调用时值不相同，所以并没有使用闭包的方式访问这两个变量。 因为 Go 编译器可以根据赋值运算符右边的值来推导类型，声明常量的时候不需要指定类型。 1const dataFile = \"data/data.json\" 我们声明了一个名叫 Feed 的结构类型。这个类型会对外暴露。这个类型里面声明了 3 个字段，每个字段的类型都是字符串，对应于数据文件中各个文档的不同字段。每个字段的声明最后` 引号里的部分被称作标记（tag）。这个标记里描述了 JSON 解码的元数据，用于创建 Feed 类型值的切片。每个标记将结构类型里字段对应到 JSON 文档里指定名字的字段。 123456// Feed 包含我们需要处理的数据源的信息type Feed struct { Name string `json:\"site\"` URI string `json:\"link\"` Type string `json:\"type\"`} 12345678910111213141516171819202122[ { \"site\" : \"npr\", \"link\" : \"http://www.npr.org/rss/rss.php?id=1001\", \"type\" : \"rss\" }, { \"site\" : \"cnn\", \"link\" : \"http://rss.cnn.com/rss/cnn_world.rss\", \"type\" : \"rss\" }, { \"site\" : \"foxnews\", \"link\" : \"http://feeds.foxnews.com/foxnews/world?format=xml\", \"type\" : \"rss\" }, { \"site\" : \"nbcnews\", \"link\" : \"http://feeds.nbcnews.com/feeds/topstories\", \"type\" : \"rss\" }] 1234567891011121314151617181920// RetrieveFeeds 读取并反序列化源数据文件func RetrieveFeeds() ([]*Feed, error) { // 打开文件 file, err := os.Open(dataFile) if err != nil { return nil, err } // 当函数返回时 // 关闭文件 defer file.Close() // 将文件解码到一个切片里 // 这个切片的每一项是一个指向一个Feed 类型值的指针 var feeds []*Feed err = json.NewDecoder(file).Decode(&amp;feeds) // 这个函数不需要检查错误，调用者会做这件事 return feeds, err} 第一个返回值是一个切片，其中每一项指向一个 Feed 类型的值（指针类型）。第二个返回值是一个 error 类型的值，用来表示函数是否调用成功。在这个代码示例里，会经常看到返回 error 类型值来表示函数是否调用成功。这种用法在标准库里也很常见。 现在让我们看看第 4 行到第 7 行。在这几行里，我们使用 os 包打开了数据文件。我们使用相对路径调用 Open 方法，并得到两个返回值。第一个返回值是一个指针，指向 File 类型的值，第二个返回值是 error 类型的值，检查 Open 调用是否成功。紧接着第 21 行就检查了返回的 error 类型错误值，如果打开文件真的有问题，就把这个错误值返回给调用者。 关键字 defer 会安排随后的函数调用在函数返回时才执行。在使用完文件后，需要主动关闭文件。使用关键字 defer 来安排调用 Close 方法，可以保证这个函数一定会被调用。哪怕函数意外崩溃终止，也能保证关键字 defer 安排调用的函数会被执行。关键字 defer 可以缩短打开文件和关闭文件之间间隔的代码行数，有助提高代码可读性，减少错误。（申请资源、释放资源要匹配） 1func (dec *Decoder) Decode(v interface{}) error Decode 方法接受一个类型为 interface{} 的值作为参数。这个类型在 Go 语言里很特殊，一般会配合 reflect 包里提供的反射功能一起使用。 12345// Matcher 定义了要实现的// 新搜索类型的行为type Matcher interface { Search(feed *Feed, searchTerm string) ([]*Result, error)} interface 关键字声明了一个接口，这个接口声明了结构类型或者具名类型需要实现的行为。一个接口的行为最终由在这个接口类型中声明的方法决定。如果接口类型只包含一个方法，那么这个类型的名字以 er 结尾。如果接口类型内部声明了多个方法，其名字需要与其行为关联。 123456789101112131415package search// defaultMatcher 实现了默认匹配器type defaultMatcher struct{}// init 函数将默认匹配器注册到程序里func init() { var matcher defaultMatcher Register(\"default\", matcher)}// Search 实现了默认匹配器的行为func (m defaultMatcher) Search(feed *Feed, searchTerm string) ([]*Result, error) { return nil, nil} 在第 04 行，我们使用一个空结构声明了一个名叫 defaultMatcher 的结构类型。空结构在创建实例时，不会分配任何内存。这种结构很适合创建没有任何状态的类型。 1func (m defaultMatcher) Search 如果声明函数的时候带有接收者，则意味着声明了一个方法。这个方法会和指定的接收者的类型绑在一起。在我们的例子里，Search 方法与 defaultMatcher 类型的值绑在一起。这意味着我们可以使用 defaultMatcher 类型的值或者指向这个类型值的指针来调用 Search 方法。无论我们是使用接收者类型的值来调用这个方，还是使用接收者类型值的指针来调用这个方法，编译器都会正确地引用或者解引用对应的值，作为接收者传递给 Search 方法。 1234567891011121314151617// 方法声明为使用 defaultMatcher 类型的值作为接收者func (m defaultMatcher) Search(feed *Feed, searchTerm string)// 声明一个指向 defaultMatcher 类型值的指针dm := new(defaultMatch)// 编译器会解开dm 指针的引用，使用对应的值调用方法dm.Search(feed, \"test\")// 方法声明为使用指向 defaultMatcher 类型值的指针作为接收者func (m *defaultMatcher) Search(feed *Feed, searchTerm string)// 声明一个 defaultMatcher 类型的值var dm defaultMatch// 编译器会自动生成指针引用 dm 值，使用指针调用方法dm.Search(feed, \"test\") 因为大部分方法在被调用后都需要维护接收者的值的状态，所以，一个最佳实践是，将方法的接收者声明为指针。对于 defaultMatcher 类型来说，使用值作为接收者是因为创建一个 defaultMatcher 类型的值不需要分配内存。由于 defaultMatcher 不需要维护状态，所以不需要指针形式的接收者。 与直接通过值或者指针调用方法不同，如果通过接口类型的值调用方法，规则有很大不同，使用指针作为接收者声明的方法，只能在接口类型的值是一个指针的时候被调用。使用值作为接收者声明的方法，在接口类型的值为值或者指针时，都可以被调用。 123456789101112131415161718192021// 方法声明为使用指向defaultMatcher 类型值的指针作为接收者func (m *defaultMatcher) Search(feed *Feed, searchTerm string)// 通过interface 类型的值来调用方法var dm defaultMatchervar matcher Matcher = dm // 将值赋值给接口类型matcher.Search(feed, \"test\") // 使用值来调用接口方法&gt; go buildcannot use dm (type defaultMatcher) as type Matcher in assignment// 方法声明为使用defaultMatcher 类型的值作为接收者func (m defaultMatcher) Search(feed *Feed, searchTerm string)// 通过interface 类型的值来调用方法var dm defaultMatchervar matcher Matcher = &amp;dm // 将指针赋值给接口类型matcher.Search(feed, \"test\") // 使用指针来调用接口方法&gt; go buildBuild Successful 123456789101112131415// Match 函数，为每个数据源单独启动goroutine 来执行这个函数// 并发地执行搜索func Match(matcher Matcher, feed *Feed, searchTerm string, results chan&lt;- *Result) { // 对特定的匹配器执行搜索 searchResults, err := matcher.Search(feed, searchTerm) if err != nil { log.Println(err) return } // 将结果写入通道 for _, result := range searchResults { results &lt;- result }} 这个函数使用实现了 Matcher 接口的值或者指针，进行真正的搜索。这个函数接受 Matcher 类型的值作为第一个参数。只有实现了 Matcher 接口的值或者指针能被接受。因为 defaultMatcher 类型使用值作为接收者，实现了这个接口，所以 defaultMatcher 类型的值或者指针可以传入这个函数。 123456789// Display 从每个单独的 goroutine 接收到结果后// 在终端窗口输出func Display(results chan *Result) { // 通道会一直被阻塞，直到有结果写入 // 一旦通道被关闭，for 循环就会终止 for result := range results { fmt.Printf(\"%s:\\n%s\\n\\n\", result.Field, result.Content) }} 当通道被关闭时，通道和关键字 range 的行为，使这个函数在处理完所有结果后才会返回。 match.go 代码文件的 for range 循环会一直阻塞，直到有结果写入通道。在某个搜索 goroutine 向通道写入结果后，for range 循环被唤醒，读出这些结果。之后，结果会立刻写到日志中。看上去这个 for range 循环会无限循环下去，但其实不然。一旦 search.go 代码文件关闭了通道，for range 循环就会终止，Display 函数也会返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445type (// item 根据 item 字段的标签，将定义的字段// 与 rss 文档的字段关联起来item struct { XMLName xml.Name `xml:\"item\"` PubDate string `xml:\"pubDate\"` Title string `xml:\"title\"` Description string `xml:\"description\"` Link string `xml:\"link\"` GUID string `xml:\"guid\"` GeoRssPoint string `xml:\"georss:point\"`}// image 根据 image 字段的标签，将定义的字段// 与 rss 文档的字段关联起来image struct { XMLName xml.Name `xml:\"image\"` URL string `xml:\"url\"` Title string `xml:\"title\"` Link string `xml:\"link\"`}// channel 根据 channel 字段的标签，将定义的字段// 与 rss 文档的字段关联起来channel struct { XMLName xml.Name `xml:\"channel\"` Title string `xml:\"title\"` Description string `xml:\"description\"` Link string `xml:\"link\"` PubDate string `xml:\"pubDate\"` LastBuildDate string `xml:\"lastBuildDate\"` TTL string `xml:\"ttl\"` Language string `xml:\"language\"` ManagingEditor string `xml:\"managingEditor\"` WebMaster string `xml:\"webMaster\"` Image image `xml:\"image\"` Item []item `xml:\"item\"`}// rssDocument 定义了与 rss 文档关联的字段rssDocument struct { XMLName xml.Name `xml:\"rss\"` Channel channel `xml:\"channel\"`}) 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Search 在文档中查找特定的搜索项func (m rssMatcher) Search(feed *search.Feed, searchTerm string) ([]*search.Result, error) { var results []*search.Result log.Printf(\"Search Feed Type[%s] Site[%s] For Uri[%s]\\n\", feed.Type, feed.Name, feed.URI) // 获取要搜索的数据 document, err := m.retrieve(feed) if err != nil { return nil, err } for _, channelItem := range document.Channel.Item{ // 检查标题部分是否包含搜索项 matched, err := regexp.MatchString(searchTerm, channelItem.Title) if err != nil{ return nil, err } // 如果找到匹配的项，将其作为结果保存 if matched { results = append(results, &amp;search.Result{ Field: \"Title\", Content: channelItem.Title, }) } // 检查描述部分是否包含搜索项 matched, err = regexp.MatchString(searchTerm, channelItem.Description) if err != nil { return nil, err } // 如果找到匹配的项，将其作为结果保存 if matched { results = append(results, &amp;search.Result{ Field: \"Description\", Content: channelItem.Description, }) } return results, nil }} 1234567for _, channelItem := range document.Channel.Item { // 检查标题部分是否包含搜索项 matched, err := regexp.MatchString(searchTerm, channelItem.Title) if err != nil { return nil, err }} 既然 document.Channel.Item 是一个 item 类型值的切片，我们对其使用 for range 循环，依次访问其内部的每一项。我们使用 regexp 包里的 MatchString 函数，对 channelItem 值里的 Title 字段进行搜索，查找是否有匹配的搜索项，之后检查错误。 1234567// 如果找到匹配的项，将其作为结果保存if matched { results = append(results, &amp;search.Result{ Field: \"Title\", Content: channelItem.Title, })} 如果调用 MatchString 方法返回的 matched 的值为真，我们使用内置的 append 函数，将搜索结果加入到 results 切片里。append 这个内置函数会根据切片需要，决定是否要增加切片的长度和容量。这个函数的第一个参数是希望追加到的切片，第二个参数是要追加的值。在这个例子里，追加到切片的值是一个指向 Result 类型值的指针。这个值直接使用字面声明的方式，初始化为 Result 类型的值。之后使用取地址运算符（&amp;），获得这个新值的地址。最终将这个指针存入了切片。 三、打包和工具链3.1、包在 Go 语言里，包是个非常重要的概念。其设计理念是使用包来封装不同语义单元的功能。这样做，能够更好地复用代码，并对每个包内的数据的使用有更好的控制。 所有的 .go 文件，除了空行和注释，都应该在第一行声明自己所属的包。每个包都在一个单独的目录里。不能把多个包放到同一个目录中，也不能把同一个包的文件分拆到多个不同目录中。这意味着，同一个目录下的所有 .go 文件必须声明同一个包名。 给包及其目录命名时，应该使用简洁、清晰且全小写的名字，这有利于开发时频繁输入包名。 一般情况下，包被导入后会使用你的包名作为默认的名字，不过这个导入后的名字可以修改。这个特性在需要导入不同目录的同名包时很有用。 main包 在 Go 语言里，命名为 main 的包具有特殊的含义。Go 语言的编译程序会试图把这种名字的包编译为二进制可执行文件。 当编译器发现某个包的名字为 main 时，它一定也会发现名为 main() 的函数，否则不会创建可执行文件。main() 函数是程序的入口，所以，如果没有这个函数，程序就没有办法开始执行。程序编译时，会使用声明 main 包的代码所在的目录的目录名作为二进制可执行文件的文件名。 在 Go 语言里，命令是指任何可执行程序，包更常用来指语义上可导入的功能单元。","link":"/post/a470d515.html"},{"title":"本地仓库代码推送到github","text":"本地仓库代码推送到 github 的步骤 使用 github 只需要简单的三步： 初始化本地仓库 git 将自己的电脑与指定 github 账户关联 将自己的仓库与 github 上的某个项目关联 一、初始化本地仓库 git1、首先下载 git 先去 git 官方地址下载 git。下载后，直接按照默认配置安装。 2、验证是否安装成功 回到电脑桌面，鼠标右击如果看到有两个 git 相关的右键菜单栏，则安装成功。 或者 “Win+R” 进入命令行界面，输入 cmd。当输入 git，出现以下界面，则表示安装成功。 3、git 初始化及仓库创建操作 新建一个文件夹作为本地仓库，右建，选择 git bash here，在打开的页面中输入 git init（初始化本地仓库） 二、将自己的电脑与指定 github 账户关联1、注册 GitHub 账户 设置用户名：git config –global user.name ‘你在 github上 注册的用户名’; 设置用户邮箱：git config –global user.email ‘注册时候的邮箱’; 12git config --global user.name 'beyond'git config --global user.mail '123456@qq.com' 检验是否配置成功：git config –list 123456789101112131415161718192021$ git config --listdiff.astextplain.textconv=astextplainfilter.lfs.clean=git-lfs clean -- %ffilter.lfs.smudge=git-lfs smudge -- %ffilter.lfs.process=git-lfs filter-processfilter.lfs.required=truehttp.sslbackend=opensslhttp.sslcainfo=D:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crtcore.autocrlf=truecore.fscache=truecore.symlinks=falsepull.rebase=falsecredential.helper=manageruser.name=beyonduser.mail=123456@qq.comcore.repositoryformatversion=0core.filemode=falsecore.bare=falsecore.logallrefupdates=truecore.symlinks=falsecore.ignorecase=true 2、将 GitHub 上对应的项目复制到本地 git clone 仓库地址（即 github 上的地址，项目在之前已经在 github 上 new repository 出来了） 123456$ git clone https://github.com/beyondhxl/chatroom.gitCloning into 'chatroom'...remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), 583 bytes | 83.00 KiB/s, done. 3、将本地项目同步到 GitHub 上：git push 生成本机的 SSH key输入：ssh-keygen -t rsa -C &quot;邮箱&quot; （注意！双引号里面是你在 github 注册的邮箱）123456789101112131415161718192021$ ssh-keygen -t rsa -C \"123456@qq.com\"Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/PCSetupAccount/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/PCSetupAccount/.ssh/id_rsaYour public key has been saved in /c/Users/PCSetupAccount/.ssh/id_rsa.pubThe key fingerprint is:SHA256:hPXgDS5RHWD5w0EudhANVvNn3rY54332jzbB+qUB9q0 123456@qq.comThe key's randomart image is:+---[RSA 3072]----+| ..%X=. || O.B+o || o *o=.. o || + o+ + . || S .o.. o|| . oooo|| .o*o|| . +**|| oE+B|+----[SHA256]-----+ 完成上面操作无误后，即可在上面指出的目录下找到两个文件 id_rsa 和 id_rsa_pub。接着用 Notepad++ 打开 id_rsa_pub 文件，复制 id_rsa_pub 文件里面的所有内容。打开 github，进入 settings，选择左边的 SSH and GPG keys，把刚才复制的密钥添加进去，title 那里可以自己取一个名字，点击添加，最后就可以看到生成 sshkey 了。下次上传项目时就不需要再配置密钥了。 4、遇到的问题 推送问题一 123$ git push -u origin mastererror: src refspec master does not match anyerror: failed to push some refs to 'github.com:beyondhxl/chatroom.git' 引起该错误的原因是，目录中没有文件，空目录是不能提交上去的，而且在 push 之前至少有过一次 commit。解法方法： 123456git init git touch README git add README git commit -m 'first commit'git remote add origin https://github.com/xxx.github.io.gitgit push origin master 如果在 github 的 remote 上已经有了文件，会出现错误。此时应当先 pull 一下，即 1git pull origin master 推送问题二 12345678$ git push origin masterTo github.com:beyondhxl/chatroom.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'github.com:beyondhxl/chatroom.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 可以使用如下语句强制推送 1$ git push -u origin master -f 但是这样会使远程修改丢失，一般是不可取的，尤其是多人协作开发的时候。 推送问题三 12$ git remote add origin git@github.com:beyondhxl/somedocs.gitfatal: not a git repository (or any of the parent directories): .git 对应解决方法 12$ git initInitialized empty Git repository in D:/somedocs/.git/ 推送问题四 12345678910111213$ git commit -m\"更新\"*** Please tell me who you are.Run git config --global user.email \"you@example.com\" git config --global user.name \"Your Name\"to set your account's default identity.Omit --global to set the identity only in this repository.fatal: unable to auto-detect email address (got 'PCSetupAccount@L-R90YFQ7W-1223.(none)') 参考文章:1、github上传时出现error: src refspec master does not match any解决办法2、Git 提示error:src refspec master does not match any3、将本地代码上传到GitHub4、【Git】Updates were rejected because the tip of your current branch is behind","link":"/post/5cc80e12.html"},{"title":"进程结构和内存布局","text":"进程结构和内存布局 一、进程和程序进程（process）是一个可执行程序（program）的实例。 程序是包含了一系列信息的文件，这些信息描述了如何在运行时创建一个进程，包含如下内容： 二进制格式标识：每个程序文件都包含用于描述可执行文件格式的元信息（meta information）。 机器语言指令：对程序算法进行编码。 程序入口地址：标识程序开始执行时的起始指令位置。 数据：程序文件包含的变量初始值和程序使用的字面常量值（比如字符串）。 符号表及重定位表：描述程序中函数和变量的位置及名称。这些表格有多种用途，其中包含调试和运行时的符号解析（动态链接）。 共享库和动态链接信息：程序文件所包含的一些字段，列出了程序运行时需要使用的共享库，以及加载共享库的动态链接器的路径名。 其它信息：程序文件还包含许多其它信息，用以描述如何创建进程。 从内核角度看，进程由用户内存空间和一系列内核数据结构组成，其中用户内存空间包含了程序代码及代码所使用的变量，而内核数据结构则用于维护进程状态信息。 记录在内核数据结构中的信息包括许多与进程相关的标识号、虚拟内存表、打开文件的描述符表、信号传递及处理的有关信息、进程资源使用及限制、当前工作目录和大量的其它信息。 每个进程都有一个进程号（PID），进程号是一个正数，用以唯一标识系统中的某个进程。 Linux 内核限制进程号需小于等于 32767。新进程创建时，内核会按顺序将下一个可用的进程号分配给其使用。每当进程号达到 32767 的限制时，内核将重置进程号计数器，以便从小整数开始分配。（实际上，一旦进程号达到 32767，会将进程号计数器重置为 300，而不是 1。因为低数值的进程号为系统进程和守护进程所长期占用。） 在 Linux2.4 版本及更早的版本，进程号的上限是 32767，有内核常量 PID_MAX 所定义。在 Linux2.6 中，情况有所改变，尽管进程号的默认上限仍为 32767，但可以通过 Linux 系统中特有的 /proc/sys/kernel/pid_max 文件来进行调整（其值=最大进程号+1）。在 32 位平台中，pid_max 文件的最大值为 32768，但是在 64 位平台中，该文件的最大值可以高达 222（约400万），系统可能容纳的进程数量会非常庞大。 每个进程都有一个创建自己的进程，每个进程的父进程号属性反应了系统上所有进程间的树状关系。每个进程的父进程又有自己的父进程，以此类推，回溯到 1 号进程 –init 进程，即所有进程的始祖。 如果子进程的父进程终止，则子进程就会变成“孤儿”，init 进程随即将收养该进程。 二、进程内存布局每个进程所分配的内存由很多部分组成，通常称之为“段（segment）”： 文本段：包含了进程运行的程序机器语言指令。文本段具有只读属性，以防止进程通过错误指针意外修改自身指令。因为多个进程可同时运行同一程序，所以又将文本段设为可共享，这样，一份程序代码的拷贝可以映射到所有这些进程的虚拟地址空间中。 初始化数据段：包含显示初始化的全局变量和静态变量。当程序加载到内存时，从可执行文件中读取这些变量的值。 未初始化数据段：包含了未进行显示初始化的全局变量和静态变量。程序启动之前，系统将本段内所有内存初始化为 0。出于历史原因，此段常被称为 BSS 段，这源于老版本的汇编语言助记符 “block started by symbol”。将经过初始化的全局变量和静态变量与未初始化的全局变量和静态变量分开存放，其主要原因在于程序在磁盘上存储时，没有必要为未经初始化的变量分配存储空间。相反，可执行文件只需记录未初始化数据段的位置及所需大小，直到运行时再由程序加载器来分配空间。 栈（stack）：是一个动态增长和收缩的段，由栈帧（stack frames）组成。系统会为每个当前调用的函数分配一个栈帧。栈帧中存储了函数的局部变量（所谓自动变量）、实参和返回值。 堆（heap）：是可在运行时（为变量）动态进行内存分配的一块区域。堆顶端称为 program break。 对于初始化和未初始化的数据段而言，不太常用、但表达更清晰的称谓分别是用户初始化数据段（user-initialized data segment）和零初始化数据段（zero-initialized data segment）。 在大多数 Unix（包括 Linux）中的 C 语言编程环境提供了 3 个全局符号（symbol）：etext、edata、end，可以在程序中使用这些符号以获取相应程序文本段、初始化数据段和非初始化数据段结尾处下一字节的地址。 使用这些符号，必须显式声明如下： 1extern char etext, edata, end; // For example, &amp;etext gives the address of the end of the program text / start of initialized data 图中标灰的区域表示这些范围在进程虚拟地址空间中不可用，也就是说，没有为这些区域创建页表（page table）。 三、虚拟内存管理Linux 采用了虚拟内存管理技术。该技术利用了大多数程序的一个典型特征，即访问局部性（locality of reference），以求高效使用 CPU 和 RAM（物理内存）资源。 大多数程序都展现了两种类型的局部性： 空间局部性（Spatial locality）：是指程序倾向于访问在最近访问过的内存地址附近的内存（由于指令是顺序执行的，且有时会按顺序处理数据结构）。 时间局部性（Temporal locality）：是指程序倾向于在不久的将来再次访问最近刚访问过的内存地址（由于循环）。 正是由于访问局部性特征，使得程序即便仅有部分地址空间存在于 RAM 中，依然可能得以执行。 虚拟内存的规划之一是将每个程序使用的内存分割成小型的、固定大小的“页（page）”单元。相应地，将 RAM 划分成一系列与虚存页尺寸相同的页帧。任一时刻，每个程序仅有部分页需要驻留在物理内存页帧中。这些页构成了所谓的驻留集（resident set）。程序未使用的页拷贝保存在交换区（swap area）内 – 这是磁盘空间中的保留区域，作为计算机 RAM 的补充 – 仅在需要时才会载入物理内存。若进程欲访问的页面目前并未驻留在内存中，将会发生页面错误（page fault），内核即刻挂起进程的执行，同时从磁盘中将该页面载入内存。（程序可调用 sysconf(_SC_PAGESIZE) 来获取系统虚拟内存的页面大小）。 为支持这一组织方式，内核需要为每个进程维护一张页表（page table）。该页表描述了每页在进程虚拟地址空间（virtual address space）中的位置（可为进程所用的所有虚拟内存页面的集合）。页表中的每个条目要么指出一个虚拟页面在 RAM 中的所在位置，要么表明其当前驻留在磁盘上。 在进程虚拟地址空间中，并非所有的地址范围都需要页表条目。通常情况下，由于可能存在大段的虚拟地址空间并未投入使用，故而也无必要为其维护相应的页表条目。若进程试图访问的地址并无页表条目与之对应，那么进程将收到一个 SIGSEGV 信号。 由于内核能够为进程分配和释放页（和页表条目），所以进程的有效虚拟地址范围在其生命周期中可以发生变化。这可能会发生于如下场景： 由于栈向下增长超出之前曾达到的位置。 当在堆中分配或释放内存时，通过调用 brk()、sbrk() 或 malloc 函数族来提升 program break 的位置。 当调用 shmat() 连接 System V 共享内存区时，或者当调用 shmdt() 脱离共享内存区时。 当调用 mmap() 创建内存映射时，或者当调用 munmap() 解除内存映射时。 虚拟内存管理是使进程的虚拟地址空间与 RAM 物理地址空间隔离开来，这带来许多优点： 进程与进程、进程与内核相互隔离，所以一个进程不能读取或修改另一个进程或内核的内存。这是因为每个进程的页表条目指向 RAM（或交换区）中截然不同的物理页面集合。 适当情况下，两个或更多进程能够共享内存。这是由于内核可以使不同进程的页表条目指向相同的 RAM 页。内存共享常发生于如下两种场景： 执行同一程序的多个进程，可共享一份（只读的）程序代码副本。当多个程序执行相同的程序文件（或加载相同的共享库）时，会隐式地实现这一类型的共享。 进程可以使用 shmget() 和 mmap() 系统调用显示地请求与其他进程共享内存区。这么做是出于进程间通信的目的。 便于实现内存保护机制：也就是说，可以对页表条目进行标记，以表示相关页面内容是可读、可写、可执行亦或是这些保护措施的组合。多个进程共享 RAM 页面时，允许每个进程对内存采取不同的保护措施。例如：一个进程可能以只读方式访问某页面，而另一进程则以读写方式访问同一页面。 程序员和编译器、链接器之类的工具无需关注程序在 RAM 中的物理布局。 因为需要驻留在内存中的仅是程序的一部分，所以程序的加载和运行都很快。而且，一个进程所占用的内存（即虚拟内存大小）能够超出 RAM 的容量。 虚拟内存管理的最后一个优点是：由于每个进程使用的 RAM 减少了，RAM 中同时可以容纳的进程数量就增多了。这增大了如下事件的概率：在任一时刻，CPU 都可执行至少一个进程，因而往往也会提高 CPU 的利用率。 参考文章:进程结构和内存布局","link":"/post/4b36a800.html"},{"title":"Go面向对象简述","text":"Go 是一个完全面向对象的语言。例如，它允许基于我们的类型定义方法，而没有像其他语言一样的装箱/拆箱操作。 Go 没有使用 classes，但提供很多相似的功能： 通过嵌入实现的自动消息委托 通过接口实现多态 通过 exports 实现的命名空间 Go 语言中没有继承。忘记 is-a 的关系，Go 采用组合的方式面向对象设计。 “使用经典的继承始终是可选的；每个问题都可以通过其他方法得到解决” - Sandi Metz 1、例子说明组合维修工需要知道自行车出行需要带上的备件，决定哪一辆自行车出租出去。问题可以通过经典的继承来解决，山地车和公路自行车是自行车基类的一个特殊化例子。 2、Packages（包）123package mainimport \"fmt\" 包提供了命名空间概念，main() 函数是这个包的入口函数，fmt 包提供格式化功能。 3、Types（类型）12345type Part struct { Name string Description string NeedsSpare bool} 我们定义了一个新的类型名为 Part，非常像 C 的结构体 1type Parts []Part Parts 类型是包含 Part 类型的数组切片，Slice 可以理解为动态增长的数组，在 Go 中是很常见的。 我们可以在任何类型上声明方法，所以我们不需要要再去封装 []Part，这意味着 Parts 会拥有 slice 的所有行为，再加上我们自己定义的行为方法。 4、方法12345678func (parts Parts) Spares() (spares Parts) { for _, part := range parts { if part.NeedsSpare { spares = append(spares, part) } } return spares} Go 中定义方法就像一个函数，除了它有一个显式的接收者，紧接着 func 之后定义。 方法的主体十分简单。我们重复 parts，忽略索引的位置 (_)，过滤 parts 后返回。append builtin 需要分配和返回一个大的切片，因为我们并没有预先分配好它的容量。 这段代码没有 ruby 代码来得优雅。在 Go 语言中有过滤函数，但它并非是 builtin。 5、内嵌1234type Bicycle struct { Size string Parts} 自行车由 Size 和 Parts 组成。没有给 Parts 指定一个名称，我们是要保证实现内嵌。这样可以提供自动的委托，不需特殊的声明，例如 bike.Spares() 和 bike.Parts.Spares() 是等同的。 如果我们向 Bicycle 增加一个 Spares() 方法，它会得到优先权，但是我们仍然引用嵌入的 Parts.Spares()。这跟继承十分相似，但是内嵌并不提供多态。Parts 的方法的接收者通常是 Parts 类型，甚至是通过 Bicycle 委托的。 与继承一起使用的模式，就像模板方法模式，并不适合于内嵌。 6、Composite Literals（复合语义）1234567891011121314151617181920var ( RoadBikeParts = Parts{ {\"chain\", \"10-speed\", true}, {\"tire_size\", \"23\", true}, {\"tape_color\", \"red\", true}, } MountainBikeParts = Parts{ {\"chain\", \"10-speed\", true}, {\"tire_size\", \"2.1\", true}, {\"front_shock\", \"Manitou\", false}, {\"rear_shock\", \"Fox\", true}, } RecumbentBikeParts = Parts{ {\"chain\", \"9-speed\", true}, {\"tire_size\", \"28\", true}, {\"flag\", \"tall and orange\", true}, }) Go 提供优美的语法，来初始化对象，叫做 composite literals。使用像数组初始化一样的语法，来初始化一个结构，使得我们不再需要 ruby 例子中的 Parts 工厂。 Composite literals（复合语义）同样可以用于字段:值的语法，所有的字段都是可选的。 简短的定义操作符 (:=) 通过 Bicycle 类型，使用类型推论来初始化 roadBike 和其他。 1234func main() { roadBike := Bicycle{Size: \"L\", Parts: RoadBikeParts} mountainBike := Bicycle{Size: \"L\", Parts: MountainBikeParts} recumbentBike := Bicycle{Size: \"L\", Parts: RecumbentBikeParts} 7、输出123fmt.Println(roadBike.Spares())fmt.Println(mountainBike.Spares())fmt.Println(recumbentBike.Spares()) 我们将以默认格式打印 Spares 的调用结果： 123[{chain 10-speed true} {tire_size 23 true} {tape_color red true}][{chain 10-speed true} {tire_size 2.1 true} {rear_shock Fox true}][{chain 9-speed true} {tire_size 28 true} {flag tall and orange true}] 8、组合 Parts12345678910 ... comboParts := Parts{} comboParts = append(comboParts, mountainBike.Parts...) comboParts = append(comboParts, roadBike.Parts...) comboParts = append(comboParts, recumbentBike.Parts...) fmt.Println(len(comboParts), comboParts[9:]) fmt.Println(comboParts.Spares())} Parts 的行为类似于 slice。按照长度获取切片，或者将数个切片结合。Ruby 中的类似解决方案就数组的子类，但是当两个 Parts 连接在一起时，Ruby 将会“错置” spares 方法。 “……在一个完美的面向对象的语言，这种解决方案是完全正确的。不幸的是，Ruby 语言并没有完美的实现……” —— Sandi Metz 在 Ruby 中有一个难看的解决方法，使用 Enumerable、forwardable，以及 def_delegators。Go 没有这样的缺陷，[]Part 正是我们所需要的，且更为简洁（更新：Ruby 的 SimpleDelegator 看上去好了一点）。 9、接口 InterfacesGo 的多态性由接口提供。不像 JAVA 和 C#，它们是隐含实现的，所以接口可以为不属于我们的代码定义。 和动态类型比较，接口是在它们声明过程中静态检查和说明的，而不是通过写一系列响应（respond_to）测试完成的。 “不可能不知不觉的或者偶然的创建一个抽象；在静态类型语言中定义的接口总是有倾向性的。” - Sandi Metz 给个简单的例子，假设我们不需要打印 Part 的 NeedsSpare 标记。我们可以写这样的字符串方法： 123func (part Part) String() string { return fmt.Sprintf(\"%s: %s\", part.Name, part.Description)} 然后对上述 Print 的调用将会输出这样的替代结果： 123[chain: 10-speed tire_size: 23 tape_color: red][chain: 10-speed tire_size: 2.1 rear_shock: Fox][chain: 9-speed tire_size: 28 flag: tall and orange] 这个机理是因为我们实现了 fmt 包会用到的 Stringer 接口。它是这么定义的： 123type Stringer interface { String() string} 接口类型在同一个地方可以用作其它类型。变量与参数可以携带一个 Stringer，可以是任何实现 String() string 方法签名的接口。 10、Exports 导出Go 使用包来管理命名空间，要使某个符号对其他包（package ）可见（即可以访问），需要将该符号定义为以大写字母开头，当然如果以小写字母开头，那就是私有的，包外不可见。 12345type Part struct { name string description string needsSpare bool} 为了对 Part 类型应用统一的访问原则（uniform access principle），我们可以改变 Part 类型的定义并提供 setter/getter 方法，就像这样: 1234567func (part Part) Name() string { return part.name}func (part *Part) SetName(name string) { part.name = name} 这样可以很容易的确定哪些是 public API，哪些是私有的属性和方法，只要通过字母的大小写。（例如 part.Name() vs .part.name） 注意，我们不必要对 getters 加前 Get，（例如.GetName），Getter 不是必需，特别是对于字符串，当我们有需要时，我们可以使用满足Stringer 类型接口的自定义的类型去改变 Name 字段。 11、找到一些私有性私有命名（小写字母）可以从同一个包的任何地方访问到，即使是包含了跨越多个文件的多个结构。如果你觉得这令人不安，包也可以像你希望的那么小。 可能的情况下用（更稳固的）公共 API 是一个好的实践，即使是来自经典语言的同样的类中。这需要一些约定，当然这些约定可以应用在 GO 中。 12、最大的好处组合、内嵌和接口提供了 Go 语言中面向对象设计的强大工具。 习惯 Go 需要思维的改变，当触及到 Go 对象模型的力量时，我非常高兴的吃惊于 Go 代码的简单和简洁。 参考文章:Go 面向对象","link":"/post/be20ec3e.html"},{"title":"设计模式-单例模式","text":"单例模式 1int pthread_once(pthread_once_t* once_control, void (*init_routine)(void)); 功能是本函数使用初值为 PTHREAD_ONCE_INIT 的 once_control 变量保证 init_routine() 函数在本进程执行序列中仅执行一次。 C++11 一种实现1234567891011121314151617181920212223template&lt;typename T&gt;class Singlrton : boost::noncopyable {public: static T&amp; instance() { // 只调用一次 init() pthread_once(&amp;once_, &amp;Singleton::init); return *value; }private: Singleton(); ~Singleton(); static void init() { value_ = new T(); } static pthread_once_t once_; static T* value_;};template&lt;typename T&gt;pthread_once_t Singleton&lt;T&gt;::once_ = PTHREAD_ONCE_INIT;template&lt;typename T&gt;T* Singleton&lt;T&gt;::value_ = nullptr; 参考文章:参考链接","link":"/post/69e7b86f.html"},{"title":"分布式事务的四种解决方案","text":"分布式事务解决方案 分布式事务指事务的操作位于不同的节点上，需要保证事务的 AICD 特性。 例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。 一、两阶段提交（2PC）两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。 1.1、运行过程1、准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。 2、提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 1.2、存在的问题1、同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。 2、单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。 3、数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 4、太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 二、补偿事务（TCC）TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try 阶段执行成功并开始执行 Confirm 阶段时，默认 Confirm 阶段是不会出错的。即：只要Try 成功，Confirm 一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假入 Bob 要向 Smith 转账，思路大概是：我们有一个本地方法，里面依次调用 首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。 在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。 如果第 2 步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 优点 跟 2PC 比起来，实现以及流程相对简单了一些，但数据的一致性比 2PC 也要差一些。 缺点 缺点还是比较明显的，在 2、3 步中都有可能失败。TCC 属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用 TCC 不太好定义及处理。 三、本地消息表（异步确保）本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 优点 一种非常经典的实现，避免了分布式事务，实现了最终一致性。 缺点 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 四、MQ 事务消息有一些第三方的 MQ 是支持事务消息的，比如 RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的 MQ 都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： 第一阶段 Prepared 消息，会拿到消息的地址。 第二阶段执行本地事务 第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要向消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了，RocketMQ 会定期扫描消息集群中的事务消息，这时候发现了 Prepared 消息，它会向消息发送者确认，所以生产方需要实现一个 check 接口，RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 优点 实现了最终一致性，不需要依赖本地数据库事务。 缺点 实现难度大，主流 MQ 不支持，RocketMQ 事务消息部分代码也未开源。 五、总结通过本文我们总结并对比了几种分布式事务解决方案的优缺点，分布式事务本身是一个技术难题，是没有一种完美的方案应对所有场景的，具体还是要根据业务场景去抉择。阿里 RocketMQ 实现的分布式事务，现在也有了很多分布式事务的协调器，比如 LCN 等，大家可以多去尝试。 参考原文:分布式事务的四种解决方案","link":"/post/75ca4e90.html"},{"title":"细说new与malloc的10点区别(转载)","text":"new 与 malloc 的区别 一、申请的内存所在位置new 操作符从自由存储区（free store）上为对象动态分配内存空间，而 malloc 函数从堆上动态分配内存。自由存储区是 C++ 基于 new 操作符的一个抽象概念，凡是通过 new 操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C 语言使用 malloc 从堆上分配内存，使用 free 释放已分配的对应内存。 那么自由存储区是否能够是堆（问题等价于 new 是否能在堆上动态分配内存），这取决于 operator new 的实现细节。自由存储区不仅可以是堆，还可以是静态存储区，这要看 operator new 在哪里为对象分配内存。 特别的，new 甚至可以不为对象分配内存！定位 new 的功能可以办到这一点： 1new (place_address) type place_address 为一个指针，代表一块内存的地址。当使用上面这种仅以一个地址调用 new 操作符时，new 操作符调用特殊的 operator new，也就是下面这个版本： 1void * operator new (size_t, void *) //不允许重定义这个版本的operator new 这个 operator new 不分配任何的内存，它只是简单地返回指针实参，然后 new 表达式负责在 place_address 指定的地址进行对象的初始化工作。 二、返回类型安全性new 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 new 是符合类型安全性的操作符。而malloc 内存分配成功则是返回 void * ，需要通过强制类型转换将 void * 指针转换成我们需要的类型。 类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域。 三、内存分配失败时的返回值new 内存分配失败时，会抛出 bac_alloc 异常，它不会返回 NULL；malloc 分配内存失败时返回 NULL。 在使用 C 语言时，我们习惯在 malloc 分配内存后判断分配是否成功： 123456789int *a = (int *)malloc(sizeof(int));if(NULL == a){ ...}else { ...} 从 C 语言走入 C++ 阵营的新手可能会把这个习惯带入 C++： 123456789int *a = new int();if(NULL == a){ ...}else{ ...} 实际上这样做一点意义也没有，因为 new 根本不会返回 NULL，而且程序能够执行到 if 语句已经说明内存分配成功了，如果失败早就抛异常了。正确的做法应该是使用异常机制： 12345678try{ int *a = new int();}catch(bad_alloc){ ...} 如果你想顺便了解下异常基础，可以看 http://www.cnblogs.com/QG-whz/p/5136883.htmlC++ 异常机制分析。 四、是否需要指定内存大小使用 new 操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而 malloc 则需要显式地指出所需内存的尺寸。 123class A{...}A *ptr = new A;A *ptr = (A *)malloc(sizeof(A)); //需要显式指定所需内存大小sizeof(A); 当然了，我这里使用 malloc 来为我们自定义类型分配内存是不怎么合适的，请看下一条。 五、是否调用构造函数/析构函数使用 new 操作符来分配对象内存时会经历三个步骤： 第一步：调用 operator new 函数（对于数组是 operator new[]）分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。 第二步：编译器运行相应的构造函数以构造对象，并为其传入初值。 第三部：对象构造完成后，返回一个指向该对象的指针。 使用 delete 操作符来释放对象内存时会经历两个步骤： 第一步：调用对象的析构函数。 第二步：编译器调用 operator delete（或 operator delete[]）函数释放内存空间。 总之来说，new/delete 会调用对象的构造函数/析构函数以完成对象的构造/析构。而 malloc 则不会。 12345678910111213class A{public: A() : a(1), b(1.11) {}private: int a; double b;};int main(){ A *ptr = (A*)malloc(sizeof(A)); return 0;} 在 return 处设置断点，观看 ptr 所指内存的内容： 可以看出 A 的默认构造函数并没有被调用，因为数据成员 a、b 的值并没有得到初始化，这也是上面我为什么说使用 malloc/free 来处理 C++ 的自定义类型不合适，其实不止自定义类型，标准库中凡是需要构造/析构的类型通通不合适。 而使用 new 来分配对象时： 1234int main(){ A *ptr = new A;} 查看程序生成的汇编代码可以发现，A 的默认构造函数被调用了： 六、对数组的处理C++ 提供了 new[] 与 delete[] 来专门处理数组类型: 1A *ptr = new A[10]; //分配10个A对象 使用 new[] 分配的内存必须使用 delete[] 进行释放： 1delete [] ptr; new 对数组的支持体现在它会分别调用构造函数初始化每一个数组元素，释放对象时为每个对象调用析构函数。注意 delete[] 要与 new[] 配套使用，不然会造成数组对象部分释放的现象，造成内存泄漏。 至于 malloc，它并知道你在这块内存上要放的数组还是啥别的东西，反正它就给你一块原始的内存，再给你个内存的地址就完事。所以如果要动态分配一个数组的内存，还需要我们手动自定数组的大小： 1int *ptr = (int *)malloc(sizeof(int)*10); //分配一个10个int元素的数组 七、new与malloc是否可以相互调用operator new /operator delete 的实现可以基于 malloc，而 malloc 的实现不可以去调用 new。下面是编写 operator new /operator delete 的一种简单方式，其他版本也与之类似： 123456789101112void * operator new (sieze_t size){ if(void * mem = malloc(size)) return mem; else throw bad_alloc();}void operator delete(void *mem) noexcept{ free(mem);} 八、是否可以被重载opeartor new /operator delete 可以被重载。标准库是定义了 operator new 函数和 operator delete 函数的 8 个重载版本： 1234567891011//这些版本可能抛出异常void * operator new(size_t);void * operator new[](size_t);void * operator delete(void * ) noexcept;void * operator delete[](void *) noexcept;//这些版本承诺不抛出异常void * operator new(size_t, nothrow_t&amp;) noexcept;void * operator new[](size_t, nothrow_t&amp;) noexcept;void * operator delete (void *, nothrow_t&amp;) noexcept;void * operator delete[](void *, nothrow_t&amp;) noexcept; 我们可以自定义上面函数版本中的任意一个，前提是自定义版本必须位于全局作用域或者类作用域中。太细节的东西不在这里讲述，总之，我们知道我们有足够的自由去重载 operator new /operator delete，以决定我们的 new 与 delete 如何为对象分配内存，如何回收对象。 而 malloc/free 并不允许重载。 九、能够直观地重新分配内存使用 malloc 分配的内存后，如果在使用过程中发现内存不足，可以使用 realloc 函数进行内存重新分配实现内存的扩充。realloc 先判断当前的指针所指内存是否有足够的连续空间，如果有，原地扩大可分配的内存地址，并且返回原来的地址指针；如果空间不够，先按照新指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来的内存区域。 new 没有这样直观的配套设施来扩充内存。 十、客户处理内存分配不足在 operator new 抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是 new-handler。new_handler 是一个指针类型： 1234namespace std{ typedef void (*new_handler)();} 指向了一个没有参数没有返回值的函数，即为错误处理函数。为了指定错误处理函数，客户需要调用 set_new_handler，这是一个声明于的一个标准库函数: 1234namespace std{ new_handler set_new_handler(new_handler p) throw();} set_new_handler 的参数为 new_handler 指针，指向了 operator new 无法分配足够内存时该调用的函数。其返回值也是个指针，指向set_new_handler 被调用前正在执行（但马上就要发生替换）的那个 new_handler 函数。 对于 malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着 malloc 返回 NULL。 十一、总结 特征 new/delete malloc/free 分配内存的位置 自由存储区 堆 内存分配成功的返回值 完整类型指针 void* 内存分配失败的返回值 默认抛出异常 返回 NULL 分配内存的大小 由编译器根据类型计算得出 必须显式指定字节数 处理数组 有处理数组的 new 版本 new[] 需要用户计算数组的大小后进行内存分配 已分配内存的扩充 无法直观地处理 使用 realloc 简单完成 是否相互调用 可以，看具体的 operator new/delete 实现 不可调用 new 分配内存时内存不足 客户能够指定处理函数或重新制定分配器 无法通过用户代码进行处理 函数重载 允许 不允许 构造函数与析构函数 调用 不调用 malloc 给你的就好像一块原始的土地，你要种什么需要自己在土地上来播种 而 new 帮你划好了田地的分块（数组），帮你播了种（构造函数），还提供其他的设施给你使用: 当然，malloc 并不是说比不上 new，它们各自有适用的地方。在 C++ 这种偏重 OOP 的语言，使用 new/delete 自然是更合适的。 参考原文:细说new与malloc的10点区别","link":"/post/31846410.html"},{"title":"深度探索C++对象模型（简单对象模型、表格驱动模型、C++对象模型）","text":"深度探索 C++ 对象模型 零、前言对象模型是深层结构知识，关系到“与语言无关、与平台无关、跨网络可执行”软件组件的基础。 C++ 相对于精瘦的 C 来说，多了许多特性，正因如此，我们更有必要去探索、了解 C++ 对象模型，到底背着我们又发生了什么事情。在了解 C++ 对象模型之前，有必要先从简单一点的两个模型入手：简单对象模型、表格驱动模型。 一、简单对象模型现在我们考虑一个 Point 类，其声明如下： 1234567891011class Point {public: Point(float xval); virtual ~Point(); float x() const; static int PointCount();protected: virtual ostream&amp; print(ostream&amp; os) const; float _x; static int _point_count;}; 在 C++ 中，成员数据（class data member）有两种：static 和 nonstatic，成员函数（class member function）有三种：static、nonstatic 和 virtual。 那么上述的 Point 类，用简单对象模型应该怎么塑模这些 data members 和 function members 呢，如下： 这个对象模型比较简单，在这个简单模型中，object 中存放的并不是 member 而是一系列的 slots，每个 slot 指向一个 member，按 member 在 class 中的声明顺序，即 object 中存放的是“指向 member 的指针”，这就避免了因不同类型的 member 需要不同存储空间所带来的问题。 二、表格驱动模型与简单对象模型类似，但又有所不同。表格驱动对象模型将 class 中的 member 分成 data 和 function 两个部分，一个放在 data member table 中，一个放在 member function table 中，而 class object 则持有指向这两个 table 的指针。在往下划分，data member table 直接存放 data 本身，而 member function table 则是一系列的 slots，每个 slot 指向一个 member function，如下。 这种对象模型不会因 class 中 data membe 和 member function 的增减而改变其大小，但在操作 member function 时，比 data member 多了一次寻址。 三、CPlusPlus 对象模型C++ 对象模型是从简单对象模型派生而来的，并对内存空间和存取时间做了优化。在此模型中对 data 而言 nonstatic data member 被置于class object 之内，static data member 被置于 class object 之外；对 function 而言，static 和 nonstatic member function 被置于 class object 之外，virtual member function 则由以下两步支持： 每一个 class 产生出一堆指向 virtual function 的指针，并存放于表格中，即 virtual table（vtbl）； 每个 class object 被安插一个指针（vptr），指向相关的 virtual table。 上面两点是用以支持 virtual function 的。在 C++ 中，关键字 virtual 的存在只有两处，一出现在 member function 之前形成 virtual function，二出现在 inheritance 时形成 virtual inheritance（虚拟继承），若 base class 或 derived class 不是以上两种情况，也无 virtual table 之说了。 另外，在 C++ 对象模型中我们可以看到 vptr 指向的 virtual table 中多了一个 type_info，并且位于 vtbl 的第一个 slot，这是用以支持rumtime type identification（RTTI）的，vptr 这个指针的设定、重置都由每一个 class 的 constructor、destructor 和 copy assignment 运算符自动完成。 更进一步的说，pt-&gt;vtbl[0] 指向 Point 的 type_info object，pt-&gt;vtbl[1] 指向 Point::~Point()，pt-&gt;vtbl[2] 指向 Point::print()。 参考原文:《深度探索C++对象模型》：简单对象模型、表格驱动模型、C++对象模型","link":"/post/1787b1c6.html"},{"title":"游戏服务器的架构演进(转载)","text":"游戏服务器的架构演进 一、游戏服务器特征游戏服务器端，是一个会长期运行的程序，并且它还要服务于多个不定时，不定点的网络请求。所以这类软件的特点是要非常关注稳定性和性能。这类程序如果需要多个协作来提高承载能力，则还要关注部署和扩容的便利性；同时，还需要考虑如何实现某种程度容灾需求。由于多进程协同工作，也带来了开发的复杂度，这也是需要关注的问题。 功能约束，是架构设计决定性因素。基于游戏领域的功能特征，对服务器端系统来说，有以下几个特殊的需求： 对于游戏数据和玩家数据的存储 对玩家数据进行数据广播和同步 把一部分游戏逻辑在服务器上运算，做好验证，防止外挂 针对以上的需求特征，在服务器端，我们往往会关注对电脑内存和 CPU 的使用，以求在特定业务代码下，能尽量满足承载量和响应延迟的需求。最基本的做法就是“空间换时间”，用各种缓存的方式来以求得 CPU 和内存空间上的平衡。 在 CPU 和内存之上，是另外一个约束因素网卡。网络带宽直接限制了服务器的处理能力，所以游戏服务器架构也必定要考虑这个因素。 二、游戏服务器架构要素对于游戏服务端架构，最重要的三个部分就是，如何使用 CPU、内存、网卡的设计： 内存架构：主要决定服务器如何使用内存，以最大化利用服务器端内存来提高承载量，降低服务延迟。 逻辑架构：设计如何使用进程、线程、协程这些对于 CPU 调度的方案。选择同步、异步等不同的编程模型，以提高服务器的稳定性和承载量。可以分区分服，也可以采用世界服的方式，将相同功能模块划分到不同的服务器来处理。 通信模式：决定使用何种方式通讯。基于游戏类型不同采用不同的通信模式，比如 http、tcp、udp 等。 三、服务器演化进程3.1、卡牌等休闲游戏弱交互游戏 这种服务器架构和我们常用的 web 服务器架构差不多，也是采用 nginx 负载集群支持服务器的水平扩展，memcache 做缓存。 唯一不同在于通信层需要对协议再加工和加密，一般每个公司都有自己的一套基于 http 的协议层框架，很少采用开源框架。 3.2、长链接游戏服务器长连接游戏和弱联网游戏不同的地方在于，长连接中，玩家是有状态的，服务器可以时时和 client 交互，数据的传送，不像弱联网一般每次都需要重新创建一个连接，消息传送的频率以及速度上都快于弱联网游戏。 1、第一代网游服务器（单线程无阻塞）最早的游戏服务器是 1978 年，英国著名的财经学校 University of Essex 的学生 Roy Trubshaw 编写了世界上第一个 MUD 程序，叫做《MUD1》。 《MUD1》程序的源代码在 ARPANET 共享之后，在全世界广泛流行起来。不断完善的 MUD1 的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖。 《MUD1》是一款纯文字的世界，没有任何图片，但是不同计算机前的玩家可以在游戏里共同冒险、交流。 与以往具有网络联机功能的游戏相比，MUD1 是第一款真正意义上的实时多人交互的网络游戏，它最大的特色是能够保证整个虚拟世界和玩家角色的持续发展 —— 无论是玩家退出后重新登录还是服务器重启，游戏中的场景、宝箱、怪物和谜题仍保持不变，玩家的角色也依然是上次的状态。 MUDOS 使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处理，主线程每隔 1 秒钟更新一次所有对象（网络收发，对象状态，刷新地图，刷新 NPC）。 用户使用 Telnet 之类的客户端用 Tcp 协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。这样的系统在当时每台服务器承载个 4000 人同时游戏。从 1991 年的 MUDOS 发布后，全球各地都在为他改进，扩充，推出新版本。 MUDOS 中游戏内容通过 LPC 脚本进行定制，逻辑处理采用单线程 tick 轮询，这也是第一款服务端架构模型，后来被应用到不同游戏上。后续很多游戏都是跟《UO》一样，直接在 MUDOS 上进行二次开发，直到如今，一些回合制游戏，以及对运算量小的游戏，依然采用这种服务器架构。 第一代服务器架构图 线程模型 2、第二代网游服务器（分区分服）2000 年左右，随着图形界面的出现，游戏更多的采用图形界面与用户交互。此时随着在线人数的增加和游戏数据的增加，服务器变得不堪重负。于是就有了分服模型。分服模型结构如下： 分服模型是游戏服务器中最典型，也是历久最悠久的模型。在早期服务器的承载量达到上限的时候，游戏开发者就通过架设更多的服务器来解决。这样提供了很多个游戏的“平行世界”，让游戏中的人与人之间的比较，产生了更多的空间。 其特征是游戏服务器是一个个单独的世界。每个服务器的帐号是独立的，每台服务器用户的状态都是不一样的，一个服就是一个世界，大家各不牵扯。 后来游戏玩家呼吁要跨服打架，于是出现了跨服战，再加上随着游戏的运行，单个服务器的游戏活跃玩家越来越少，所以后期就有了服务器的合并以及迁移，慢慢的以服务器的开放、合并形成了一套成熟的运营手段。目前多数游戏还采用分服的结构来架设服务器，多数页游还是采用这种模式。 线程调度 分服虽然可以解决服务器扩展的瓶颈，但单台服务器在以前单线程的方式来运行，没办法充分利用服务器资源，于是又演变出了以下2种线程模型。 异步-多线程 基于每个场景（或者房间），分配一个线程。每个场景的玩家同属于一个线程。游戏的场景是固定的，不会很多，如此线程的数量可以保证不会不断增大。每个场景线程，同样采用 tick 轮询的方式，来定时更新该场景内的（对象状态，刷新地图，刷新 NPC）数据状态。玩家如果跨场景的话，就采用投递和通知的方式，告知两个场景线程，以此更新两个场景的玩家数据。 多进程 由于单进程架构下，总会存在承载量的极限，越是复杂的游戏，其单进程承载量就越低，因此一定要突破进程的限制，才能支撑更复杂的游戏。多进程系统的其他一些好处：能够利用上多核 CPU 能力、更容易进行容灾处理。 多进程系统比较经典的模型是“三层架构”，比如，基于之前的场景线程再做改进，把网络部分和数据库部分分离为单独的进程来处理，逻辑进程专心处理逻辑任务，不合 IO 打交道，网络 IO 和磁盘 IO分 别交由网路进程和 DB 进程处理。 3、第三代网游服务器之前的网游服务器都是分区分服，玩家都被划分在不同的服务器上，每台服务器运行的逻辑相同，玩家不能在不同服务器之间交互。想要更多的玩家在同一世界，保持玩家的活跃度，于是就有了世界服模型了。世界服类型也有以下 3 种演化: 一类型（三层架构） 网关部分分离成单独的 gate 服务器，DB 部分分离为 DB 服务器，把网络功能单独提取出来，让用户统一去连接一个网关服务器，再由网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网关进行交换。所有有 DB 交互的，都连接到 DB 服务器来代理处理。 二类型（cluster） 有了一类型的经验，后续肯定是拆分的越细，性能越好，就类似现在微服务，每个相同的模块分布到一台服务器处理，多组服务器集群共同组成一个游戏服务端。 一般地，我们可以将一个组内的服务器简单地分成两类：场景相关的（如行走、战斗等）以及场景不相关的（如公会聊天、不受区域限制的贸易等）。经常可以见到的一种方案是：gate 服务器、场景服务器、非场景服务器、聊天管理器、AI 服务器以及数据库代理服务器。如下模型: 我们简单的讲下服务器的三种类型功能： 场景服务器：它负责完成主要的游戏逻辑，这些逻辑包括：角色在游戏场景中的进入与退出、角色的行走与跑动、角色战斗（包括打怪）、任务的认领等。场景服务器设计的好坏是整个游戏世界服务器性能差异的主要体现，它的设计难度不仅仅在于通信模型方面，更主要的是整个服务器的体系架构和同步机制的设计。 非场景服务器：它主要负责完成与游戏场景不相关的游戏逻辑，这些逻辑不依靠游戏的地图系统也能正常进行，比如公会聊天或世界聊天，之所以把它从场景服务器中独立出来，是为了节省场景服务器的 CPU 和带宽资源，让场景服务器能够尽可能快地处理那些对游戏流畅性影响较大的游戏逻辑。 网关服务器: 在类型一种的架构中，玩家在多个地图跳转或者场景切换的时候采用跳转的模式，以此进行跳转不同的服务器。还有一种方式是把这些服务器的节点都通过网关服务器管理，玩家和网关服务器交互，每个场景或者服务器切换的时候，也有网关服务器统一来交换数据，如此玩家操作会比较流畅。 通过这种类型服务器架构，因为压力分散了，性能会有明显提升，负载也更大了，包括目前一些大型的 MMORPG 游戏就是采用此架构。不过每增加一级服务器，状态机复杂度可能会翻倍，导致研发和找 bug 的成本上升，这个对开发组挑战比较大，没有经验，很容易出错。 三类型（无缝地图） 魔兽世界的中无缝地图，想必大家印象深刻。整个世界的移动没有像以往的游戏一样，在切换场景的时候需要 loading 等待，而是直接行走过去，体验流畅。 现在的游戏大地图采用无缝地图多数采用的是 9 宫格的样式来处理，由于地图没有魔兽世界那么大，所以采用单台服务器多进程处理即可，不过类似魔兽世界这种大世界地图，必须考虑 2 个问题： 多个地图节点如何无缝拼接，特别是当地图节点比较多的时候，如何保证无缝拼接 如何支持动态分布，有些区域人多，有些区域人少，保证服务器资源利用的最大化 为了解决这个问题，比较以往按照地图来切割游戏而言，无缝世界并不存在一块地图上面的人有且只由一台服务器处理了，此时需要一组服务器来处理，每台 Node 服务器用来管理一块地图区域，由 NodeMaster（NM）来为他们提供总体管理。更高层次的 World 则提供大陆级别的管理服务。 一个 Node 所负责的区域，地理上没必要连接在一起，可以统一交给一个 Node 去管理，而这些区块在地理上并没有联系在一起的必要性。一个 Node 到底管理哪些区块，可以根据游戏实时运行的负载情况，定时维护的时候进行更改 NodeMaster 上面的配置。 对象的无缝迁移 玩家 A、B、C 分别代表 3 种不同的状态，以及不同的迁移方式，我们分别来看。 玩家 A：玩家 A 在 node1 地图服务器上，由 node1 控制，如果迁移到 node2 上，需要将其数据复制到 node2 上，然后从 node1 移除。 玩家 B：玩家 B 在 node1 和 node2 中间，此时由 node1 和 node2 维护，若是从 node1 行走到 node2 的过程中，会向 1 请求，同时向 2 请求，待全部移动过去了再移除。 玩家 C：玩家 C 在 node2 地图服务器上，由 node2 控制，如果迁移到 node1 上，需要将其数据复制到 node1 上，然后从 node2 移除。 3.3、房间服务器（游戏大厅）房间类玩法和 MMORPG 有很大的不同，在于其在线广播单元的不确定性和广播数量很小。而且需要匹配一台房间服务器让少数人进入一个服务器。 这一类游戏最重要的是其“游戏大厅”的承载量，每个“游戏房间”受逻辑所限，需要维持和广播的玩家数据是有限的，但是“游戏大厅”需要维持相当高的在线用户数，所以一般来说，这种游戏还是需要做“分服”的。典型的游戏就是《英雄联盟》这一类游戏了。而“游戏大厅”里面最有挑战性的任务，就是“自动匹配”玩家进入一个“游戏房间”，这需要对所有在线玩家做搜索和过滤。 玩家先登录“大厅服务器”，然后选择组队游戏的功能，服务器会通知参与的所有游戏客户端，新开一条连接到房间服务器上，这样所有参与的用户就能在房间服务器里进行游戏交互了。 参考原文:游戏服务器的架构演进(完整版)","link":"/post/7899d015.html"},{"title":"Google-C++编程代码风格(转载)","text":"Google C++ Code Style 零、序C++ 是 Google 大部分开源项目的主要编程语言。正如每个 C++ 程序员都知道的，C++ 有很多强大的特性，但这种强大不可避免的导致它走向复杂，使代码更容易产生 bug， 难以阅读和维护。 本指南的目的是通过详细阐述 C++ 注意事项来驾驭其复杂性。这些规则在保证代码易于管理的同时，也能高效使用 C++ 的语言特性。 风格亦被称作可读性，也就是指导 C++ 编程的约定。使用术语 “风格” 有些用词不当，因为这些习惯远不止源代码文件格式化这么简单。 使代码易于管理的方法之一是加强代码一致性。让任何程序员都可以快速读懂你的代码这点非常重要。保持统一编程风格并遵守约定意味着可以很容易根据 “模式匹配” 规则来推断各种标识符的含义。创建通用、必需的习惯用语和模式可以使代码更容易理解。在一些情况下可能有充分的理由改变某些编程风格，但我们还是应该遵循一致性原则，尽量不这么做。 一、预编译1.1、头文件一个 .cc/.cpp 文件都应该对应一个 .h 文件。也有些常见例外，例如单元测试代码和只包含 main() 入口函数的源文件。 1.1.1、Self-contained 头文件 头文件应该能够自给自足（self-contained，也就是可以作为第一个头文件被引入），简单来说就是头文件中依赖的其他声明要在头文件中定义清楚，而不能依赖在 .cc 文件中调整引入顺序解决依赖。 如果 .h 文件声明了一个模板或内联函数，同时也在该文件加以定义。凡是有用到这些的 .cc 文件，就得统统包含该头文件，否则程序可能会在构建中链接失败。 有个例外：如果某函数模板为所有相关模板参数显式实例化，或本身就是某类的一个私有成员，那么它就只能定义在实例化该模板的 .cc 文件里。 1.1.2、#define 保护 所有头文件都应该使用 #define 来防止头文件被多重包含，命名格式当是：&lt; PROJECT &gt; _ &lt; PATH &gt; _ &lt; FILE &gt; _ H _。 为保证唯一性，头文件的命名应该基于所在项目源代码树的全路径。例如项目 foo 中的头文件 foo/src/bar/baz.h 可按如下方式保护: 1234#ifndef FOO_BAR_BAZ_H_#define FOO_BAR_BAZ_H_...#endif // FOO_BAR_BAZ_H_ #define 与 #pragma once 区别 #pragma once 是编译相关，就是说这个编译系统上能用，但在其他编译系统不一定可以，也就是说移植性差。所以尽量使用 #ifndef 来避免头文件重复引用。 1.1.3、前置声明 尽可能地避免使用前置声明。使用 #include 包含需要的头文件即可。 所谓「前置声明」（forward declaration）是类、函数和模板的纯粹声明，没有伴随着定义。 优点 前置声明能够节省编译时间，多余的 #include 会迫使编译器展开更多的文件，处理更多的输入。 前置声明能够节省不必要的重新编译的时间。#include 使代码因为头文件中无关的改动而被重新编译多次。 缺点 前置声明隐藏了依赖关系，头文件改动时，用户的代码会跳过必要的重新编译过程。 前置声明可能会被库的后续更改所破坏。前置声明函数或模板有时会妨碍头文件开发者变动其 API。例如扩大形参类型，加个自带默认参数的模板形参等等。 前置声明来自命名空间 std:: 的 symbol 时，其行为未定义。 很难判断什么时候该用前置声明，什么时候该用 #include。极端情况下，用前置声明代替 #include 甚至都会暗暗地改变代码的含义： 123456789// b.h:struct B {};struct D : B {}// good_user.cc:#include \"b.h\"void f(B*);void f(void*);void test(D* x) { f(x); } // calls f(B*) 如果 #include 被 B 和 D 的前置声明替代，test() 就会调用 f(void*)。 前置声明不少来自头文件的 symbol 时，就会比单单一行的 include 冗长。 仅仅为了能前置声明而重构代码（比如用指针成员代替对象成员）会使代码变得更慢更复杂。 结论 尽量避免前置声明那些定义在其他项目中的实体。 函数总是使用 #include。 类模板优先使用 #include。 1.1.4、内联函数 只有当函数只有 10 行甚至更少时才将其定义为内联函数。 定义当函数被声明为内联函数之后，编译器会将其内联展开，而不是按通常的函数调用机制进行调用。 优点只要内联的函数体较小，内联该函数可以令目标代码更加高效。对于存取函数以及其它函数体比较短，性能关键的函数，鼓励使用内联。 缺点滥用内联将导致程序变得更慢。内联可能使目标代码量或增或减，这取决于内联函数的大小。内联非常短小的存取函数通常会减少代码大小，但内联一个相当大的函数将增加代码大小。现代处理器由于更好的利用了指令缓存，小巧的代码往往执行更快。 结论一个较为合理的经验准则是，不要内联超过 10 行的函数。谨慎对待析构函数，析构函数往往比其表面看起来要更长，因为有隐含的成员和基类析构函数被调用。 有些函数即使声明为内联的也不一定会被编译器内联，这点很重要；比如虚函数和递归函数就不会被正常内联。通常递归函数不应该声明成内联函数，递归调用堆栈的展开并不像循环那么简单，比如递归层数在编译时可能是未知的，大多数编译器都不支持内联递归函数。虚函数内联的主要原因则是想把它的函数体放在类定义内，为了图个方便，抑或是当作文档描述其行为，比如精短的存取函数。 1.1.5、#include 的路径及顺序 使用标准的头文件包含顺序可增强可读性，避免隐藏依赖相关头文件、C 库、C++ 库、其他库的 .h，本项目内的 .h。 项目内头文件应按照项目源代码目录树结构排列，避免使用 UNIX 特殊的快捷目录 .(当前目录) 或 ..(上级目录)。例如， google-awesome-project/src/base/logging.h 应该按如下方式包含: 1#include \"base/logging.h\" 又如，dir/foo.cc 或 dir/foo_test.cc 的主要作用是实现或测试 dir2/foo2.h 的功能，foo.cc 中包含头文件的次序如下： dir2/foo2.h（优先位置，详情如下） C 系统文件 C++ 系统文件 其他库的 .h 文件 本项目内 .h 文件 这种优先的顺序排序保证当 dir2/foo2.h 遗漏某些必要的库时，dir/foo.cc 或 dir/foo_test.cc 的构建会立刻中止。因此这一条规则保证维护这些文件的人们首先看到构建中止的消息而不是维护其他包的人们。 您所依赖的符号（symbols）被哪些头文件所定义，您就应该包含（include）哪些头文件，前置声明 (forward declarations) 情况除外。比如您要用到 bar.h 中的某个符号，哪怕您所包含的 foo.h 已经包含了 bar.h，也照样得包含bar.h，除非 foo.h 有明确说明它会自动向您提供bar.h 中的 symbol。不过，凡是 cc 文件所对应的「相关头文件」已经包含的，就不用再重复包含进其 cc 文件里面了，就像 foo.cc 只包含foo.h 就够了，不用再管后者所包含的其它内容。 举例来说，google-awesome-project/src/foo/internal/fooserver.cc 的包含次序如下: 1234567891011#include \"foo/public/fooserver.h\" // 优先位置#include #include #include #include#include \"base/basictypes.h\"#include \"base/commandlineflags.h\"#include \"foo/public/bar.h\" 1.1.6、小结 避免多重包含。 头文件尽量避免使用前置声明，直接 #include。 内联函数最好少于 10 行。类内部的函数一般会自动内联。所以某函数一旦不需要内联，其定义就不要再放在头文件里，而是放到对应的 .cc 文件里。 包含文件的次序除了美观之外，最重要的是可以减少隐藏依赖，使每个头文件在 “最需要编译” 的地方编译。 1.2、作用域1.2.1、命名空间 鼓励在 .cc 文件内使用匿名命名空间或 static 声明。使用具名的命名空间时，其名称可基于项目名或相对路径。禁止使用 using 指示 （using-directive e.g. using namespace foo;）。禁止使用内联命名空间 (inline namespace)。 定义 命名空间将全局作用域细分为独立的，具名的作用域，可有效防止全局作用域的命名冲突。 优点 类已经提将命名分割在不同类的作用域内，命名空间在这基础上又封装了一层。 举例来说，两个不同项目的全局作用域都有一个类 Foo，这样在编译或运行时造成冲突。如果每个项目将代码置于不同命名空间中， project1::Foo 和 project2::Foo 作为不同符号自然不会冲突。 内联命名空间会自动把内部的标识符放到外层作用域，比如：12345namespace X {inline namespace Y {void foo();} // namespace Y} // namespace X X::Y::foo() 与 X::foo() 彼此可代替。内联命名空间主要用来保持跨版本的 ABI 兼容性。 缺点 命名空间具有迷惑性，因为它们使得区分两个相同命名所指代的定义更加困难。 内联命名空间很容易令人迷惑，毕竟其内部的成员不再受其声明所在命名空间的限制。内联命名空间只在大型版本控制里有用。 结论 根据下文将要提到的策略合理使用命名空间。 遵守命名空间命名中的规则。 像之前的几个例子中一样，在命名空间的最后注释出命名空间的名字。 用命名空间把文件包含，以及类的前置声明以外的整个源文件封装起来，以区别于其它命名空间:123456789101112// .h 文件namespace mynamespace {// 所有声明都置于命名空间中// 注意不要使用缩进class MyClass { public: ... void Foo();};} // namespace mynamespace 不要在命名空间 std 内声明任何东西，包括标准库的类前置声明。在 std 命名空间声明实体是未定义的行为，会导致如不可移植。声明标准库下的实体，需要包含对应的头文件。 不应该使用 using 指示引入整个命名空间的标识符号。12// 禁止 —— 污染命名空间using namespace foo; 不要在头文件中使用命名空间别名，除非显式标记内部命名空间使用。因为任何在头文件中引入的命名空间都会成为公开 API 的一部分。 禁止用内联命名空间 1.2.2、匿名命名空间和静态变量 在 .cc 文件中定义一个不需要被外部引用的变量时，可以将它们放在匿名命名空间或声明为 static。但是不要在 .h 文件中这么做。 定义所有置于匿名命名空间的声明都具有内部链接性，函数和变量可以经由声明为 static 拥有内部链接性，这意味着你在这个文件中声明的这些标识符都不能在另一个文件中被访问。即使两个文件声明了完全一样名字的标识符，它们所指向的实体实际上是完全不同的。 结论推荐、鼓励在 .cc 中对于不需要在其他地方引用的标识符使用内部链接性声明，但是不要在 .h 中使用。 匿名命名空间的声明和具名的格式相同，在最后注释上 namespace: 123namespace {...} // namespace 1.2.3、非成员函数、静态成员函数和全局函数 使用静态成员函数或命名空间内的非成员函数，尽量不要用裸的全局函数。将一系列函数直接置于命名空间中，不要用类的静态方法模拟出命名空间的效果，类的静态方法应当和类的实例或静态数据紧密相关。 优点某些情况下，非成员函数和静态成员函数是非常有用的，将非成员函数放在命名空间内可避免污染全局作用域。 缺点将非成员函数和静态成员函数作为新类的成员或许更有意义，当它们需要访问外部资源或具有重要的依赖关系时更是如此。 结论有时，把函数的定义同类的实例脱钩是有益的，甚至是必要的。这样的函数可以被定义成静态成员，或是非成员函数。非成员函数不应依赖于外部变量，应尽量置于某个命名空间内。相比单纯为了封装若干不共享任何静态数据的静态成员函数而创建类，不如使用命名空间。举例而言，对于头文件 myproject/foo_bar.h，应当使用 123456namespace myproject { namespace foo_bar { void Function1(); void Function2(); } // namespace foo_bar } // namespace myproject 而非 1234567namespace myproject { class FooBar { public: static void Function1(); static void Function2(); }; } // namespace myproject 定义在同一编译单元的函数，被其他编译单元直接调用可能会引入不必要的耦合和链接时依赖；静态成员函数对此尤其敏感。可以考虑提取到新类中，或者将函数置于独立库的命名空间内。 如果你必须定义非成员函数，又只是在 .cc 文件中使用它，可使用匿名命名空间或 static 链接关键字 (如 static int Foo() {…}) 限定其作用域。 1.2.4、局部变量 将函数变量尽可能置于最小作用域内，并在变量声明时进行初始化。 C++ 允许在函数的任何位置声明变量。我们提倡在尽可能小的作用域中声明变量，离第一次使用越近越好。这使得代码浏览者更容易定位变量声明的位置，了解变量的类型和初始值。特别是应使用初始化的方式替代声明再赋值, 比如： 12345678910int i;i = f(); // 坏——初始化和声明分离int j = g(); // 好——初始化时声明vector v;v.push_back(1); // 用花括号初始化更好v.push_back(2);vector v = {1, 2}; // 好—— v 一开始就初始化 属于 if、while 和 for 语句的变量应当在这些语句中正常地声明，这样子这些变量的作用域就被限制在这些语句中了，举例而言: 1while (const char* p = strchr(str, '/')) str = p + 1; 有一个例外，如果变量是一个对象，每次进入作用域都要调用其构造函数，每次退出作用域都要调用其析构函数。这会导致效率降低。 1234567891011// 低效的实现for (int i = 0; i &lt; 1000000; ++i) { Foo f; // 构造函数和析构函数分别调用 1000000 次! f.DoSomething(i);}// 高效的实现Foo f; // 构造函数和析构函数只调用 1 次for (int i = 0; i &lt; 1000000; ++i) { f.DoSomething(i);} 1.2.5、静态和全局变量 禁止定义静态储存周期非 POD 变量，禁止使用含有副作用的函数初始化 POD 全局变量，因为多编译单元中的静态变量执行时的构造和析构顺序是未明确的，这将导致代码的不可移植。 静态生存周期的对象，即包括了全局变量，静态变量，静态类成员变量和函数静态变量，都必须是原生数据类型（POD : Plain Old Data）: 即 int、char 和 float，以及 POD 类型的指针、数组和结构体。 静态变量的构造函数、析构函数和初始化的顺序在 C++ 中是只有部分明确的，甚至随着构建变化而变化，导致难以发现的 bug。所以除了禁用类类型的全局变量，我们也不允许用函数返回值来初始化 POD 变量，除非该函数（比如 getenv() 或 getpid()）不涉及任何全局变量。函数作用域里的静态变量除外，毕竟它的初始化顺序是有明确定义的，而且只会在指令执行到它的声明那里才会发生。 综上所述，我们只允许 POD 类型的静态变量，即完全禁用 vector（使用 C 数组替代）和 string（使用 const char []）。 1.2.6、小结 .cc 中的匿名命名空间可避免命名冲突、限定作用域，避免直接使用 using 关键字污染命名空间 尽量不用全局函数和全局变量，考虑作用域和命名空间限制，尽量单独形成编译单元 多线程中的全局变量 (含静态成员变量) 不要使用 class 类型 (含 STL 容器)，避免不明确行为导致的 bug 局部变量在声明的同时进行显式值初始化，比起隐式初始化再赋值的两步过程要高效 二、类类是 C++ 中代码的基本单元。显然，它们被广泛使用。本节列举了在写一个类时的主要注意事项。 2.1、构造函数的职责 总述 不要在构造函数中调用虚函数，也不要在无法报出错误时进行可能失败的初始化。 定义 在构造函数中可以进行各种初始化操作。 优点 无需考虑类是否被初始化 经过构造函数完全初始化后的对象可以为 const 类型，也能更方便地被标准容器或算法使用 缺点 如果在构造函数内调用了自身的虚函数，这类调用是不会重定向到子类的虚函数实现。即使当前没有子类化实现，将来仍是隐患。 如果执行失败，会得到一个初始化失败的对象，这个对象有可能进入不正常的状态，必须使用 bool isValid() 或类似这样的机制才能检查出来，然而这是一个十分容易被疏忽的方法。 构造函数的地址是无法被取得的，因此，举例来说，由构造函数完成的工作是无法以简单的方式交给其他线程的。 结论 构造函数不允许调用虚函数。如果代码允许，直接终止程序是一个合适的处理错误的方式。否则，考虑用 Init() 方法或工厂函数。 2.2、隐式类型转换 总述 不要定义隐式类型转换。对于转换运算符和单参数构造函数，请使用 explicit 关键字。 定义 隐式类型转换允许一个某种类型 (称作源类型) 的对象被用于需要另一种类型 (称作目的类型) 的位置，例如将一个 int 类型的参数传递给需要double 类型的函数。 explicit 关键字可以用于构造函数或（在 C++11 引入）类型转换运算符，以保证只有当目的类型在调用点被显式写明时才能进行类型转换，例如使用 cast。这不仅作用于隐式类型转换，还能作用于 C++11 的列表初始化语法： 123456class Foo { explicit Foo(int x, double y); ...};void Func(Foo f); 此时下面的代码是不允许的： 1Func({42, 3.14}); // Error 这一代码从技术上说并非隐式类型转换，但是语言标准认为这是 explicit 应当限制的行为。 优点 有时目的类型名是一目了然的，通过避免显式地写出类型名，隐式类型转换可以让一个类型的可用性和表达性更强。 隐式类型转换可以简单地取代函数重载。 在初始化对象时，列表初始化语法是一种简洁明了的写法。 缺点 隐式类型转换会隐藏类型不匹配的错误。有时目的类型并不符合用户的期望，甚至用户根本没有意识到发生了类型转换。 隐式类型转换会让代码难以阅读，尤其是在有函数重载的时候，因为这时很难判断到底是哪个函数被调用。 单参数构造函数有可能会被无意地用作隐式类型转换。 如果单参数构造函数没有加上 explicit 关键字，读者无法判断这一函数究竟是要作为隐式类型转换，还是作者忘了加上 explicit 标记。 并没有明确的方法用来判断哪个类应该提供类型转换，这会使得代码变得含糊不清。 如果目的类型是隐式指定的，那么列表初始化会出现和隐式类型转换一样的问题，尤其是在列表中只有一个元素的时候。 结论 在类型定义中，类型转换运算符和单参数构造函数都应当用 explicit 进行标记. 一个例外是拷贝和移动构造函数不应当被标记为 explicit,，因为它们并不执行类型转换。 不能以一个参数进行调用的构造函数不应当加上 explicit。接受一个 std::initializer_list 作为参数的构造函数也应当省略 explicit，以便支持拷贝初始化（例如 MyType m = {1, 2};）。 2.3、可拷贝类型和可移动类型 总述 如果你的类型需要，就让它们支持拷贝 / 移动。否则，就把隐式产生的拷贝和移动函数禁用。 定义 可拷贝类型允许对象在初始化时得到来自相同类型的另一对象的值，或在赋值时被赋予相同类型的另一对象的值，同时不改变源对象的值。对于用户定义的类型，拷贝操作一般通过拷贝构造函数与拷贝赋值操作符定义。string 类型就是一个可拷贝类型的例子。 可移动类型允许对象在初始化时得到来自相同类型的临时对象的值，或在赋值时被赋予相同类型的临时对象的值（因此所有可拷贝对象也是可移动的）。std::unique_ptr&lt; int &gt; 就是一个可移动但不可复制的对象的例子。对于用户定义的类型，移动操作一般是通过移动构造函数和移动赋值操作符实现的。 拷贝 / 移动构造函数在某些情况下会被编译器隐式调用。例如，通过传值的方式传递对象。 缺点 许多类型都不需要拷贝，为它们提供拷贝操作会让人迷惑，也显得荒谬而不合理。单件类型（Registerer），与特定的作用域相关的类型 （Cleanup），与其他对象实体紧耦合的类型（Mutex）从逻辑上来说都不应该提供拷贝操作。为基类提供拷贝 / 赋值操作是有害的，因为在使用它们时会造成对象切割。默认的或者随意的拷贝操作实现可能是不正确的，这往往导致令人困惑并且难以诊断出的错误。 拷贝构造函数是隐式调用的，也就是说，这些调用很容易被忽略。这会让人迷惑，尤其是对那些所用的语言约定或强制要求传引用的程序员来说更是如此。同时，这从一定程度上说会鼓励过度拷贝，从而导致性能上的问题。 结论 如果需要就让你的类型可拷贝 / 可移动。作为一个经验法则，如果对于你的用户来说这个拷贝操作不是一眼就能看出来的，那就不要把类型设置为可拷贝。如果让类型可拷贝，一定要同时给出拷贝构造函数和赋值操作的定义，反之亦然。如果让类型可拷贝，同时移动操作的效率高于拷贝操作，那么就把移动的两个操作（移动构造函数和赋值操作）也给出定义。如果类型不可拷贝，但是移动操作的正确性对用户显然可见，那么把这个类型设置为只可移动并定义移动的两个操作。 如果定义了拷贝 / 移动操作，则要保证这些操作的默认实现是正确的。记得时刻检查默认操作的正确性，并且在文档中说明类是可拷贝的且 / 或可移动的。12345678class Foo {public: Foo(Foo&amp;&amp; other) : field_(other.field) {} // 差, 只定义了移动构造函数, 而没有定义对应的赋值运算符.private: Field field_;}; 由于存在对象切割的风险，不要为任何有可能有派生类的对象提供赋值操作或者拷贝 / 移动构造函数（当然也不要继承有这样的成员函数的类）。如果你的基类需要可复制属性，请提供一个 public virtual Clone() 和一个 protected 的拷贝构造函数以供派生类实现。 如果你的类不需要拷贝 / 移动操作，请显式地通过在 public 域中使用 = delete 或其他手段禁用之。123// MyClass is neither copyable nor movable.MyClass(const MyClass&amp;) = delete;MyClass&amp; operator=(const MyClass&amp;) = delete; 参考原文:Google C++ 编程风格","link":"/post/d5d5709a.html"},{"title":"无锁队列的一种实现","text":"无锁队列 无锁编程，称为 lock-free，是利用处理器的一些特殊原子指令来避免传统并行设计中对锁的使用，例如 x86 平台下对应的指令是 CMPXCHG。使用无锁编程至少能够带来两个方面的好处，首先是避免锁的争用，提高性能，其次通过避免锁的使用，避免死锁。无锁队列是无锁编程中最基础的，本文在这里给出一个实现。 一、无锁编程基础无锁编程最基本的一个操作是 CAS(compare and swap)，无锁编程的操作用 C++ 语言描述的话如下所示，简而言之就是看看 *reg 里面的内容是不是 oldval，如果是的话，对其复制为 newval。 12345678template &lt;typename T&gt;bool compare_and_swap(T *reg, T oldval, T newval) { if (*reg = oldval) { *reg = newval; return true; } return false;} CAS 实现是依赖编译器的： GCC 的 CASGCC4.1+ 版本支持 CAS 的原子操作。 12bool __sync_bool_compare_and_swap (type *ptr, type oldval, type newval, ...)type __sync_val_compare_and_swap (type *ptr, type oldval, type newval, ...) Windows 的 CAS 123InterlockedCompareExchange ( __inout LONG volatile *Target, __in LONG Exchange, __in LONG Comperand); C++11 中的 CAS 123456template&lt; class T &gt;bool atomic_compare_exchange_weak( std::atomic* obj, T* expected, T desired );template&lt; class T &gt;bool atomic_compare_exchange_weak( volatile std::atomic* obj, T* expected, T desired ); 二、无锁队列的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;struct ListNode { ListNode *next; int value; ListNode (int val) : value(val), next(NULL) { }};class CASQueue {private: ListNode *head; ListNode *tail;public: CASQueue() { head = new ListNode(0); tail = head; } void push(int value) { ListNode *node = new ListNode(value); ListNode *p = tail; do { while (p-&gt;next != NULL) { p = p-&gt;next; } } while (__sync_bool_compare_and_swap(&amp;p-&gt;next, NULL, node) != true); __sync_bool_compare_and_swap(&amp;tail, p, node); } int pop() { ListNode *node = head; ListNode *p; do { p = head; } while (__sync_bool_compare_and_swap(&amp;head, p, p-&gt;next) != true); int val = node-&gt;next-&gt;value; delete node-&gt;next; node-&gt;next = NULL; return val; }};int main() { CASQueue queue; queue.push(3); queue.push(4); cout &lt;&lt; queue.pop() &lt;&lt; endl; return 0;} 三、CAS 的 ABA 问题CAS 的 ABA 问题可以概括如下： 进程 P1 在共享变量中读到值为 A P1 被抢占了，进程 P2 执行 P2 把共享变量里的值从 A 改成了 B，再改回到 A，此时被 P1 抢占 P1 回来看到共享变量里的值没有被改变，于是继续执行 虽然 P1 以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。ABA 问题最容易发生在 lock free 的算法中的，CAS 首当其冲，因为 CAS 判断的是指针的地址。如果这个地址被重用了呢，问题就很大了。（地址被重用是很经常发生的，一个内存分配后释放了，再分配，很有可能还是原来的地址）。 维基百科上有一个比较通俗的比喻： 你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。 四、解决 ABA 问题可以用 double CAS，双保险 CAS 解决 ABA 问题，例如在 32 位系统上，我们要检查 64 位长的内容。 一次用 CAS 检查双倍长度的值，前半部是指针，后半部分是一个计数器。 只有这两个都一样，才算通过检查，要赋新的值。并把计数器累加 1。 这样一来，ABA 发生时，虽然值一样，但是计数器就不一样（但是在 32 位的系统上，这个计数器会溢出回来又从 1 开始的，这还是会有 ABA 的问题）。 参考原文:无锁队列的实现","link":"/post/870c5c36.html"},{"title":"设计模式-浅谈控制反转与依赖注入","text":"控制反转与依赖注入 一、小明和他的手机从前有个人叫小明 小明有三大爱好，抽烟，喝酒…… 咳咳，不好意思，走错片场了。应该是逛知乎、玩王者农药和抢微信红包 我们用一段简单的伪代码，来制造一个这样的小明 123456789101112131415161718192021class Ming extends Person{ private $_name; private $_age; function read() { //逛知乎 } function play() { //玩农药 } function grab() { //抢红包 }} 但是，小明作为一个人类，没有办法仅靠自己就能实现以上的功能，他必须依赖一部手机，所以他买了一台 iphone6，接下来我们来制造一个 iphone6。 1234567891011121314151617class iPhone6 extends Iphone{ function read($user=\"某人\") { echo $user.\"打开了知乎然后编了一个故事 \\n\"; } function play($user=\"某人\") { echo $user.\"打开了王者农药并送起了人头 \\n\"; } function grab($user=\"某人\") { echo $user.\"开始抢红包却只抢不发 \\n\"; }} 小明非常珍惜自己的新手机，每天把它牢牢控制在手心里，所以小明变成了这个样子 123456789101112131415161718192021222324252627282930class Ming extends Person{ private $_name; private $_age; public function __construct() { $this-&gt;_name = '小明'; $this-&gt;_age = 26; } function read() { //…… 省略若干代码 (new iPhone6())-&gt;read($this-&gt;_name); //逛知乎 } function play() { //…… 省略若干代码 (new iPhone6())-&gt;play($this-&gt;_name);//玩农药 } function grab() { //…… 省略若干代码 (new iPhone6())-&gt;grab($this-&gt;_name);//抢红包 }} 今天是周六，小明不用上班，于是他起床，并依次逛起了知乎，玩王者农药，并抢了个红包。 1234$ming = new Ming(); //小明起床$ming-&gt;read();$ming-&gt;play();$ming-&gt;grab(); 这个时候，我们可以在命令行里看到输出如下 123小明打开了知乎然后编了一个故事 小明打开了王者农药并送起了人头 小明开始抢红包却只抢不发 这一天，小明过得很充实，他觉得自己是世界上最幸福的人。 二、小明的快乐与忧伤小明和他的手机曾一起度过了一段美好的时光，一到空闲时刻，他就抱着手机，逛知乎，刷微博，玩游戏，他觉得自己根本不需要女朋友，只要有手机在身边，就满足了。 可谁能想到，一次次地系统更新彻底打碎了他的梦想，他的手机变得越来越卡顿，电池的使用寿命也越来越短，一直到某一天的寒风中，他的手机终于耐不住寒冷，头也不回地关了机。 小明很忧伤，他意识到，自己要换手机了。 为了能获得更好的使用体验，小明一咬牙，剁手了一台 iphoneX，这部手机铃声很大，电量很足，还能双卡双待，小明很喜欢，但是他遇到一个问题，就是他之前过度依赖了原来那一部 iPhone6，他们之间已经深深耦合在一起了，如果要换手机，他就要拿起刀来改造自己，把自己体内所有方法中的 iphone6 都换成 iphoneX。 经历了漫长的改造过程，小明终于把代码中的 iphone6 全部换成了 iphoneX。虽然很辛苦，但是小明觉得他是快乐的。 于是小明开开心心地带着手机去上班了，并在回来的路上被小偷偷走了。为了应急，小明只好重新使用那部刚刚被遗弃的 iphone6，但是一想到那漫长的改造过程，小明的心里就说不出的委屈，他觉得自己过于依赖手机了，为什么每次手机出什么问题他都要去改造他自己，这不仅仅是过度耦合，简直是本末倒置，他向天空大喊，我不要再控制我的手机了。 天空中的造物主，也就是作为程序员的我，听到了他的呐喊，我告诉他，你不用再控制你的手机了，交给我来管理，把控制权交给我。这就叫做控制反转。 三、造物主的智慧小明听到了我的话，他既高兴，又有一点害怕，他跪下来磕了几个头，虔诚地说到：“原来您就是传说中的造物主，巴格梅克上神。我听到您刚刚说了 控制反转 四个字，就是把手机的控制权从我的手里交给你，但这只是您的想法，是一种思想罢了，要用什么办法才能实现控制反转，又可以让我继续使用手机呢？” “呵”，身为造物主的我在表现完不屑以后，扔下了四个大字，“依赖注入！” 接下来，伟大的我开始对小明进行惨无人道的改造，如下 12345678910111213141516171819202122232425262728293031323334class Ming extends Person{ private $_name; private $_age; private $_phone; //将手机作为自己的成员变量 public function __construct($phone) { $this-&gt;_name = '小明'; $this-&gt;_age = 26; $this-&gt;_phone = $phone; echo \"小明起床了 \\n\"; } function read() { //…… 省略若干代码 $this-&gt;_phone-&gt;read($this-&gt;_name); //逛知乎 } function play() { //…… 省略若干代码 $this-&gt;_phone-&gt;play($this-&gt;_name);//玩农药 } function grab() { //…… 省略若干代码 $this-&gt;_phone-&gt;grab($this-&gt;_name);//抢红包 }} 接下来，我们来模拟运行小明的一天 12345678$phone = new IphoneX(); //创建一个iphoneX的实例if($phone-&gt;isBroken()){//如果iphone不可用，则使用旧版手机 $phone = new Iphone6();}$ming = new Ming($phone);//小明不用关心是什么手机，他只要玩就行了。$ming-&gt;read();$ming-&gt;play();$ming-&gt;grab(); 我们先看一下 iphoneX 是否可以使用，如果不可以使用，则直接换成 iphone6，然后唤醒小明，并把手机塞到他的手里，换句话说，把他所依赖的手机直接注入到他的身上，他不需要关心自己拿的是什么手机，他只要直接使用就可以了。 这就是依赖注入。 四、小明的感悟小明的生活开始变得简单了起来，而他把省出来的时间都用来写笔记了，他在笔记本上这样写到 我曾经有很强的控制欲，过度依赖于我的手机，导致我和手机之间耦合程度太高，只要手机出现一点点问题，我都要改造我自己，这实在是既浪费时间又容易出问题。自从我把控制权交给了造物主，他每天在唤醒我以前，就已经替我选好了手机，我只要按照平时一样玩手机就可以了，根本不用关心是什么手机。即便手机出了问题，也可以由造物主直接搞定，不需要再改造我自己了，我现在买了七部手机，都交给了造物主，每天换一部，美滋滋！我也从其中获得了这样的感悟： 如果一个类 A 的功能实现需要借助于类 B，那么就称类 B 是类 A 的依赖，如果在类 A 的内部去实例化类 B，那么两者之间会出现较高的耦合，一旦类 B 出现了问题，类 A 也需要进行改造，如果这样的情况较多，每个类之间都有很多依赖，那么就会出现牵一发而动全身的情况，程序会极难维护，并且很容易出现问题。要解决这个问题，就要把 A 类对 B 类的控制权抽离出来，交给一个第三方去做，把控制权反转给第三方，就称作控制反转（IOC Inversion Of Control）。控制反转是一种思想，是能够解决问题的一种可能的结果，而依赖注入（Dependency Injection）就是其最典型的实现方法。由第三方（我们称作IOC容器）来控制依赖，把他通过构造函数、属性或者工厂模式等方法，注入到类 A 内，这样就极大程度的对类 A 和类 B 进行了解耦。 参考原文:浅谈控制反转与依赖注入","link":"/post/27cdd96c.html"},{"title":"数据结构与算法-二分查找","text":"二分查找 零、二分查找实例-定位 IP 对应省份通过 IP 地址来查找 IP 归属地功能，不知道你用过没？没用过也没关系，打开百度，在搜索框里随便输入一个 IP 地址，就会看到它的归属地。 这个功能并不复杂，它是通过维护一个很大的 IP 地址库来实现。地址库中包括 IP 地址范围和归属地的对应关系。 当我们想要查询 202.102.133.13 这个 IP 地址的归属地时，我们就在地址库中搜索，发到 IP 地址落在[202.102.133.0, 202.102.133.255] 这个地址范围内，那我们就可以将这个 IP 地址范围对应的归属地“山东东营市”显示给用户了。 123456[202.102.133.0, 202.102.133.255] 山东东营市 [202.102.135.0, 202.102.136.255] 山东烟台 [202.102.156.34, 202.102.157.255] 山东青岛 [202.102.48.0, 202.102.48.255] 江苏宿迁 [202.102.49.15, 202.102.51.251] 江苏泰州 [202.102.56.0, 202.102.56.255] 江苏连云港 现在我的问题是，在庞大地址库中逐一比对 IP 地址所在的区间，是非常耗时的。假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速出一个 IP 地址的归属地呢？ 唐纳德·克努特（Donald E.Knuth）在《计算机程序设计艺术》的第 3 卷《排序和查找》中说到：“尽管第一个二分查找算法于 1946 年出现，然而第一个完全正确的二分查找算法实现直到 1962 年才出现。” 二分查找的变形问题很多。 一、查找第一个值等于给定值的元素如果有序数据集合中存在重复的数据，我们希望找到第一个值等于给定值的数据。 比如下面这样一个有序数组，其中 a[5]，a[6]，a[7] 的值都等于 8，是重复的数据。我们希望查找第一个等于 8 的数据，也就是下标是 5 的元素。 1、写法一 100 个人写二分查找就会有 100 种写法。网上有很多关于变形二分查找的实现方法，有很多写得非常简洁，比如下面这个写法。但是，尽管简洁，理解起来却非常烧脑，也很容易写错。 123456789101112131415public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low &lt;= high) { int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt;= value) { high = mid - 1; } else { low = mid + 1; } } if (low &lt; n &amp;&amp; a[low]==value) return low; else return -1;} 2、方法二 12345678910111213141516public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low &lt;= high) { int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt; value) { high = mid - 1; } else if (a[mid] &lt; value) { low = mid + 1; } else { if ((mid == 0) || (a[mid - 1] != value)) return mid; else high = mid - 1; } } return -1;} a[mid] 跟要查找的 value 的大小关系有三种情况：大于、小于、等于。对于 a[mid] &gt; value 的情况，我们需要更新 high = mid-1；对于 a[mid] &lt; value 的情况，我们需要更新 low = mid+1。那当 a[mid] = value 的时候应该如何处理呢？ 如果我们查找的是任意一个值等于给定值的元素，当 a[mid] 等于要查找的值时，a[mid] 就是我们要找的元素。但是，如果我们求解的是第一个值等于给定值的元素，当 a[mid] 等于要查找的值时，我们就需要确认一下这个 a[mid] 是不是第一个值等于给定值的元素。 我们重点看第 11 行代码。如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid] 的前一个元素 a[mid-1] 不等于 value，那也说明 a[mid] 就是我们要找的第一个值等于给定值的元素。 如果经过检查之后发现 a[mid] 前面的一个元素 a[mid-1] 也等于 value，那说明此时的 a[mid] 肯定不是我们要查找的第一个值等于给定值的元素。那我们就更新 high = mid-1，因为要找的元素肯定出现在 [low, mid-1] 之间。 对比上面的两段代码，是不是下面那种更好理解？实际上，很多人都觉得变形的二分查找很难写，主要原因是太追求第一种那样完美、简洁的写法。而对于我们做工程开发的人来说，代码易读懂、没 Bug，其实更重要，所以我觉得第二种写法更好。 3、方法三 123456789101112131415161718192021222324// 查找第一个等于给定值的元素private int binarySearchFirst(int[] a, int value) { int n = a.length; int low = 0; int high = n - 1; while (low &lt;= high) { int mid = (low + high) / 2; if (a[mid] == value) { if (a[low] == value) { return low; } if(a[mid - 1] != value) { return mid; }else { high = mid -1; } } else if (a[mid] &lt; value) { low = mid + 1; } else { high = mid - 1; } } return -1;} 二、查找最后一个等于给定值的元素1、方法一 12345678910111213141516public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low &lt;= high) { int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt; value) { high = mid - 1; } else if (a[mid] &lt; value) { low = mid + 1; } else { if ((mid == n - 1) || (a[mid + 1] != value)) return mid; else low = mid + 1; } } return -1;} 我们还是重点看第 11 行代码。如果 a[mid] 这个元素已经是数组中的最后一个元素了，那它肯定是我们要找的；如果 a[mid] 的后一个元素 a[mid+1] 不等于 value，那也说明 a[mid] 就是我们要找的最后一个值等于给定值的元素。 如果我们经过检查之后，发现 a[mid] 后面的一个元素 a[mid+1] 也等于 value，那说明当前的这个 a[mid] 并不是最后一个值等于给定值的元素。我们就更新 low = mid+1，因为要找的元素肯定出现在 [mid+1, high] 之间。 2、方法二 123456789101112131415161718192021222324// 查找最后一个等于给定值的元素private int binarySearchLast(int[] a, int value) { int n = a.length; int low = 0; int high = n - 1; while (low &lt;= high) { int mid = (low + high) / 2; if (a[mid] == value) { if (a[high] == value) { return high; } if(a[mid + 1] != value) { return mid; }else { low = mid + 1; } } else if (a[mid] &lt; value) { low = mid + 1; } else { high = mid - 1; } } return -1;} 三、查找第一个大于等于给定值的元素现在我们再来看另外一类变形问题。在有序数组中，查找第一个大于等于给定值的元素。比如，数组中存储的这样一个序列：3，4，6，7，10。如果查找第一个大于等于 5 的元素，那就是 6。 1、方法一 1234567891011121314public int bsearch(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low &lt;= high) { int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt;= value) { if ((mid == 0) || (a[mid - 1] &lt; value)) return mid; else high = mid - 1; } else { low = mid + 1; } } return -1;} 如果 a[mid] 小于要查找的值 value，那要查找的值肯定在 [mid+1, high] 之间，所以，我们更新 low = mid+1。 对于 a[mid] 大于等于给定值 value 的情况，我们要先看下这个 a[mid] 是不是我们要找的第一个值大于等于给定值的元素。如果 a[mid] 前面已经没有元素，或者前面一个元素小于要查找的值 value，那 a[mid] 就是我们要找的元素。这段逻辑对应的代码是第 7 行。 如果 a[mid-1] 也大于等于要查找的值 value，那说明要查找的元素在 [low, mid-1] 之间，所以，我们将 high 更新为 mid-1。 2、方法二 1234567891011121314151617181920212223// 第一个大于等于private int greaterOrEqualFirst(int[]a, int value) { int n = a.length; int low = 0; int high = n -1; // 判断首尾元素与value的大小关系 if(value &lt;= a[low]) { return low; } if(value &gt; a[high]) { return -1; } // 进入循环之后，保证 a[low] &lt; value &lt;= a[high] while(low + 1 != high) { int mid = (low + high) / 2; if(a[mid] &gt;= value) { high = mid + 1 ; }else { low = mid + 1; } } return high;} 四、查找最后一个小于等于给定值的元素现在，我们来看最后一种二分查找的变形问题，查找最后一个小于等于给定值的元素。比如，数组中存储了这样一组数据：3，5，6，8，9，10。最后一个小于等于 7 的元素就是 6。是不是有点类似上面那一种？实际上，实现思路也是一样的。 1、方法一 1234567891011121314public int bsearch7(int[] a, int n, int value) { int low = 0; int high = n - 1; while (low &lt;= high) { int mid = low + ((high - low) &gt;&gt; 1); if (a[mid] &gt; value) { high = mid - 1; } else { if ((mid == n - 1) || (a[mid + 1] &gt; value)) return mid; else low = mid + 1; } } return -1;} 2、方法二 123456789101112131415161718192021// 最后一个小于等于private int lessOrEqualLast(int[]a, int value) { int n = a.length; int low = 0; int high = n -1; if(value &lt; a[low]) { return -1; } if(value &gt;= a[high]) { return high; } while(low + 1 != high) { int mid = (low + high) / 2; if(a[mid] &lt;= value) { low = mid + 1; }else { high = mid + 1; } } return low;} 五、IP 问题解答如何快速定位出一个 IP 地址的归属地？ 现在这个问题应该很简单了。如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。如何来排序呢？我们知道，IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。 然后，这个问题就可以转化为第四种变形问题“在有序数组中，查找最后一个小于等于某个给定值的元素”了。 当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。 六、内容小结凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。那二分查找真的没什么用处了吗？ 实际上，上一节讲的求“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。用其他数据结构，比如散列表、二叉树，就比较难实现了。 变体的二分查找算法写起来非常烧脑，很容易因为细节处理不好而产生 Bug，这些容易出错的细节有：终止条件、区间上下界更新方法、返回值选择。 参考原文:二分查找（下）：如何快速定位IP对应的省份地址？","link":"/post/43138433.html"},{"title":"行为树（Behavior-Tree）知识点","text":"行为树（Behavior-Tree） 一、基本概念 这是我们为一个士兵定义的一颗行为树（可以先不管这些绿圈和红圈是做什么的），首先，可以看到这是一个树形结构的图，有根节点，有分支，而且子节点个数可以任意，然后有三个分支，分别是巡逻（Patrol），攻击（Attack），逃跑（Retreat），这个三个分支可以看成是我们为这个士兵定义的三个大的行为（Behavior），当然，如果有更多的行为，我们可以继续在根节点中添加新的分支。当我们要决策当前这个士兵要做什么样的行为的时候，我们就会自顶向下的，通过一些条件来搜索这颗树，最终确定需要做的行为（叶节点），并且执行它，这就是行为树的基本原理。 值得注意的是，我们标识的三大行为其实并不是真正的决策的结果，它只是一个类型，来帮助我们了解这个分支的一些行为是属于这类的，真正的行为树的行为都是在叶节点上，一般称之为行为节点（Action Node），如下图红圈表示的 这些叶节点才是我们真正通过行为树决策出来的结果，如果用我以前提到的那个层次化的AI结构来描述的话，这些行为结果，相当于就是一个个定义好的“请求”（Request），比如移动（Move），无所事事（Idle），射击（Shoot）等等。所以行为树是一种决策树，来帮助我们搜寻到我们想要的某个行为。 行为节点是游戏相关的，因不同的游戏，我们需要定义不同的行为节点，但对于某个游戏来说，在行为树上行为节点是可以复用的，比如移动，在巡逻的分支上，需要用到，在逃跑分支上，也会用到，这种情况下，我们就可以复用这个节点。行为节点一般分为两种运行状态： 运行中（Executing）：该行为还在处理中 完成（Completed）：该行为处理完成，成功或者失败 除了行为节点，其余一般称之为控制节点（Control Node），用树的“学名”的话，就是那些父节点，如下图绿圈表示 控制节点其实是行为树的精髓所在，我们要搜索一个行为，如何搜索？其实就是通过这些控制节点来定义的，从控制节点上，我们就可以看出整个行为树的逻辑走向，所以，行为树的特点之一就是其逻辑的可见性。 我们可以为行为树定义各种各样的控制节点（这也是行为树有意思的地方之一），一般来说，常用的控制节点有以下三种 选择（Selector）：选择其子节点的某一个执行 序列（Sequence）：将其所有子节点依次执行，也就是说当前一个返回“完成”状态后，再运行先一个子节点 并行（Parallel）：将其所有子节点都运行一遍 用图来表示的话，就是这样，依次为选择，序列和并行 可以看到，控制节点其实就是“控制”其子节点（子节点可以是叶节点，也可以是控制节点，所谓“执行控制节点”，就是执行其定义的控制逻辑）如何被执行，所以，我们可以扩展出很多其他的控制节点，比如循环（Loop）等，与行为节点不同的是，控制节点是与游戏无关的，因为他只负责行为树逻辑的控制，而不牵涉到任何的游戏代码。如果是作为一个行为树的库的话，其中就一定会包含定义好的控制节点库。 如果我们继续考察选择节点，会产生一个问题，如何从子节点中选择呢？选择的依据是什么呢？这里就要引入另一个概念，一般称之为前提（Precondition），每一个节点，不管是行为节点还是控制节点，都会包含一个前提的部分，如下图 前提就提供了“选择”的依据，它包含了进入，或者说选择这个节点的条件，当我们用到选择节点的时候，它就是去依次测试每一个子节点的前提，如果满足，则选择此节点。由于我们最终返回的是某个行为节点（叶节点），所以，当前行为的“总”前提就可以看成是： 当前行为节点的前提 And 父节点的前提 And 父节点的父节点的前提 And….And 根节点的前提（一般是不设，直接返回 True） 行为树就是通过行为节点，控制节点，以及每个节点上的前提，把整个 AI 的决策逻辑描述了出来，对于每次的 Tick，可以用如下的流程来描述： action = root.FindNextAction(input);if action is not empty thenaction.Execute(request, input) // request是输出的请求elseprint “no action is available” 从概念上来说，行为树还是比较简单的，但对 AI 程序员来说，却是充满了吸引力，它的一些特性，比如可视化的决策逻辑，可复用的控制节点，逻辑和实现的低耦合等，较之传统的状态机，都是可以大大帮助我们迅速而便捷的组织我们的行为决策。最后，对这个士兵的巡逻分支画了一个示意图，供大家参考： 二、节点2.1、关于选择节点的讨论我们说过选择节点的定义是通过判断子节点的前提条件来选择一个节点执行，这就牵涉到判断顺序的问题，是自左向右，还是随机选择，或者其他的一些规则等等，这样就延伸出各种各样的选择节点。 1、带优先级的选择节点（Priority Selector） 这种选择节点每次都是自左向右依次选择，当发现找到一个可执行的子节点后就停止搜索后续子节点。这样的选择方式，就存在一个优先级的问题，也就是说最左边的节点优先级最高，因为它是被最先判断的。对于这种选择节点来说，它的子节点的前提设定，必须是“从窄到宽”的方式，否则后续节点都会发生“饿死”的情况，也就是说永远不会被执行到，为了更清楚的说明，看下面第一张图，这三个子节点在一个带优先级的选择节点下，它们的前提会被依次判断，可以看到这个三个子节点的前提从左向右，一个比一个更严格，如果我们现在 a 为 9，按照下图的定义会执行第一个子节点，如果 a 为 7，则会执行第二个子节点，如果 a=11，则会执行第三个子节点。下面的第二张图演示了一种节点“饿死”（Starvation）的情况，我们看到第一个子节点的前提，比第二个子节点更宽泛，只要 a&lt;10，那自左向右判断的话，永远会进第一个节点，所以，如果要用到带优先级的选择节点，则必须检查每一个子节点的前提，以防止节点饿死的情况。 2、不带优先级的选择节点（Non-priority Selector） 这种选择节点的选择顺序是从上一个执行过的子节点开始选择，如果前提满足，则继续执行此节点，如果条件不满足，则从此节点开始，依次判断每一个子节点的前提，当找到一个满足条件的子节点后，则执行该节点。这种方式，是基于一种称之为“持续性”的假设，因为在游戏中，一个行为一般不会在一帧里结束，而是会持续一段时间，所以有时为了优化的目的，我们可以优先判断上一个执行的节点，当其条件不满足时，再寻找下一个可执行的节点。这种寻找方式不存在哪个节点优先判断的问题，所以对于前提的设置的要求，就是要保证“互斥”（Exclusion）。用上面第一张图来说明，如果我们把控制节点换成不带优先级的选择节点，可以看到，当 a=3 时，第二个子节点会被执行，下一次当 a 变成 9 时，由于不是从头依次判断前提的，所以，我们还是会选择第二个节点，而不是我们可能期望的第一个节点。正确的做法见下图，注意每一个子节点的前提是“互斥的”。所以对于不带优先级的选择节点，它子节点的排列顺序就不是那么重要了，可以任意排列。 3、带权值的选择节点（Weighted Selector） 对于这种选择节点，我们会预先为每一个分支标注一个“权值”（Weight Value），然后当我们选择的时候，采用随机选择的方式来选，随机时会参考权值，并且保证已经被测试过的节点不会再被测试，直到有一个节点的前提被满足，或者测试完所有的节点。带权值的选择节点对于子节点前提由于随机的存在，所以子节点的前提可以任意，而不会发生“饿死”的情况，一般来说，我们通常会把所有子节点的前提设为相同，以更好的表现出权值带来的概率上的效果。当所有子节点的权值一样时，这种选择节点就成为了随机选择节点（Random Selector），带权值的选择节点对于需要丰富 AI 行为的地方，非常适用，比如养成类游戏中，小狗表示开心的时候，可能会有各种各样的表现，我们就可以用这种选择节点，添加各种子节点行为来实现。 这些就是常用的选择节点类型，我们可以根据需要，定义更多的选择节点的选择行为，其实我们可以看到，不同的选择行为对于子节点前提的要求会有略微的不同，这是在搭建行为树的时候需要注意的地方。 2.2、关于并行节点结束条件的讨论我们每个节点都会有一个运行状态，来表示当前行为是否结束。对于控制节点来说，它的运行状态就是其子节点的运行状态，选择节点和序列节点比较好处理，因为对于这两种控制节点来说，每时刻，只会有一个子节点在运行，只要返回在运行的这个子节点的状态即可。但对于并行节点来说，它同时刻会有多个子节点运行，那我们如何来处理并行节点的运行状态问题呢？一般有两种： 与：只有所有的子节点都运行结束，才返回结束。 或：只要有一个子节点运行结束，就返回结束。 为什么要需要有节点的运行状态呢？ 序列控制节点中，需要用运行状态来控制序列的执行 外部世界需要了解行为的运行状态，来决定是否要更新决策（如果行为树在决策层）/ 请求（如果行为树在行为层） 对于第二点，可以举个例子，比如我们有一个行为是“走到 A 点”，假设这个行为是不可被打断的，那当我们在走向 A 点的过程中，行为树的运行状态就是“正在执行”，当到达 A 点时，行为树就返回“已完成”，这样，对外部来说，当我们看到行为树是“正在执行”的时候，我们就不需要做任何新的行为（为了优化，或者为了行为抖动等等），当看到“已完成”的时候，我们就可以做新的决策或者行为了。这样一个运行状态还有助于我们检测行为树的状态，帮助调试。 2.3、关于具体实现的讨论行为树的实现可以有多种多样，一般来说，行为树每个节点需要有进入（Enter），离开（Exit），运行（Execute）等部分，需要有行为节点（ActionNode），控制节点（ControlNode），前提（Precondition）等基类，然后，还需要定义行为树的输入（InputParam）和输出（OutputParam），一般来说，我们希望行为树是一个黑盒，也就是说，它仅依赖于预定义的输入。输入可以是黑板（Blackboard），工作池（Working Memory）等等数据结构，输出可以是请求（Request），或者其他自定义的数据结构，如下图: 2.4、关于绘制和调试的讨论看到行为树的定义后，作为程序员的直觉，我们很自然的就会想到，这好像应该能做一个工具来辅助行为树的创建和调试，我们可以把预定义好的前提和节点，在一个可视化的编辑器里搭建成行为树，然后再导出成数据给游戏用。对于调试来说，我们可以让工具和游戏通信，然后实时的检测行为树的运行状况，比如当前在哪个分支中等等。由于行为树的逻辑是可见的，并且是静态的，所以我们看其选择的路径，我们就可以知道 AI 为什么会作出这样的决策了。 参考原文:行为树（Behavior Tree）实践（1）– 基本概念","link":"/post/ef1e8494.html"},{"title":"C++STL知识点简析","text":"STL 一、STL 简介Standard Template Library，标准模板库，是 C++ 的标准库之一，一套基于模板的容器类库，还包括许多常用的算法，提高了程序开发效率和复用性。STL 包含 6 大部件：容器、迭代器、算法、仿函数、适配器和空间配置器。 容器：容纳一组元素的对象。 迭代器：提供一种访问容器中每个元素的方法。 函数对象：一个行为类似函数的对象，调用它就像调用函数一样。 算法：包括查找算法、排序算法等等。 适配器：用来修饰容器等，比如 queue 和 stack，底层借助了 deque。 空间配置器：负责空间配置和管理。 二、STL 空间配置器对象构造前的空间配置和对象析构后的空间释放，由 &lt;stl_alloc.h&gt; 负责，SGI 对此的设计哲学如下： 向 system heap 申请空间。 考虑多线程状态。 考虑内存不足时的应变措施。 考虑过多“小型区块”可能造成的内存碎片问题。 考虑小型区块造成的内存破碎问题，SGI 设计了双层级配置器： 第一级直接使用 allocate() 调用 malloc()、deallocate() 调用 free()，使用类似new_handler 机制解决内存不足（抛出异常），配置无法满足的问题（如果在申请动态内存时找不到足够大的内存块，malloc 和 new 将返回 NULL 指针，宣告内存申请失败）。 第二级视情况使用不同的策略，当配置区块大于 128 bytes 时，调用第一级配置器，当配置区块小于 128 bytes 时，采用内存池的方式：配置器维护 16 个（128/8）自由链表，负责 16 种小型区块的配置能力。内存池以 malloc 配置而得，如果内存不足转第一级配置器处理。 1、第二级空间配置器详解 第二级空间配置器实际上是一个内存池，维护了 16 个自由链表。自由链表是一个指针数组，有点类似 hash 桶，它的数组大小为 16，每个数组元素代表所挂的区块大小，比如 free_list[0] 代表下面挂的是 8 bytes 的区块，free_list[1] 代表下面挂的是 16 bytes 的区块。依次类推，直到 free_list[15] 代表下面挂的是 128 bytes 的区块。 2、空间配置器存在的问题 自由链表所挂区块都是 8 的整数倍，因此当我们需要非 8 倍数的区块，往往会导致浪费。 由于配置器的所有方法，成员都是静态的，都存放在静态区。释放时机就是程序结束，这样会导致自由链表一直占用内存，自己进程可以用，其他进程却用不了。 三、STL 各种容器 vector可变大小的数组。支持快速随机访问，在尾部之外的位置插入和删除元素可能会很慢。 deque双端队列。支持快速随机访问，在头尾位置插入/删除速度很快。 list只支持双向顺序访问。在 list 任何位置插入/删除速度很快。 forward_list单向链表。只支持单向顺序访问。在 forward_list 任何位置插入/删除速度很快。 array固定大小的数组。支持快速随机访问，不能添加或者删除元素。 string与 vector 相似的容器，专门存储字符。随机访问快。在尾位置插入/删除速度很快。 支持随机访问的容器：vector、deque、array、string。 支持在任意位置插入/删除元素：list、forward_list。 在尾部插入元素：vector、string、deque（头部也可以）。 vector1、vector 的底层原理 vector 底层是一个动态数组，包含三个迭代器，start 和 finish 之间是已经被使用的空间范围，end_of_storage 是整块连续空间包括备用空间的尾部。 当空间不够装下数据（vec.push_back(val)）时，会自动申请另一片更大的空间（1.5 倍或者 2 倍），然后把原来的数据拷贝到新的内存空间，接着释放原来的那片空间（vector 内存增长机制）。 当释放或者删除（vec.clear()）里面的数据时，其存储空间不释放，仅仅是清空了里面的数据。 因此，对 vector 的任何操作一旦引起了空间的重新配置，指向原 vector 的所有迭代器会都失效了。 2、vector 中的 reserve() 和 resize() 的区别 resize(n)调整容器的长度大小，使其能容纳 n 个元素。如果 n 小于容器的当前的 size，则删除多出来的元素。否则，添加采用值初始化的元素。 resize(n，t)多一个参数 t，将所有新添加的元素初始化为 t。 reserve(n)预分配 n 个元素的存储空间。 reserve() 是直接扩充到已经确定的大小，可以减少多次开辟、释放空间的问题（优化 push_back()），其次还可以减少多次要拷贝数据的问题。reserve() 只是保证 vector 中的空间大小（capacity）最少达到参数所指定的大小 n。reserve() 只有一个参数。 resize() 可以改变有效空间的大小，也有改变默认值的功能。capacity 的大小也会随着改变。resize() 可以有多个参数。 3、容器的 capacity（容量）与 size（长度）的区别 size 指容器当前拥有的元素个数，而 capacity 则指容器在必须分配新存储空间之前可以存储的元素总数，也可以说是预分配存储空间的大小。 resize() 函数和容器的 size 息息相关。调用 resize(n) 后，容器的 size 即为 n。至于是否影响 capacity，取决于调整后的容器的 size 是否大于 capacity。 reserve() 函数和容器的 capacity 息息相关。调用 reserve(n) 后，若容器的 capacity &lt; n，则重新分配内存空间，从而使得 capacity 等于n。如果 capacity &gt;=n 呢？capacity 无变化。 从两个函数的用途可以发现，容器调用 resize() 函数后，所有的空间都已经初始化了，所以可以直接访问。而 reserve() 函数预分配出的空间没有被初始化，所以不可访问。 4、迭代器失效的情况 当插入一个元素到 vector 中，由于引起了内存重新分配，所以指向原内存的迭代器全部失效。 当删除容器中一个元素后，该迭代器所指向的元素已经被删除，那么也造成迭代器失效。erase 方法会返回下一个有效的迭代器，所以当我们要删除某个元素时，需要 it = vec.erase(it);。 5、vector 的元素类型可以是引用吗？ vector 的底层实现要求连续的对象排列，引用并非对象，没有实际地址，因此 vector 的元素类型不能是引用。 6、正确释放 vector 的内存（clear()、swap()、shrink_to_fit()） 1234vec.clear(); // 清空内容，但是不释放内存。vector&lt;int&gt;().swap(vec); // 清空内容，且释放内存，得到一个全新的 vector。vec.shrink_to_fit(); // 请求容器降低其 capacity 和 size 匹配。vec.clear(); vec.shrink_to_fit(); // 清空内容，且释放内存。 std::vector::clear() Removes all elements from the vector (which are destroyed), leaving the container with a size of 0. 12345678910111213141516171819202122232425#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main(){ vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); v.push_back(4); v.push_back(5); cout &lt;&lt; \"size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; v.clear(); cout &lt;&lt; \"after clear size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"after clear capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; return 0;}//输出size:5capacity:6after clear size:0after clear capacity:6 A reallocation is not guaranteed to happen, and the vector capacity is not guaranteed to change due to calling this function. A typical alternative that forces a reallocation is to use swap. std::vector::swap Exchanges the content of the container by the content of x, which is another vector object of the same type. Sizes may differ. After the call to this member function, the elements in this container are those which were in x before the call, and the elements of x are those which were in this. All iterators, references and pointers remain valid for the swapped objects. Notice that a non-member function exists with the same name, swap, overloading that algorithm with an optimization that behaves like this member function. 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;vector&gt;int main(){ std::vector&lt;int&gt; foo; foo.push_back(1); foo.push_back(2); foo.push_back(3); foo.push_back(4); foo.push_back(5); std::vector&lt;int&gt; bar; bar.push_back(1); bar.push_back(2); std::cout &lt;&lt; \"foo size:\" &lt;&lt; foo.size() &lt;&lt; std::endl; std::cout &lt;&lt; \"foo capacity:\" &lt;&lt; foo.capacity() &lt;&lt; std::endl; std::cout &lt;&lt; \"bar size:\" &lt;&lt; bar.size() &lt;&lt; std::endl; std::cout &lt;&lt; \"bar capacity:\" &lt;&lt; bar.capacity() &lt;&lt; std::endl; foo.swap(bar); std::cout &lt;&lt; \"after swap foo size:\" &lt;&lt; foo.size() &lt;&lt; std::endl; std::cout &lt;&lt; \"after swap foo capacity:\" &lt;&lt; foo.capacity() &lt;&lt; std::endl; std::cout &lt;&lt; \"after swap bar size:\" &lt;&lt; bar.size() &lt;&lt; std::endl; std::cout &lt;&lt; \"after swap bar capacity:\" &lt;&lt; bar.capacity() &lt;&lt; std::endl; return 0;}//输出：foo size:5foo capacity:6bar size:2bar capacity:2after swap foo size:2after swap foo capacity:2after swap bar size:5after swap bar capacity:6 swap 之后，不仅仅是 size 变化了，capacity 也是变化了。用 swap 实现真正的 clear。 12345678910111213141516171819202122232425#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main(){ vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); v.push_back(4); v.push_back(5); cout &lt;&lt; \"size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; vector&lt;int&gt;().swap(v); cout &lt;&lt; \"after swap size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"after swap capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; return 0;}//输出：size:5capacity:6after swap size:0after swap capacity:0 C++11 推出了 shrink_to_fit 方法，也可以达到正确释放 vector 的内存的目的。 1234567891011121314151617181920212223242526#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main(){ vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); v.push_back(4); v.push_back(5); cout &lt;&lt; \"size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; v.clear(); v.shrink_to_fit(); cout &lt;&lt; \"after swap size:\" &lt;&lt; v.size() &lt;&lt; endl; cout &lt;&lt; \"after swap capacity:\" &lt;&lt; v.capacity() &lt;&lt; endl; return 0;}//输出：size:5capacity:6after swap size:0after swap capacity:0 7、vector 扩容为什么要以 1.5 倍或者 2 倍扩容？ 根据查阅的资料显示，考虑可能产生的堆空间浪费，成倍增长倍数不能太大，使用较为广泛的扩容方式有两种，以 2 倍的方式扩容，或者以 1.5 倍的方式扩容。 以 2 倍的方式扩容，导致下一次申请的内存必然大于之前分配内存的总和，导致之前分配的内存不能再被使用，所以最好倍增长因子设置为（1-2）之间： $$k\\sum_{i=0}^{n}2^i = k(2^{n+1} - 1) &lt; k2^{n+1} $$ 8、vector 的常用函数 12345678vector&lt;int&gt; vec(10, 100); // 创建10个元素,每个元素值为100vec.resize(r, vector&lt;int&gt;(c, 0)); // 二维数组初始化reverse(vec.begin(), vec.end()) // 将元素翻转sort(vec.begin(), vec.end()); // 排序，默认升序排列vec.push_back(val); // 尾部插入数字vec.size(); // 向量大小find(vec.begin(), vec.end(), 1); // 查找元素iterator = vec.erase(iterator) // 删除元素 9、vector 实例 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std; void main(){ vector&lt;int&gt; a; a.reserve(10); cout &lt;&lt; \"a的容量:\"&lt;&lt; a.capacity() &lt;&lt; \" ;a的大小:\"&lt;&lt; a.size() &lt;&lt; endl; /* for (int i = 0; i &lt; 10; i++ ){ a.push_back(i); //新元素这时才构造 } */ vector&lt;int&gt; b; b.resize(10); cout &lt;&lt; \"b的容量:\"&lt;&lt; b.capacity() &lt;&lt; \" ;b的大小:\" &lt;&lt; b.size() &lt;&lt; endl; cout &lt;&lt; \"b[7]=\" &lt;&lt;b[7] &lt;&lt; endl; vector&lt;int&gt; b1; b1.resize(10,7); cout &lt;&lt; \"b1的容量:\"&lt;&lt; b1.capacity() &lt;&lt; \" ;b1的大小:\" &lt;&lt; b1.size() &lt;&lt; endl; cout &lt;&lt; \"b1[7]=\" &lt;&lt;b1[7] &lt;&lt; endl; vector&lt;int&gt; c; cout &lt;&lt; \"c的容量:\"&lt;&lt; c.capacity() &lt;&lt; \" ;c的大小:\" &lt;&lt; c.size() &lt;&lt; endl; vector&lt;int&gt; d(10); cout &lt;&lt; \"d的容量:\"&lt;&lt; d.capacity() &lt;&lt; \" ;d的大小:\" &lt;&lt; d.size() &lt;&lt; endl; cout &lt;&lt; \"d[7]=\"&lt;&lt; d[7] &lt;&lt; endl; vector&lt;int&gt; d1(10,7); cout &lt;&lt; \"d1的容量:\"&lt;&lt; d1.capacity() &lt;&lt; \" ;d1的大小:\" &lt;&lt; d1.size() &lt;&lt; endl; cout &lt;&lt; \"d1[7]=\"&lt;&lt; d1[7] &lt;&lt; endl;} 12345678910a的容量:10 ;a的大小:0b的容量:10 ;b的大小:10b[7]=0b1的容量:10 ;b1的大小:10b1[7]=7c的容量:0 ;c的大小:0d的容量:10 ;d的大小:10d[7]=0d1的容量:10 ;d1的大小:10d1[7]=7 10、vector 中 push_back 的时间复杂度分析 vector 是 STL 中的一种序列式容器，采用的数据结构为线性连续空间，它以两个迭代器 start 和 finish 分别指向配置得来的连续空间中目前已被使用的范围，并以迭代器 end_of_storage 指向整块连续空间（含备用空间）的尾端，结构如下所示: 1234567891011template &lt;class T Alloc = alloc&gt;class vector{ ... protected: iterator start; // 表示目前使用空间的头 iterator finish; // 表示目前使用空间的尾 iterator end_of_storage; // 表示可用空间的尾 ...} 该函数首先检查是否还有备用空间，如果有就直接在备用空间上构造元素，并调整迭代器 finish，使 vector 变大。如果没有备用空间了，就扩充空间，重新配置、移动数据，释放原空间。​ 其中​判断是否有备用空间，就是判断 finish 是否与 end_of_storage 相等。如果 finish != end_of_storage，说明还有备用空间，否则已无备用空间。 当执行 push_back 操作，该 vector 需要分配更多空间时，它的容量（capacity）会增大到原来的 m 倍。​现在我们用均摊分析方法来计算 push_back 操作的时间复杂度。 假定有 n 个元素，倍增因子为 m。那么完成这 n 个元素往一个 vector 中的 push_back ​操作，需要重新分配内存的次数大约为 logm(n)，第 i 次重新分配将会导致复制 m^i （也就是当前的 vector.size() 大小）个旧空间中元素，因此 n 次 push_back 操作所花费的总时间约为 n*m/(m - 1)。 很明显这是一个等比数列。那么 n 个元素，n 次操作，每一次操作需要花费时间为 m / (m - 1)，这是一个常量。 所以，我们采用均摊分析的方法可知，vector 中 push_back 操作的时间复杂度为常量时间。 在 STL 中，vector 的每次扩容都是 2 倍，也就是 m=2。这样，n 次总的时间约为 n*2/(2-1) = 2n；那么每一操作要花的时间就是 2，因此是常量级。 list1、list 的底层是一个双向链表，以结点为单位存放数据，结点的地址在内存中不一定连续，每次插入或删除一个元素，就配置或释放一个元素空间。 2、list 不支持随机存取，如果需要大量的插入和删除，而不关心随机存取，建议使用 list。 1、list 常用函数 123456789list.push_back(elem); // 在尾部加入一个数据list.pop_back(); // 删除尾部数据list.push_front(elem); // 在头部插入一个数据list.pop_front(); // 删除头部数据list.size(); // 返回容器中实际数据的个数list.sort(); // 排序，默认由小到大 list.unique(); // 移除数值相同的连续元素list.back(); // 取尾部迭代器list.erase(iterator); // 删除一个元素，参数是迭代器，返回的是删除迭代器的下一个位置 deque1、deque 的底层原理 deque 是一个双向开口的连续线性空间（双端队列），在头尾两端进行元素的插入跟删除操作都有理想的时间复杂度。 2、什么情况下用 vector，什么情况下用 list，什么情况下用 deque？ vector 可以随机存储元素（即可以通过公式直接计算出元素地址，而不需要挨个查找），但在非尾部插入删除数据时，效率很低，适合对象简单，对象数量变化不大，随机访问频繁。除非必要，我们尽可能选择使用 vector 而非 deque，因为 deque 的迭代器比 vector 迭代器复杂很多。 list 不支持随机存储，适用于对象大，对象数量变化频繁，插入和删除频繁，比如写多读少的场景。 需要从首尾两端进行插入或删除操作的时候需要选择 deque。 3、deque 常用函数 123456deque.push_back(elem); // 在尾部加入一个数据。deque.pop_back(); // 删除尾部数据。deque.push_front(elem); // 在头部插入一个数据。deque.pop_front(); // 删除头部数据。deque.size(); // 返回容器中实际数据的个数。deque.at(idx); // 传回索引idx所指的数据，如果idx越界，抛出out_of_range。 priority_queue 优先级队列1、priority_queue 的底层原理 其底层是用堆来实现的。在优先队列中，队首元素一定是当前队列中优先级最高的那一个。 2、priority_queue 的常用函数 1234567priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq; // 最小堆priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt;&gt; pq; // 最大堆pq.empty(); // 如果队列为空返回真pq.pop(); // 删除对顶元素pq.push(val); // 加入一个元素pq.size(); // 返回优先队列中拥有的元素个数pq.top(); // 返回优先级最高的元素 map、set、multiset、multimap1、map 、set、multiset、multimap 的底层原理 map、set、multiset、multimap 的底层实现都是红黑树。 对于 STL 里的 map 容器，count 方法与 find 方法，都可以用来判断一个 key 是否出现，mp.count(key) &gt; 0 统计的是 key 出现的次数，因此只能为 0/1，而 mp.find(key) != mp.end() 则表示 key 存在。 2、map 、set、multiset、multimap 的特点 set 和 multiset 会根据特定的排序准则自动将元素排序，set 中元素不允许重复，multiset 可以重复。 map 和multimap 将 key 和 value 组成的 pair 作为元素，根据 key 的排序准则自动将元素排序（因为红黑树也是二叉搜索树，所以 map 默认是按 key 排序的），map 中元素的 key 不允许重复，multimap 可以重复。 map 和 set 的增删改查速度为都是 O(logn)，是比较高效的。 3、为何 map 和 set 的插入删除效率比其他序列容器高，而且每次 insert 之后，以前保存的 iterator 不会失效？ 因为存储的是结点，不需要内存拷贝和内存移动。 因为插入操作只是结点指针交换，结点内存没有改变。而 iterator 就像指向结点的指针，内存没变，指向内存的指针也不会变。 4、为何 map 和 set 不能像 vector 一样有个 reserve 函数来预分配数据？ 因为在 map 和 set 内部存储的已经不是元素本身了，而是包含元素的结点。也就是说 map 内部使用的 Alloc 并不是 map&lt;Key, Data, Compare, Alloc&gt; 声明的时候从参数中传入的 Alloc。 5、map、set、multiset、multimap 的常用函数 123456789101112131415it map.begin(); // 返回指向容器起始位置的迭代器（iterator） it map.end(); // 返回指向容器末尾位置的迭代器 bool map.empty(); // 若容器为空，则返回true，否则falseit map.find(k); // 寻找键值为k的元素，并用返回其地址int map.size(); // 返回map中已存在元素的数量map.insert({int,string}); // 插入元素// 遍历删除for (it = map.begin(); it != map.end(); ){ if (it-&gt;second == \"target\") map.erase(it++) ; // erase之后，令当前迭代器指向其后继。 else ++it;} unordered_map、unordered_set1、unordered_map、unordered_set 的底层原理 unordered_map 的底层是一个防冗余的哈希表（采用除留余数法）。哈希表最大的优点，就是把数据的存储和查找消耗的时间大大降低，时间复杂度为 O(1)；而代价仅仅是消耗比较多的内存。 使用一个下标范围比较大的数组来存储元素。可以设计一个函数（哈希函数（一般使用除留取余法），也叫做散列函数），使得每个元素的 key 都与一个函数值（即数组下标，hash 值）相对应，于是用这个数组单元来存储这个元素；也可以简单的理解为，按照 key 为每一个元素“分类”，然后将这个元素存储在相应“类”所对应的地方，称为桶。 但是，不能够保证每个元素的 key 与函数值是一一对应的，因此极有可能出现对于不同的元素，却计算出了相同的函数值，这样就产生了“冲突”，换句话说，就是把不同的元素分在了相同的“类”之中。一般可采用拉链法解决冲突： 2、哈希表的实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;random&gt;#include &lt;ctime&gt;using namespace std;const int hashsize = 12;//定一个节点的结构体template&lt;typename T, typename U&gt;struct HashNode { T _key; //键 U _value; //值};//使用拉链法实现哈希表类template &lt;typename T, typename U&gt;class HashTable{public: HashTable() : vec(hashsize) {}//类中的容器需要通过构造函数来指定大小 ~HashTable() {} bool insert_data(const T &amp;key, const U &amp;value); int hash(const T &amp;key); bool hash_find(const T &amp;key);private: vector&lt;list&lt;HashNode&lt;T, U&gt;&gt;&gt; vec;//将节点存储到容器中};//哈希函数（除留取余）template &lt;typename T, typename U&gt;int HashTable&lt;T, U&gt;::hash(const T &amp;key){ return key % 13;}//哈希查找template &lt;typename T, typename U&gt;bool HashTable&lt;T, U&gt;::hash_find(const T &amp;key){ int index = hash(key);//计算哈希值 for (auto it = vec[index].begin(); it != vec[index].end(); ++it) { if (key == it -&gt; _key)//如果找到则打印其关联值 { cout &lt;&lt; it-&gt;_value &lt;&lt; endl;//输出数据前应该确认是否包含相应类型 return true; } } return false;}//插入数据template &lt;typename T, typename U&gt;bool HashTable&lt;T, U&gt;::insert_data(const T &amp;key, const U &amp;value){ //初始化数据 HashNode&lt;T, U&gt; node; node._key = key; node._value = value; for (int i = 0; i &lt; hashsize; ++i) { if (i == hash(key))//如果溢出则把相应的键值添加进链表 { vec[i].push_back(node); return true; } }}int main(int argc, char const *argv[]){ HashTable&lt;int, int&gt; ht; static default_random_engine e; static uniform_int_distribution&lt;unsigned&gt; u(0, 100); long long int a = 10000000; for (long long int i = 0; i &lt; a; ++i) ht.insert_data(i, u(e)); clock_t start_time = clock(); ht.hash_find(114); clock_t end_time = clock(); cout &lt;&lt; \"Running time is: \" &lt;&lt; static_cast&lt;double&gt;(end_time - start_time) / CLOCKS_PER_SEC * 1000 &lt;&lt; \"ms\" &lt;&lt; endl;//输出运行时间。 system(\"pause\"); system(\"pause\"); return 0;} 3、unordered_map 与 map 的区别与使用场景 构造函数unordered_map 需要 hash 函数、等于函数；map 只需要比较函数（小于函数）。 存储结构unordered_map 采用 hash 表存储，map 一般采用红黑树（RB Tree）实现。因此它们的 memory 数据结构是不一样的。 总体来说，unordered_map 查找速度会比 map 快，而且查找速度基本和数据数据量大小相关，属于常数级别；而 map 的查找速度是 O(log(n)) 级别，并不一定常数就比 O(log(n)) 小。hash 还有 hash 函数的耗时，如果你考虑效率，特别是在元素达到一定数量级时，考虑 unordered_map。但若你对内存使用特别严格，希望程序尽可能少消耗内存，unordered_map 可能会让你陷入尴尬，特别是当你的 unordered_map 对象特别多时，你就更无法控制了，而且 unordered_map 的构造速度较慢。 4、unordered_map、unordered_set 的常用函数 12345678unordered_map.begin(); // 返回指向容器起始位置的迭代器（iterator） unordered_map.end(); // 返回指向容器末尾位置的迭代器 unordered_map.cbegin(); // 返回指向容器起始位置的常迭代器（const_iterator） unordered_map.cend(); // 返回指向容器末尾位置的常迭代器 unordered_map.size(); // 返回有效元素个数 unordered_map.insert(key); // 插入元素 unordered_map.find(key); // 查找元素，返回迭代器unordered_map.count(key); // 返回匹配给定主键的元素的个数 四、STL 迭代器的底层机制和失效的问题迭代器的底层原理迭代器是连接容器和算法的一种重要桥梁，通过迭代器可以在不了解容器内部原理的情况下遍历容器。它的底层实现包含两个重要的部分：萃取技术和模板偏特化。 萃取技术（traits）可以进行类型推导，根据不同类型可以执行不同的处理流程，比如容器是 vector，那么 traits 必须推导出其迭代器类型为随机访问迭代器，而 list 则为双向迭代器。 例如 STL 算法库中的 distance 函数，distance 函数接受两个迭代器参数，然后计算他们两者之间的距离。显然对于不同的迭代器计算效率差别很大。比如对于 vector 容器来说，由于内存是连续分配的，因此指针直接相减即可获得两者的距离；而 list 容器是链式表，内存一般都不是连续分配，因此只能通过一级一级调用 next() 或其他函数，每调用一次再判断迭代器是否相等来计算距离。vector 迭代器计算 distance 的效率为 O(1)，而 list 则为 O(n)，n 为距离的大小。 使用萃取技术（traits）进行类型推导的过程中会使用到模板偏特化。模板偏特化可以用来推导参数，如果我们自定义了多个类型，除非我们把这些自定义类型的特化版本写出来，否则我们只能判断他们是内置类型，并不能判断他们具体属于是个类型。 1234567891011121314template &lt;typename T&gt;struct TraitsHelper { static const bool isPointer = false;};template &lt;typename T&gt;struct TraitsHelper&lt;T*&gt; { static const bool isPointer = true;};if (TraitsHelper&lt;T&gt;::isPointer) ...... // 可以得出当前类型int*为指针类型else ...... // 可以得出当前类型int非指针类型 一个理解 traits 的例子1234567891011121314151617181920212223242526272829// 需要在T为int类型时，Compute方法的参数为int，返回类型也为int，// 当T为float时，Compute方法的参数为float，返回类型为inttemplate &lt;typename T&gt;class Test {public: TraitsHelper&lt;T&gt;::ret_type Compute(TraitsHelper&lt;T&gt;::par_type d);private: T mData;};template &lt;typename T&gt;struct TraitsHelper { typedef T ret_type; typedef T par_type;};// 模板偏特化，处理int类型template &lt;&gt;struct TraitsHelper&lt;int&gt; { typedef int ret_type; typedef int par_type;};// 模板偏特化，处理float类型template &lt;&gt;struct TraitsHelper&lt;float&gt; { typedef float ret_type; typedef int par_type;}; 当函数，类或者一些封装的通用算法中的某些部分会因为数据类型不同而导致处理或逻辑不同时，traits 会是一种很好的解决方案。 迭代器的种类 输入迭代器：是只读迭代器，在每个被遍历的位置上只能读取一次。例如上面 find 函数参数就是输入迭代器。 输出迭代器：是只写迭代器，在每个被遍历的位置上只能被写一次。 前向迭代器：兼具输入和输出迭代器的能力，但是它可以对同一个位置重复进行读和写。但它不支持 operator–，所以只能向前移动。 双向迭代器：很像前向迭代器，只是它向后移动和向前移动同样容易。 随机访问迭代器：有双向迭代器的所有功能。而且，它还提供了“迭代器算术”，即在一步内可以向前或向后跳跃任意位置，包含指针的所有操作，可进行随机访问，随意移动指定的步数。支持前面四种 Iterator 的所有操作，并另外支持 it + n、it - n、it += n、 it -= n、it1 - it2 和 it[n] 等操作。 迭代器失效的问题插入操作 对于 vector 和 string，如果容器内存被重新分配，iterators、pointers、references 失效；如果没有重新分配，那么插入点之前的iterator 有效，插入点之后的 iterator 失效； 对于 deque，如果插入点位于除 front 和 back 的其它位置，iterators、pointers、references 失效；当我们插入元素到 front 和 back 时，deque 的迭代器失效，但 reference 和 pointers 有效； 对于 list 和 forward_list，所有的 iterator、pointer 和 refercnce 有效。 删除操作 对于 vector 和 string，删除点之前的 iterators、pointers、references 有效；off-the-end 迭代器总是失效的； 对于 deque，如果删除点位于除 front 和 back 的其它位置，iterators、pointers、references 失效；当我们插入元素到 front 和 back 时，off-the-end 失效，其他的 iterators、pointers、references 有效； 对于 list 和 forward_list，所有的 iterator、pointer 和 refercnce 有效。 对于关联容器 map 来说，如果某一个元素已经被删除，那么其对应的迭代器就失效了，不应该再被使用，否则会导致程序无定义的行为。 五、STL 容器的线程安全性5.1、线程安全的情况 多个读取者是安全的。多线程可能同时读取一个容器的内容，这将正确地执行。当然，在读取时不能有任何写入者操作这个容器； 对不同容器的多个写入者是安全的。多线程可以同时写不同的容器。 5.2、线程不安全的情况 在对同一个容器进行多线程的读写、写操作时； 在每次调用容器的成员函数期间都要锁定该容器； 在每个容器返回的迭代器（例如通过调用 begin 或 end）的生存期之内都要锁定该容器； 在每个在容器上调用的算法执行期间锁定该容器。 参考原文:STL详解","link":"/post/2835216b.html"},{"title":"leetcode-超级次方SuperPow","text":"一、题目你的任务是计算 ab 对 1337 取模，a 是一个正整数，b 是一个非常大的正整数且会以数组形式给出。 示例 1: 输入: a = 2, b = [3]输出: 8示例 2: 输入: a = 2, b = [1,0]输出: 1024 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/super-pow著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 二、Pow(x, n)给定一个数，求 n 次方。n 次方可以分解成两个 n/2 次方相乘，所以递归即可。 12345678910111213141516171819202122232425262728293031323334class Solution{ public: double myPow(double x, int n) { bool negative = n &lt; 0; double res = helper(x, n); return negative ? 1 / res : res; } private: double helper(int x, int n) { if(n == 0) { return 1; } if(n == 1) { return x; } if(n % 2) { double res = helper(x, n / 2); return res * res *x; } else { double res = helper(x, n / 2); return res * res; } }}; 三、Super Pow同样是求某个数的 n 次方，但是 n 存在数组中，如 [1, 0] 代表 n 为 10。而且数组代表的 n 会非常大，有可能会超过 int 的范围，所以直接还原 n 然后计算 n 次方的方法是行不通的。既然这样，就只能从每位下手，有这样一个公式： 1(a * b) % k = (a % k) * (b % k) % k 以数组为 [1, 2, 3, 4, 5, 6, 7] 为例，表示 a 的 1234567 次方，因为有 1a ^ 1234567 = (a ^ 1234560) * (a ^ 7) 所以 1(a ^ 1234567) % k = (((a ^ 1234560) % k) * ((a ^ 7) % k)) % k 而 1(a ^ 1234560) % k = ((a ^ 123456) ^ 10) % k = (((a ^ 123456) % k) ^ 10 ) % k 所以 1(a ^ 1234567) % k = (((((a ^ 123456) % k) ^ 10 ) % k) * ((a ^ 7) % k)) % k 将 a ^ n % k 抽象为 f(a, n) 函数，那么上式可以写成 1f(a, 1234567) = f(f(a, 123456), 10) * f(a, 7) % k 可以发现，每次都可以把 n 的最后一位去除，从而减少 n，当 n 为 1 或为 0 时返回即可。不过注意上面的式子对于 n 为 [0 : 10] 内的数都不需要再调用 f 函数了，直接求就可以，也就是将外层 f 改为 pown。 1f(a, 1234567) = pown(f(a, 123456), 10) * pown(a, 7) % k 12345678910111213141516171819202122232425class Solution {public: int superPow(int a, vector&lt;int&gt;&amp; b) { if(b.empty()) return 1; int back = b.back(); b.pop_back(); return pown(superPow(a, b), 10) * pown(a, back) % base_; }private: int pown(int n, int k) { /* * 因为n可能很大，这里实现取模防止在for循环result * n中溢出 * 比如result为第二次for循环后的某个数，而n为INT_MAX，乘完直接溢出 */ n %= base_; int result = 1; for(int i = 0; i &lt; k; ++ i) result = (result * n) % base_; return result; } const int base_ = 1337;}; 参考原文:每天一道LeetCode—–求一个数的n次方，n是很大很大的数，n用数组存储着","link":"/post/68268b40.html"},{"title":"数据结构与算法-二叉树的遍历（递归、非递归）分析","text":"二叉树的遍历（递归、非递归） 零、背景递归的实现方法相对简单，但由于递归的执行方式每次都会产生一个新的方法调用栈，如果递归层级较深，会造成较大的内存开销，相比之下，非递归的方式则可以避免这个问题。递归遍历容易实现，非递归则没那么简单，非递归调用本质上是通过维护一个栈，模拟递归调用的方法调用栈的行为。 在此之前，先简单定义节点的数据结构： 二叉树节点最多只有两个儿子，并保存一个节点的值，为了实验的方便，假定它为 int。同时，我们直接使用 Java 的 System.out.print 方法来输出节点值，以显示遍历结果。 123456789public class Node { public int value; public Node leftNode; public Node rightNode; public Node(int i) { value = i; } } 一、前序遍历1.1、递归实现递归实现很简单，在每次访问到某个节点时，先输出节点值，然后再依次递归的对左儿子、右儿子调用遍历的方法。代码如下 1234567public void preOrderTrav(Node n) { if (n != null) { System.out.print(n.value + \" \"); preOrderTrav(n.leftNode); preOrderTrav(n.rightNode); }} 1.2、非递归实现方法 1 123456789101112public void preOrderTravNoRecur(Node n) { Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); stack.add(root); while (!stack.empty()) { Node t = stack.pop(); System.out.print(t.value + \" \"); if (t.rightNode != null) stack.add(t.rightNode); if (t.leftNode != null) stack.add(t.leftNode); }} 描述维护一个栈，将根节点压入栈中。此后，每次从栈中读出栈顶的节点，作为对节点的访问，然后将该节点的儿子节点按照先右后左的顺序，压入栈中，实现递归模拟。 分析这个栈的递归策略不具备很好的扩展性，其他的遍历方式无法使用这种策略。实际上，它并不是对程序调用栈的模拟，而是针对先序遍历的特殊实现：先序遍历先对当前节点做出访问后，然后递归的调用对儿子节点的遍历，不需要在对儿子节点遍历结束后再回过头来处理当前节点。于是模拟的递归中也不需要存储之前的调用栈信息，只需要类似的生成一个未来的儿子节点的访问计划即可。 方法 2 1234567891011121314public void preOrderTravNoRecurII(Node n) { System.out.println(\"No Recursive: \"); Stack&lt;Node&gt; s = new Stack&lt;Node&gt;(); while (n != null | !s.empty()){ while (n!=null ){ System.out.print(n.value + \" \"); s.add(n); n = n.leftNode; } n = s.pop(); n = n.rightNode; } System.out.println();} 描述1、维护一个栈 s 和一个当前节点 n。初始时将 n 赋值为根节点。2、逐个访问当前节点 n 的左子链上的节点，并推入栈中，直到没有左儿子。3、取出栈顶的节点，将 n 赋值为该节点的右儿子。4、不断执行 2，3，直到栈为空且当前节点也为空。 分析该方法模拟了递归的前序遍历中程序调用栈的行为过程：在调用栈中，会不断的递归进入左儿子链中，直到没有左儿子，再进入对右儿子的处理中。与递归方法的调用栈的不同之处在于，内层 while 循环将递归方法中针对左儿子链上所有节点的递归过程集中到了一起。 二、中序遍历2.1、递归实现1234567public void inorderTrav(Node n) { if (n != null) { inorderTrav(n.leftNode); System.out.print(n.value + \" \"); inorderTrav(n.rightNode); }} 2.2、非递归实现12345678910111213public void inorderTravNoRecu(Node n) { System.out.println(\"No Recursive: \"); Stack&lt;Node&gt; s = new Stack&lt;Node&gt;(); while (n != null | !s.empty()){ while (n!=null ){ s.add(n); n = n.leftNode; } n = s.pop(); System.out.print(n.value + \" \"); n = n.rightNode; }} 描述1、维护一个栈 s 和一个当前节点 n。初始时将 n 赋值为根节点。2、将当前节点 n 的左子链上的节点逐个推入栈中，直到没有左儿子。3、取出栈顶的节点，访问该节点，将 n 赋值为该节点的右儿子。4、不断执行 2，3，直到栈为空且当前节点也为空。 分析跟前序遍历的非递归实现方法二很类似。唯一的不同是访问当前节点的时机：前序遍历在入栈前访问，而中序遍历在出栈后访问。 三、后序遍历3.1、递归实现1234567public void postOrderTrav(Node n) { if (n != null) { postOrderTrav(n.leftNode); postOrderTrav(n.rightNode); System.out.print(n.value + \" \"); } } 3.2、非递归实现1234567891011121314151617181920212223242526public void postOrderTravNoRecu(Node n) { Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); int[] flag = new int[max]; while (n != null) { stack.push(n); flag[stack.size()] = 0; n = n.leftNode; } while (!stack.empty()) { n = stack.peek(); while (n.rightNode != null &amp;&amp; flag[stack.size()] == 0) { n = n.rightNode; flag[stack.size()] = 1; while (n != null) { stack.push(n); flag[stack.size()] = 0; n = n.leftNode; } n = stack.peek(); } n = stack.pop(); System.out.print(n.value + \" \"); } } 描述1、维护一个栈 stack、当前节点 n 和一个标记数组 flag。将根节点的左儿子链上的所有节点压入 stack 中，并将标记数组对应值置为 0。2、将当前节点赋值为栈顶的节点。如果节点有右儿子，且没有被处理过（通过标记数组判定），则将右子树的根节点及其左儿子全部压入栈中。3、将当前节点赋值为栈顶的节点，访问它，并将该节点从栈中 pop 出。4、循环 2，3 两步，直到栈为空。 分析在非递归方法中用栈模拟程序调用栈，碰到的最大的问题就是模拟递归方法所处的状态。编码维护的栈能记录节点，但无法记录如何处理该节点。这里使用了一个 flag 数组来记录节点的右子树是否被访问过，对每个节点进行访问的时候，都保证已经处理完了左右子树（通过先压入左边儿子链为主线，处理栈中的每个节点时，再压入右边儿子来实现）。 四、层次遍历4.1、无法使用递归方法层序遍历不同于其他的遍历，无法使用递归实现。 反证法证明如果能实现对 A 节点的层序递归，在对 A 节点处理的过程中，应该递归的对两个儿子 B 和 C 分别调用了层序遍历。在这种情况下，我们无法让 B 和 C 的同一个层级的儿子在集中的时间中被遍历到，换言之，B 的第一层儿子在对 B 的调用中被遍历，而 C 的第一层儿子，则在对 C 的调用中遍历，这是分离开的。不成立，得证。 4.2、非递归方法12345678910111213public void levelOrderTrav(Node n) { System.out.print(\"Level OrderTrav: \"); Queue&lt;Node&gt; q = new LinkedList&lt;Node&gt;(); q.add(n); while (q.size() != 0) { n = q.poll(); System.out.print(\" \" + n.value); if (n.leftNode != null) q.add(n.leftNode); if (n.rightNode != null) q.add(n.rightNode); }} 分析用一个队列实现层序遍历，拓扑排序中也有用到这种方式。 五、总结非递归实现的代码相对来说没有递归实现的直观。其核心都是维护了一个栈来保存状态，避免了产生过多方法调用栈浪费内存空间。 参考原文:二叉树的遍历（递归、非递归）分析","link":"/post/31ed7c83.html"},{"title":"TCP三次握手与四次挥手原理与过程分析","text":"TCP三次握手、四次挥手 零、状态转换图 一、TCP三次握手1.1、服务端准备连接的过程创建套接字 要创建一个可用的套接字，需要使用下面的函数： 1int socket(int domain, int type, int protocol) domain 就是指 PF_INET、PF_INET6 以及 PF_LOCAL 等，表示什么样的套接字。 type 可用的值是： SOCK_STREAM: 表示的是字节流，对应 TCP； SOCK_DGRAM： 表示的是数据报，对应 UDP； SOCK_RAW: 表示的是原始套接字。 参数 protocol 原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成。protocol 目前一般写成 0 即可。 bind: 设定电话号码 创建出来的套接字如果需要被别人使用，就需要调用 bind 函数把套接字和套接字地址绑定，就像去电信局登记我们的电话号码一样。 调用 bind 函数的方式如下： 1bind(int fd, sockaddr * addr, socklen_t len) 我们需要注意到 bind 函数后面的第二个参数是通用地址格式 sockaddr * addr。这里有一个地方值得注意，那就是虽然接收的是通用地址格式，实际上传入的参数可能是 IPv4、IPv6 或者本地套接字格式。bind 函数会根据 len 字段判断传入的参数 addr 该怎么解析，len 字段表示的就是传入的地址长度，它是一个可变值。 这里其实可以把 bind 函数理解成这样： 1bind(int fd, void * addr, socklen_t len)： 对于使用者来说，每次需要将 IPv4、IPv6 或者本地套接字格式转化为通用套接字格式，就像下面的 IPv4 套接字地址格式的例子一样： 12struct sockaddr_in name;bind(sock, (struct sockaddr *)&amp;name, sizeof(name)) 我们可以把地址设置成本机的 IP 地址，这相当于告诉操作系统内核，仅仅对目标 IP 是本机 IP 地址的 IP 包进行处理。但是这样写的程序在部署时有一个问题，我们编写应用程序时并不清楚自己的应用程序将会被部署到哪台机器上。这个时候，可以利用通配地址的能力帮助我们解决这个问题。通配地址相当于告诉操作系统内核：“Hi，我可不挑活，只要目标地址是咱们的都可以。”比如一台机器有两块网卡，IP 地址分别是 202.61.22.55 和 192.168.1.11，那么向这两个 IP 请求的请求包都会被我们编写的应用程序处理。 对于 IPv4 的地址来说，使用 INADDR_ANY 来完成通配地址的设置；对于 IPv6 的地址来说，使用 IN6ADDR_ANY 来完成通配地址的设置。 12struct sockaddr_in name;name.sin_addr.s_addr = htonl(INADDR_ANY); /* IPV4 通配地址 */ 除了地址，还有端口。如果把端口设置成 0，就相当于把端口的选择权交给操作系统内核来处理，操作系统内核会根据一定的算法选择一个空闲的端口，完成套接字的绑定。这在服务器端不常使用。 一般来说，服务器端的程序一定要绑定到一个众所周知的端口上。服务器端的 IP 地址和端口数据，相当于打电话拨号时需要知道的对方号码，如果没有电话号码，就没有办法和对方建立连接。 一个初始化 IPv4 TCP 套接字的例子: 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;int make_socket(uint16_t port){ int sock; struct sockaddr_in name; /* 创建字节流类型的IPV4 socket. */ sock = socket(PF_INET, SOCK_STREAM, 0); if(sock &lt; 0) { perror (\"socket\"); exit (EXIT_FAILURE); } /* 绑定到 port 和 ip. */ name.sin_family = AF_INET; /* IPV4 */ name.sin_port = htons(port); /* 指定端口 */ name.sin_addr.s_addr = htonl(INADDR_ANY); /* 通配地址 */ /* 把 IPV4 地址转换成通用地址格式，同时传递长度 */ if(bind(sock, (struct sockaddr *)&amp;name, sizeof(name)) &lt; 0) { perror(\"bind\"); exit(EXIT_FAILURE); } return sock;} listen：接上电话线，一切准备就绪 bind 函数只是让我们的套接字和地址关联，如同登记了电话号码。如果要让别人打通电话，还需要我们把电话设备接入电话线，让服务器真正处于可接听的状态，这个过程需要依赖 listen 函数。 初始化创建的套接字，可以认为是一个”主动”套接字，其目的是之后主动发起请求（通过调用 connect 函数，后面会讲到）。通过 listen 函数，可以将原来的”主动”套接字转换为”被动”套接字，告诉操作系统内核：“我这个套接字是用来等待用户请求的。”当然，操作系统内核会为此做好接收用户请求的一切准备，比如完成连接队列。 listen 函数的原型是这样的： 1int listen(int socketfd, int backlog) 第一个参数 socketdf 为套接字描述符，第二个参数 backlog，在 Linux 中表示已完成 (ESTABLISHED) 且未 accept 的队列大小，这个参数的大小决定了可以接收的并发数目。这个参数越大，并发数目理论上也会越大。但是参数过大也会占用过多的系统资源，一些系统，比如 Linux 并不允许对这个参数进行改变。 accept: 电话铃响起了…… 当客户端的连接请求到达时，服务器端应答成功，连接建立，这个时候操作系统内核需要把这个事件通知到应用程序，并让应用程序感知到这个连接。这个过程，就好比电信运营商完成了一次电话连接的建立, 应答方的电话铃声响起，通知有人拨打了号码，这个时候就需要拿起电话筒开始应答。 accept 这个函数看成是操作系统内核和应用程序之间的桥梁。 1int accept(int listensockfd, struct sockaddr *cliaddr, socklen_t *addrlen) 函数的第一个参数 listensockfd 是套接字，可以叫它为 listen 套接字，因为这就是前面通过 bind，listen 一系列操作而得到的套接字。函数的返回值有两个部分，第一个部分 cliadd 是通过指针方式获取的客户端的地址，addrlen 告诉我们地址的大小，这可以理解成当我们拿起电话机时，看到了来电显示，知道了对方的号码；另一个部分是函数的返回值，这个返回值是一个全新的描述字，代表了与客户端的连接。 这里一定要注意有两个套接字描述字，第一个是监听套接字描述字 listensockfd，它是作为输入参数存在的；第二个是返回的已连接套接字描述字。 这里和打电话的情形非常不一样的地方就在于，打电话一旦有一个连接建立，别人是不能再打进来的，只会得到语音播报：“您拨的电话正在通话中。”而网络程序的一个重要特征就是并发处理，不可能一个应用程序运行之后只能服务一个客户，如果是这样，双 11 抢购得需要多少服务器才能满足全国 “剁手党 ” 的需求？ 监听套接字一直都存在，它是要为成千上万的客户来服务的，直到这个监听套接字关闭；而一旦一个客户和服务器连接成功，完成了 TCP 三次握手，操作系统内核就为这个客户生成一个已连接套接字，让应用服务器使用这个已连接套接字和客户进行通信处理。如果应用服务器完成了对这个客户的服务，比如一次网购下单，一次付款成功，那么关闭的就是已连接套接字，这样就完成了 TCP 连接的释放。请注意，这个时候释放的只是这一个客户连接，其它被服务的客户连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。 1.2、客户端发起连接的过程connect: 拨打电话 客户端和服务器端的连接建立，是通过 connect 函数完成的。这是 connect 的构建函数： 1int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen) 函数的第一个参数 sockfd 是连接套接字，通过前面讲述的 socket 函数创建。第二个、第三个参数 servaddr 和 addrlen，分别代表指向套接字地址结构的指针和该结构的大小。套接字地址结构必须含有服务器的 IP 地址和端口号。 客户在调用函数 connect 前不必非得调用 bind 函数，因为如果需要的话，内核会确定源 IP 地址，并按照一定的算法选择一个临时端口作为源端口。 如果是 TCP 套接字，那么调用 connect 函数将激发 TCP 的三次握手过程，而且仅在连接建立成功或出错时才返回。其中出错返回可能有以下几种情况： 三次握手无法建立，客户端发出的 SYN 包没有任何响应，于是返回 TIMEOUT 错误。这种情况比较常见的原因是对应的服务端 IP 写错。 客户端收到了 RST（复位）回答，这时候客户端会立即返回 CONNECTION REFUSED 错误。这种情况比较常见于客户端发送连接请求时的请求端口写错，因为 RST 是 TCP 在发生错误时发送的一种 TCP 分节。产生 RST 的三个条件是：目的地为某端口的 SYN 到达，然而该端口上没有正在监听的服务器（如前所述）；TCP 想取消一个已有连接；TCP 接收到一个根本不存在的连接上的分节。 客户发出的 SYN 包在网络上引起了”destination unreachable”，即目的不可达的错误。这种情况比较常见的原因是客户端和服务器端路由不通。 这里我们使用的网络编程模型都是阻塞式的。所谓阻塞式，就是调用发起后不会直接返回，由操作系统内核处理之后才会返回。 1.3、TCP 三次握手的解读 客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 j，客户端进入 SYNC_SENT 状态； 服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 j+1，表示对 SYN 包 j 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 k，服务器端进入 SYNC_RCVD 状态； 客户端协议栈收到 ACK 之后，使得应用程序从 connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 k+1； 应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入 ESTABLISHED 状态 1.4、思考题为什么tcp建立连接需要三次握手？ TCP 连接的双方要确保各自的收发消息的能力都是正常的。客户端第一次发送握手消息到服务端，服务端接收到握手消息后把 ack 和自己的 syn 一同发送给客户端，这是第二次握手，当客户端接收到服务端发送来的第二次握手消息后，客户端可以确认“服务端的收发能力 OK，客户端的收发能力 OK”，但是服务端只能确认“客户端的发送 OK，服务端的接收 OK”，所以还需要第三次握手，客户端收到服务端的第二次握手消息后，发起第三次握手消息，服务端收到客户端发送的第三次握手消息后，就能够确定“服务端的发送 OK，客户端的接收 OK”，至此，客户端和服务端都能够确认自己和对方的收发能力OK，TCP 连接建立完成。 这个问题的本质是信道不可靠，但是通信双发需要就某个问题达成一致。而要解决这个问题，无论你在消息中包含什么信息，三次通信是理论上的最小值.。所以三次握手不是 TCP 本身的要求，而是为了满足”在不可靠信道上可靠地传输信息”这一需求所致。 关于阻塞调用的，既然有阻塞调用，就应该有非阻塞调用，那么如何使用非阻塞调用套接字呢？使用的场景又是哪里呢？ 非阻塞调用的使用的场景：程序在调用返回之前，需要做其他事情，可以选择用定时轮询或事件通知的方式获取调用结果。 客户端发起 connect 调用之前，可以调用 bind 函数么？ 可以，但是调用 bind 函数，也就是客户端指定了端口号，这样容易造成端口冲突，所以客户端不调用 bind 函数，让系统自动选择空闲端口比较好。 二、TCP四次挥手2.1、如何理解 TCP 四次挥手？TCP 建立一个连接需 3 次握手，而终止一个连接则需要四次挥手。四次挥手的整个过程是这样的： 首先，一方应用程序调用 close，我们称该方为主动关闭方，该端的 TCP 发送一个 FIN 包，表示需要关闭连接。之后主动关闭方进入 FIN_WAIT_1 状态。 接着，接收到这个 FIN 包的对端执行被动关闭。这个 FIN 由 TCP 协议栈处理，我们知道，TCP 协议栈为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。一定要注意，这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着接收端应用程序需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，被动关闭方进入 CLOSE_WAIT 状态。 接下来，被动关闭方将读到这个 EOF，于是，应用程序也调用 close 关闭它的套接字，这导致它的 TCP 也发送一个 FIN 包。这样，被动关闭方将进入 LAST_ACK 状态。 最终，主动关闭方接收到对方的 FIN 包，并确认这个 FIN 包。主动关闭方进入 TIME_WAIT 状态，而接收到 ACK 的被动关闭方则进入 CLOSED 状态。经过 2MSL 时间之后，主动关闭方也进入 CLOSED 状态。 每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 当然，这中间使用 shutdown，执行一端到另一端的半关闭也是可以的。 当套接字被关闭时，TCP 为其所在端发送一个 FIN 包。在大多数情况下，这是由应用进程调用 close 而发生的，值得注意的是，一个进程无论是正常退出（exit 或者 main 函数返回），还是非正常退出（比如，收到 SIGKILL 信号关闭，就是 kill -9），所有该进程打开的描述符都会被系统关闭，这也导致 TCP 描述符对应的连接上发出一个 FIN 包。 无论是客户端还是服务器，任何一端都可以发起主动关闭。大多数真实情况是客户端执行主动关闭，你可能不会想到的是，HTTP/1.0 却是由服务器发起主动关闭的。 2.2、最大分组 MSL 是 TCP 分组在网络中存活的最长时间吗？MSL 是任何 IP 数据报能够在因特网中存活的最长时间。其实它的实现不是靠计时器来完成的，在每个数据报里都包含有一个被称为 TTL（time to live）的 8 位字段，它的最大值为 255。TTL 可译为“生存时间”，这个生存时间由源主机设置初始值，它表示的是一个 IP 数据报可以经过的最大跳跃数，每经过一个路由器，就相当于经过了一跳，它的值就减 1，当此值减为 0 时，则所在的路由器会将其丢弃，同时发送 ICMP 报文通知源主机。RFC793 中规定 MSL 的时间为 2 分钟，Linux 实际设置为 30 秒。 2.3、关于 listen 函数中参数 backlog 的释义问题我们该如何理解 listen 函数中的参数 backlog？如果 backlog 表示的是未完成连接队列的大小，那么已完成连接的队列的大小有限制吗？如果都是已经建立连接的状态，那么并发取决于已完成连接的队列的大小吗？ backlog 的值含义从来就没有被严格定义过。原先 Linux 实现中，backlog 参数定义了该套接字对应的未完成连接队列的最大长度 （pending connections)。如果一个连接到达时，该队列已满，客户端将会接收一个 ECONNREFUSED 的错误信息，如果支持重传，该请求可能会被忽略，之后会进行一次重传。 从 Linux 2.2 开始，backlog 的参数内核有了新的语义，它现在定义的是已完成连接队列的最大长度，表示的是已建立的连接（established connection），正在等待被接收（accept 调用返回），而不是原先的未完成队列的最大长度。现在，未完成队列的最大长度值可以通过 /proc/sys/net/ipv4/tcp_max_syn_backlog 完成修改，默认值为 128。 至于已完成连接队列，如果声明的 backlog 参数比 /proc/sys/net/core/somaxconn 的参数要大，那么就会使用我们声明的那个值。实际上，这个默认的值为 128。注意在 Linux 2.4.25 之前，这个值是不可以修改的一个固定值，大小也是 128。 设计良好的程序，在 128 固定值的情况下也是可以支持成千上万的并发连接的，这取决于 I/O 分发的效率，以及多线程程序的设计。 2.4、UDP 连接和断开套接字的过程是怎样的？UDP 连接套接字不是发起连接请求的过程，而是记录目的地址和端口到套接字的映射关系。断开套接字则相反，将删除原来记录的映射关系。 2.5、在 UDP 中不进行 connect，为什么客户端会收到信息？UDP 只有 connect 才建立 socket 和 IP 地址的映射，那么如果不进行 connect，收到信息后内核又如何把数据交给对应的 socket？ 这对应了两个不同的 API 场景。 第一个场景就是 connect 场景，在这个场景里，我们讨论的是 ICMP 报文和 socket 之间的定位。我们知道，ICMP 报文发送的是一个不可达的信息，不可达的信息是通过目的地址和端口来区分的，如果没有 connect 操作，目的地址和端口就没有办法和 socket 套接字进行对应，所以，即使收到了 ICMP 报文，内核也没有办法通知到对应的应用程序，告诉它连接地址不可达。 那么为什么在不 connect 的情况下，我们的客户端又可以收到服务器回显的信息了？ 这就涉及到了第二个场景，也就是报文发送的场景。服务器端程序，先通过 recvfrom 函数调用获取了客户端的地址和端口信息，这当然是可以的，因为 UDP 报文里面包含了这部分信息。然后我们看到服务器端又通过调用 sendto 函数，把客户端的地址和端口信息告诉了内核协议栈，可以肯定的是，之后发送的 UDP 报文就带上了客户端的地址和端口信息，通过客户端的地址和端口信息，可以找到对应的套接字和应用程序，完成数据的收发。 12345678910//服务器端程序，先通过 recvfrom 函数调用获取了客户端的地址和端口信息int n = recvfrom(socket_fd, message, MAXLINE, 0, (struct sockaddr *) &amp;client_addr, &amp;client_len);message[n] = 0;printf(\"received %d bytes: %s\\n\", n, message);char send_line[MAXLINE];sprintf(send_line, \"Hi, %s\", message);//服务器端程序调用 send 函数，把客户端的地址和端口信息告诉了内核sendto(socket_fd, send_line, strlen(send_line), 0, (struct sockaddr *) &amp;client_addr, client_len); 从代码中可以看到，这里的 connect 的作用是记录客户端目的地址和端口–套接字的关系，而之所以能正确收到从服务器端发送的报文，那是因为系统已经记录了客户端源地址和端口–套接字的映射关系。 2.6、我们是否可以对一个 UDP 套接字进行多次 connect 的操作?我们知道，对于 TCP 套接字，connect 只能调用一次。但是，对一个 UDP 套接字来说，进行多次 connect 操作是被允许的，这样主要有两个作用。 第一个作用是可以重新指定新的 IP 地址和端口号；第二个作用是可以断开一个已连接的套接字。为了断开一个已连接的 UDP 套接字，第二次调用 connect 时，调用方需要把套接字地址结构的地址族成员设置为 AF_UNSPEC。 AF_UNSPEC 则意味着函数返回的是适用于指定主机名和服务名且适合任何协议族的地址。如果某个主机既有 AAAA 记录（IPV6）地址，同时又有 A 记录（IPV4）地址，那么 AAAA 记录将作为 sockaddr_in6 结构返回，而 A 记录则作为 sockaddr_in 结构返回。 参考文章:网络编程实战","link":"/post/d18c2e08.html"},{"title":"C++11新特性-初始化列表initializer_list","text":"initializer_list、初始化列表、列表初始化 一、什么是列表初始化使用一个花括号来初始化变量，表现形式如下： 12345// 第一种std::vector&lt;int&gt; a{1,2,3,4,5};// 第二种std::vector&lt;int&gt; a = {1,2,3,4,5}; 这里用到了一个新的类型，即 initializer_list，包含在标准库头文件中。 二、优点1、在 C++11 以前，如果要初始化一个 vector，需要这样做 123456std::vector&lt;int&gt; a;a.push_back(1);a.push_back(2);a.push_back(3);a.push_back(4);a.push_back(5); 很明显，使用列表初始化使得代码量少了很多，也更加的简洁优雅。 2、这种方式不仅仅可以用在 STL 中，也可以用于一般的内置类型。 12int c{3};int c = {3}; 乍一看，这样做没什么优点，并没有变得更简洁，甚至还要多写两个花括号。但在 CppCoreGuideline 中，非常推荐这种写法。原因是有一个类型检查。 12int c = 3.3; //这里会进行默认类型转换int b = {3.3}; //这里编译器会给出警告（也有可能是错误） 理论上，这样的代码更加健壮。 三、自定义类型使用 initializer_listC++11 也提供了方法，让用户可以在自定义类型（一般指类）中使用初始化列表。 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;vector&gt;class Num{ private: std::vector&lt;int&gt; vv; public: Num(const std::initializer_list&lt;int&gt; &amp;v) { for (auto a : v) { vv.push_back(a); } } void PrintNum(void) { for (auto v : vv) { std::cout &lt;&lt; v &lt;&lt; \" \"; } std::cout &lt;&lt; std::endl; }};int main(int argc, char **argv){ Num n{1, 2, 3, 4}; n.PrintNum(); return 0;} 实现方法，简单来说，就是加入 initializer_list 类型来实现构造函数，在新建对象时，就可以使用列表初始化的方式了。 四、一个特殊用法在使用 python 的时候，有时候会这样操作 12for i in [1,2,3]: print(i) 看起来很简洁优雅，C++ 其实也有这种操作 123456789#include &lt;iostream&gt;int main(int argc, char **argv){ for(auto n : {1,2,3,4,5,6}) { std::cout&lt;&lt;n&lt;&lt;std::endl; }} 参考原文initializer_list、初始化列表、列表初始化","link":"/post/a130f417.html"},{"title":"C++String类的一种简单实现","text":"String 实现 一、构造 - 默认构造与传参构造的结合体1、函数声明 当我们声明了一个类，却不声明构造函数，编译器就会生成一个默认的构造函数，其对类中的成员进行默认值初始化，并且不接受任何参数。 我们的 String 类除了默认构造函数之外，肯定还需要一个传入字符串参数的构造函数。 综合以上两个需求，可以书写一个函数就完成两个函数的功能，也就是将该字符串参数定义为默认为空（也就是默认构造函数的功能）。 1String(const char* str = nullptr); 这里为什么要使用 const char* str 呢？ 这是因为，如果你使用了 char str*，而不是 const char* str，则只能向这个构造函数传递非 const 的 char 参数；当你定义为了 const char* str 之后，你既可以传递 const char* 的字符串，也可以传递 char* 的字符串。这是因为非 const 向 const 的转化是可以的，const 向非 const 的转化却是有风险的。 2、函数定义 这个构造函数处理传递进来的字符串参数，用它来初始化 String 类中的 m_data 成员变量。又由于我们的 m_data 是一个需要动态管理的内存成员，因此我们需要一些分配空间的操作。 另外，因为我们的参数字符串可能为空，我们还需要分情况处理。 1234567891011121314String::String(const char* str){ if (str == nullptr) { m_data = new char[1]; *m_data = '\\0'; cout &lt;&lt; \"Default constructor\" &lt;&lt; endl; } else { int length = strlen(str); m_data = new char[length + 1]; strcpy(m_data, str); cout &lt;&lt; \"Pass argument constructor\" &lt;&lt; endl; }} 当检测到传入参数字符串为空的时候，我们为 m_data 分配了一个字节的空间。为什么是一个字节呢？因为 \\0 啊，因为即使为空，还是有一个字节的结束标志符的空间需要分配，这点非常非常重要！ 当检测到传入参数字符串不为空，我们获取传入字符串的长度，按照此长度 + 1，进行内存空间的分配。为什么要 + 1 其实很简单，还是那个 \\0 的原因。最后，将 str 拷贝到 m_data 中去。 二、析构 - 我挥一挥衣袖，真的不带走一片内存空间析构函数的语义其实非常简单，就是为了清理好类对象的一些使用的资源。比如动态内存的分配、数据库连接之类的。 良好的类的设计，就是在它离开的时候，就像它未曾来过一样那么干净清爽。 12345String::~String(){ delete[] m_data; cout &lt;&lt; \"Destructor\" &lt;&lt; endl;} 这里使用 delete[] 还是 delete 都是可以的，就我个人来说，更加喜欢清晰的语义化，使用了 delete[] 来释放 m_data 的内存空间。 三、拷贝 - 构造、赋值，这个工作并不简单拷贝操作，顾名思义，就是通过一个已经存在的类的对象，去构造或者赋值另一个对象。 在这个操作中，我们要考虑很多方面，比如说这两个对象是不是同一个对象（自赋值问题），原来的对象的痕迹有没有被清除干净（先析构）。 1、拷贝构造函数 拷贝构造函数，就是传入参数为该类 const 引用对象的构造函数： （1）为什么要是 const 类型因为只有 const 类型，才能接收 const 和非 const 对象参数。（2）为什么要是引用类型因为只有是引用类型，才能够规避递归使用拷贝构造的死循环问题。（3）String(const String other)这个函数传递参数就会发生另一个参数 other 传入，默认实参匹配调用拷贝构造，然后又调用这个函数，…，直到死循环的情况。使用引用直接传对象实体进来，就不会在实参匹配时调用拷贝构造函数了。 作为拷贝构造函数，只需要处理好本对象的动态内存空间的分配，以及另一个对象的数据的拷贝即可： 1234567String::String(const String&amp; other){ int length = strlen(other.m_data); m_data = new char[length + 1]; strcpy(m_data, other.m_data); cout &lt;&lt; \"Copy constructor\" &lt;&lt; endl;} 构造构造，必然要对本对象进行一些处理，这里就是将另一个对象的数据拿来初始化了本对象的数据。 2、拷贝赋值运算符 我们可能觉得，只需要将另一个对象赋值给本对象即可。还需要考虑其他什么吗？ （1）要不要析构本对象的数据？是的，我们必须要析构我们本对象的数据，不然赋值过来，原来的动态内存空间就是野空间了，这就是内存泄露。还有就是赋值的字符串的长度可能与本字符串的长度不相等。（2）如果是本对象赋值给本对象呢？我们要先进行本对象的甄别操作。否则的话，我们析构了本对象的数据，再拿另一个对象的数据进行拷贝时，会发现数据已经在刚才被析构了。 1234567891011String&amp; String::operator=(const String&amp; other){ if (this != &amp;other) { if (!m_data) delete[] m_data; int length = strlen(other.m_data); m_data = new char[length + 1]; strcpy(m_data, other.m_data); } cout &lt;&lt; \"Copy assignment\" &lt;&lt; endl; return *this;} 我们首先进行了自赋值的检查，this 是本对象的地址，因此比较的时候，使用的是 other 的地址进行比较。 然后，我们进行了本对象 m_data 的释放操作，这是为了避免内存泄露。 最后，我们分配 m_data 的空间，将 other 的数据拷贝到 m_data 中去，最后返回本对象即可（this 是本对象的地址，因此返回实体就是 *this）。 四、移动 - 构造、赋值，我不是归人，只是一个过客移动，说白了就是一个对象直接接管一块临时对象的数据而已。 我们可以直接移动对象数据，而不需要进行（有时候多余的）拷贝操作。 从概念上也就决定了，移动操作的代码，必然要比拷贝操作的代码，少一些内存分配的工作，为什么呢？因为移动操作直接移动内存数据，根本不需要重新分配内存空间。 1、移动构造 根据 C++ Primer 第五版第 13 章作者的建议，我们在使用了移动构造传入对象之后，需要使得该对象不能再访问已经移动的内存区域，所以该对象的 m_data 应该置为空。 123456String::String(String&amp;&amp; other){ m_data = other.m_data; other.m_data = nullptr; cout &lt;&lt; \"Move constructor\" &lt;&lt; endl;} 传入 String&amp;&amp; 代表着右值对象。我们直接接管了 other.m_data 数据，在移动过来了之后，我们将 other.m_data 置为了空，以免出现问题。 2、移动赋值 移动赋值，相比拷贝赋值来说，少了内存空间的分配操作，多了传入右值对象的 m_data 成员的置空考虑。 自赋值都是两者需要考虑的。 12345678910String&amp; String::operator=(String&amp;&amp; other){ if (this != &amp;other) { delete[] m_data; m_data = other.m_data; other.m_data = nullptr; } cout &lt;&lt; \"Move assignment\" &lt;&lt; endl; return *this;} 总的来说，移动操作的实现是要比拷贝操作的实现简单的，因为少了内存空间的分配工作。但是，我们需要处理好移动后传入对象对于该内存区域的访问情况，最好置为空，以免出现问题。 五、完整实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class String {public: // 构造：默认（传参）、拷贝构造、移动构造 String(const char *str = nullptr); String(const String &amp;other); String(String &amp;&amp;other); // 析构 ~String(); // 赋值：拷贝赋值、移动赋值 String &amp;operator=(const String &amp;other); String &amp;operator=(String &amp;&amp;other);private: char *m_data;};String::String(const char *str){ if (str == nullptr) { m_data = new char[1]; *m_data = '\\0'; cout &lt;&lt; \"Default constructor\" &lt;&lt; endl; } else { int length = strlen(str); m_data = new char[length + 1]; strcpy(m_data, str); cout &lt;&lt; \"Pass argument constructor\" &lt;&lt; endl; }}String::String(const String &amp;other){ int length = strlen(other.m_data); m_data = new char[length + 1]; strcpy(m_data, other.m_data); cout &lt;&lt; \"Copy constructor\" &lt;&lt; endl;}String::String(String &amp;&amp;other){ m_data = other.m_data; other.m_data = nullptr; cout &lt;&lt; \"Move constructor\" &lt;&lt; endl;}String::~String(){ delete[] m_data; cout &lt;&lt; \"Destructor\" &lt;&lt; endl;}String &amp;String::operator=(const String &amp;other){ if (this != &amp;other) { if (!m_data) delete[] m_data; int length = strlen(other.m_data); m_data = new char[length + 1]; strcpy(m_data, other.m_data); } cout &lt;&lt; \"Copy assignment\" &lt;&lt; endl; return *this;}String &amp;String::operator=(String &amp;&amp;other){ if (this != &amp;other) { delete[] m_data; m_data = other.m_data; other.m_data = nullptr; } cout &lt;&lt; \"Move assignment\" &lt;&lt; endl; return *this;} 参考原文:让我们一步一步实现一个完整的 String 类：构造、拷贝、赋值、移动和析构","link":"/post/cfbac8cc.html"},{"title":"数据结构与算法-跳跃表","text":"假如我们要用某种数据结构来维护一组有序的 int 型数据的集合，并且希望这个数据结构在插入、删除、查找等操作上能够尽可能的快速，那么，你会用什么样的数据结构呢？ 一、数组一种很简单的方法应该就是采用数组了，在查找方面，用数组存储的话，采用二分法可以在 O(logn) 的时间里找到指定的元素，不过数组在插入、删除这些操作中比较不友好，找到目标位置所需时间为 O(logn)，进行插入和删除这个动作所需的时间复杂度为 O(n)，因为都需要移动元素，所以最终所需要的时间复杂度为 O(n)。 例如对于下面这个数组： 插入元素 3 二、链表另外一种简单的方法应该就是用链表了，链表在插入、删除的支持上就相对友好，当我们找到目标位置之后，插入、删除元素所需的时间复杂度为 O(1)，注意，我说的是找到目标位置之后，插入、删除的时间复杂度才为 O(1)。 但链表在查找上就不友好了，不能像数组那样采用二分查找的方式，只能一个一个结点遍历，所以加上查找所需的时间，插入、删除所需的总的时间复杂度为 O(n)。 假如我们能够提高链表的查找效率，使链表的查找的时间复杂度尽可能接近 O(logn)，那链表将会是很棒的选择。 三、提高链表的查找速度那链表的查找速度可以提高吗？ 对于下面这个链表： 假如我们要查找元素 9，按道理我们需要从头结点开始遍历，一共遍历 8 个结点才能找到元素 9。能否采取某些策略，让我们遍历 5 次以内就找到元素 9 呢？请大家花一分钟时间想一下如何实现？ 由于元素的有序的，我们是可以通过增加一些路径来加快查找速度的。 通过这种方法，我们只需要遍历 5 次就可以找到元素 9 了（红色的线为查找路径）。 还能继续加快查找速度吗？ 答案是可以的，再增加一层就行了，这样只需要 4 次就能找到了，这就如同我们搭地铁的时候，去某个站点时，有快线和慢线几种路线，通过快线 + 慢线的搭配，我们可以更快找到达某个站点。 当然，还能再增加一层 基于这种方法，对于具有 n 个元素的链表，我们可以采取（O(logn) + 1)）层指针路径的形式，就可以实现在 O(logn) 的时间复杂度内，查找到某个目标元素了，这种数据结构，我们也称之为跳跃表，跳跃表也可以算是链表的一种变形，只是它具有二分查找的功能。 四、插入与删除上面例子中，9 个结点，一共 4 层，可以说是理想的跳跃表了，不过随着我们对跳跃表进行插入/删除结点的操作，那么跳跃表结点数就会改变，意味着跳跃表的层数也会动态改变。 这里我们面临一个问题，就是新插入的结点应该跨越多少层？ 这个问题已经有大牛替我们解决好了，采取的策略是通过抛硬币来决定新插入结点跨越的层数：每次我们要插入一个结点的时候，就来抛硬币，如果抛出来的是正面，则继续抛，直到出现负面为止，统计这个过程中出现正面的次数，这个次数作为结点跨越的层数。 通过这种方法，可以尽可能的接近理想的层数。大家可以想一下为什么会这样呢？ 4.1、插入例如，我们要插入结点 3、4，通过抛硬币知道 3、4 跨越的层数分别为 0、2 (层数从 0 开始算)，则插入的过程如下 插入 3，跨越 0 层 插入 4，跨越 2 层 4.2、删除解决了插入之后，我们来看看删除，删除就比较简单了，例如我们要删除 4，那我们直接把 4 及其所跨越的层数删除就行了。 五、小结总结下跳跃表的有关性质： (1). 跳跃表的每一层都是一条有序的链表。 (2). 跳跃表的查找次数近似于层数，时间复杂度为 O(logn)，插入、删除也为 O(logn)。 (3). 最底层的链表包含所有元素。 (4). 跳跃表是一种随机化的数据结构（通过抛硬币来决定层数）。 (5). 跳跃表的空间复杂度为 O(n)。 5.1、跳跃表 vs 二叉查找树有人可能会说，也可以采用二叉查找树啊，因为二叉查找树的插入、删除、查找也是近似 O(logn) 的时间复杂度。 不过，二叉查找树是有可能出现一种极端的情况的，就是如果插入的数据刚好一直有序，那么所有节点会偏向某一边。 这种结构会导致二叉查找树的查找效率变为 O(n)，这会使二叉查找树大打折扣。 5.2、跳跃表 vs 红黑树红黑树可以说是二叉查找树的一种变形，红黑树在查找、插入，删除也是近似 O(logn) 的时间复杂度。 而且红黑树插入，删除结点时，是通过调整结构来保持红黑树的平衡，比起跳跃表直接通过一个随机数来决定跨越几层，在时间复杂度的花销上是要高于跳跃表的。 当然，红黑树并不是一定比跳跃表差，在有些场合红黑树会是更好的选择，所以选择一种数据结构，关键还得看场合。 总上所述，维护一组有序的集合，并且希望在查找、插入、删除等操作上尽可能快，那么跳跃表会是不错的选择。redis 中的某些数据结构便是采用了跳跃表，当然，redis 也结合了哈希表等数据结构，采用的是一种复合数据结构。 5.3、小结跳表是一种可以替代平衡树的数据结构。跳表追求的是概率性平衡，而不是严格平衡。因此，跟平衡二叉树相比，跳表的插入和删除操作要简单得多，执行也更快。 Skiplist 的复杂度和红黑树一样，而且实现起来更简单。在并发环境下 Skiplist 有另外一个优势，红黑树在插入和删除的时候可能需要做一些 rebalance 的操作，这样的操作可能会涉及到整个树的其他部分，而 Skiplist 的操作显然更加局部性一些，需要关注的节点更少，因此在这样的情况下性能好一些。 六、代码实现Java 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125 //节点 class Node{ int value = -1; int level;//跨越几层 Node[] next;//指向下一个节点 public Node(int value, int level) { this.value = value; this.level = level; this.next = new Node[level]; } } //跳跃表 public class SkipList { //允许的最大层数 int maxLevel = 16; //头节点，充当辅助。 Node head = new Node(-1, 16); //当前跳跃表节点的个数 int size = 0; //当前跳跃表的层数,初始化为1层。 int levelCount = 1; public Node find(int value) { Node temp = head; for (int i = levelCount - 1; i &gt;= 0; i--) { while (temp.next[i] != null &amp;&amp; temp.next[i].value &lt; value) { temp = temp.next[i]; } } //判断是否有该元素存在 if (temp.next[0] != null &amp;&amp; temp.next[0].value == value) { System.out.println(value + \" 查找成功\"); return temp.next[0]; } else { return null; } } //为了方便，跳跃表在插入的时候，插入的节点在当前跳跃表是不存在的 //不允许插入重复数值的节点。 public void insert(int value) { int level = getLevel(); Node newNode = new Node(value, level); //update用于记录要插入节点的前驱 Node[] update = new Node[level]; Node temp = head; for (int i = level - 1; i &gt;= 0; i--) { while (temp.next[i] != null &amp;&amp; temp.next[i].value &lt; value) { temp = temp.next[i]; } update[i] = temp; } //把插入节点的每一层连接起来 for (int i = 0; i &lt; level; i++) { newNode.next[i] = update[i].next[i]; update[i].next[i] = newNode; } //判断是否需要更新跳跃表的层数 if (level &gt; levelCount) { levelCount = level; } size++; System.out.println(value + \" 插入成功\"); } public void delete(int value) { Node[] update = new Node[levelCount]; Node temp = head; for (int i = levelCount - 1; i &gt;= 0; i--) { while (temp.next[i] != null &amp;&amp; temp.next[i].value &lt; value) { temp = temp.next[i]; } update[i] = temp; } if (temp.next[0] != null &amp;&amp; temp.next[0].value == value) { size--; System.out.println(value + \" 删除成功\"); for (int i = levelCount - 1; i &gt;= 0; i--) { if (update[i].next[i] != null &amp;&amp; update[i].next[i].value == value) { update[i].next[i] = update[i].next[i].next[i]; } } } } //打印所有节点 public void printAllNode() { Node temp = head; while (temp.next[0] != null) { System.out.println(temp.next[0].value + \" \"); temp = temp.next[0]; } } //模拟抛硬币 private int getLevel() { int level = 1; while (true) { int t = (int)(Math.random() * 100); if (t % 2 == 0) { level++; } else { break; } } System.out.println(\"当前的level = \" + level); return level; } //测试数据 public static void main(String[] args) { SkipList list = new SkipList(); for (int i = 0; i &lt; 6; i++) { list.insert(i); } list.printAllNode(); list.delete(4); list.printAllNode(); System.out.println(list.find(3)); System.out.println(list.size + \" \" + list.levelCount); }} 跳跃表构造图示 C++ 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174#ifndef SKIPLIST_H#define SKIPLIST_H#include &lt;ctime&gt;#include &lt;initializer_list&gt;#include &lt;iostream&gt;#include &lt;random&gt;template &lt;typename Key&gt;class Skiplist{ public: struct Node { Node(K k) : key(k) {} Key key; Node* next[1]; // C 语言中的柔性数组技巧 }; private: int maxLevel; Node* head; enum { kMaxLevel = 12 }; public: Skiplist() : maxLevel(1) { head = newNode(0, kMaxLevel); } Skiplist(std::initializer_list&lt;Key&gt; init) : Skiplist() { for(const Key&amp; k : int) { insert(k); } } ~Skiplist() { Node* pNode = head; Node* delNode; while(nullptr != pNode) { delNode = pNode; pNode = pNode-&gt;next[0]; free(delNode); // 对应 malloc } } // 禁止拷贝构造和赋值构造 Skiplist(const Skiplist&amp;) = delete; Skiplist&amp; operator=(const Skiplist&amp;) = delete; Skiplist&amp; operator=(Skiplist&amp;&amp;) = delete; private: Node* newNode(const Key&amp; key, int level) { /* 开辟 sizeof(Node) + sizeof(Node*) * (level - 1) 大小的空间 sizeof(Node*) * (level - 1) 大小的空间是给 Node.next[1] 指针数组用的 为什么是 level - 1 而不是 level，因为 sizeof(Node) 已包含一个 Node* 指针的空间 */ void* node_memory = malloc(sizeof(Node) + sizeof(Node*) * (level - 1)); Node* node = new (node_memory) Node(Key); for(int i = 0; i &lt; level; ++i) { node-&gt;next[i] = nullptr; } return node; } // 随机函数，范围 [1, kMaxLevel]，越小概率越大 static int randomLevel() { int level = 1; while(rand() % 2 &amp;&amp; level &lt; kMaxLevel) { level++; } return level; } public: Node* find(const Key* key) { // 从最高层开始查找，每层查找最后一个小于 key 的前驱节点，不断缩小范围 Node* pNode = head; for(int i = maxLevel - 1; i &gt;= 0; --i) { while(pNode-&gt;next[i] != nullptr &amp;&amp; pNode-&gt;next[i]-&gt;key &lt; key) { pNode = pNode-&gt;next[i]; } } // 如果第一层的 pNode[0]-&gt;key == key，则返回 pNode-&gt;next[0]，即找到 key if(nullptr != pNode-&gt;next[0] &amp;&amp; pNode-&gt;next[0]-&gt;key == key) { return pNode-&gt;next[0]; } return nullptr; } void insert(const Key&amp; key) { int level = randomLevel(); Node* new_node = newNode(key, level); Node* prev[kMaxLevel]; Node* pNode = head; // 从最高层开始查找，每层查找最后一个小于 key 的前继节点 for(int i = level - 1; i &gt;= 0; --i) { while(pNode-&gt;next[i] != nullptr &amp;&amp; pNode-&gt;next[i]-&gt;key &lt; key) { pNode = pNode-&gt;next[i]; } prev[i] = pNode; } // 然后每层将新节点插入到前继节点后面 for(int i = 0; i &lt; level; ++i) { new_node-&gt;next[i] = prev-&gt;next[i]; prev[i]-&gt;next[i] = new_node; } if(maxLevel &lt; level) // 层数大于最大层数，更新最大层数 { maxLevel = level; } } void erase(const Key&amp; key) { Node* prev[maxLevel]; Node* pNode = head; // 从最高层开始查找，每层查找最后一个小于 key 的前继节点 for(int i = maxLevel - 1; i &gt;= 0; --i) { while(pNode-&gt;next[i] != nullptr &amp;&amp; pNode-&gt;next[i]-&gt;key &lt; key) { pNode = pNode-&gt;next[i]; } prev[i] = pNode; } // 如果找到 key if(pNode-&gt;next[0] != nullptr &amp;&amp; pNode-&gt;next[0]-&gt;key == key) { Node* delNode = pNode-&gt;next[0]; // 从最高层开始，如果当前层的 next 节点的值等于 key，则删除 next 节点 for(int i = maxLevel - 1; i &gt;= 0; --i) { if(prev[i]-&gt;next[i] != nullptr &amp;&amp; key == prev[i]-&gt;next[i]-&gt;key) { prev[i]-&gt;next[i] = prev[i]-&gt;next[i]-&gt;next[i]; } } free(delNode); // 最后销毁 pNode-&gt;next[0] 节点 } // 如果 maxLevel &gt; 1 且头结点的 next 指针为空，则该层已无数据，maxLevel 减 1 while(maxLevel &gt; 1 &amp;&amp; head-&gt;next[maxLevel] == nullptr) { maxLevel--; } }};#endif 初始化列表参考C++11新特性-初始化列表initializer_list 参考原文:以后有面试官问你「跳跃表」，你就把这篇文章扔给他","link":"/post/8caa7793.html"},{"title":"服务端TCP连接大量TIME_WAIT状态的分析与问题解决","text":"TIME_WAIT 一、问题描述模拟高并发的场景，会出现批量的 TIME_WAIT 的 TCP 连接： 短时间后，所有的 TIME_WAIT 全都消失，连接被回收，端口包括服务，均正常。即，在高并发的场景下，TIME_WAIT 连接存在，属于正常现象。 线上场景中，持续的高并发场景： 一部分 TIME_WAIT 连接被回收，但新的 TIME_WAIT 连接产生； 一些极端情况下，会出现大量的 TIME_WAIT 连接。 Think：上述大量的 TIME_WAIT 状态 TCP 连接，有什么业务上的影响吗？ Nginx 作为反向代理时，大量的短链接，可能导致 Nginx 上的 TCP 连接处于 time_wait 状态： 每一个 time_wait 状态，都会占用一个「本地端口」，上限为 65535（16 bit，2 Byte）； 当大量的连接处于 time_wait 时，新建立 TCP 连接会出错，address already in use : connect 异常 统计 TCP 连接的状态： 1234567// 统计：各种连接的数量$ netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'ESTABLISHED 1154TIME_WAIT 1645 Tips：TCP 本地端口数量，上限为 65535（6.5w），这是因为 TCP 头部使用 16 bit 存储「端口号」，因此约束上限为 65535。 二、问题分析大量的 TIME_WAIT 状态 TCP 连接存在，其本质原因是什么？ 大量的短连接存在 特别是 HTTP 请求中，如果 connection 头部取值被设置为 close 时，基本都由「服务端」发起主动关闭连接 TCP 四次挥手关闭连接机制中，为了保证 ACK 重发和丢弃延迟数据，设置 time_wait 为 2 倍的 MSL（报文最大存活时间） TIME_WAIT 状态： TCP 连接中，主动关闭连接的一方出现的状态；（收到 FIN 命令，进入 TIME_WAIT 状态，并返回 ACK 命令） 保持 2 个 MSL 时间，即 4 分钟；（MSL 为 2 分钟） 三、解决办法解决上述 time_wait 状态大量存在，导致新连接创建失败的问题，一般解决办法： 客户端HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么设置。 服务器端1、允许 time_wait 状态的 socket 被重用2、缩减 time_wait 时间，设置为 1 MSL（即 2 mins） 四、总结 time_wait 状态的影响 TCP 连接中，「主动发起关闭连接」的一端，会进入 time_wait 状态 time_wait 状态，默认会持续 2 MSL（报文的最大生存时间），一般是 2x2 mins time_wait 状态下，TCP 连接占用的端口，无法被再次使用 TCP 端口数量，上限是 6.5w（65535，16 bit） 大量 time_wait 状态存在，会导致新建 TCP 连接会出错，address already in use : connect 异常 现实场景 服务器端，一般设置：不允许「主动关闭连接」 但 HTTP 请求中，http 头部 connection 参数，可能设置为 close，则服务端处理完请求会主动关闭 TCP 连接 现在浏览器中， HTTP 请求 connection 参数，一般都设置为 keep-alived Nginx 反向代理场景中，可能出现大量短链接，服务器端，可能存在 解决办法 服务器端允许 time_wait 状态的 socket 被重用 缩减 time_wait 时间，设置为 1 MSL（即 2 mins） 五、拓展5.1、查询 TCP 连接状态Mac 下，查询 TCP 连接状态的具体命令： 123456789101112// Mac 下，查询 TCP 连接状态$ netstat -nat | grep TIME_WAIT// Mac 下，查询 TCP 连接状态，其中 -E 表示 grep 或的匹配逻辑$ netstat -nat | grep -E \"TIME_WAIT|Local Address\"Proto Recv-Q Send-Q Local Address Foreign Address (state)tcp4 0 0 127.0.0.1.1080 127.0.0.1.59061 TIME_WAIT// 统计：各种连接的数量$ netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'ESTABLISHED 1154TIME_WAIT 1645 5.2、MSL 时间MSL，Maximum Segment Lifetime，“报文最大生存时间” 任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。（IP 报文） TCP 报文（segment）是 ip 数据报（datagram）的数据部分。 Tips：RFC 793 中规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。 2MSL，TCP 的 TIME_WAIT 状态，也称为 2MSL 等待状态： 当 TCP 的一端发起主动关闭（收到 FIN 请求），在发出最后一个 ACK 响应后，即第 3 次挥手完成后，发送了第四次挥手的 ACK 包后，就进入了 TIME_WAIT 状态。 必须在此状态上停留两倍的 MSL 时间，等待 2MSL 时间主要目的是怕最后一个 ACK 包对方没收到，那么对方在超时后将重发第三次挥手的 FIN 包，主动关闭端接到重发的 FIN 包后，可以再发一个 ACK 应答包。 在 TIME_WAIT 状态时，两端的端口不能使用，要等到 2MSL 时间结束，才可继续使用。（IP 层） 当连接处于 2MSL 等待阶段时，任何迟到的报文段都将被丢弃。 不过在实际应用中，可以通过设置「SO_REUSEADDR 选项」，达到不必等待 2MSL 时间结束，即可使用被占用的端口。 5.3、TCP 三次握手和四次握手 1、time_wait 是「服务器端」的状态 or「客户端」的状态？ time_wait 是「主动关闭 TCP 连接」一方的状态，可能是「客服端」的，也可能是「服务器端」的 一般情况下，都是「客户端」所处的状态，「服务器端」一般设置「不主动关闭连接」 2、服务器在对外服务时，是「客户端」发起的断开连接？还是「服务器」发起的断开连接？ 正常情况下，都是「客户端」发起的断开连接 「服务器」一般设置为「不主动关闭连接」，服务器通常执行「被动关闭」 但 HTTP 请求中，http 头部 connection 参数，可能设置为 close，则，服务端处理完请求会主动关闭 TCP 连接 3、关于 HTTP 请求中，设置的主动关闭 TCP 连接的机制：TIME_WAIT 的是主动断开方才会出现的，所以主动断开方是服务端？ 答案是是的。在 HTTP1.1 协议中，有个 Connection 头，Connection 有两个值，close 和 keep-alive，这个头就相当于客户端告诉服务端，服务端你执行完成请求之后，是关闭连接还是保持连接，保持连接就意味着在保持连接期间，只能由客户端主动断开连接。还有一个 keep-alive 的头，设置的值就代表了服务端保持连接保持多久。 HTTP 默认的 Connection 值为 close，那么就意味着关闭请求的一方几乎都会是由服务端这边发起的。那么这个服务端产生 TIME_WAIT 过多的情况就很正常了。 虽然 HTTP 默认 Connection 值为 close，但是，现在的浏览器发送请求的时候一般都会设置 Connection 为 keep-alive 了。所以，也有人说，现在没有必要通过调整参数来使 TIME_WAIT 降低了。 4、time_wait 状态存在的必要性 可靠的实现 TCP 全双工连接的终止四次挥手关闭 TCP 连接过程中，最后的 ACK 是由「主动关闭连接」的一端发出的，如果这个 ACK 丢失，则对方会重发 FIN 请求，因此，在「主动关闭连接」的一段，需要维护一个 time_wait 状态，处理对方重发的 FIN 请求。 处理延迟到达的报文由于路由器可能抖动，TCP 报文会延迟到达，为了避免「延迟到达的 TCP 报文」被误认为是「新 TCP 连接」的数据，则需要在允许新创建 TCP 连接之前，保持一个不可用的状态，等待所有延迟报文的消失，一般设置为 2 倍的 MSL（报文的最大生存时间），解决「延迟达到的 TCP 报文」问题。 原文连接:服务端 TCP 连接的 TIME_WAIT 过多问题的分析与解决","link":"/post/bbd7d4be.html"},{"title":"C/C++内存知识点","text":"内存 一、概念1.1、内存地址空间 程序地址空间 Stack 高地址 向下成长 ↓ 向上成长 ↑ Heap 低地址 1.2、C++ 内存上的布局以及存取时间主要的额外负担是由 virtual 引起的virtual function 机制用以支持一个有效率的执行期绑定（runtime binding）。 虚继承 virtual base class 用以实现多次出现在继承体系中的 base class，有一个单一而被共享的实体。 1.3、C++ 内存布局堆、栈、自由存储区、全局/静态存储区、常量存储区 1.4、自由存储区和堆一般认为自由存储区与堆的划分标准是申请和释放内存是使用的 new/delete 还是 malloc/free。C++ 标准并没有给出 new/delete 应该如何实现，但很多编译器的 new/delete 都是以 malloc/free 为基础来实现的。从技术上来说，堆（heap）是 C 语言和操作系统的术语，堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，使用 malloc()、free() 来申请/释放内存。而自由存储是 C++ 中通过 new 和 delete 动态分配和释放对象的抽象概念。基本上，所有的 C++ 编译器默认使用堆来实现自由存储。也就是说，默认的全局运算符 new 和 delete 也许会使用 malloc 和 free 的方式申请和释放存储空间，也就是说自由存储区就位于堆上。但程序员也可以通过重载操作符，改用其他内存来实现自由存储，例如全局变量做的对象池，这时自由存储区就不位于堆上了。 自由存储区和堆的区别是：堆是操作系统维护的一块内存，是一个物理概念，而自由存储是 C++ 中通过 new 与 delete 动态分配和释放的对象的存储区，是一个逻辑概念。 1.5、动态内存分配问题内存分配有静态分配和动态分配两种。静态分配在程序编译链接时分配的大小和使用寿命就已经确定，而应用上要求操作系统可以提供给进程运行时申请和释放任意大小内存的功能，这就是内存的动态分配。 因此动态分配将不可避免会产生内存碎片的问题，那么什么是内存碎片？内存碎片即“碎片的内存”，描述一个系统中所有不可用的空闲内存，这些碎片之所以不能被使用，是因为负责动态分配内存的分配算法使得这些空闲的内存无法使用，这一问题的发生，原因在于这些空闲内存以较小且不连续方式出现在不同的位置。因此这个问题或多或少取决于内存管理算法的实现上。 1.6、为什么会产生这些小且不连续的空闲内存碎片呢？实际上这些空闲内存碎片存在的方式有两种： 内部碎片内部碎片的产生：因为所有的内存分配必须起始于可被 4、8 或 16 整除（视处理器体系结构而定）的地址或者因为 MMU 的分页机制的限制，决定内存分配算法仅能把预定大小的内存块分配给客户。假设当某个客户请求一个 43 字节的内存块时，因为没有适合大小的内存，所以它可能会获得 44 字节、48 字节等稍大一点的字节内存块，因此由所需大小四舍五入而产生的多余空间就叫内部碎片。 外部碎片外部碎片的产生：频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。假设有一块一共有 100 个单位的连续空闲内存空间，范围是 0 ~ 99。如果你从中申请一块内存，如 10 个单位，那么申请出来的内存块就为 0 ~ 9 区间。这时候你继续申请一块内存，比如说5个单位大，第二块得到的内存块就应该为 10 ~ 14 区间。如果你把第一块内存块释放，然后再申请一块大于 10 个单位的内存块，比如说 20 个单位。因为刚被释放的内存块不能满足新的请求，所以只能从 15 开始分配出 20 个单位的内存块。现在整个内存空间的状态是 0 ~ 9 空闲，10 ~ 14 被占用，15 ~ 24 被占用，25 ~ 99 空闲。其中 0 ~ 9 就是一个内存碎片了。如果 10 ~ 14 一直被占用，而以后申请的空间都大于 10 个单位，那么 0 ~ 9 就永远用不上了，变成外部碎片。 1.7、系统内存回收机制问题内存碎片是一个系统问题，反复的 malloc 和 free，而 free 后的内存又不能马上被系统回收利用。这个与系统对内存的回收机制有关。 内存碎片带来的问题：大量的内存碎片会使系统缓慢，原因在于虚拟内存的使用会使内存与硬盘之间的数据交换成为系统缓慢的根源，最终造成内存的枯竭。 1.8、如何避免内存碎片的产生1、少用动态内存分配的函数（尽量使用栈空间） 2、分配内存和释放内存尽量在同一个函数中 3、尽量一次性申请较大的内存（2的指数次幂大小的内存空间），而不要反复申请小内存（少进行内存的分割） 4、使用内存池来减少使用堆内存引起的内存碎片 1.9、memcpy 与 memmove 的区别memcpy 和 memmove 都是 C 语言的库函数，相比于 strcpy 和 strncpy 只能拷贝字符串数组，memcpy 与 memmove 可以拷贝其它类型的数组。 123void *memcpy(void *restrict s1, const void *restrict s2, size_t n);void *memmove(void *s1, const void *s2, size_t n); 这两个函数都是将 s2 指向位置的 n 字节数据拷贝到 s1 指向的位置，区别就在于关键字 restrict，memcpy 假定两块内存区域没有数据重叠，而 memmove 没有这个前提条件。如果复制的两个区域存在重叠时使用 memcpy，其结果是不可预知的，有可能成功也有可能失败的，所以如果使用了 memcpy，程序员自身必须确保两块内存没有重叠部分。 正常情况下，即使内容有重叠，src 的内容也可以正确地被拷贝到了 dest 指向的空间。 这种情况下，src 的地址小于 dest 的地址，拷贝前 3 个字节没问题，但是拷贝第 4，5 个字节时，原有的内容已经被 src 拷贝过来的字符覆盖了，所以已经丢失原来 src 的内容，这很明显就是问题所在。 memcpy 的实现 123456789#include &lt;stddef.h&gt; /* size_t */void *memcpy(void *dest, const void *src, size_t n){ char *dp = dest; const char *sp = src; while (n--) *dp++ = *sp++; return dest;} memmove 的实现 memmove 会对拷贝的数据作检查，确保内存没有覆盖，如果发现会覆盖数据，简单的实现是调转开始拷贝的位置，从尾部开始拷贝: 12345678910111213#include &lt;stddef.h&gt; /* for size_t */void *memmove(void *dest, const void *src, size_t n){ unsigned char *pd = dest; const unsigned char *ps = src; if (__np_anyptrlt(ps, pd)) for (pd += n, ps += n; n--;) *--pd = *--ps; else while(n--) *pd++ = *ps++; return dest;} 这里 __np_anyptrlt 是一个简单的宏，用于结合拷贝的长度检测 dest 与 src 的位置，如果 dest 和 src 指向同样的对象，且 src 比dest 地址小，就需要从尾部开始拷贝，否则就和 memcpy 处理相同。但是实际在 C99 实现中，是将内容拷贝到临时空间，再拷贝到目标地址中： 12345678910#include &lt;stddef.h&gt; /* for size_t */#include &lt;stdlib.h&gt; /* for memcpy */void *memmove(void *dest, const void *src, size_t n){ unsigned char tmp[n]; memcpy(tmp, src, n); memcpy(dest, tmp, n); return dest;} 由此可见 memcpy 的速度比 memmove 快一点，如果使用者可以确定内存不会重叠，则可以选用 memcpy，否则 memmove 更安全一些。另外一个提示是第三个参数是拷贝的长度，如果你是拷贝 10 个 double 类型的数值，要写成 sizeof(double)*10，而不仅仅是 10。 实现 memmove 有两个要点： （1）从 src 指向的内存拷贝 count 个字节到 dst 指向的内存中。 （2）处理 src 和 dst 有重叠的情况，这是和 memcpy 不一样的地方。 1234567891011121314151617181920212223242526272829303132333435363738void * __cdecl memmove ( void * dst, const void * src, size_t count ){ void * ret = dst; if (dst &lt;= src || (char *)dst &gt;= ((char *)src + count)) { /* * Non-Overlapping Buffers * copy from lower addresses to higher addresses */ while (count--) { *(char *)dst = *(char *)src; dst = (char *)dst + 1; src = (char *)src + 1; } } else { /* * Overlapping Buffers * copy from higher addresses to lower addresses */ dst = (char *)dst + count - 1; src = (char *)src + count - 1; while (count--) { *(char *)dst = *(char *)src; dst = (char *)dst - 1; src = (char *)src - 1; } } return(ret);} 1.10、为什么 new[]/delete[] 需要记录对象个数？ 对于有 non-trivial destructor 的 class T，现在通常的 C++ 实现会在 new[] 的时候多分配 sizeof(size_t) 字节用于保存数组大小，在 delete[] 的时候会依次逆序调用数组中各对象的析构函数。有的文献管这多分配的几个字节叫 new cookie (Itanium C++ ABI)。 new/malloc 会记录分配的内存的长度，delete/free 的时候无需指定长度，只要传入首地址即可。 那或许有人会问，既然根据数组首地址就能知道分配了多少字节内存，那为什么 new[] 还需要再保存对象的数目？这不是多余吗？直接用内存长度 / sizeof(T) 不就可以算出需要析构多少个对象了？ 原因很简单： 内存长度 / sizeof(T) &gt;= 对象个数 因为 new / malloc 在分配内存的时候会 round up 到某个数的倍数（8 或 16 等，跟 malloc 具体实现有关），即内存长度 = round_up(sizeof(T) * 对象个数)，那么反过来我们就不能用内存长度算出对象个数了，必须单独保存对象个数。 假如不采用 new cookie，如果 sizeof(Foo) == 4，那么 Foo* p = new Foo[28]; 会分配 112 字节来构造 28 个对象，但实际会从 libc 拿到 116 字节，那么 delete[] p; 会析构 116/4 = 29 个对象，这就有大问题了。 因此，通常的 C++ 实现在必要时会在 new[] 的时候多分配 sizeof(size_t) 字节用于保存对象数目，而不是让 delete[] 依靠内存大小来算出需要析构多少个对象。 二、内存分配方式C++ 中内存分配十分重要，并且容易造成内存泄露等等问题，之前只是知道 new 和 delete 底层调用的是 malloc 和 free，下面就深入分析一下 new 和 delete 的执行步骤以及自定义内存池。 C++ 中内存分配的层次，其中 C++ Library 分配器就是 STL 中的内存分配结构，将 new/malloc 以及 delete/free 进一步封装，减少 new/malloc 的次数，做成一个内存池。 2.1、malloc/free 函数C 语言中的内存分配函数，速度很快，返回的是 void* 类型的指针 12void* p1 = malloc(512);free (p1); 2.2、new/delete 函数new 动作包含两个动作： 开辟空间 构造对象 delete 动作包含两个动作： 析构对象 释放空间 12complex&lt;int&gt;* p2 = new complex&lt;int&gt;;delete p2; 2.3、array new/delete 函数如果使用 array new，则必须使用 array delete 相对应，否则会出现内存泄露的现象。 12Complex *pca = new Complex[3]; //唤起三次ctordelete [] pca; //唤起三次dtor 2.4、::operator new/delete 函数**这是一个全局函数，在调用 new 函数的时候，首先编译器会先调用这个函数，并且此函数是唯一可以重载的，使用自己定义的 ::operator new 函数（但是一般不会重载全局的 ::operator new/delete 函数），而是重载类中对应的 operator new/delete 函数，这样就不会影响全局的 ::operator new/delete 函数。 ::operator new 返回的也是 void* 类型的指针 12void* a = ::operator new (sizeof(int));::operator delete(a); 2.5、new 整体流程1Complex *pc = new Complex(1, 2); 上述程序会被编译器转换为： 12345678910Complex *pc;try{void *mem = operator new (sizeof(Complex)); //分配空间pc = static_cast&lt;Complex*&gt;(mem); //类型强制转换pc-&gt;Complex::Complex(1, 2); //调用构造函数//只有编译器可以像上面一样直接调用构造函数（ctor），我们可以使用 placement new 来调用 }catch(std::bad_alloc){ //分配失败} 我们知道对象的指针是不可以直接调用构造函数的，但是编译器可以直接调用，此为编译器的特权。 首先 new 会调用 operator new 函数，如果我们不重载 operator new 函数的话，operator new 函数中调用的即为 malloc 函数，然后进行强制类型转换，以及对象的构造。 2.6、delete 整体流程1delete pc; 上述程序会被编译器转换为： 12345678pc-&gt;~Complex(); //先析构operator delete(pc); //然后释放内存 //没有重载的operate delete函数void _cdecl operator delete (void *p) //operator delete 里面调用 free 函数{ free(p);} 没有重载的全局 operator delete 函数直接调用 free 函数。 2.7、operator new/delete 的重载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;#include &lt;initializer_list&gt;#include &lt;algorithm&gt;#include &lt;thread&gt;#include &lt;cmath&gt;#include &lt;vector&gt;#include &lt;tuple&gt; #include &lt;utility&gt;#include &lt;type_traits&gt; using namespace std; class Foo{public: int _id; int _data; string _str;public: Foo():_id(0) { cout &lt;&lt; \"default ctor.this=\"&lt;&lt;this&lt;&lt;\" id=\"&lt;&lt;_id&lt;&lt;endl; } Foo(int i):_id(i){ cout &lt;&lt; \"default ctor.this=\"&lt;&lt;this&lt;&lt;\" id=\"&lt;&lt;_id&lt;&lt;endl; } ~Foo() {cout &lt;&lt;\"dctor.this=\"&lt;&lt;this&lt;&lt;\" id=\"&lt;&lt;_id&lt;&lt;endl; } //在类中进行重写，这里要使用静态函数，因为这时对象还是不存在的，没有构造出来 static void* operator new(size_t size); static void operator delete(void *pdead, size_t size); static void* operator new[](size_t size); static void operator delete[](void *pdead, size_t size); void *operator new(size_t size, void *start) { return start; } }; void* Foo::operator new(size_t size){ Foo *p = (Foo *)malloc(size); cout&lt;&lt;\"operator new\"&lt;&lt;endl; return p;}void Foo::operator delete(void* pdead, size_t size){ cout &lt;&lt; \"operator delete\"&lt;&lt;endl; free(pdead); } void* Foo::operator new[](size_t size){ Foo *p = (Foo *)malloc(size); cout&lt;&lt;\"operator new[]\"&lt;&lt;endl; return p;}void Foo::operator delete[](void* pdead, size_t size){ cout &lt;&lt; \"operator delete[]\"&lt;&lt;endl; free(pdead); } int main(){ cout &lt;&lt; sizeof(Foo) &lt;&lt; endl; Foo *p = new Foo(7); delete p; Foo *pArray = new Foo[5]; delete [] pArray; // //这样会绕过上面的函数，使用全局的new、delete函数 // Foo* p = ::new Foo(7);// ::delete p;// // Foo* pArray = ::new Foo[5];// ::delete [] pArray;} 三、如何避免内存泄露近年来，讨论 C++ 的人越来越少了，一方面是由于像 Python，Go 等优秀的语言的流行，另一方面，大家也越来越明白一个道理，并不是所有的场景都必须使用 C++ 进行开发。Python 可以应付大部分对性能要求不高的场景，Go 可以应付大部分对并发要求较高的场景，而由于 C++ 的复杂性，只有在对性能极其苛刻的场景下，才会考虑使用。 那么到底多苛刻算是苛刻呢？Go 自带内存管理，也就是 GC 功能，经过多年的优化，在 Go 中每次 GC 可能会引入 500us 的 STW 延迟。 也就是说，如果你的应用场景可以容忍不定期的 500us 的延迟，那么用 Go 都是没有问题的。如果你无法容忍 500us 的延迟，那么带 GC 功能的语言就基本无法使用了，只能选择自己管理内存的语言，例如 C++。那么由手动管理内存而带来的编程复杂度也就随之而来了。 作为 C++ 程序员，内存泄露始终是悬在头上的一颗炸弹。在过去几年的 C++ 开发过程中，由于我们采用了一些技术，我们的程序发生内存泄露的情况屈指可数。今天就在这里向大家做一个简单的介绍。 3.1、内存是如何泄露的在 C++ 程序中，主要涉及到的内存就是『栈』和『堆』（其他部分不在本文中介绍了）。 通常来说，一个线程的栈内存是有限的，通常来说是 8M 左右（取决于运行的环境）。栈上的内存通常是由编译器来自动管理的。当在栈上分配一个新的变量时，或进入一个函数时，栈的指针会下移，相当于在栈上分配了一块内存。我们把一个变量分配在栈上，也就是利用了栈上的内存空间。当这个变量的生命周期结束时，栈的指针会上移，相同于回收了内存。 由于栈上的内存的分配和回收都是由编译器控制的，所以在栈上是不会发生内存泄露的，只会发生栈溢出（Stack Overflow），也就是分配的空间超过了规定的栈大小。 而堆上的内存是由程序直接控制的，程序可以通过 malloc/free 或 new/delete 来分配和回收内存，如果程序中通过 malloc/new 分配了一块内存，但忘记使用 free/delete 来回收内存，就发生了内存泄露。 经验 #1：尽量避免在堆上分配内存既然只有堆上会发生内存泄露，那第一原则肯定是避免在堆上面进行内存分配，尽可能的使用栈上的内存，由编译器进行分配和回收，这样当然就不会有内存泄露了。 然而，只在栈上分配内存，在有 IO 的情况下是存在一定局限性的。 举个例子，为了完成一个请求，我们通常会为这个请求构造一个 Context 对象，用于描述和这个请求有关的一些上下文。例如下面一段代码： 1234void Foo(Reuqest* req) { RequestContext ctx(req); HandleRequest(&amp;ctx);} 如果 HandleRequest 是一个同步函数，当这个函数返回时，请求就可以被处理完成，那么显然 ctx 是可以被分配在栈上的。 但如果 HandleRequest 是一个异步函数，例如： 1void HandleRequest(RequestContext* ctx, Callback cb); 那么显然，ctx 是不能被分配在栈上的，因为如果 ctx 被分配在栈上，那么当 Foo 函数退出后，ctx 对象的生命周期也就结束了。而 FooCB 中显然会使用到 ctx 对象。 1234567891011void HandleRequest(RequestContext* ctx, Callback cb);void Foo(Reuqest* req) { auto ctx = new RequestContext(req); HandleRequest(ctx, FooCB);}void FooCB(RequestContext* ctx) { FinishRequest(ctx); delete ctx;} 在这种情况下，如果忘记在 FooCB 中调用 delete ctx，则就会触发内存泄露。尽管我们可以借助一些静态检查工具对代码进行检查，但往往异步程序的逻辑是极其复杂的，一个请求的生命周期中，也需要进行大量的内存分配操作，静态检查工具往往无法发现所有的内存泄露情况。 那么怎么才能避免这种情况的产生呢？引入智能指针显然是一种可行的方法，但引入 shared_ptr 往往引入了额外的性能开销，并不十分理想。 经验 #2：使用 ArenaArena 是一种统一化管理内存生命周期的方法。所有需要在堆上分配的内存，不通过 malloc/new，而是通过 Arena 的 CreateObject 接口。同时，不需要手动的执行 free/delete，而是在 Arena 被销毁的时候，统一释放所有通过 Arena 对象申请的内存。所以，只需要确保 Arena 对象一定被销毁就可以了，而不用再关心其他对象是否有漏掉的 free/delete。这样显然降低了内存管理的复杂度。 此外，我们还可以将 Arena 的生命周期与 Request 的生命周期绑定，一个 Request 生命周期内的所有内存分配都通过 Arena 完成。这样的好处是，我们可以在构造 Arena 的时候，大概预估出处理完成这个 Request 会消耗多少内存，并提前将会使用到的内存一次性的申请完成，从而减少了在处理一个请求的过程中，分配和回收内存的次数，从而优化了性能。 经验 #3：使用 CoroutineCoroutine 相信大家并不陌生，那 Coroutine 的本质是什么？我认为 Coroutine 的本质，是使得一个线程中可以存在多个上下文，并可以由用户控制在多个上下文之间进行切换。而在上下文中，一个重要的组成部分，就是栈指针。使用 Coroutine，意味着我们在一个线程中，可以创造（或模拟）多个栈。 有了多个栈，意味着当我们要做一个异步处理时，不需要释放当前栈上的内存，而只需要切换到另一个栈上，就可以继续做其他的事情了，当异步处理完成时，可以再切换回到这个栈上，将这个请求处理完成。 还是以刚才的代码为示例： 12345678910void Foo(Reuqest* req) { RequestContext ctx(req); HandleRequest(&amp;ctx);}void HandleRequest(RequestCtx* ctx) { SubmitAsync(ctx); Coroutine::Self()-&gt;Yield(); CompleteRequest(ctx);} 这里的精髓在于，尽管 Coroutine::Self()-&gt;Yield() 被调用时，程序可以跳出 HandleRequest 函数去执行其他代码逻辑，但当前的栈却被保存了下来，所以 ctx 对象是安全的，并没有被释放。 这样一来，我们就可以完全抛弃在堆上申请内存，只是用栈上的内存，就可以完成请求的处理，完全不用考虑内存泄露的问题。然而这种假设过于理想，由于在栈上申请内存存在一定的限制，例如栈大小的限制，以及需要在编译是知道分配内存的大小，所以在实际场景中，我们通常会结合使用 Arena 和 Coroutine 两种技术一起使用。 有人可能会提到，想要多个栈用多个线程不就可以了？然而用多线程实现多个栈的问题在于，线程的创建和销毁的开销极大，且线程间切换，也就是在栈之间进行切换的代销需要经过操作系统，这个开销也是极大的。所以想用线程模拟多个栈的想法在实际场景中是走不通的。 这里需要强调一下，Coroutine 确实会带来一定的性能开销，通常 Coroutine 切换的开销在 20ns 以内，然而我们依然在对性能要求很苛刻的场景使用 Coroutine，一方面是因为 20ns 的性能开销是相对很小的，另一方面是因为 Coroutine 极大的降低了异步编程的复杂度，降低了内存泄露的可能性，使得编写异步程序像编写同步程序一样简单，降低了程序员心智的开销。 经验 #4：善用 RAII尽管在有些场景使用了 Coroutine，但还是可能会有在堆上申请内存的需要，而此时有可能 Arena 也并不适用。在这种情况下，善用 RAII（Resource Acquisition Is Initialization）思想会帮助我们解决很多问题。 简单来说，RAII 可以帮助我们将管理堆上的内存，简化为管理栈上的内存，从而达到利用编译器自动解决内存回收问题的效果。此外，RAII 可以简化的还不仅仅是内存管理，还可以简化对资源的管理，例如 fd，锁，引用计数等等。 当我们需要在堆上分配内存时，我们可以同时在栈上面分配一个对象，让栈上面的对象对堆上面的对象进行封装，同时通过在栈对象的析构函数中释放堆内存的方式，将栈对象的生命周期和堆内存进行绑定。 unique_ptr 就是一种很典型的例子。然而 unique_ptr 管理的对象类型只能是指针，对于其他的资源，例如 fd，我们可以通过将 fd 封装成另外一个 FileHandle 对象的方式管理，也可以采用一些更通用的方式。例如，在我们内部的 C++ 基础库中实现了 Defer 类，想法类似于 Go 中 defer。 12345void Foo() { int fd = open(); Defer d = [=]() { close(fd); } // do something with fd} 经验 #5：便于 Debug在特定的情况下，我们难免还是要手动管理堆上的内存。然而当我们面临一个正在发生内存泄露线上程序时，我们应该怎么处理呢？ 当然不是简单的『重启大法好』，毕竟重启后还是可能会产生泄露，而且最宝贵的现场也被破坏了。最佳的方式，还是利用现场进行 Debug，这就要求程序具有便于 Debug 的能力。 这里不得不提到一个经典而强大的工具 gperftools。gperftools 是 google 开源的一个工具集，包含了 tcmalloc，heap profiler，heap checker，cpu profiler 等等。gperftools 的作者之一，就是大名鼎鼎的 Sanjay Ghemawat，没错，就是与 Jeff Dean 齐名，并和他一起写 MapReduce 的那个 Sanjay。 gperftools 的一些经典用法，我们就不在这里进行介绍了，大家可以自行查看文档。而使用 gperftools 可以在不重启程序的情况下，进行内存泄露检查，这个恐怕是很少有人了解。 实际上我们 Release 版本的 C++ 程序可执行文件在编译时全部都链接了 gperftools。在 gperftools 的 heap profiler 中，提供了 HeapProfilerStart 和 HeapProfilerStop 的接口，使得我们可以在运行时启动和停止 heap profiler。同时，我们每个程序都暴露了 RPC 接口，用于接收控制命令和调试命令。在调试命令中，我们就增加了调用 HeapProfilerStart 和 HeapProfilerStop 的命令。由于链接了 tcmalloc，所以 tcmalloc 可以获取所有内存分配和回收的信息。当 heap profiler 启动后，就会定期的将程序内存分配和回收的行为 dump 到一个临时文件中。 当程序运行一段时间后，你将得到一组 heap profile 文件 1234profile.0001.heapprofile.0002.heap...profile.0100.heap 每个 profile 文件中都包含了一段时间内，程序中内存分配和回收的记录。如果想要找到内存泄露的线索，可以通过使用 1pprof --base=profile.0001.heap /usr/bin/xxx profile.0100.heap --text 来进行查看，也可以生成 pdf 文件，会更直观一些。 这样一来，我们就可以很方便的对线上程序的内存泄露进行 Debug 了。 总结C++ 可谓是最复杂、最灵活的语言，也最容易给大家带来困扰。如果想要用好 C++，团队必须保持比较成熟的心态，团队成员必须愿意按照一定的规则来使用 C++，而不是任性的随意发挥。这样大家才能把更多精力放在业务本身，而不是编程语言的特性上。 参考原文:1、memcpy与memmove的区别2、C++ 如何避免内存泄漏","link":"/post/dda3c6bd.html"},{"title":"leetcode-最大连续子序列","text":"一、题目给定 K 个整数的序列{ N1, N2, …, NK }，其任意连续子序列可表示为{ Ni, Ni+1, …, Nj }，其中 1 &lt;= i &lt;= j &lt;= K。最大连续子序列是所有连续子序列中元素和最大的一个，例如给定序列{ -2, 11, -4, 13, -5, -2 }，其最大连续子序列为{ 11, -4, 13 }，最大和为 20。现在增加一个要求，即还需要输出该子序列的第一个和最后一个元素。 输入描述: 测试输入包含若干测试用例，每个测试用例占 2 行，第 1 行给出正整数K（K &lt; 10000），第 2 行给出 K 个整数，中间用空格分隔。当 K 为 0 时，输入结束，该用例不被处理。 输出描述: 对每个测试用例，在 1 行里输出最大和、最大连续子序列的第一个和最后一个元素，中间用空格分隔。如果最大连续子序列不唯一，则输出序号 i 和 j 最小的那个（如输入样例的第 2、3 组）。若所有 K 个元素都是负数，则定义其最大和为 0，输出整个序列的首尾元素。 示例 1 输入 6-2 11 -4 13 -5 -210-10 1 2 3 4 -5 -23 3 7 -2165 -8 3 2 5 01103-1 -5 -23-1 0 -20 输出 20 11 1310 1 410 3 510 10 100 -1 -20 0 0 二、题解一（1）当前面最大子序列和为负数的时候，后面的数加上 sum，其和一定会比后面本身更小，所以把 sum 重置为 0，重新寻找连续最大子序列和 （2）重新寻找的时候，也就是新序列开始的时候，记录下此时的数，可能是最大连续子序列和的开始数 （3）当新的连续最大子序列和大于之前的，说明之前的子序列不是所求，则更新序列的开始数和结尾数 三、代码实现（C++）123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;int main(){ int sum, K, max; while(cin &gt;&gt; K) { if(K == 0) break; sum = 0, max = 0; int nstart, start, nend, first, last; cin &gt;&gt; nstart; first = last = start = max = sum = nend = nstart; for(int i = 1; i &lt; K; i++) { int tmp; cin &gt;&gt; tmp; if(sum &lt; 0) // 重新寻找最大连续子序列和 { sum = 0; start = tmp; // 记录序列的开始数 } sum += tmp; if(sum &gt; max) { max = sum; nstart = start; nend = tmp; } if(i == K - 1) { last = tmp; } } if(max &lt; 0) { cout &lt;&lt; 0 &lt;&lt; \" \" &lt;&lt; first &lt;&lt; \" \" &lt;&lt; last &lt;&lt; endl; } else { cout &lt;&lt; max &lt;&lt; \" \" &lt;&lt; nstart &lt;&lt; \" \" &lt;&lt; nend &lt;&lt; endl; } } return 0;} 四、题解二DP - 最大连续子序列和问题的变形 记 dp[i] - 以元素 ai（1 &lt;= i &lt;= n）结尾的连续子序列的和，则有两种情况： 这个最大和的连续子序列只有一个元素，即以 a[i] 开始，以 a[i] 结尾； 这个最大和的连续子序列有多个元素，即从前面某处 a[j] 开始（j &lt; i），一直到 a[i] 结尾。 对第一种情况，最大和即 a[i] 本身；对第二种情况，最大和即 dp[i-1] + a[i]。 于是得到状态转移方程：dp[i] = max{ A[i], dp[i-1]+A[i] } (边界条件: dp[1] = a[1]) 不过，这里要求判断输入全为负数的情况，并要求输出所求最大连续子序列的起点和终点元素，因此稍作处理即可，本质不变。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;stdio.h&gt;#define maxn 10010int n, a[maxn];struct DP // 以第 i 个元素为终点的连续子序列{ int left; // 子序列起点 int right; // 子序列终点 int val; // 子序列和}dp[maxn];// 判断输入是否均为负数int Judge(int *a, int n){ int i; for(i = 1; i &lt;= n; i++) { if(a[i] &gt;= 0) { return 0; } } return 1;}int main(){ int i; int maxLeft, maxRight, maxVal; // 记录最大连续子序列起点、终点、和 while(scanf(\"%d\", &amp;n) != EOF) { if(n == 0) break; for(i = 1; i &lt;= n; i++) { scanf(\"%d\", &amp;a[i]); } // 输入数据均为负数，则输出 0 及首尾元素 if(Judge(a, n)) { printf(\"0 %d %d\\n\", a[1], a[n]); } else // 否则，递推 { dp[1].left = dp[1].right = 1; dp[1].val = a[1]; // 考察 a[i] 与 dp[i-1].val + a[i] 的大小关系 for(i = 2; i &lt;= n; i++) { // 后者大，说明在 dp[i-1] 的基础上追加 a[i] 得到的连续子序列和更大 if(a[i] &lt; dp[i-1].val + a[i]) { dp[i].left = dp[i-1].left; dp[i].right = i; dp[i].val = dp[i-1].val + a[i]; } else { // 前者大，说明此时 a[i] 独自成为一个连续子序列 dp[i].left = i; dp[i].right = i; dp[i].val = a[i]; } } // 在所有连续子序列中求解和最大的 maxLeft = dp[1].left; maxRight = dp[1].right; maxVal = dp[1].val; for(i = 2; i &lt;= n; i++) { if(dp[i].val &gt; maxVal) { maxVal = dp[i].val; maxLeft = dp[i].left; maxRight = dp[i].right; } } printf(\"%d %d %d\\n\", maxVal, a[maxLeft], a[maxRight]); } } return 0;} 题目链接[编程题]最大连续子序列","link":"/post/3dd36c53.html"},{"title":"C++线程thread知识点","text":"线程 thread 1、sleep 和 wait 的区别对于 sleep() 方法，我们首先要知道该方法是属于 Thread 类中的。而 wait() 方法，则是属于 Object 类中的。 sleep() 方法导致了程序暂停执行指定的时间，让出 CPU 给其他线程，但是它的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。 在调用 sleep() 方法的过程中，线程不会释放对象锁。 而当调用 wait() 方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify() 方法后本线程才进入对象锁定池准备。 sleep() 可以在任何地方使用，而 wait() 只能在同步方法或者同步块中使用。 sleep() 是 Thread 的静态方法，wait() 是 Object 的方法，任何对象实例都能调用。 sleep() 不会释放锁，它也不需要占用锁。wait() 会释放锁，但调用它的前提是当前线程占有锁（即代码要在 synchronized 中）。 它们都可以被 interrupted 方法中断。 Thread.Sleep(0) 的作用，就是触发操作系统立刻重新进行一次 CPU 竞争，竞争的结果也许是当前线程仍然获得 CPU 控制权，也许会换成别的线程获得 CPU 控制权。 wait(1000) 表示将锁释放 1000 毫秒，到时间后如果锁没有被其他线程占用，则再次得到锁，然后 wait() 方法结束，执行后面的代码，如果锁被其他线程占用，则等待其他线程释放锁。注意，设置了超时时间的 wait() 方法一旦过了超时时间，并不需要其他线程执行 notify() 也能自动解除阻塞，但是如果没设置超时时间的 wait() 方法必须等待其他线程执行 notify()。 wait() sleep() 同步 只能在同步上下文中调用 wait() 方法 不需要在同步方法或同步块中调用 调用对象 wait() 作用于对象本身 sleep() 作用于当前线程 释放锁资源 是 否 唤醒条件 其他线程调用对象的 notify() 或者 notifyAll() 方法 超时或者用 interrupt() 方法 方法属性 wait() 是实例方法 sleep() 是静态方法 2、线程的分类1、IO 线程，这类线程的主循环是 IO multiplexing，阻塞地等在 select/poll/epoll_wait 系统调用上。这类线程也处理定时事件。当然它的功能不止 IO，有些简单计算也可以放入其中，比如消息的编码或解码。2、计算线程，这类线程的主循环是 blocking queue，阻塞地等待在 condition variable 上。这类线程一般位于 thread pool 中。这种线程不涉及 IO，一般要避免任何阻塞操作。3、第三库所用的线程，比如 logging，又比如 database connection。 3、Linux同时启动线程的数目对于 32-bit Linux，一个进程的地址空间是 4GiB，其中用户态能访问 3GiB 左右，而一个线程的默认栈(stack)大小是 10MB，一个进程大约最多能同时启动300个线程。如果不改线程的调用栈大小的话，300左右是上限，因为程序的其他部分(数据段、代码段、堆、动态库等等)同样要占用内存(地址空间)。 4、第三方库用自己的线程第三库不一定能很好地适应并融入这个 event loop framework，有时需要用线程来做一些串并转换。比如检测串口上的数据到达可以用文件描述符的可读事件，因此可以方便地融入 event loop。但是检测串口上的某些控制信号（DCD）只能用轮询（ioctl(fd, TIOCMGET, &amp;flags)）或阻塞等待（ioctl(fd, TIOCMIWAIT, TIOCM_CAR)），想要融入 event loop，需要单独起一个线程来查询串口信号翻转，再转换为文件描述符的读写事件（可以通过 pipe）。 5、工作集指服务程序响应一次请求所访问的内存大小。如果工作集较大，就用多线程，避免 CPU cache 换入换出，影响性能；否则就用单线程多进程。线程不能减少工作量，即不能减少 CPU 时间。 6、线程原语11个最基本的 Pthreads 函数： 2个：线程的创建和等待结束(join) 4个：mutex 的创建、销毁、加锁、解锁 5个：条件变量的创建、销毁、等待、通知、广播不推荐使用读写锁的原因是它往往造成提高性能的错觉(允许多个线程并发读)，实际上在很多情况下，与使用简单的 mutex 相比，它实际上降低了性能。写操作会阻塞读操作，如果要求优化读操作的延迟，用读写锁是不合适的。 7、内存序(内存能见度)规定一个线程多某个共享变量的修改何时能被其他线程看到。 8、线程库第一个支持用户态线程的 Unix 操作系统出现在 20 世纪 90 年代早期。线程库的出现给系统函数库也带来了冲击： errno 不再是全局变量，因为每个线程可能会执行不同的系统库函数。 有些纯函数不受影响，如 memset/strcpy/snprintf 等等。 有些影响全局状态或者有副作用的函数可以通过加锁来实现线程安全，如 malloc/free、printf、fread/fseek 等等。 有些返回或使用静态空间的函数不可能做到线程安全，因此要提供另外的版本，如 asctime_r/ctime_r/gmtime_r、stderror_r、strtok_r 等等。 传统的 fork() 并发模型不再适用于多线程程序。 9、线程安全性不必担心系统调用的安全性，因为系统调用对于用户态程序来说是原子的。 尽管单个函数是线程安全的，但是对某个文件 “先 seek 再 read” 这两步操作中间有可能会被打断，其他线程有可能趁机修改了文件的当前位置，让程序逻辑无法正确执行。可以用 flockfile(File) 和 funlockfile(File) 函数来显示地加锁。并且由于 File* 的锁是可重入的，加锁之后再调用 fread() 不会造成死锁。 编写线程安全程序的一个难点在意线程安全是不可组合的（composable），一个函数 foo() 调用了两个线程安全的函数，而这个 foo() 函数本身很可能不是线程安全的。 凡是非共享的对象都是彼此独立的，如果一个对象从始至终只被一个线程用到，那么它就是安全的。另外一个事实标准是：共享的对象的 read-only 操作是安全的，前提是不能有并发的写操作。 单个成员函数的线程安全并具备可组合性（composable）。假设有 safe_vector class，它的接口与 std::vector 相同，不过每个成员函数都是线程安全的（类似 Java synchronized 方法）。但是用 safe_vector 并不一定能写出线程安全的代码。 123456safe_vector&lt;int&gt; vec; // 全局可见if (!vec.empty()) // 没有加锁保护{ int x = vec[0]; // 这两步在多线程下是不安全的} 在 if 语句判断 vec 非空之后，别的线程可能清空其元素，从而造成 vec[0] 失效。 C++ 标准库中的绝大数泛型算法是线程安全的，因为这些都是无状态纯函数。只要输入区间是线程安全的，那么泛型函数就是线程安全的。 线程标识 POSIX threads 库提供了 pthread_self 函数用于返回当前进程的标识符，类型为 pthread_t。pthread_t 不一定是一个数值类型(整数或指针)，也可能是一个结构体，Pthreads 提供了 pthread_equal 函数用于对比两个线程标识符是否相等。但有如下问题：1、无法打印输出 pthread_t，因为不知道其确切类型。也就没法在日志中用它表示当前线程的 id。2、无法比较 pthread_t 的大小或计算其 hash 值，因此无法用作关联容器的 key。3、无法定义一个非法的 pthread_t 值，用来表示绝对不可能存在的线程 id，因此 MutexLock class 没有办法有效判断当前线程是否已经持有本锁。4、pthread_t 值只在进程内有意义，与操作系统的任务调度之间无法建立有效关联。比如 /proc 文件系统中找不到 pthread_t 对应的 task。 Pthreads 只保证同一进程之内，同一时刻的各个线程的 id 不同；不能保证同一进程先后多个线程具有不同的 id，更不要说同一台机器上多个进程之间的 id 唯一性了。在 Linux 上，建议使用 gettid() 系统调用的返回值作为线程 id，理由如下：1、它的类型是 pid_t，其值通常是一个小整数，便于在日志中输出。2、它直接表示内核的任务调度 id，因此在 /proc 文件系统中可以轻易找到对应项：/proc/tid 或 /proc/pid/task/tid。3、在其他系统工具中也容易定位到具体某一个线程，如在 top 中可以按线程列出任务，然后找出 CPU 使用率最高的线程 id，再根据程序日志判断到底哪一个线程在耗用 CPU。4、任何时刻都是全局唯一的，并且由于 Linux 分配新 pid 采用递增轮回办法，短时间内启动的多个线程也会具有不同的线程 id。5、0是非法值，因为操作系统第一个进程 init 的 pid 是1。 10、线程创建与销毁创建：1、程序库不应该在未提前告知的情况下创建自己的“背景线程”。2、尽量用相同的方式创建线程。3、在进入 main() 函数之前不应该启动线程。会影响全局对象的安全构造。4、程序中线程的创建最好能在初始化阶段全部完成。 销毁：1、自然死亡。从线程主函数返回，线程正常退出。2、非正常死亡。从线程主函数抛出异常或线程触发 segfault 信号等非法操作。3、自杀。在线程中调用 pthread_exit() 来立刻退出线程。4、他杀。其他线程调用 pthread_cancel() 来强制终止某个线程。 pthread_kill() 是往线程发信号。 线程正常退出的方式只有一种，即自然死亡。因为强行终止线程的话(无论是自杀还是他杀)，它都没有机会清理资源，也没有机会释放已经持有的锁，其他线程如果再想对同一个 mutex 加锁，那么就会立刻死锁。 exit() 函数在 C++ 中的作用除了终止进程，还会析构全局对象和已经构造完的函数静态对象。这有潜在的死锁可能。 11、__thread 关键字__thread 是 GCC 内置的线程局部存储设施（thread local storage）。存取效率可与全局变量相比。 12int g_var; // 全局变量__thread int t_var; // __thread 变量 只能用于修饰 POD 类型，不能修饰 class 类型，因为无法自动调用构造函数和析构函数。thread 可以用于修饰全局变量、函数内的静态变量，但是不能修饰函数的局部变量或者 class 的普通成员变量。thread 变量的初始化只能用编译期常量。 123__thread string t_obj1(\"hello world\"); // 错误，不能调用对象的构造函数__thread string *t_obj2 = new string; // 错误，初始化必须用编译期常量__thread string *t_obj3 = NULL; // 正确，但是需要手工初始化并销毁对象 __thread 变量是每个线程有一份独立实体，各个线程的变量值互不干扰。它还可以修饰那些“值可能会变，带有全局性，但是又不值得用全局锁保护”的变量。 12、多线程与 IO操作文件描述符的系统调用本身是线程安全的，不用担心多个线程同时操作文件描述符会造成进程奔溃或内核奔溃。 多个线程操作同一个 socket 需要考虑的情况：1、如果一个线程正在阻塞地 read() 某个 socket，而另一个线程 close() 了此 socket。2、如果一个线程正在阻塞地 accept() 某个 listening socket，而另一个线程 close() 了此 socket。3、一个线程正准备 read() 某个 socket，而另一个线程 close() 了此 socket；第三个线程又恰好 open() 了另一个文件描述符，其 fd 正好与前面的 socket 相同。 读写情况：1、如果两个线程同时 read() 同一个 TCP socket，两个线程几乎同时各自收到一部分数据，如何把数据拼成完整的消息？如何知道哪部分数据先到达？2、如果两个线程同时 write() 同一个 TCP socket，每个线程都只发出去半条消息，那接收方收到数据如何处理？3、如果给每个 TCP socket 配一把锁，让同时只能有一个线程读或写此 socket，但是这样还不如直接始终让同一个线程来操作此 socket。4、对于非阻塞 IO，收发消息的完整性与原子性几乎不可能用锁来保证，因为这样会阻塞其他 IO 线程。 每个文件描述符只由一个线程操作，从而轻松解决消息收发的顺序性问题，也避免了关闭文件描述符的各种 race condition。一个线程可以操作多个文件描述符，但一个线程不能操作别的线程拥有的文件描述符。 这条规则有连个例外：对于磁盘文件，在必要的时候多个线程可以同时调用 pread()/pwrite() 来读写同一个文件；对于 UDP，由于协议本身保证消息的原子性，在适当的条件下(比如消息之间彼此独立)可以多个线程同时读写同一个 UDP 文件描述符。","link":"/post/155a216b.html"},{"title":"MySQL主从复制原理简析","text":"主从复制 一、主从复制原因1、在业务复杂的系统中，有这么一个情景，有一条 sql 语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运行。2、做数据的热备，主库宕机后能够及时替换主库，保证业务可用性。3、架构的扩展，业务量越来越大，I/O 访问频率过高，单机无法满足，此时做多库的存储，降低磁盘 I/O 访问的频率，提高单个机器的 I/O 性能。 二、主从复制流程 1、主库 db 的更新事件(update、insert、delete)被写到 binlog2、主库创建一个 binlog dump thread，把 binlog 的内容发送到从库3、从库启动并发起连接，连接到主库4、从库启动之后，创建一个 I/O 线程，读取主库传过来的 binlog 内容并写入到 relay log5、从库启动之后，创建一个 SQL 线程，从 relay log 里面读取内容，从 Exec_Master_Log_Pos 位置开始执行读取到的更新事件，将更新内容写入到 slave 的 db 三、主从复制原理1、binlog: binary log，主库中保存所有更新事件日志的二进制文件。2、主从复制的基础是主库记录数据库的所有变更记录到 binlog。binlog 是数据库服务器启动的那一刻起，保存所有修改数据库结构或内容的一个文件。3、mysql 主从复制是一个异步的复制过程，主库发送更新事件到从库，从库读取更新记录，并执行更新记录，使得从库的内容与主库保持一致。4、在主库里，只要有更新事件出现，就会被依次地写入到 binlog 里面，之后会推到从库中作为从库进行复制的数据源。5、binlog 输出线程。每当有从库连接到主库的时候，主库都会创建一个线程然后发送 binlog 内容到从库。对于每一个即将发送给从库的 sql 事件，binlog 输出线程会将其锁住。一旦该事件被线程读取完之后，该锁会被释放，即在该事件完全发送到从库的时候，该锁也会被释放。6、在从库里，当复制开始的时候，从库就会创建两个线程进行处理： 从库 I/O 线程。当 START SLAVE 语句在从库开始执行之后，从库创建一个 I/O 线程，该线程连接到主库并请求主库发送 binlog 里面的更新记录到从库上。从库 I/O 线程读取主库的 binlog 输出线程发送的更新并拷贝这些更新到本地文件，其中包括 relay log 文件。 从库的 SQL 线程。从库创建一个 SQL 线程，这个线程读取从库 I/O 线程写到 relay log 的更新事件并执行。 7、可以知道，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个 binlog 输出线程，每一个从库都有它自己的 I/O 线程 和 SQL 线程。8、从库通过创建两个独立的线程，使得在进行复制时，从库的读和写进行了分离。因此，即使负责执行的线程运行较慢，负责读取更新语句的线程并不会因此变得缓慢。比如说，如果从库有一段时间没运行了，当它在启动的时候，尽管它的 SQL 线程执行比较慢，它的 I/O 线程可以快速地从主库里读取所有的 binlog 内容。这样一来，即使从库在 SQL 线程执行完所有读取到的语句前停止运行了， I/O 线程也至少完全读取了所有的内容，并将其安全地备份在从库本地的 relay log，随时准备在从库下一次启动的时候执行语句。 四、分库分表如何实现？具体分几个库几个表，主从复制，读写分离？在实际的生产环境中，对数据库的读和写都在同一个数据库中，是不能满足实际需求的，通过主从复制的方式来同步数据，再通过读写分离来提升数据库的并发负载能力。 复制类型： 基于语句的复制。在服务器上执行 SQL 语句，在从服务器上执行同样的语句，MySQL 默认采用基于语句的复制，执行效率高。 基于行的复制。把改变的内容复制过去，而不是把命令在从服务器上执行一遍。 混合类型的复制。默认采用基于语句的复制，一旦发现基于语句无法精确复制时，就会采用基于行的复制。 读写分离： 读写分离就是在主服务器上修改，数据会同步到从服务器，从服务器只能提供读取数据，不能写入，实现备份的同时也实现了数据库性能的优化，以及提升了服务器安全。可分为： 基于程序代码内部实现。根据 SELECT、INSERT 进行路由分类。 基于中间代理层实现。代理数据库服务器接收到应用服务器的请求后根据判断后转发到后端数据库。 参考文章:MySQL主从复制原理探索","link":"/post/2518a838.html"},{"title":"多线程资源竞争的互斥与同步方法(转载)","text":"对于共享资源，如果没有上锁，在多线程的环境里，那么就可能会发生并发访问的问题。 一、竞争与协作在单核 CPU 系统里，为了实现多个程序同时运行的假象，操作系统通常以时间片调度的方式，让每个进程每次执行一个时间片，时间片用完了，就切换下一个进程运行，由于这个时间片的时间很短，于是就造成了「并发」的现象。 另外，操作系统也为每个进程创建巨大、私有的虚拟内存的假象，这种地址空间的抽象让每个程序好像拥有自己的内存，而实际上操作系统在背后秘密地让多个地址空间「复用」物理内存或者磁盘。 如果一个程序只有一个执行流程，也代表它是单线程的。当然一个程序可以有多个执行流程，也就是所谓的多线程程序，线程是调度的基本单位，进程则是资源分配的基本单位。 那么问题就来了，多个线程竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。 我们做个小实验，创建两个线程，它们分别对共享变量 i 自增 1 执行 10000 次，如下代码（虽然说是 C++ 代码，但是没学过 C++ 的同学也是看得懂的） 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt; // std::cout#include &lt;thread&gt; // std::treadint i = 0;// 线程函数，对共享变量 i 自增 1 执行 10000 次void test(){ int num = 10000; for(int n = 0; n &lt; num; n++) { i = i + 1; }}int main(void){ std::cout &lt;&lt; \"Start all threads.\" &lt;&lt; std::endl; // 创建线程 std::thread thread_test1(test); std::thread thread_test2(test); // 等待线程执行完成 thread_test1.join(); thread_test2.join(); std::cout &lt;&lt; \"All threads joined.\" &lt;&lt; std::endl; std::cout &lt;&lt; \"now i is\" &lt;&lt; i &lt;&lt; std::endl; return 0;} 按理来说，i 变量最后的值应该是 20000，但很不幸，并不是如此。我们对上面的程序执行一下： 123456789ubuntu@VM-0-9-ubuntu:~$ ./test_thread Start all threads.All threads joined.now i is 20000ubuntu@VM-0-9-ubuntu:~$ ./test_thread Start all threads.All threads joined.now i is 15173 运行了两次，发现出现了 i 值的结果是 15173，也会是 20000 的 i 值情况。 每次运行不但会产生错误，而且得到不同的结果。在计算机里是不能容忍的，虽然是小概率出现的错误，但是小概率事件它一定是会发生的，「墨菲定律」大家都懂吧。 为什么会发生这种情况？ 为了理解为什么会发生这种情况，我们必须了解编译器为更新计数器 i 变量生成的代码序列，也就是要了解汇编指令的执行顺序。 在这个例子中，我们只是想给 i 加上数字 1，那么它对应的汇编指令执行过程是这样的： 可以发现，只是单纯给 i 加上数字 1，在 CPU 运行的时候，实际上要执行 3 条指令。 设想我们的线程 1 进入这个代码区域，它将 i 的值（假设此时是 50 ）从内存加载到它的寄存器中，然后它向寄存器加 1，此时在寄存器中的 i 值是 51。 现在，一件不幸的事情发生了：时钟中断发生。因此，操作系统将当前正在运行的线程的状态保存到线程的线程控制块 TCP。 现在更糟的事情发生了，线程 2 被调度运行，并进入同一段代码。它也执行了第一条指令，从内存获取 i 值并将其放入到寄存器中，此时内存中 i 的值仍为 50，因此线程 2 寄存器中的 i 值也是 50。假设线程 2 执行接下来的两条指令，将寄存器中的 i 值 + 1，然后将寄存器中的 i 值保存到内存中，于是此时全局变量 i 值是 51。 最后，又发生一次上下文切换，线程 1 恢复执行。还记得它已经执行了两条汇编指令，现在准备执行最后一条指令。回忆一下， 线程 1 寄存器中的 i 值是51，因此，执行最后一条指令后，将值保存到内存，全局变量 i 的值再次被设置为 51。 简单来说，增加 i （值为 50 ）的代码被运行两次，按理来说，最后的 i 值应该是 52，但是由于不可控的调度，导致最后 i 值却是 51。 1.1、互斥的概念上面展示的情况称为竞争条件（race condition），当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在不确定性（indeterminate）。 由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。 我们希望这段代码是互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。 另外，说一下互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使用互斥的方式来避免资源竞争造成的资源混乱。 1.2、同步的概念互斥解决了并发进程/线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程/线程进入了临界区，其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。 我们都知道在多线程里，每个线程并一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。 例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。 所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。 举个生活的同步例子，你肚子饿了想要吃饭，你叫妈妈早点做菜，妈妈听到后就开始做菜，但是在妈妈没有做完饭之前，你必须阻塞等待，等妈妈做完饭后，自然会通知你，接着你吃饭的事情就可以进行了。 注意，同步与互斥是两种不同的概念： 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等； 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」； 二、互斥与同步的实现和使用在进程/线程并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。 为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种： 锁：加锁、解锁操作； 信号量：P、V 操作； 这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。 2.1、锁使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题。 任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。 根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。 「忙等待锁」的实现 在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊原子操作指令 —— 测试和置位（Test-and-Set）指令。 如果用 C 代码表示 Test-and-Set 指令，形式如下： 123456int TestAndSet(int* old_ptr, int new){ int old = *old_ptr; *old_ptr = new; return old;} 测试并设置指令做了下述事情: 把 old_ptr 更新为 new 的新值； 返回 old_ptr 的旧值。 当然，关键是这些代码是原子执行。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。 那什么是原子操作呢？原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态。 我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下： 1234567891011121314151617181920typedef struct lock_t{ int flag;}lock_t;void init(lock_t* lock){ lock-&gt;flag = 0;}void lock(lock_t* lock){ while(TestAndSet(&amp;lock-&gt;flag, 1) == 1); // do nothing // 临界区}void unlock(lock_t* lock){ lock-&gt;flag = 0;} 我们来确保理解为什么这个锁能工作： 第一个场景是，首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 TestAndSet(flag, 1) 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为 1，标志锁已经被持有。当线程离开临界区，调用 unlock() 将 flag 清理为 0。 第二种场景是，当某一个线程已经持有锁（即 flag 为 1）。本线程调用 lock()，然后调用 TestAndSet(flag, 1)，这一次返回 1。只要另一个线程一直持有锁，TestAndSet() 会重复返回 1，本线程会一直忙等。当 flag 终于被改为 0，本线程会调用 TestAndSet()，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。 很明显，当获取不到锁时，线程就会一直 wile 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（spin lock）。 这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。 「无等待锁」的实现 无等待锁顾明思议就是获取不到锁的时候，不用自旋。 既然不想自旋，那当获取不到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。 1234567891011121314151617181920212223242526272829303132333435typedef struct lock_t{ int flag; queue_t* q; // 等待队列}lock_t;void init(lock_t* lock){ lock-&gt;flag = 0; queue_init(lock-&gt;q);}void lock(lock_t* lock){ while(TestAndSet(&amp;lock-&gt;flag, 1) == 1) { // 保存现在运行线程 TCB； // 将现在运行的线程 TCB 插入到等待队列； // 设置该线程为等待状态； // 调度程序； } // 临界区}void unlock(lock_t* lock){ if(lock-&gt;q != NULL) { // 移出等待队列的对头元素； // 将该线程的 TCB 插入到就绪队列； // 设置该线程为就绪状态； } lock-&gt;flag = 0;} 本例只是提出了两种简单锁的实现方式。当然，在具体操作系统实现中，会更复杂，但也离不开本例两个基本元素。 如果你想要对锁的更进一步理解，推荐大家可以看《操作系统导论》第 28 章锁的内容，这本书在「微信读书」就可以免费看。 2.1、信号量信号量是操作系统提供的一种协调共享资源访问的方法。 通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。 另外，还有两个原子操作的系统调用函数来控制信号量的，分别是： P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞； P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。 类比如下，2 个资源的信号量，相当于 2 条火车轨道，PV 操作如下图过程： 操作系统是如何实现 PV 操作的呢？ 信号量数据结构与 PV 操作的算法描述如下图： 1234567891011121314151617181920212223242526272829303132333435363738// 信号量数据结构typedef struct sem_t{ int sem; // 资源个数 queue_t *q; // 等待队列}sem_t;// 初始化信号量void init(sem_t* s, int sem){ s-&gt;sem = sem; queue_init(s-&gt;q);}// P 操作void P(sem_t* s){ s-&gt;sem--; if(s-&gt;sem &lt; 0) { 1. 保留调用线程 CPU 现场； 2. 将该线程的 TCB 插入到 s 的等待队列； 3. 设置该线程为等待状态； 4. 执行调度程序； }}// V 操作void V(sem_t* s){ s-&gt;sem++; if(s-&gt;sem &lt;= 0) { 1. 移出 s 等待队列首元素； 2. 将该线程的 TCB 插入就绪队列； 3. 设置该线程为就绪状态 }} PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是原子性的。 PV 操作如何使用的呢？ 信号量不仅可以实现临界区的互斥访问控制，还可以实现线程间的事件同步。 我们先来说说如何使用信号量实现临界区的互斥访问。 为每类共享资源设置一个信号量 s，其初值为 1，表示该临界资源未被占用。 只要把进入临界区的操作置于 P(s) 和 V(s) 之间，即可实现进程/线程互斥： 此时，任何想进入临界区的线程，必先在互斥信号量上执行 P 操作，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。 若此时又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用，因此，第二个线程被阻塞。 并且，直到第一个线程执行 V 操作，释放临界资源，恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。 对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示： 如果互斥信号量为 1，表示没有线程进入临界区； 如果互斥信号量为 0，表示有一个线程进入临界区； 如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。 通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。 再来，我们说说如何使用信号量实现事件同步。 同步的方式是设置一个信号量，其初值为 0。 我们把前面的「吃饭-做饭」同步的例子，用代码的方式实现一下： 12345678910111213141516171819202122232425semaphore s1 = 0; // 表示需要吃饭semaphore s2 = 0; // 表示饭还没做完// 儿子线程函数void son(){ while(TRUE) { 肚子饿； V(s1); // 叫妈妈做饭 P(s2); // 等待妈妈做完饭 吃饭； }}// 妈妈线程函数void mom(){ while(TRUE) { P(s1); // 询问需不需要做饭 做饭； V(s2); // 做完饭，通知儿子吃饭 }} 妈妈一开始询问儿子要不要做饭时，执行的是 P(s1) ，相当于询问儿子需不需要吃饭，由于 s1 初始值为 0，此时 s1 变成 -1，表明儿子不需要吃饭，所以妈妈线程就进入等待状态。 当儿子肚子饿时，执行了 V(s1)，使得 s1 信号量从 -1 变成 0，表明此时儿子需要吃饭了，于是就唤醒了阻塞中的妈妈线程，妈妈线程就开始做饭。 接着，儿子线程执行了 P(s2)，相当于询问妈妈饭做完了吗，由于 s2 初始值是 0，则此时 s2 变成 -1，说明妈妈还没做完饭，儿子线程就是等待状态。 最后，妈妈终于做完饭了，于是执行 V(s2)，s2 信号量从 -1 变回了 0，于是就唤醒等待中的儿子线程，唤醒后，儿子线程就可以进行吃饭了。 2.2、生产者-消费者问题 生产者-消费者问题描述： 生产者在生成数据后，放在一个缓冲区中； 消费者从缓冲区取出数据处理； 任何时刻，只能有一个生产者或消费者可以访问缓冲区； 我们对问题分析可以得出： 任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，需要互斥； 缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。 那么我们需要三个信号量，分别是： 互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1； 资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）； 资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）； 123456789101112131415161718192021222324252627282930#define N 100semaphore mutex = 1;semaphore emptyBuffers = N;semaphore fullBuffers = 0;// 生产者线程函数void producer(){ while(TRUE) { P(emptyBuffers); // 讲空槽的个数 - 1 P(mutex); // 进入临界区 将生成的数据放到缓冲区中; V(mutex); // 离开临界区 V(fullBuffers); // 将满槽的个数 + 1 }}// 消费者线程函数void consumer(){ while(TRUE) { P(fullBuffers); // 将满槽的个数 - 1 P(mutex); // 进入临界区 从缓冲区里读取数据； V(mutex); // 离开临界区 V(emptyBuffers); // 将空槽的个数 + 1 }} 如果消费者线程一开始执行 P(fullBuffers)，由于信号量 fullBuffers 初始值为 0，则此时 fullBuffers 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。 接着，轮到生产者执行 P(emptyBuffers)，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 V(fullBuffers) ，信号量 fullBuffers 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。 消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。 三、经典同步问题3.1、哲学家就餐问题 先来看看哲学家就餐的问题描述： 5 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面； 巧就巧在，这个桌子只有 5 支叉子，每两个哲学家之间放一支叉子； 哲学家围在一起先思考，思考中途饿了就会想进餐； 奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐； 吃完后，会把两支叉子放回原处，继续思考； 那么问题来了，如何保证哲学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？ 方案一 我们用信号量的方式，也就是 PV 操作来尝试解决它，代码如下： 123456789101112131415#define N 5 // 哲学家个数semaphore fork[5]; // 信号量初值为 1，也就是叉子的个数void smart_person(int i) // i 为哲学家编号 0 - 4{ while(TRUE) { think(); // 哲学家思考 P(fork[i]); // 去拿左边的叉子 P(fork[(i + 1) % N]); // 去拿右边的叉子 eat(); // 进餐 V(fork[i]); // 放下左边的叉子 V(fork[(i + 1) % N]); // 放下右边的叉子 }} 上面的程序，好似很自然。拿起叉子用 P 操作，有叉子就直接用，没有叉子时就等待其他哲学家放回叉子。 不过，这种解法存在一个极端的问题：假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 P(fork[(i + 1) % N ]) 这条语句阻塞了，很明显这发生了死锁的现象。 方案二 既然「方案一」会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量，代码如下： 123456789101112131415161718#define N 5 // 哲学家个数semaphore fork[5]; // 信号量初值为 1，也就是叉子的个数semaphore mutex; // 互斥信号量，初值为 1void smart_person(int i) // i 为哲学家编号 0 - 4{ while(TRUE) { think(); // 哲学家思考 P(mutex); // 进入临界区 P(fork[i]); // 去拿左边的叉子 P(fork[(i + 1) % N]); // 去拿右边的叉子 eat(); // 进餐 V(fork[i]); // 放下左边的叉子 V(fork[(i + 1) % N]); // 放下右边的叉子 V(mutex); // 退出临界区 }} 上面程序中的互斥信号量的作用就在于，只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。 方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。 方案三 那既然方案二使用互斥信号量，会导致只能允许一个哲学家就餐，那么我们就不用它。 另外，方案一的问题在于，会出现所有哲学家同时拿左边刀叉的可能性，那我们就避免哲学家可以同时拿左边的刀叉，采用分支结构，根据哲学家的编号的不同，而采取不同的动作。 即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。 1234567891011121314151617181920212223242526#define N 5 // 哲学家个数semaphore fork[5]; // 信号量初值为 1，也就是叉子的个数void smart_person(int i) // i 为哲学家编号 0 - 4{ while(TRUE) { think(); // 哲学家思考 if(i % 2 == 0) { P(fork[i]); // 去拿左边的叉子 P(fork[(i + 1) % N]); // 去拿右边的叉子 } else { P(fork[(i + 1) % N]); // 去拿右边的叉子 P(fork[i]); // 去拿左边的叉子 } eat(); // 进餐 V(fork[i]); // 放下左边的叉子 V(fork[(i + 1) % N]); // 放下右边的叉子 }} 上面的程序，在 P 操作时，根据哲学家的编号不同，拿起左右两边叉子的顺序不同。另外，V 操作是不需要分支的，因为 V 操作是不会阻塞的。 方案三即不会出现死锁，也可以两人同时进餐。 方案四 在这里再提出另外一种可行的解决方案，我们用一个数组 state 来记录每一位哲学家在进餐、思考还是饥饿状态（正在试图拿叉子）。 那么，一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。 第 i 个哲学家的左邻右舍，则由宏 LEFT 和 RIGHT 定义： LEFT : ( i + 5 - 1 ) % 5 RIGHT : ( i + 1 ) % 5 比如 i 为 2，则 LEFT 为 1，RIGHT 为 3。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#define N 5#define LEFT (i + N - 1) % N#define RIGHT (i + 1) % N#define THINKING 0#define HUNGRY 1#define EATING 2int state[N];semaphore s[5];semaphore mutex;void test(int i) // i 为哲学家编号 0-4{ // 如果 i 号的左边右边哲学家都不是进餐状态，把 i 号哲学家标记为进餐状态 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) { state[i] = EATING; // 两把叉子到手，进餐状态 V(s[i]); // 通知第 i 个哲学家可以进餐了 }}// 功能：要么拿两把叉子，要么被阻塞起来void take_forks(int i) // i 为哲学家编号 0-4{ P(mutex); // 进入临界区 state[i] = HUNGRY; // 标记哲学家处于饥饿状态 test(i); // 尝试获取 2 支叉子 V(mutex); // 离开临界区 P(s[i]); // 没有叉子则阻塞，有叉子则继续正常执行}// 功能：把两把叉子放回原处，并在需要的时候，去唤醒左邻右舍void put_forks(int i) // i 为哲学家编号 0-4{ P(mutex); // 进入临界区 state[i] = THINKING; // 吃完饭了，交出叉子，标记思考状态 test(LEFT); // 检查左边的左邻右舍是否在进餐，没则唤醒 test(RIGHT); // 检查右边的左邻右舍是否在进餐，没则唤醒 V(mutex); // 退出临界区}// 哲学家主代码void smart_person(int i) // i 为哲学家编号 0-4{ while(TRUE) { think(); // 思考 take_forks(i); // 准备去拿叉子吃饭 eat(); // 就餐 put_forks(i); // 吃完放回叉子 }} 上面的程序使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。 注意，每个进程/线程将 smart_person 函数作为主代码运行，而其他 take_forks、put_forks 和 test 只是普通的函数，而非单独的进程/线程。 3.2、读者-写者问题前面的「哲学家进餐问题」对于互斥访问有限的竞争问题（如 I/O 设备）一类的建模过程十分有用。 另外，还有个著名的问题是「读者-写者」，它为数据库访问建立了一个模型。 读者只会读取数据，不会修改数据，而写者既可以读也可以修改数据。 读者-写者的问题描述： 「读-读」允许：同一时刻，允许多个读者同时读 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写 「写-写」互斥：没有其他写者时，写者才能写 方案一 使用信号量的方式来尝试解决： 信号量 wMutex：控制写操作的互斥信号量，初始值为 1 ； 读者计数 rCount：正在进行读操作的读者个数，初始化为 0； 信号量 rCountMutex：控制对 rCount 读者计数器的互斥修改，初始值为 1； 123456789101112131415161718192021222324252627282930313233343536373839semaphore wMutex; // 控制写操作的互斥信号量，初始值为 1semaphore rCountMutex; // 控制对 rCount 的互斥修改，初始值为 1int rCount; // 正在进行读操作的读者个数，初始化为 0// 写者进程/线程执行的函数void writer(){ while(TRUE) { P(wMutex); // 进入临界区 write(); V(wMutex); // 退出临界区 }}// 读者进程/线程执行的函数void reader(){ while(TRUE) { P(rCountMutex); // 进入临界区 if(rCount == 0) { P(wMutex); // 如果有写者，则阻塞写者 } rCount++; // 读者计数 + 1 V(rCountMutex); // 离开临界区 read(); // 读数据 P(rCountMutex); // 进入临界区 rCount--; // 读完数据，准备离开 if(rCount == 0) { V(wMutex); // 最后一个读者离开了，则唤醒写者 } V(rCountMutex); // 离开临界区 }} 上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。 方案二 那既然有读者优先策略，自然也有写者优先策略： 只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞； 如果有写者持续不断写入，则读者就处于饥饿； 在方案一的基础上新增如下变量： 信号量 rMutex：控制读者进入的互斥信号量，初始值为 1； 信号量 wDataMutex：控制写者写操作的互斥信号量，初始值为 1； 写者计数 wCount：记录写者数量，初始值为 0； 信号量 wCountMutex：控制 wCount 互斥修改，初始值为 1； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162semaphore rCountMutex; // 控制对 rCount 的互斥修改，初始值为 1semaphore rMutex; // 控制读者进入的互斥信号量，初始值为 1semaphore wCountMutex; // 控制 wCount 互斥修改，初始值为 1semaphore wDataMutex; // 控制写者写操作的互斥信号量，初始值为 1int rCount = 0; // 正在进行读操作的读者个数，初始化为 0int wCount = 0; // 正在进行写操作的写者个数，初始化为 0// 写者进程/线程执行的函数void writer(){ while(TRUE) { P(wCountMutex); // 进入临界区 if(wCount == 0) { P(rMutex); // 当第一个写者进入，如果有读者则阻塞读者 } wCount++; // 写者计数 + 1 V(wCountMutex); // 离开临界区 P(wDataMutex); // 写者写操作之间互斥，进入临界区 write(); // 写数据 V(wDataMutex); // 离开临界区 P(wCountMutex); // 进入临界区 wCount--; // 写完数据，准备离开 if(wCount == 0) { V(rMutex); // 最后一个写者离开了，则唤醒读者 } V(wCountMutex); // 离开临界区 }}// 读者进程/线程执行的函数void reader(){ while(TRUE) { P(rMutex); P(rCountMutex); // 进入临界区 if(rCount == 0) { P(wDataMutex); // 当第一个读者进入，如果有写者则阻塞写者写操作 } rCount++; // 读者计数 + 1 V(rCountMutex); // 离开临界区 V(rMutex); read(); // 读数据 P(rCountMutex); // 进入临界区 rCount--; if(rCount == 0) { V(wDataMutex); // 当没有读者了，则唤醒阻塞中写者的写操作 } V(rCountMutex); // 离开临界区 }} 注意，这里 rMutex 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 P(rMutex) 之后，后续的读者由于阻塞在 rMutex 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。 同时，第一个写者执行了 P(rMutex) 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 V(wDataMutex) 唤醒写者的写操作。 方案三 既然读者优先策略和写者优先策略都会造成饥饿的现象，那么我们就来实现一下公平策略。 公平策略： 优先级相同； 写者、读者互斥访问； 只能一个写者访问临界区； 可以有多个读者同时访问临界资源； 1234567891011121314151617181920212223242526272829303132333435363738394041424344semaphore rCountMutex; // 控制对 rCount 的互斥修改，初始值为 1semaphore wDataMutex; // 控制写者写操作的互斥信号量，初始值为 1semaphore flag; // 用于实现公平竞争，初始值为 1int rCount = 0; // 正在进行读操作的读者个数，初始位为 0// 写者进程/线程执行的函数void writer(){ while(TRUE) { P(flag); P(wDataMutex); // 写者写操作之间互斥，进入临界区 write(); // 写数据 V(wDataMutex); // 离开临界区 V(flag); }}// 读者进程/线程执行的函数void reader(){ while(TRUE) { P(flag); P(rCountMutex); // 进入临界区 if(rCount == 0) { P(wDataMutex); // 第一个读者进入，如果有写者则阻塞写者写操作 } rCount++; V(rCountMutex); // 离开临界区 V(flag); read(); // 读数据 P(rCountMutex); // 进入临界区 rCount--; if(rCount == 0) { V(wDataMutex); // 当没有读者了，则唤醒阻塞中写者的写操作 } V(rCountMutex); // 离开临界区 }} 对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列，而写者必须等待，直到没有读者到达。 没有读者到达会导致读者队列为空，即 rCount==0，此时写者才可以进入临界区执行写操作。 而这里 flag 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。 比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 P(falg) 操作，使得后续到来的读者都阻塞在 flag 上，不能进入读者队列，这会使得读者队列逐渐为空，即 rCount 减为 0。 这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 wDataMutex 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 V(wDataMutex)，唤醒刚才的写者，写者则继续开始进行写操作。 四、拓展1、Java 多线程–三个线程分别打印 a、b、c，用多线程实现循环打印 15 次 abc 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class PrintABC { int count = 0; //打印次数 Lock lock = new ReentrantLock(); //可重写锁 Condition conditionA = this.lock.newCondition(); Condition conditionB = this.lock.newCondition(); Condition conditionC = this.lock.newCondition(); public class PrintA implements Runnable { @Override public void run() { while (true) if (count &lt; 15) { lock.lock(); System.out.print(\"A\"); try { conditionB.signal(); //线程b唤醒,因为a打印完应该打印b conditionA.await(); //线程a进入等待队列 } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } } public class PrintB implements Runnable { @Override public void run() { while (true) if (count &lt; 15) { lock.lock(); System.out.print(\"B\"); try { conditionC.signal(); conditionB.await(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } } public class PrintC implements Runnable { @Override public void run() { while (true) if (count &lt; 15) { lock.lock(); System.out.println(\"C\" + count); count++; //打印完c后,count++ try { conditionA.signal(); conditionC.await(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } } } public static void main(String[] args) { PrintABC printABCD = new PrintABC(); new Thread(printABCD.new PrintA()).start(); new Thread(printABCD.new PrintB()).start(); new Thread(printABCD.new PrintC()).start(); }} 原文链接:多个线程为了同个资源打起架来了，该如何让他们安分？","link":"/post/a24a7945.html"},{"title":"数据结构与算法-红黑树(转载)","text":"为什么工程中都喜欢用红黑树，而不是其他平衡二叉查找树呢？ 零、什么是平衡二叉查找树？平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1。 平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。最先被发明的平衡二叉查找树是 AVL 树，它严格符合我刚讲到的平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。 发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。 所以，平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。 一、如何定义一棵红黑树？平衡二叉查找树其实有很多，比如，Splay Tree（伸展树）、Treap（树堆）等，但是我们提到平衡二叉查找树，听到的基本都是红黑树。它的出镜率甚至要高于“平衡二叉查找树”这几个字，有时候，我们甚至默认平衡二叉查找树就是红黑树，那我们现在就来看看这个“明星树”。 红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树。 顾名思义，红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求： 根节点是黑色的； 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据； 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的； 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点； 二、为什么说红黑树是近似平衡的？“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化得太严重。 一棵极其平衡的二叉树（满二叉树或完全二叉树）的高度大约是 log2n，所以如果要证明红黑树是近似平衡的，我们只需要分析，红黑树的高度是否比较稳定地趋近 log2n 就好了。 首先，我们来看，如果我们将红色节点从红黑树中去掉，那单纯包含黑色节点的红黑树的高度是多少呢？ 红色节点删除之后，有些节点就没有父节点了，它们会直接拿这些节点的祖父节点（父节点的父节点）作为父节点。所以，之前的二叉树就变成了四叉树。 前面红黑树的定义里有这么一条：从任意节点到可达的叶子节点的每个路径包含相同数目的黑色节点。我们从四叉树中取出某些节点，放到叶节点位置，四叉树就变成了完全二叉树。所以，仅包含黑色节点的四叉树的高度，比包含相同节点个数的完全二叉树的高度还要小。 完全二叉树的高度近似 log2n，这里的四叉“黑树”的高度要低于完全二叉树，所以去掉红色节点的“黑树”的高度也不会超过 log2n。 我们现在知道只包含黑色节点的“黑树”的高度，那我们现在把红色节点加回去，高度会变成多少呢？ 在红黑树中，红色节点不能相邻，也就是说，有一个红色节点就要至少有一个黑色节点，将它跟其他红色节点隔开。红黑树中包含最多黑色节点的路径不会超过 log2n，所以加入红色节点之后，最长路径不会超过 2log2n，也就是说，红黑树的高度近似 2log2n。 红黑树的高度只比高度平衡的 AVL 树的高度（log2n）仅仅大了一倍，在性能上，下降得并不多。这样推导出来的结果不够精确，实际上红黑树的性能更好。 三、内容小结前面提到 Treap、Splay Tree，绝大部分情况下，它们操作的效率都很高，但是也无法避免极端情况下时间复杂度的退化。尽管这种情况出现的概率不大，但是对于单次操作时间非常敏感的场景来说，它们并不适用。 AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是，有利就有弊，AVL 树为了维持这种高度的平衡，就要付出更多的代价。每次插入、删除都要做调整，就比较复杂、耗时。所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。 红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比 AVL 树要低。 所以，红黑树的插入、删除、查找各种操作性能都比较稳定。对于工程应用来说，要面对各种异常情况，为了支撑这种工业级的应用，我们更倾向于这种性能稳定的平衡二叉查找树。 红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。 因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它。 四、实现红黑树的基本思想一棵合格的红黑树需要满足这样几个要求： 根节点是黑色的； 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据； 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的； 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。 两个非常重要的操作，左旋（rotate left）、右旋（rotate right）。左旋全称其实是叫围绕某个节点的左旋，那右旋的全称估计你已经猜到了，就叫围绕某个节点的右旋。下图中的 a，b，r 表示子树，可以为空。 红黑树的插入、删除操作会破坏红黑树的定义，具体来说就是会破坏红黑树的平衡，所以，我们现在就来看下，红黑树在插入、删除数据之后，如何调整平衡，继续当一棵合格的红黑树的。 五、插入操作的平衡调整红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。所以，关于插入操作的平衡调整，有这样两种特殊情况，但是也都非常好处理。 如果插入节点的父节点是黑色的，那我们什么都不用做，它仍然满足红黑树的定义。 如果插入的节点是根节点，那我们直接改变它的颜色，把它变成黑色就可以了。 红黑树的平衡调整过程是一个迭代的过程。我们把正在处理的节点叫做关注节点。关注节点会随着不停地迭代处理，而不断发生变化。最开始的关注节点就是新插入的节点。 新节点插入之后，如果红黑树的平衡被打破，那一般会有下面三种情况。我们只需要根据每种情况的特点，不停地调整，就可以让红黑树继续符合定义，也就是继续保持平衡。 CASE 1：如果关注节点是 a，它的叔叔节点 d 是红色，我们就依次执行下面的操作： 将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色； 将关注节点 a 的祖父节点 c 的颜色设置成红色； 关注节点变成 a 的祖父节点 c； 跳到 CASE 2 或者 CASE 3。 CASE 2：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点，我们就依次执行下面的操作： 关注节点变成节点 a 的父节点 b； 围绕新的关注节点 b 左旋； 跳到 CASE 3。 CASE 3：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点，我们就依次执行下面的操作： 围绕关注节点 a 的祖父节点 c 右旋； 将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换。 调整结束。 六、删除操作的平衡调整删除操作的平衡调整分为两步，第一步是针对删除节点初步调整。初步调整只是保证整棵红黑树在一个节点删除之后，仍然满足最后一条定义的要求，也就是说，每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；第二步是针对关注节点进行二次调整，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。 6.1、针对删除节点初步调整这里需要注意一下，红黑树的定义中“只包含红色节点和黑色节点”，经过初步调整之后，为了保证满足红黑树定义的最后一条要求，有些节点会被标记成两种颜色，“红 - 黑”或者“黑 - 黑”。如果一个节点被标记为了“黑 - 黑”，那在计算黑色节点个数的时候，要算成两个黑色节点。 如果一个节点既可以是红色，也可以是黑色，在画图的时候，会用一半红色一半黑色来表示。如果一个节点是“红 - 黑”或者“黑 - 黑”，会用左上角的一个小黑点来表示额外的黑色。 CASE 1：如果要删除的节点是 a，它只有一个子节点 b，那我们就依次进行下面的操作： 删除节点 a，并且把节点 b 替换到节点 a 的位置，这一部分操作跟普通的二叉查找树的删除操作一样； 节点 a 只能是黑色，节点 b 也只能是红色，其他情况均不符合红黑树的定义。这种情况下，我们把节点 b 改为黑色； 调整结束，不需要进行二次调整。 CASE 2：如果要删除的节点 a 有两个非空子节点，并且它的后继节点就是节点 a 的右子节点 c。我们就依次进行下面的操作： 如果节点 a 的后继节点就是右子节点 c，那右子节点 c 肯定没有左子树。我们把节点 a 删除，并且将节点 c 替换到节点 a 的位置。这一部分操作跟普通的二叉查找树的删除操作无异； 然后把节点 c 的颜色设置为跟节点 a 相同的颜色； 如果节点 c 是黑色，为了不违反红黑树的最后一条定义，我们给节点 c 的右子节点 d 多加一个黑色，这个时候节点 d 就成了“红 - 黑”或者“黑 - 黑”； 这个时候，关注节点变成了节点 d，第二步的调整操作就会针对关注节点来做。 CASE 3：如果要删除的是节点 a，它有两个非空子节点，并且节点 a 的后继节点不是右子节点，我们就依次进行下面的操作： 找到后继节点 d，并将它删除，删除后继节点 d 的过程参照 CASE 1； 将节点 a 替换成后继节点 d； 把节点 d 的颜色设置为跟节点 a 相同的颜色；如果节点 d 是黑色，为了不违反红黑树的最后一条定义，我们给节点 d 的右子节点 c 多加一个黑色，这个时候节点 c 就成了“红 - 黑”或者“黑 - 黑”； 这个时候，关注节点变成了节点 c，第二步的调整操作就会针对关注节点来做。 6.2、针对关注节点进行二次调整经过初步调整之后，关注节点变成了“红 - 黑”或者“黑 - 黑”节点。针对这个关注节点，我们再分四种情况来进行二次调整。二次调整是为了让红黑树中不存在相邻的红色节点。 CASE 1：如果关注节点是 a，它的兄弟节点 c 是红色的，我们就依次进行下面的操作： 围绕关注节点 a 的父节点 b 左旋； 关注节点 a 的父节点 b 和祖父节点 c 交换颜色； 关注节点不变； 继续从四种情况中选择适合的规则来调整。 CASE 2：如果关注节点是 a，它的兄弟节点 c 是黑色的，并且节点 c 的左右子节点 d、e 都是黑色的，我们就依次进行下面的操作： 将关注节点 a 的兄弟节点 c 的颜色变成红色； 从关注节点 a 中去掉一个黑色，这个时候节点 a 就是单纯的红色或者黑色； 给关注节点 a 的父节点 b 添加一个黑色，这个时候节点 b 就变成了“红 - 黑”或者“黑 - 黑”； 关注节点从 a 变成其父节点 b； 继续从四种情况中选择符合的规则来调整。 CASE 3：如果关注节点是 a，它的兄弟节点 c 是黑色，c 的左子节点 d 是红色，c 的右子节点 e 是黑色，我们就依次进行下面的操作： 围绕关注节点 a 的兄弟节点 c 右旋； 节点 c 和节点 d 交换颜色； 关注节点不变； 跳转到 CASE 4，继续调整。 CASE 4：如果关注节点 a 的兄弟节点 c 是黑色的，并且 c 的右子节点是红色的，我们就依次进行下面的操作： 围绕关注节点 a 的父节点 b 左旋； 将关注节点 a 的兄弟节点 c 的颜色，跟关注节点 a 的父节点 b 设置成相同的颜色； 将关注节点 a 的父节点 b 的颜色设置为黑色； 从关注节点 a 中去掉一个黑色，节点 a 就变成了单纯的红色或者黑色； 将关注节点 a 的叔叔节点 e 设置为黑色； 调整结束。 6.3、为什么红黑树的定义中，要求叶子节点是黑色的空节点？只要满足这一条要求，那在任何时刻，红黑树的平衡操作都可以归结为我们刚刚讲的那几种情况。 通过一个例子来解释一下。假设红黑树的定义中不包含刚刚提到的那一条“叶子节点必须是黑色的空节点”，我们往一棵红黑树中插入一个数据，新插入节点的父节点也是红色的，两个红色的节点相邻，这个时候，红黑树的定义就被破坏了。那我们应该如何调整呢？ 你会发现，这个时候，我们前面在讲插入时，三种情况下的平衡调整规则，没有一种是适用的。但是，如果我们把黑色的空节点都给它加上，变成下面这样，你会发现，它满足 CASE 2 了。 你可能会说，你可以调整一下平衡调整规则啊。比如把 CASE 2 改为“如果关注节点 a 的叔叔节点 b 是黑色或者不存在，a 是父节点的右子节点，就进行某某操作”。当然可以，但是这样的话规则就没有原来简洁了。 你可能还会说，这样给红黑树添加黑色的空的叶子节点，会不会比较浪费存储空间呢？答案是不会的。虽然我们在讲解或者画图的时候，每个黑色的、空的叶子节点都是独立画出来的。实际上，在具体实现的时候，我们只需要像下面这样，共用一个黑色的、空的叶子节点就行了。 七、内容小结第一点，把红黑树的平衡调整的过程比作魔方复原，不要过于深究这个算法的正确性。你只需要明白，只要按照固定的操作步骤，保持插入、删除的过程，不破坏平衡树的定义就行了。 第二点，找准关注节点，不要搞丢、搞错关注节点。因为每种操作规则，都是基于关注节点来做的，只有弄对了关注节点，才能对应到正确的操作规则中。在迭代的调整过程中，关注节点在不停地改变，所以，这个过程一定要注意，不要弄丢了关注节点。 第三点，插入操作的平衡调整比较简单，但是删除操作就比较复杂。针对删除操作，我们有两次调整，第一次是针对要删除的节点做初步调整，让调整后的红黑树继续满足第四条定义，“每个节点到可达叶子节点的路径都包含相同个数的黑色节点”。但是这个时候，第三条定义就不满足了，有可能会存在两个红色节点相邻的情况。第二次调整就是解决这个问题，让红黑树不存在相邻的红色节点。 八、红黑树的实现（C++） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297#include&lt;iostream&gt;using namespace std; enum COLOR { RED, BLACK }; template&lt;class K, class V&gt;struct RBTreeNode{ RBTreeNode&lt;K, V&gt;* _pLeft; RBTreeNode&lt;K, V&gt;* _pRight; RBTreeNode&lt;K, V&gt;* _pParent; K _key; V _value; COLOR _color; RBTreeNode(const K&amp; key = K(), const V&amp; value = V(), const COLOR&amp; color = RED) : _pLeft(NULL) , _pRight(NULL) , _pParent(NULL) , _key(key) , _value(value) , _color(color) {}}; template&lt;class K, class V&gt;class RBTree{ typedef RBTreeNode&lt;K, V&gt; Node;private: Node* _pRoot;public: RBTree() : _pRoot(NULL) {} // 插入 bool Insert(const K&amp; key, const V&amp;value); // 左旋 void _RotateL(Node* parent); // 右旋 void _RotateR(Node* parent); // 中序遍历 void InOrder(); // 中序遍历 void _InOrder(Node* pRoot); // 是否是红黑树 bool CheckRBTree(); // 是否是红黑树 bool _CheckRBTree(Node* pRoot,int counter,int k);}; //插入节点template&lt;class K, class V&gt;bool RBTree&lt;K, V&gt;::Insert(const K&amp; key, const V&amp; value){ //创建根节点 if (_pRoot == NULL) { _pRoot = new Node(key, value); _pRoot-&gt;_color = BLACK; return true; } //寻找插入位置 Node* pCur = _pRoot; Node* parent = NULL; while (pCur) { if (key &lt; pCur-&gt;_key) { parent = pCur; pCur = pCur-&gt;_pLeft; } else if (key &gt; pCur-&gt;_key) { parent = pCur; pCur = pCur-&gt;_pRight; } else return false; } //插入 pCur = new Node(key, value); if (key &lt; parent-&gt;_key) parent-&gt;_pLeft = pCur; else parent-&gt;_pRight = pCur; pCur-&gt;_pParent = parent; //注意 //看红黑树是否满足性质，分情况讨论 while (_pRoot != pCur &amp;&amp; pCur-&gt;_pParent-&gt;_color == RED) { Node* gf = parent-&gt;_pParent; //双亲的双亲肯定存在，不然不会进入这个循环 //双亲在左，叔叔（存在的话）在右 if (gf-&gt;_pLeft == parent) { Node* uncle = gf-&gt;_pRight; if (uncle&amp;&amp;uncle-&gt;_color == RED) //情况一 { parent-&gt;_color = BLACK; uncle-&gt;_color = BLACK; gf-&gt;_color = RED; //向上更新 pCur = gf; parent = pCur-&gt;_pParent; } else //情况二，三（将三转化为二，再一起处理） { if (parent-&gt;_pRight == pCur) { _RotateL(parent); std::swap(parent, pCur); } gf-&gt;_color = RED; parent-&gt;_color = BLACK; _RotateR(gf); } } else//双亲在右 { Node*uncle = gf-&gt;_pLeft; if (uncle &amp;&amp; uncle-&gt;_color == RED) //情况一 { parent-&gt;_color = BLACK; uncle-&gt;_color = BLACK; gf-&gt;_color = RED; //向上更新 pCur = gf; parent = pCur-&gt;_pParent; } else //情况二、三（将情况三转化为情况二，再一起处理） { if (parent-&gt;_pLeft == pCur) { _RotateR(parent); std::swap(parent, pCur); } gf-&gt;_color = RED; parent-&gt;_color = BLACK; _RotateL(gf); } } } _pRoot-&gt;_color = BLACK; return true;} //左旋template&lt;class K, class V&gt;void RBTree&lt;K, V&gt;::_RotateL(Node* parent){ Node* subR = parent-&gt;_pRight; Node* subRL = subR-&gt;_pLeft; //可能不存在 parent-&gt;_pRight = subRL; if (subRL) subRL-&gt;_pParent = parent; subR-&gt;_pLeft = parent; Node* gparent = parent-&gt;_pParent; parent-&gt;_pParent = subR; subR-&gt;_pParent = gparent; if (gparent == NULL) //parent是根节点 _pRoot = subR; else if (gparent-&gt;_pLeft == parent) gparent-&gt;_pLeft = subR; else gparent-&gt;_pRight = subR; } //右旋template&lt;class K, class V&gt;void RBTree&lt;K, V&gt;::_RotateR(Node* parent){ Node* subL = parent-&gt;_pLeft; Node* subLR = subL-&gt;_pRight; parent-&gt;_pLeft = subLR; if (subLR) subLR-&gt;_pParent = parent; subL-&gt;_pRight = parent; Node* gparent = parent-&gt;_pParent; parent-&gt;_pParent = subL; subL-&gt;_pParent = gparent; if (gparent == NULL) _pRoot = subL; else if (gparent-&gt;_pLeft == parent) gparent-&gt;_pLeft = subL; else gparent-&gt;_pRight = subL;} template&lt;class K, class V&gt;void RBTree&lt;K, V&gt;::InOrder(){ cout &lt;&lt; \"InOrder: \"; _InOrder(_pRoot); cout &lt;&lt; endl;} template&lt;class K, class V&gt;void RBTree&lt;K, V&gt;::_InOrder(Node* pRoot){ if (pRoot) { _InOrder(pRoot-&gt;_pLeft); cout &lt;&lt; pRoot-&gt;_key &lt;&lt; \" \"; _InOrder(pRoot-&gt;_pRight); }} template&lt;class K, class V&gt;bool RBTree&lt;K, V&gt;::CheckRBTree(){ if (_pRoot == NULL) return true; if (_pRoot-&gt;_color == RED) // 违反性质2“根结点为黑色” return false; int blackcount = 0; //统计一条链上黑色结点的个数 Node* pCur = _pRoot; while (pCur) { if (pCur-&gt;_color == BLACK) blackcount++; pCur = pCur-&gt;_pLeft; //这里以最左边的那一条链为例 } //验证性质4“每条链上的黑色结点都相等”，验证性质3“红色结点不能相连” return _CheckRBTree(_pRoot, blackcount, 0);} template&lt;class K, class V&gt;bool RBTree&lt;K, V&gt;::_CheckRBTree(Node* pRoot, int counter, int k){ if (pRoot == NULL) return true; if (pRoot-&gt;_color == BLACK) k++; Node* parent = pRoot-&gt;_pParent; if (parent &amp;&amp; parent-&gt;_color == RED &amp;&amp; pRoot-&gt;_color == RED) //违反性质3“红色结点不能相连” return false; if (pRoot == NULL) { if (k != counter) //违反性质4“每条链上的黑色结点都相等” return false; } return _CheckRBTree(pRoot-&gt;_pLeft, counter, k) &amp;&amp; _CheckRBTree(pRoot-&gt;_pRight, counter, k);} void TestRBTree(){ int a[] = { 10, 7, 8, 15, 5, 6, 11, 13, 12 }; //int a[] = { 16,3,7,9,11,26,18,14 }; //int a[] = { 3,7,5,8,4,2,9,0 }; RBTree&lt;int, int&gt; t; cout &lt;&lt; \"NotOrder: \"; for (int index = 0; index &lt; sizeof(a) / sizeof(a[0]); index++) { cout &lt;&lt; a[index] &lt;&lt; \" \"; t.Insert(a[index], index); } cout &lt;&lt; endl; t.InOrder(); if (t.CheckRBTree()) cout &lt;&lt; \"是红黑树！\" &lt;&lt; endl; else cout &lt;&lt; \"不是红黑树！\" &lt;&lt; endl;} int main(){ TestRBTree(); return 0;} 原文红黑树（上）：为什么工程中都用红黑树这种二叉树？红黑树（下）：掌握这些技巧，你也可以实现一个红黑树 参考文章:红黑树的实现与验证–C++","link":"/post/b1830f1a.html"},{"title":"进程和线程的区别(转载)","text":"进程与线程 零、前言我们写好的一行行代码，为了让其工作起来，我们还得把它送进城（进程）里，那既然进了城里，那肯定不能胡作非为了。 城里人有城里人的规矩，城中有个专门管辖你们的城管（操作系统），人家让你休息就休息，让你工作就工作，毕竟摊位（CPU）就一个，每个人都要占这个摊位来工作，城里要工作的人多着去了。 所以城管为了公平起见，它使用一种策略（调度）方式，给每个人一个固定的工作时间（时间片），时间到了就会通知你去休息而换另外一个人上场工作。 另外，在休息时候你也不能偷懒，要记住工作到哪了，不然下次到你工作了，你忘记工作到哪了，那还怎么继续？ 有的人，可能还进入了县城（线程）工作，这里相对轻松一些，在休息的时候，要记住的东西相对较少，而且还能共享城里的资源。 一、进程我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」。 现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。 做个类比，你去煮开水时，你会傻傻的等水壶烧开吗？很明显，小孩也不会傻等。我们可以在水壶烧开之前去做其他事情。当水壶烧开了，我们自然就会听到“嘀嘀嘀”的声音，于是再把烧开的水倒入到水杯里就好了。 所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。 这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。 对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。 虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。 并发和并行有什么区别？ 进程与程序的关系的类比 到了晚饭时间，一对小情侣肚子都咕咕叫了，于是男生见机行事，就想给女生做晚饭，所以他就在网上找了辣子鸡的菜谱，接着买了一些鸡肉、辣椒、香料等材料，然后边看边学边做这道菜。 突然，女生说她想喝可乐，那么男生只好把做菜的事情暂停一下，并在手机菜谱标记做到哪一个步骤，把状态信息记录了下来。 然后男生听从女生的指令，跑去下楼买了一瓶冰可乐后，又回到厨房继续做菜。 这体现了，CPU 可以从一个进程（做菜）切换到另外一个进程（买可乐），在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。 所以，可以发现进程有着「运行 - 暂停 - 运行」的活动规律。 1.1、进程的状态一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。 它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。 所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。 上图中各个状态的意义： 运行状态（Runing）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，但因为其他进程正在运行而暂停停止； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 当然，进程另外两个基本状态： 创建状态（New）：进程正在被创建时的状态； 结束状态（Exit）：进程正在从系统中消失时的状态； 于是，一个完整的进程状态的变迁如下图： 再来详细说明一下进程的状态变迁： NULL -&gt; 创建状态：一个新进程被创建时的第一个状态； 创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； 就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； 运行状态 -&gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理； 运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； 运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件； 阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态； 另外，还有一个状态叫挂起状态，它表示进程没有占有物理内存空间。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。 由于虚拟内存管理原因，进程的所使用的空间可能并没有映射到物理内存，而是在硬盘上，这时进程就会出现挂起状态，另外调用 sleep 也会被挂起。 挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 这两种挂起状态加上前面的五种状态，就变成了七种状态变迁，见如下图： 1.2、进程的控制结构在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。 PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。 PCB 具体包含什么信息呢？ 进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。 每个 PCB 是如何组织的呢？ 通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如： 将所有处于就绪状态的进程链在一起，称为就绪队列； 把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列； 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。 那么，就绪队列和阻塞队列链表的组织形式如下图： 除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。 一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。 1.3、进程的控制1、创建进程 操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时，同时也会终止其所有的子进程。 创建进程的过程如下： 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败； 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源； 初始化 PCB； 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行； 2、终止进程 进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。 终止进程的过程如下： 查找需要终止的进程的 PCB； 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程； 如果其还有子进程，则应将其所有子进程终止； 将该进程所拥有的全部资源都归还给父进程或操作系统； 将其从 PCB 所在队列中删除； 3、阻塞进程 当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。 阻塞进程的过程如下： 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行； 将该 PCB 插入的阻塞队列中去； 4、唤醒进程 进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。 如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。 唤醒进程的过程如下： 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插入到就绪队列中，等待调度程序调度； 进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。 1.4、进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候，进程之间需要切换，让不同的进程可以在 CPU 执行，这个一个进程切换到另一个进程运行，称为进程的上下文切换。 CPU 上下文切换 大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。 任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。 所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。 CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。 再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。 所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。 CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。 进程的上下文切换到底是切换什么呢？ 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示： 进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。 发生进程上下文切换有哪些场景？ 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行； 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行； 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度； 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行； 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序； 二、线程2.1、为什么使用线程？假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个： 从视频文件当中读取数据； 对读取的数据进行解压缩； 把解压缩后的视频数据播放出来； 对于单进程的实现方式，我想大家都会是以下这个方式： 对于单进程的这种方式，存在以下问题： 播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放； 各个函数之间不是并发执行，影响资源的使用效率； 那改进成多进程的方式： 对于多进程的这种方式，依然会存在问题： 进程之间如何通信，共享数据？ 维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息； 那到底如何解决呢？需要有一种新的实体，满足以下特性： 实体之间可以并发运行； 实体之间共享相同的地址空间； 这个新的实体，就是线程 (Thread)，线程之间可以并发运行且共享相同的地址空间。 2.2、什么是线程？线程是进程当中的一条执行流程。 同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程都有独立一套的寄存器和栈，这样可以确保线程的控制流是相对独立的。 线程的优缺点？ 线程的优点： 一个进程中可以同时存在多个线程； 各个线程之间可以并发执行； 各个线程之间可以共享地址空间和文件等资源； 线程的缺点： 当进程中的一个线程奔溃时，会导致其所属进程的所有线程奔溃。 举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程。 2.3、线程与进程的比较线程与进程的比较如下： 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销； 对于，线程相比进程能减少开销，体现在： 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了； 所以，线程比进程不管是时间效率，还是空间效率都要高。 2.4、线程的上下文切换在前面我们知道了，线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。 所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。 对于线程和进程，我们可以这么理解： 当进程只有一个线程时，可以认为进程就等于线程； 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的； 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 线程上下文切换的是什么？ 这还得看线程是不是属于同一个进程： 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 所以，线程的上下文切换相比进程，开销要小很多。 2.5、线程的实现主要有三种线程的实现方式： 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（LightWeight Process）：在内核中来支持用户线程； 还需要考虑一个问题，用户线程和内核线程的对应关系。 首先，第一种关系是多对一的关系，也就是多个用户线程对应同一个内核线程： 第二种是一对一的关系，也就是一个用户线程对应一个内核线程： 第三种是多对多的关系，也就是多个用户线程对应到多个内核线程： 用户线程如何理解？存在什么优势和缺陷？ 用户线程是基于用户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB）也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。 所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。 用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程，如下图所示： 用户线程的优点： 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快； 用户线程的缺点： 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢； 那内核线程如何理解？存在什么优势和缺陷？ 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。 内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程，如下图所示： 内核线程的优点： 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 多线程的进程获得更多的 CPU 运行时间； 内核线程的缺点： 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大； 最后的轻量级进程如何理解？ 轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。 另外，LWP 只能由内核管理并像普通进程一样被调度，Linux 内核是支持 LWP 的典型例子。 在大多数系统中，LWP 与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。 在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种： 1 : 1，即一个 LWP 对应 一个用户线程； N : 1，即一个 LWP 对应多个用户线程； N : N，即多个 LWP 对应多个用户线程； 1 : 1 模式 一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP； 缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。 N : 1 模式 多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。 优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高； 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。 M : N 模式 根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。 优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。 组合模式 如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。 三、调度进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。 一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。 选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（scheduler）。 那到底什么时候调度进程，或以什么原则来调度进程呢？ 3.1、调度时机在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。 比如，以下状态的变化都会触发操作系统的调度： 从就绪态 -&gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行； 从运行态 -&gt; 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行； 从运行态 -&gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行； 因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。 另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类： 非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。 抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。 3.2、调度原则原则一：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。 原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。 原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。 原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。 原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。 针对上面的五种调度原则，总结成如下： CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。 这么多调度原则，目的就是要使得进程要「快」。 3.3、调度算法 01 先来先服务调度算法 最简单的一个调度算法，就是非抢占式的先来先服务（First Come First Severd, FCFS）算法了。 顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。 这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。 02 最短作业优先调度算法 最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。 这显然对长作业不利，很容易造成一种极端现象。 比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。 03 高响应比优先调度算法 前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。 那么，高响应比优先（Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。 每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式： 从上面的公式，可以发现： 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会； 04 时间片轮转调度算法 最古老、最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换； 另外，时间片的长度就是一个很关键的点： 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。 通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。 05 最高优先级调度算法 前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。 但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。 进程的优先级可以分为，静态优先级或动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 但是依然有缺点，可能会导致低优先级的进程永远不会运行。 多级反馈队列调度算法 多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。 顾名思义： 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列 来看看，它是如何工作的： 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下一级队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 银行办业务的例子 办理业务的客户相当于进程，银行窗口工作人员相当于 CPU。 现在，假设这个银行只有一个窗口（单核 CPU），那么工作人员一次只能处理一个业务。 那么最简单的处理方式，就是先来的先处理，后面来的就乖乖排队，这就是先来先服务（FCFS）调度算法。但是万一先来的这位老哥是来贷款的，这一谈就好几个小时，一直占用着窗口，这样后面的人只能干等，或许后面的人只是想简单的取个钱，几分钟就能搞定，却因为前面老哥办长业务而要等几个小时，你说气不气人？ 有客户抱怨了，那我们就要改进，我们干脆优先给那些几分钟就能搞定的人办理业务，这就是短作业优先（SJF）调度算法。听起来不错，但是依然还是有个极端情况，万一办理短业务的人非常的多，这会导致长业务的人一直得不到服务，万一这个长业务是个大客户，那不就捡了芝麻丢了西瓜。 那就公平起见，现在窗口工作人员规定，每个人我只处理 10 分钟。如果 10 分钟之内处理完，就马上换下一个人。如果没处理完，依然换下一个人，但是客户自己得记住办理到哪个步骤了。这个也就是时间片轮转（RR）调度算法。但是如果时间片设置过短，那么就会造成大量的上下文切换，增大了系统开销。如果时间片过长，相当于退化成退化成 FCFS 算法了。 既然公平也可能存在问题，那银行就对客户分等级，分为普通客户、VIP 客户、SVIP 客户。只要高优先级的客户一来，就第一时间处理这个客户，这就是最高优先级（HPF）调度算法。但依然也会有极端的问题，万一当天来的全是高级客户，那普通客户就没有被服务的机会。那我们把优先级改成动态的，如果客户办理业务时间增加，则降低其优先级，如果客户等待时间增加，则升高其优先级。 那有没有兼顾到公平和效率的方式呢？这里介绍一种算法，考虑的还算充分的，多级反馈队列（MFQ）调度算法，它是时间片轮转算法和优先级算法的综合和发展。它的工作方式： 银行设置了多个排队（就绪）队列，每个队列都有不同的优先级，各个队列优先级从高到低，同时每个队列执行时间片的长度也不同，优先级越高的时间片越短。 新客户（进程）来了，先进入第一级队列的末尾，按先来先服务原则排队等待被叫号（运行）。如果时间片用完客户的业务还没办理完成，则让客户进入到下一级队列的末尾，以此类推，直至客户业务办理完成。 当第一级队列没人排队时，就会叫号二级队列的客户。如果客户办理业务过程中，有新的客户加入到较高优先级的队列，那么此时办理中的客户需要停止办理，回到原队列的末尾等待再次叫号，因为要把窗口让给刚进入较高优先级队列的客户。 可以发现，对于要办理短业务的客户来说，可以很快的轮到并解决。对于要办理长业务的客户，一下子解决不了，就可以放到下一个队列，虽然等待的时间稍微变长了，但是轮到自己的办理时间也变长了，也可以接受，不会造成极端的现象，可以说是综合上面几种算法的优点。 原文链接:进程和线程基础知识全家桶，30 张图一套带走","link":"/post/7202bd7a.html"},{"title":"select、poll和epoll的原理和区别浅析","text":"select、poll 和 epoll 都是操作系统中 IO 多路复用实现的方法。 零、IO 多路复用设计这样一个应用程序，该程序从标准输入接收数据输入，然后通过套接字发送出去，同时，该程序也通过套接字接收对方发送的数据流。 我们可以使用 fgets 方法等待标准输入，但是一旦这样做，就没有办法在套接字有数据的时候读出数据；我们也可以使用 read 方法等待套接字有数据返回，但是这样做，也没有办法在标准输入有数据的情况下，读入数据并发送给对方。 I/O 多路复用的设计初衷就是解决这样的场景。我们可以把标准输入、套接字等都看做 I/O 的一路，多路复用的意思，就是在任何一路 I/O 有“事件”发生的情况下，通知应用程序去处理相应的 I/O 事件，这样我们的程序就变成了“多面手”，在同一时刻仿佛可以处理多个 I/O 事件。 一、selectselect 函数就是这样一种常见的 I/O 多路复用技术。使用 select 函数，通知内核挂起进程，当一个或多个 I/O 事件发生后，控制权返还给应用程序，由应用程序进行 I/O 事件的处理。 这些 I/O 事件的类型非常多，比如： 标准输入文件描述符准备好可以读。 监听套接字准备好，新的连接已经建立成功。 已连接套接字准备好可以写。 如果一个 I/O 事件等待超过了 10 秒，发生了超时事件。 1.1、select 原理使用 select 可以实现同时处理多个网络连接的 IO 请求，基本原理就是程序调用 select，然后整个程序就进入阻塞状态，这个时候，kernel 内核就会轮询检查所有 select 负责的文件描述符 fd，当找到其中哪个文件描述符数据准备好了，会返回给 select，select 通知系统调用，将数据从内核复制到进程的缓存区。 1.2、select 函数的使用方法123int select(int maxfd, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);返回：若有就绪描述符则为其数目，若超时则为0，若出错则为-1 在这个函数中，maxfd 表示的是待测试的描述符基数，它的值是待测试的最大描述符加 1。比如现在的 select 待测试的描述符集合是{0,1,4}，那么 maxfd 就是 5。 紧接着的是三个描述符集合，分别是读描述符集合 readset、写描述符集合 writeset 和异常描述符集合 exceptset，这三个分别通知内核，在哪些描述符上检测数据可以读，可以写和有异常发生。 以下的宏设置这些描述符集合： 1234void FD_ZERO(fd_set *fdset); void FD_SET(int fd, fd_set *fdset); void FD_CLR(int fd, fd_set *fdset); int FD_ISSET(int fd, fd_set *fdset); 可以这样想象，下面一个向量代表了一个描述符集合，其中，这个向量的每个元素都是二进制数中的 0 或者 1。 1a[maxfd-1], ..., a[1], a[0] 我们按照这样的思路来理解这些宏： FD_ZERO 用来将这个向量的所有元素都设置成 0； FD_SET 用来把对应套接字 fd 的元素 a[fd] 设置成 1； FD_CLR 用来把对应套接字 fd 的元素 a[fd] 设置成 0； FD_ISSET 对这个向量进行检测，判断出对应套接字的元素 a[fd] 是 0 还是 1。 其中 0 代表不需要处理，1 代表需要处理。 这个时候再来理解为什么描述字集合{0,1,4}，对应的 maxfd 是 5，而不是 4，就比较方便了。 因为这个向量对应的是下面这样的： 1a[4],a[3],a[2],a[1],a[0] 待测试的描述符个数显然是 5， 而不是 4。 三个描述符集合中的每一个都可以设置成空，这样就表示不需要内核进行相关的检测。 最后一个参数是 timeval 结构体时间： 1234struct timeval { long tv_sec; /* seconds */ long tv_usec; /* microseconds */}; 这个参数设置成不同的值，会有不同的可能： 第一个可能是设置成空 (NULL)，表示如果没有 I/O 事件发生，则 select 一直等待下去。 第二个可能是设置一个非零的值，这个表示等待固定的一段时间后从 select 阻塞调用中返回。 第三个可能是将 tv_sec 和 tv_usec 都设置成 0，表示根本不等待，检测完毕立即返回，这种情况使用得比较少。 1.3、程序例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152int main(int argc, char **argv) { if (argc != 2) { error(1, 0, \"usage: select01 &lt;IPaddress&gt;\"); } int socket_fd = tcp_client(argv[1], SERV_PORT); char recv_line[MAXLINE], send_line[MAXLINE]; int n; fd_set readmask; fd_set allreads; FD_ZERO(&amp;allreads); FD_SET(0, &amp;allreads); FD_SET(socket_fd, &amp;allreads); for (;;) { readmask = allreads; int rc = select(socket_fd + 1, &amp;readmask, NULL, NULL, NULL); if (rc &lt;= 0) { error(1, errno, \"select failed\"); } if (FD_ISSET(socket_fd, &amp;readmask)) { n = read(socket_fd, recv_line, MAXLINE); if (n &lt; 0) { error(1, errno, \"read error\"); } else if (n == 0) { error(1, 0, \"server terminated \\n\"); } recv_line[n] = 0; fputs(recv_line, stdout); fputs(\"\\n\", stdout); } if (FD_ISSET(STDIN_FILENO, &amp;readmask)) { if (fgets(send_line, MAXLINE, stdin) != NULL) { int i = strlen(send_line); if (send_line[i - 1] == '\\n') { send_line[i - 1] = 0; } printf(\"now sending %s\\n\", send_line); size_t rt = write(socket_fd, send_line, strlen(send_line)); if (rt &lt; 0) { error(1, errno, \"write failed \"); } printf(\"send bytes: %zu \\n\", rt); } } }} 程序的 12 行通过 FD_ZERO 初始化了一个描述符集合，这个描述符读集合是空的： 接下来程序的第 13 和 14 行，分别使用 FD_SET 将描述符 0 (即标准输入)，以及连接套接字描述符 3 设置为待检测： 接下来的 16-51 行是循环检测，这里我们没有阻塞在 fgets 或 read 调用，而是通过 select 来检测套接字描述字有数据可读，或者标准输入有数据可读。比如，当用户通过标准输入使得标准输入描述符可读时，返回的 readmask 的值为： 这个时候 select 调用返回，可以使用 FD_ISSET 来判断哪个描述符准备好可读了。如上图所示，这个时候是标准输入可读，37-51 行程序读入后发送给对端。 如果是连接描述字准备好可读了，第 24 行判断为真，使用 read 将套接字数据读出。 我们需要注意的是，这个程序的 17-18 行非常重要，初学者很容易在这里掉坑里去。 第 17 行是每次测试完之后，重新设置待测试的描述符集合。你可以看到上面的例子，在 select 测试之前的数据是{0,3}，select 测试之后就变成了{0}。 这是因为 select 调用每次完成测试之后，内核都会修改描述符集合，通过修改完的描述符集合来和应用程序交互，应用程序使用 FD_ISSET 来对每个描述符进行判断，从而知道什么样的事件发生。 第 18 行则是使用 socket_fd+1 来表示待测试的描述符基数。切记需要 +1。 1.4、套接字描述符就绪条件当我们说 select 测试返回，某个套接字准备好可读，表示什么样的事件发生呢？ 第一种情况是套接字接收缓冲区有数据可以读，如果我们使用 read 函数去执行读操作，肯定不会被阻塞，而是会直接读到这部分数据。 第二种情况是对方发送了 FIN，使用 read 函数执行读操作，不会被阻塞，直接返回 0。 第三种情况是针对一个监听套接字而言的，有已经完成的连接建立，此时使用 accept 函数去执行不会阻塞，直接返回已经完成的连接。 第四种情况是套接字有错误待处理，使用 read 函数去执行读操作，不阻塞，且返回 -1。 总结成一句话就是，内核通知我们套接字有数据可以读了，使用 read 函数不会阻塞。 刚开始理解某个套接字可写的时候，会有一个错觉，总是从应用程序角度出发去理解套接字可写，开始是这样想的，当应用程序完成相应的计算，有数据准备发送给对端了，可以往套接字写，对应的就是套接字可写。 其实这个理解是非常不正确的，select 检测套接字可写，完全是基于套接字本身的特性来说的，具体来说有以下几种情况。 第一种是套接字发送缓冲区足够大，如果我们使用套接字进行 write 操作，将不会被阻塞，直接返回。 第二种是连接的写半边已经关闭，如果继续进行写操作将会产生 SIGPIPE 信号。 第三种是套接字上有错误待处理，使用 write 函数去执行写操作，不阻塞，且返回 -1。 总结成一句话就是，内核通知我们套接字可以往里写了，使用 write 函数就不会阻塞。 1.5、总结select 函数提供了最基本的 I/O 多路复用方法，在使用 select 时，我们需要建立两个重要的认识： 描述符基数是当前最大描述符 +1； 每次 select 调用完成之后，记得要重置待测试集合。 1.6、思考题1、第一道，select 可以对诸如 UNIX 管道 (pipe) 这样的描述字进行检测么？如果可以，检测的就绪条件是什么呢？ 可以，就绪条件是有数据可读(检测可读事件)。是否可以监测可写事件需要实验。 2、第二道，根据我们前面的描述，一个描述符集合哪些描述符被设置为 1，需要进行检测是完全可以知道的，你认为 select 函数里一定需要传入描述字基数这个值么？请你分析一下这样设计的目的又是什么呢？ 不一定需要传入，那样的话内核中 for 循环需要遍历整个集合，效率低。传入基数可以减小遍历范围，提高效率。 二、pollpoll 是除了 select 之外，另一种普遍使用的 I/O 多路复用技术，和 select 相比，它和内核交互的数据结构有所变化，另外，也突破了文件描述符的个数限制。 123int poll(struct pollfd *fds, unsigned long nfds, int timeout); 返回值：若有就绪描述符则为其数目，若超时则为0，若出错则为-1 这个函数里面输入了三个参数，第一个参数是一个 pollfd 的数组。其中 pollfd 的结构如下： 12345struct pollfd { int fd; /* file descriptor */ short events; /* events to look for */ short revents; /* events returned */ }; 这个结构体由三个部分组成，首先是描述符 fd，然后是描述符上待检测的事件类型 events，注意这里的 events 可以表示多个不同的事件，具体的实现可以通过使用二进制掩码位操作来完成，例如，POLLIN 和 POLLOUT 可以表示读和写事件。 123#define POLLIN 0x0001 /* any readable data available */#define POLLPRI 0x0002 /* OOB/Urgent readable data */#define POLLOUT 0x0004 /* file descriptor is writeable */ 和 select 非常不同的地方在于，poll 每次检测之后的结果不会修改原来的传入值，而是将结果保留在 revents 字段中，这样就不需要每次检测完都得重置待检测的描述字和感兴趣的事件。我们可以把 revents 理解成“returned events”。 events 类型的事件可以分为两大类。 第一类是可读事件，有以下几种： 1234#define POLLIN 0x0001 /* any readable data available */#define POLLPRI 0x0002 /* OOB/Urgent readable data */#define POLLRDNORM 0x0040 /* non-OOB/URG data available */#define POLLRDBAND 0x0080 /* OOB/Urgent readable data */ 一般我们在程序里面有 POLLIN 即可。套接字可读事件和 select 的 readset 基本一致，是系统内核通知应用程序有数据可以读，通过 read 函数执行操作不会被阻塞。 第二类是可写事件，有以下几种： 123#define POLLOUT 0x0004 /* file descriptor is writeable */#define POLLWRNORM POLLOUT /* no write type differentiation */#define POLLWRBAND 0x0100 /* OOB/Urgent data can be written */ 一般我们在程序里面统一使用 POLLOUT。套接字可写事件和 select 的 writeset 基本一致，是系统内核通知套接字缓冲区已准备好，通过 write 函数执行写操作不会被阻塞。 以上两大类的事件都可以在“returned events”得到复用。还有另一大类事件，没有办法通过 poll 向系统内核递交检测请求，只能通过“returned events”来加以检测，这类事件是各种错误事件。 123#define POLLERR 0x0008 /* 一些错误发送 */#define POLLHUP 0x0010 /* 描述符挂起 */#define POLLNVAL 0x0020 /* 请求的事件无效 */ 参数 nfds 描述的是数组 fds 的大小，简单说，就是向 poll 申请的事件检测的个数。 最后一个参数 timeout，描述了 poll 的行为。 如果是一个 &lt;0 的数，表示在有事件发生之前永远等待；如果是 0，表示不阻塞进程，立即返回；如果是一个 &gt;0 的数，表示 poll 调用方等待指定的毫秒数后返回。 关于返回值，当有错误发生时，poll 函数的返回值为 -1；如果在指定的时间到达之前没有任何事件发生，则返回 0，否则就返回检测到的事件个数，也就是“returned events”中非 0 的描述符个数。 poll 函数有一点非常好，如果我们不想对某个 pollfd 结构进行事件检测，可以把它对应的 pollfd 结构的 fd 成员设置成一个负值。这样，poll 函数将忽略这样的 events 事件，检测完成以后，所对应的“returned events”的成员值也将设置为 0。 和 select 函数对比一下，我们发现 poll 函数和 select 不一样的地方就是，在 select 里面，文件描述符的个数已经随着 fd_set 的实现而固定，没有办法对此进行配置；而在 poll 函数里，我们可以控制 pollfd 结构的数组大小，这意味着我们可以突破原来 select 函数最大描述符的限制，在这种情况下，应用程序调用者需要分配 pollfd 数组并通知 poll 函数该数组的大小。 2.1、基于 poll 的服务器程序这个程序可以同时处理多个客户端连接，并且一旦有客户端数据接收后，同步地回显回去。这已经是一个颇具高并发处理的服务器原型了，再加上后面讲到的非阻塞 I/O 和多线程等技术，基本上就是可使用的准生产级别了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#define INIT_SIZE 128int main(int argc, char **argv) { int listen_fd, connected_fd; int ready_number; ssize_t n; char buf[MAXLINE]; struct sockaddr_in client_addr; listen_fd = tcp_server_listen(SERV_PORT); //初始化pollfd数组，这个数组的第一个元素是listen_fd，其余的用来记录将要连接的connect_fd struct pollfd event_set[INIT_SIZE]; event_set[0].fd = listen_fd; event_set[0].events = POLLRDNORM; // 用-1表示这个数组位置还没有被占用 int i; for (i = 1; i &lt; INIT_SIZE; i++) { event_set[i].fd = -1; } for (;;) { if ((ready_number = poll(event_set, INIT_SIZE, -1)) &lt; 0) { error(1, errno, \"poll failed \"); } if (event_set[0].revents &amp; POLLRDNORM) { socklen_t client_len = sizeof(client_addr); connected_fd = accept(listen_fd, (struct sockaddr *) &amp;client_addr, &amp;client_len); //找到一个可以记录该连接套接字的位置 for (i = 1; i &lt; INIT_SIZE; i++) { if (event_set[i].fd &lt; 0) { event_set[i].fd = connected_fd; event_set[i].events = POLLRDNORM; break; } } if (i == INIT_SIZE) { error(1, errno, \"can not hold so many clients\"); } if (--ready_number &lt;= 0) continue; } for (i = 1; i &lt; INIT_SIZE; i++) { int socket_fd; if ((socket_fd = event_set[i].fd) &lt; 0) continue; if (event_set[i].revents &amp; (POLLRDNORM | POLLERR)) { if ((n = read(socket_fd, buf, MAXLINE)) &gt; 0) { if (write(socket_fd, buf, n) &lt; 0) { error(1, errno, \"write error\"); } } else if (n == 0 || errno == ECONNRESET) { close(socket_fd); event_set[i].fd = -1; } else { error(1, errno, \"read error\"); } if (--ready_number &lt;= 0) break; } } }} 一开始需要创建一个监听套接字，并绑定在本地的地址和端口上，这在第 10 行调用 tcp_server_listen 函数来完成。 在第 13 行，我初始化了一个 pollfd 数组，并命名为 event_set，之所以叫这个名字，是引用 pollfd 数组确实代表了检测的事件集合。这里数组的大小固定为 INIT_SIZE，这在实际的生产环境肯定是需要改进的。 监听套接字上如果有连接建立完成，也是可以通过 I/O 事件复用来检测到的。在第 14-15 行，将监听套接字 listen_fd 和对应的 POLLRDNORM 事件加入到 event_set 里，表示我们期望系统内核检测监听套接字上的连接建立完成事件。 如果对应 pollfd 里的文件描述字 fd 为负数，poll 函数将会忽略这个 pollfd，所以我们在第 18-21 行将 event_set 数组里其他没有用到的 fd 统统设置为 -1。这里 -1 也表示了当前 pollfd 没有被使用的意思。 下面我们的程序进入一个无限循环，在这个循环体内，第 24 行调用 poll 函数来进行事件检测。poll 函数传入的参数为 event_set 数组，数组大小 INIT_SIZE 和 -1。这里之所以传入 INIT_SIZE，是因为 poll 函数已经能保证可以自动忽略 fd 为 -1 的 pollfd，否则我们每次都需要计算一下 event_size 里真正需要被检测的元素大小；timeout 设置为 -1，表示在 I/O 事件发生之前 poll 调用一直阻塞。 如果系统内核检测到监听套接字上的连接建立事件，就进入到第 28 行的判断分支。我们看到，使用了如 event_set[0].revent 来和对应的事件类型进行位与操作，这个技巧大家一定要记住，这是因为 event 都是通过二进制位来进行记录的，位与操作是和对应的二进制位进行操作，一个文件描述字是可以对应到多个事件类型的。 在这个分支里，调用 accept 函数获取了连接描述字。接下来，33-38 行做了一件事，就是把连接描述字 connect_fd 也加入到 event_set 里，而且说明了我们感兴趣的事件类型为 POLLRDNORM，也就是套接字上有数据可以读。在这里，我们从数组里查找一个没有没占用的位置，也就是 fd 为 -1 的位置，然后把 fd 设置为新的连接套接字 connect_fd。 如果在数组里找不到这样一个位置，说明我们的 event_set 已经被很多连接充满了，没有办法接收更多的连接了，这就是第 41-42 行所做的事情。 第 45-46 行是一个加速优化能力，因为 poll 返回的一个整数，说明了这次 I/O 事件描述符的个数，如果处理完监听套接字之后，就已经完成了这次 I/O 复用所要处理的事情，那么我们就可以跳过后面的处理，再次进入 poll 调用。 接下来的循环处理是查看 event_set 里面其他的事件，也就是已连接套接字的可读事件。这是通过遍历 event_set 数组来完成的。 如果数组里的 pollfd 的 fd 为 -1，说明这个 pollfd 没有递交有效的检测，直接跳过；来到第 53 行，通过检测 revents 的事件类型是 POLLRDNORM 或者 POLLERR，我们可以进行读操作。在第 54 行，读取数据正常之后，再通过 write 操作回显给客户端；在第 58 行，如果读到 EOF 或者是连接重置，则关闭这个连接，并且把 event_set 对应的 pollfd 重置；第 61 行读取数据失败。 和前面的优化加速处理一样，第 65-66 行是判断如果事件已经被完全处理完之后，直接跳过对 event_set 的循环处理，再次来到 poll 调用。 2.2、总结poll 是另一种在各种 UNIX 系统上被广泛支持的 I/O 多路复用技术，虽然名声没有 select 那么响，能力一点不比 select 差，而且因为可以突破 select 文件描述符的个数限制，在高并发的场景下尤其占优势。这一讲我们编写了一个基于 poll 的服务器程序，希望你从中学会 poll 的用法。 2.3、思考题第一道，在我们的程序里 event_set 数组的大小固定为 INIT_SIZE，这在实际的生产环境肯定是需要改进的。你知道如何改进吗？ 1、采用动态分配数组的方式2、可以把所有的描述符 push_back 到一个 vector 等类似的容器当中，直接对容器取 size 就可以获得数量 第二道，如果我们进行了改进，那么接下来把连接描述字 connect_fd 也加入到 event_set 里，如何配合进行改造呢？ 把新连接上来的 connfd 添加进去，对上面问题的容器进行一次取 size 操作就行了 三、epoll具体可以参考epoll实现原理分析这篇文章。 四、总结I/O 多路复用和阻塞 I/O 其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个 system call (select 和 recvfrom)，而blocking IO 只调用了一个 system call (recvfrom)。但是，用 select 的优势在于它可以同时处理多个 connection。 所以，如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用 multi-threading + blocking IO 的 web server 性能更好，可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 4.1、select 缺点进程可以打开的 fd 数量有限制，32 位机 1024 个，64 位 2048 个，原因是存储 fd 的是一个固定大小的数组。 select 方法本质其实就是维护了一个文件描述符（fd）数组，以此为基础，实现 IO 多路复用的功能。这个 fd 数组有长度限制，在 32 位系统中，最大值为 1024 个，而在 64 位系统中，最大值为 2048 个。 select 方法被调用，首先需要将 fd_set 从用户空间拷贝到内核空间，然后内核用 poll 机制（此 poll 机制非 IO 多路复用的那个 poll 方法）直到有一个 fd 活跃，或者超时了，方法返回。 对 socket 进行扫描是线性扫描，即采用轮询的方法，效率较低。 用户空间和内核空间之间复制数据非常的消耗资源。 select 方法返回后，需要轮询 fd_set，以检查出发生 IO 事件的 fd。这样一套下来，select 方法的缺点就很明显了： fd_set 在用户空间和内核空间的频繁复制，效率低 单个进程可监控的 fd 数量有限制，无论是 1024 还是 2048，对于很多情景来说都是不够用的 基于轮询来实现，效率低 4.2、pollpoll 的基本原理和 select 非常的类似，但是采用的是链表来存储 fd，且 poll 相比 select 不会修改描述符。poll 相对于 select 提供了更多的事件类型，并且对描述符的重复利用比 select 高。 select 和 poll 的返回结果没有声明哪些描述符已经准备好了，如果返回值大于0，应用进程就需要使用轮询的方式找到 IO 完成的描述符。这也是影响效率的一大因素。 4.3 epollepoll 主要解决了这些问题： 对 fd 的数量没有限制，所以最大数量与能打开的 fd 数量有关 epoll 不再需要每次调用都从用户空间将 fd_set 复制到内核 select 和 poll 都是主动去轮询，需要遍历每个 fd。而 epoll 采用的是被动触发的方式，给 fd 注册了相应的事件的时候，为每个 fd 指定了一个回调函数，当数据准备好后，就会把就绪的 fd 加入到就绪队列中，epoll_wait 的工作方式实际上就是在这个就绪队列中查看有没有就绪的 fd，如果有，就唤醒就绪队列上的等待者，然后调用回调函数。 就是 select 和 poll 只能通知有 fd 已经就绪了，但不能知道究竟是哪个 fd 就绪，所以 select 和 poll 就要去主动轮询一遍找到就绪的 fd。而 epoll 则是不但可以知道有 fd 可以就绪，而且还具体可以知道就绪 fd 的编号，所以直接找到就可以，不用轮询。这也是主动式和被动式的区别。 epoll 有两种触发方式：LT（水平触发）、ET（边缘触发） LT 模式：当 epoll_wait() 检查到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 ET 模式：和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。ET 模式很大程度上减少了 epoll 事件被重复触发的次数，因此效率比 LT 模式要高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 ET 模式下每次 write 或 read 需要循环 write 或 read 直到返回 EAGAIN 错误。以读操作为例，这是因为 ET 模式只在 socket 描述符状态发生变化时才触发事件，如果不一次把 socket 内核缓冲区的数据读完，会导致 socket 内核缓冲区中即使还有一部分数据，该 socket 的可读事件也不会被触发。根据上面的讨论，若 ET 模式下使用阻塞 IO，则程序一定会阻塞在最后一次 write 或 read 操作，因此说 ET 模式下一定要使用非阻塞 IO。 ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll 工作在 ET 模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 4.4 应用场景1、select 应用场景 select 的 timeout 参数精度为 1nm，比 poll 和 epoll 的 1ms 精度更高，因此 select 适合实时性要求比较高的场景。select 的可移植性非常的好。 2、poll 应用场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 3、epoll 应用场景 只能运行在 linux 平台下，有大量的描述符需要同时轮询，并且这些连接最好是长连接。在监听少量的描述符的场合，体现不出 epoll 的优势。在需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成了每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁的系统调用降低了效率。并且因为 epoll 的描述符存储在内核中，不容易调试。 原文链接:1、大名⿍⿍的select：看我如何同时感知多个I/O事件2、poll：另一种I/O多路复用3、浅谈select，poll和epoll的区别","link":"/post/2fc34bd1.html"},{"title":"数据结构与算法-LRU","text":"LRU 算法 零、基于双向链表 + HashMap 的 LRU 算法LRU 缓存算法也叫 LRU 页面置换算法，是一种经典常用的页面置换算法。 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 一、基于双向链表 + HashMap 的 LRU 算法实现（Java）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class LRU&lt;K, V&gt; implements Iterable&lt;K&gt; { private Node head; private Node tail; private HashMap&lt;K, Node&gt; map; private int maxSize; private class Node { Node pre; Node next; K k; V v; public Node(K k, V v) { this.k = k; this.v = v; } } public LRU(int maxSize) { this.maxSize = maxSize; this.map = new HashMap&lt;&gt;(maxSize * 4 / 3); head = new Node(null, null); tail = new Node(null, null); head.next = tail; tail.pre = head; } public V get(K key) { if(!map.containKey(key)) { return null; } Node node = map.get(key); unlink(node); appendHead(node); return node.v; } public void put(K key, V value) { if(map.containsKey(key)) { Node node = map.get(key); unlink(node); } Node node = new Node(key, value); map.put(key, value); appendHead(node); if(map.size() &gt; maxSize) { Node toRemove = removeTail(); map.remove(toRemove.k) } } private void unlink(Node node) { Node pre = node.pre; Node next = node.next; pre.next = next; next.pre = pre; node.pre = null; node.next = null; } private void appendHead(Node node) { Node next = head.next; node.next = next; next.pre = node; node.pre = head; head.next = node; } private Node removeTail() { Node node = tail.pre; Node pre = node.pre; tail.pre = pre; pre.next = tail; node.pre = null; node.next = null; return node; } @Override public Iterator&lt;K&gt; iterator() { return new Iterator&lt;K&gt;() { private Node cur = head.next; @Override public boolean hasNext() { return cur != tail; } @Override public K next() { Node node = cur; cur = cur.next; return node.k; } } }} 二、基于双向链表 + HashMap 的 LRU 算法实现（C++）12345678910111213141516171819202122232425262728293031323334353637383940414243//使用hash_map和list实现的LRU。 实现了get和put操作//get 得到对应的value，并且移到队列首。//put 不存在：队列首加入，此时根据容量可能会挤掉尾元素。存在：移动到队列首。 //改进点在于如果get发生缺页是否需要处理，这时候可以添加一个//hash_map存储key-value，并在get不到数据时，put一下即可。class LRU{public: LRU(int capacity) : capacity(capacity) { } int get(int key) { if(pos.find(key) != pos.end()) { put(key, pos[key]-&gt;second); return pos[key]-&gt;second; } return -1; } void put(int key, int value) { if(pos.find(key) != pos.end()) { recent.erase(pos[key]); } else if(recent.size() &gt;= capacity) { pos.erase(recent.back().first); recent.pop_back(); } recent.push_front({ key, value }); pos[key] = recent.begin(); }private: int capacity; list&lt;pair&lt;int, int&gt;&gt; recent; unordered_map&lt;int, list&lt;pair&lt;int, int&gt;&gt;::iterator&gt; pos; //value存储的是一个迭代器}; LRU 算法实现并不难，但是要高效地实现却是有难度的，要想高效实现其中的插入、删除、查找，第一想法就是红黑树，但是红黑树也是一种折中的办法。插入、删除效率最高当属链表，查找效率当属 hash。所以，这里我们就将链表和 hash 结合起来，利用空间换时间的思想，实现 LRU 算法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class LRU{private: //LRU数据结构 struct Node { int key; int value; Node(int k, int v) : key(k), value(v) {} };public: LRU(int c) : capacity(c) {} int get(int key) { if(cacheMap.find(key) == cacheMap.end()) { return -1; //这里产生缺页中断，根据页表将页面调入内存，然后set(key, value) } //将key移到第一个，并更新cacheMap cacheList.splice(cacheList.begin(), cacheList, cacheMap[key]); cacheMap[key] = cacheList.begin(); return cacheMap[key]-&gt;value; } void set(int key, int value) { if(cacheMap.find(key) == cacheMap.end()) { //淘汰最后一个，然后将其加到第一个位置 if(cacheList.size() == capacity) { cacheMap.erase(cacheList.back().key); cacheList.pop_back(); } cacheList.push_front(Node(key, value)); cacheMap[key] = cacheList.begin(); } else { //更新节点的值，并将其加到第一个位置 cacheMap[key]-&gt;value = value; cacheList.splice(cacheList.begin(), cacheList, cacheMap[key]); cacheMap[key] = cacheList.begin(); } }private: int capacity; list&lt;Node&gt; cacheList; unordered_map&lt;int, list&lt;Node&gt;::iterator&gt; cacheMap;}; C++ list::splice() 函数详解list::splice() 实现 list 拼接的功能。将源 list 的内容部分或全部元素删除，拼插入到目的 list。 函数有以下三种声明： 12345void splice(iterator position, list&lt;T, Allocator&gt;&amp; x);void splice(iterator position, list&lt;T, Allocator&gt;&amp; x, iterator it);void splice(iterator position, list&lt;T, Allocator&gt;&amp; x, iterator first, iterator last); position 是要操作的 list 对象的迭代器，list&amp;x 是被剪的对象。 会在 position 后把 list&amp;x 所有的元素剪接到要操作的 list 对象 只会把 it 的值剪接到要操作的 list 对象中 把 first 到 last 剪接到要操作的 list 对象中 1234567891011121314151617181920212223242526272829303132333435363738#include&lt;bits/stdc++.h&gt; using namespace std;int main(){ list&lt;int&gt;li1, li2; for(int i = 1; i &lt;= 4; i++) { li1.push_back(i); li2.push_back(i+10); } list&lt;int&gt;::iterator it = li1.begin(); it++; li1.splice(it, li2);//1 11 12 13 14 2 3 4 if(li2.empty()) { cout&lt;&lt;\"li2 is empty\"&lt;&lt;endl; } li2.splice(li2.begin(), li1, it); cout &lt;&lt; *it &lt;&lt;\" \" &lt;&lt; endl; it = li1.begin(); advance(it, 3);//advance 的意思是增加的意思，就是相当于 it = it+3; 这里指向13 li1.splice(li1.begin(), li1, it, li1.end()); //13 14 3 4 1 11 12 可以发现 it 到 li1.end() 被剪贴到 li1.begin() 前面了 for(list&lt;int&gt;::iterator it = li1.begin(); it != li1.end(); ++it) { cout &lt;&lt; *it &lt;&lt;\" \"; } cout &lt;&lt; endl; for(list&lt;int&gt;::iterator it = li2.begin(); it != li2.end(); ++it) { cout &lt;&lt; *it &lt;&lt;\" \"; } cout &lt;&lt; endl; return 0; 输出如下所示： 12345ubuntu@VM-0-9-ubuntu:~$ ./list li2 is empty2 13 14 3 4 1 11 12 2","link":"/post/ed98977f.html"},{"title":"C++经验谈","text":"C++ 的经验之谈 一、用异或来交换变量是错误的翻转一个字符串，例如把“12345”变成“54321”。 123456789101112131415// 版本一，用中间变量交换两个数void reverse_by_swap(char* str, int n){ char* begin = str; char* end = str + n - 1; while(begin &lt; end) { char tmp = *begin; *begin = *end; *end = tmp; ++begin; --end; }} 12345678910111213141516// 版本二，用异或运算交换两个数void reverse_by_xor(char* str, int n){ // WARNING: BAD code char* begin = str; char* end = str + n - 1; while(begin &lt; end) { *begin ^= *end; *end ^= *begin; *begin ^= *end; ++begin; --end; }} C++ 对翻转字符有更简单的解法—调用 STL 里的 std::reverse() 函数。现在的编译器会把 std::reverse() 这种简单函数自动内联展开。 12345// 版本三，用 std::reverse 颠倒一个区间void reverse_by_std(char* str, int n){ std::reverse(str, str + n);} 二、不要重载全局 ::operator new()内存管理的基本要求 既不重复 delete，也不漏掉 delete。new/delete 要配对，不仅个数相等，还隐含了 new 和 delete 的调用本身要匹配 。 用系统默认的 malloc() 分配的内存要交给系统默认的 free() 去释放。 用系统默认的 new 表达式创建的对象要交给系统默认的 delete 表达式去析构并释放。 用系统默认的 new[] 表达式创建的对象要交给系统默认的 delete[] 表达式去析构并释放。 用系统默认的 operator new() 分配的内存要交给系统默认的 ::operator delete() 去释放。 用 placement new 创建的对象要用 placement delete 去析构（其实就是直接调用析构函数）。 从某个内存池 A 分配的内存要还给这个内存池。 如果定制 new/delete，要按《Effective C++ 中文版》第8章“定制 new 和 delete”来。 重载 ::operator new() 的理由 检测代码中的内存错误； 优化性能; 获得内存使用的统计数据。 ::operator new() 的两种重载方式 不改变其签名，无缝直接替换系统原有的版本 1234#include &lt;new&gt;void* operator new(size_t size);void operator delete(void* p); 用这种方式的重载，使用方不需要包含任何特殊的头文件，也就是不需要看见这两个函数声明。“性能优化”通常用这种方式。 增加新的参数，调用时也提供这些额外的参数 12345678// 此函数返回的指针必须能被普通的 ::operator delete(void*) 释放void* operator new(size_t size, const char* file, int line);// 此函数只在构造函数抛出异常的情况下才会被调用void operator delete(void* p, const char* file, int line);// 使用方式Foo* p = new(__FILE, __LINE__) Foo; // 这样能跟踪是哪个文件哪一行代码分配的内存 也可以用宏替换 new 来节省打字。使用方需要看到这两个函数声明，也就是要主动包含你提供的头文件。“检测内存错误”和“统计内存使用情况”通常会用这种方式重载。 现实的开发环境 编写稍具规模的 C++ 应用程序，会用到一些 library。可以分为如下几大类： C 语言的标准库，也包括 Linux 编程环境提供的 glibc 系列函数。 第三方的 C 语言库，例如 OpenSSL。 C++ 语言的标准库，主要是 STL。 第三方的通用 C++ 库，例如 Boost.Regex，或者 XML 库。 公司其他团队的人开发的内部基础 C++ 库，比如网络通信和日志等基础设施。 本项目组的同事自己开发的针对本应用的基础库，比如某三维模型的仿射变换模块。 重载 ::operator new() 的困境 1、规则1：绝对不能在 library 里重载 ::operator new()如果 library 要提供给别人使用，那么你无权重载全局 ::operator new(size_t)（注意这是前面提到的第一种重载方式），因为这非常具有侵略性，任何用到你的 library 的程序都被迫使用了你重载的 ::operator new()，而别人可能不愿意这么做。另外，如果有两个 library 都试图重载 ::operator new(size_t)，估计会发生 duplicated symbol link error。 2、第二种重载方式如何？首先，void* operator new(size_t size, const char* file, int line); 这种方式得到的 void* 指针必须能同时被 void operator delete(void) 和 void operator delete(void p, const char* file, int line) 这两个函数释放。 其次，在 library 里重载 void* operator new(size_t size, const char* file, int line) 还涉及你的重载要不要暴露给 library 的使用者(其他 library 或主程序)。 包含你的头文件的代码会不会用到你重载的 ::operator new() 重载之后的 ::operator new() 分配的内存能不能在你的 library 之外被安全地释放。如果不行，那么是不是要暴露某个接口函数来让使用者安全地释放内存？或者返回 shared_ptr，利用其捕获析构动作的特性？ 在主程序里重载 ::operator new() 的作用不大 C++ library 在代码组织上有两种形式： 以头文件方式提供（如以 STL 和 Boost 为代表的模板库）； 以头文件 + 而二进制库文件方式提供（大多数非模板库以此方式发布）。 对于纯以头文件方式实现的 library，可以在你的程序的每个 .cpp 文件的第一行包含重载 ::operator new() 的头文件，这样程序里用到的其他 C++ library 也会转而使用你的 ::operator new() 来分配内存。 对于以库文件方式实现的 library，这么做并不能让其受惠，因为 library 的源文件已经编译成了二进制代码，它不会调用你新重载的 ::operator new。 替换 malloc() 直接从 malloc 层面入手，通过 LD_PRELOAD 来加载一个 .so，其中有 malloc/free 的替代实现（drop-in replacement），这样同时能为 C 和 C++ 代码服务，而且避免 C++ 重载 ::operator new()。 对于检测内存错误，可以用 valgrind、dmalloc、efence 来达到相同的目的。 对于统计内存使用情况，替换 malloc 同样能够得到足够的信息，因为可以用 backtrace() 函数来获得调用栈，这比 new(FILE, __LINE) 的信息更丰富。 为单独的 class 重载 ::operator new() 有问题吗？如果一个 class Node 需要重载 member ::operator new()，说明它用到了特殊的内存分配策略，常见情况是使用了内存池或对象池。具体地说，用 factory 来创建对象，比如 static Node* Node::createNode() 或者 static shared_ptr&lt; Node &gt; Node::createNode()。 有必要自行定制内存分配器吗？如果写一个简单的只能分配固定大小的 allocator，确实很容易做到比系统的 malloc 更快，因为每次分配操作就是移动一下指针。 三、带符号整数的除法与余数12345678910111213141516171819202122232425262728const char* convert(char buf[], int value){ static char digits[19] = { '9', '8', '7', '6', '5', '4', '3', '2', '1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' }; static const char* zero = digits + 9; // zero 指向 '0' // work for -2147483648 .. 2147483647 int i = value; char* p = buf; do { // lsd - least significant digit int lsd = i % 10; // lsd 可能小于 0 i /= 10; // 是向下取整还是向零取整？ *p++ = zero[lsd]; // 下标可能为负 }while(i != 0) if(value &lt; 0) { *p++ = '-'; } *p = '\\0'; std::reverse(buf, p); return p; // p - buf 为整数长度} 可以作为 itoa() 的参考实现。《C Traps and Pitfalls》讲到，C 语言中的整数除法（/）和取模（%）运算在操作数为负的时候，结果是 implementation-defined。也就是说，如果 m、d 都是整数， 12int q = m / d;int r = m % d; C 语言只保证 m = q × d + r。如果 m、d 当中有负数，那么 q 和 r 的正负号是由实现决定的。比如（-13）/ 4 = （-3）或（-13）/ 4 = （-4）都是合法的。 四、在单元测试中 mock 系统调用在某些情况下，单元测试是很有必要的，在测试 failure 场景的时候尤其重要。 在开发存储系统时，模拟 read()/write() 返回 EIO 错误（有可能是磁盘写满了，也有可能是磁盘出现了坏道读不出数据） 在开发网络库的时候，模拟 write() 返回 EPIPE 错误（对方意外断开连接） 在开发网络库的时候，模拟自连接（self-connection），网络库应该用 getsockname() 和 getpeername() 判断是否是自连接，然后断开之 在开发网络库的时候，模拟本地 ephemeral port 耗尽，connect() 返回 EAGAIN 临时错误 让 gethostbyname() 返回我们预设的值，防止单元测试给公司的 DNS Server 带来太大压力 4.1、系统函数的依赖注入1、采用传统的面向对象的手法，借助运行期的迟绑定实现注入与替换。自己写一个 System interface，把程序里用到的 open、close、read、write、connect、bind、listen、accept、gethostname、getpeername、getsockname 等等函数统统用虚函数封装一层。在代码里不要直接调用 open()，而是调用 System::instance.open()。这样代码主动把控制权交给了 System interface。在写单元测试的时候，把这个 singleton instance 替换为 mock object，这样就能模拟各种 error code。 2、采用编译期或链接期的迟绑定。可以在写一个 system namespace 头文件，在其中声明 read() 和 write() 等普通函数，然后在 .cc 文件里转发给对应系统的系统函数 ::read() 和 ::write() 等。 1234567891011// .hnamespace sockets{ int connect(int sockfd, const struct sockaddr_in&amp; addr);}// .ccint sockets::connect(int sockfd, const struct sockaddr_in&amp; addr){ return ::connect(sockfd, sockaddr_cast(&amp;addr), sizeof addr);} 有了这一层间接性，就可以在编写单元测试的时候链接我们的 stub 实现，以达到替换实现的目的 12345int sockets::connect(int sockfd, const struct sockaddr_in&amp; addr){ errno = EAGAIN; return -1;} 一个 C++ 程序只能有一个 main() 入口，所以要先把程序做成 library，再用单元测试代码链接这个 library。假设有一个 mynetcat 程序，为了编写 C++ 单元测试，可以把它拆成两部分，即 library 和 main()，源文件分别是 mynetcat.cc 和 main.cc。在编译普通程序的时候： 1g++ main.cc mynetcat.cc SocketsOps.cc -o mynetcat 在编译单元测试时这么写： 1g++ test.cc mynetcat.cc MockSocketsOps.cc -o test namespace 的好处在于它不是封闭的，可以随时打开往里添加新的函数，而不用改动原来的头文件。这也是以 non-member non-friend 函数为接口的优点。 4.2、链接期垫片（link seam）要仿冒 connect() 函数，可以在单元测试程序里实现一个自己的 connect() 函数，它遮盖了同名的系统函数。在链接的时候，linker 会优先采用我们自己定义的函数。（这对动态链接是城里的；如果是静态链接，会报 multiple definition 错误。好在绝大数情况下 libc 是动态链接的。） 123456789101112131415161718192021222324typedef int (*connect_func_t)(int sockfd, const struct sockaddr* addr, socklen_t addrlen);connect_func_t connect_func = dlsym(RTDL_NEXT, \"connect\");bool mock_connect;int mock_connect_errno;// mock connectextern \"C\" int connect(int sockfd, const struct sockaddr* addr, socklen_t addrlen){ if(mock_connect) { errno = mock_connect_errno; return errno == 0 ? 0 : -1; } else { return connect_func(sockfd, addr, addrlen); }} 程序真的要调用 connect()，为了防止出现无限递归的情况，用 dlsym(RTDL_NEXT, “connect”) 获得 connect() 系统函数的真实地址，然后通过函数指针 connect_func 来调用它。 Link seam 同样适用于第三方 C++ 库 1234567891011class File : boost::noncopyable{ public: File(const char* filename); ~File(); int readn(void* data, int len); int writen(const void* data, int len); size_t getSize() const; private:}; 这个 class 没有适用虚函数，无法通过 sub-classing 的方法来实现 mock object。如果需要为用到 File class 的程序编写单元测试，我们可以自己定义其成员函数的实现，这样可以注入任何我们想要的结果。 1234int File::readn(void* data, int len){ return -1;} 这种做法对动态库是可行的，但对于静态库则会报错。 五、慎用匿名 namespace其只要目的是让该 namespace 中的成员（变量或函数）具有独一无二的全局名称，避免名字碰撞（name collisions）。 5.1、C 语言的 static 关键字的两种用法 用于函数内部修饰变量，即函数内的静态变量。这种变量的生存期长于该函数，使得函数具有一定的状态。使用静态变量的函数一般是不可重入的，也不是线程安全的，比如 strtok()。 用在文件级别（函数体之外），修饰变量或函数，表示该变量或函数只在本文件可见，其他文件看不到、也访问不到该变量或函数。专业的说法叫“具有 internal linkage”（简言之：不暴露给别的 translation unit）。 5.2、C++ 语言的 static 关键字的四种用法 用于修饰 class 的数据成员，即所谓静态成员。这种数据成员的生存期大于 class 的对象（实体/instance）。静态数据成员是每个 class 有一份，普通数据成员是每个 instance 有一份吗，因此也分别叫做 class variable 和 instance variable。 用于修饰 class 的成员函数，即所谓静态成员函数。这种成员函数只能访问 class viriable 和其他静态成员函数，不能访问 instance variable 或 instance method。 这几种用法可以组合，比如 C++ 的成员函数（无论 static 还是 instance）都可以有其局部的静态变量。对于 class template 和 function template，其中的 static 对象的真正个数跟 template instantiate（模板具现化）有关。 5.3、匿名 namespace 的不利之处 匿名 namespace 中的函数是匿名的，那么在确实需要引用它的时候就比较麻烦。比如在调试的时候不便给其中的函数设断点，又比如 profiler 的输出结果也不容易判别到底是哪个文件中的 calculate() 函数需要优化。 使用某些版本的 g++ 时，同一个文件每次编译出来的二进制文件会变化。比如说拿到一个会发生 core dump 的二进制可执行文件，无法确定它是由哪个 revision 的代码编译出来的。毕竟编译结果不可复现，具有一定的随机性。另外这也可能让某些 build tool 失灵，如果该工具用到了编译出来的二进制文件的 MD5 的话。 六、采用有利于版本管理的代码格式6.1、对 diff 友好的代码格式 多行注释也用 //，不用 /* … */ 局部变量与成员变量的定义一行代码只定义一个变量，同样的道理适用于 enum 成员的定义、数组的初始化列表等。 函数声明中的参数如果函数的参数大于3个，那么在逗号后面换行，这样每个参数占一行，便于 diff。1234567class TcpClient : boost::noncopyable{ public: TcpClient(EventLoop* loop, const InetAddress&amp; serverAddr, const string&amp; name);} 函数调用时的参数在函数调用的时候，如果参数大于3个，那么把实参分行写。12345678Timestamp EpollPoller::poll(int timeoutMs, ChannelList* activeChannels){ int numEvents = ::epoll_wait(epollfd_, &amp;*events_.begin(), static_cast&lt;int&gt;(events_.size()), timeoutMs); Timestamp now(Timestamp::now());} class 初始化列表的写法class 初始化列表（initializer list）也遵循一行一个的原则。 与 namespace 有关的缩进Google 的 C++ 编程规范明确指出，namespace 不增加缩进。方便 diff -p 把函数名显示在每个 diff chunk 的头上。diff 原本是为 C 语言设计的，C 语言没有 namespace 缩进一说，所以它默认会找到顶格写的函数作为一个 diff chunk 的名字。如果函数名前面有空格，它就不认得了。123456789namespace muduo{// class 从第一列开始写，不缩进class Timestamp : public muduo::copyable{ // ...};} public 与 privateC++ diff 无法看出把一个函数从 public 区移到 private 区。 避免使用版本控制软件的 keyword substitution 功能这么做是为了避免 diff 噪声。 6.2、对 grep 友好的代码风格 操作符重载operator overloading 应仅限于和 STL algorithm/container 配合时使用，比如 std::transform() 和 map&lt; Key, Value &gt;，其他情况都用具名函数为宜。又比如，Google Protocol Buffers 的回调是 Closure class，它的接口用的是 virtual function Run() 而不是 virtual operator()()。 static_cast 与 C-style cast为什么 C++ 要引入 static_cast 之类的转型操作符，原因之一就是像 (int*)pBuffer 这样的表达式基本上没办法用 grep 判断出它是个强制类型转换，写不出一个刚好只匹配类型转换的正则表达式。 七、再探 std::stringstd::string 主要有三类实现方式 无特殊处理（eager copy），采用类似 std::vector 的数据结构。123456789101112131415161718192021222324// class invariants:// (1) [start, finish) is a valid range.// (2) Each iterator in [start, finish) points to a valid object of type value_type.// (3) *finish is a valid object of type value_type; in particular, it is value_type().// (4) [finish + 1, end_of_storage) is a valid range.// (5) Each iterator in [finish + 1, end_of_storage) points to uninitialized memory.// Note one important consequence: a string of length n must manage a block of memory// whose size is at least n + 1.class string{ public: const_pointer data() const { return start; } iterator begin() { return start; } iterator end() { return finish; } size_type size() const { return finish - start; } size_type capacity() const { return end_of_storage - start; } private: char* start; char* finish; char* end_of_storage;}; 对象的大小是3个指针，在 32-bit 中是12字节，在 64-bit 中是24字节。Eager copy string 的另一种实现方式是把后两个成员变量替换成整数，表示字符串的长度和容量。1234567891011121314class string{ public: const_pointer data() const { return start; } iterator begin() { return start; } iterator end() { return start + size_; } size_type size() const { return size_; } size_type capacity() const { return capacity_; } private: char* start; size_t size_; size_t capacity_;}; Copy-on-Write（COW）。g++ 的 std::string 一直采用这种方式实现。string 对象里只放一个指针。1234567891011class cow_string // libstdc++-v3{ struct Rep { size_t size; size_t capacity; size_t refcount; char* data[1]; // variable length }; char* start;}; 短字符串优化（SSO），利用 string 对象本身的空间来存储短字符串。Visual C++ 用的是这种实现方式。无论哪种实现方式都要保存三个数据库：1、字符串本身（char[]），2、字符串的长度（size），3、字符串的容量（capacity）。string 对象比前面两个都大，因为有本地缓冲区（local buffer）。1234567891011class sso_string{ char* start; size_t size; static const int kLocalSize = 15; union { char buffer[kLocalSize+1]; size_t capacity; }data;} 八、用 STL algorithm 做算法题C++ STL 的 algorithm 配合自定义的 functor（仿函数、函数对象）可以用来解决某些算法题。 8.1、用 next_permutation() 生成排列组合生成 N 个不同元素的全排列 把元素从小到大放好（即字典序最小的排列），然后反复调用 next_permutation()。 123456789101112131415int main(){ int elements[] = { 1, 2, 3, 4}; const size_t N = sizeof(elements)/sizeof(elements[0]); std::vector&lt;int&gt; vec(elements, elements + N); int count = 0; do { std::cout &lt;&lt; ++count &lt;&lt; \": \"; std::copy(vec.begin(), vec.end(), std::ostream_iterator&lt;int&gt;(std::cout, \", \")); std::cout &lt;&lt; std::endl; }while(next_permutation(vec.begin(), vec.end()));} 生成从 N 个元素中取出 M 个的所有组合 12345678910111213141516171819202122int main(){ int values[] = { 1, 2, 3, 4, 5, 6, 7 }; int elements[] = { 1, 1, 1, 0, 0, 0, 0 }; const size_t N = sizeof(elements)/sizeof(elements[0]); assert(N == sizeof(values)/sizeof(values[0])); std::vector&lt;int&gt; selectors(elements, elements + N); int count = 0; do { std::cout &lt;&lt; ++count &lt;&lt; \": \"; for(size_t i = 0; i &lt; selectors.size(); ++i) { if(selectors[i]) { std::cout &lt;&lt; values[i] &lt;&lt; \"，\"; } } std::cout &lt;&lt; std::endl; }while(prev_permutation(selectors.begin(), selectors.end()));} 8.2、用 unique() 去除连续重复空白std::unique() 的作用是去除相邻的重复元素。注意所有针对区间的 STL algorithm 都只能调换区间内元素的顺序，不能真正删除容器内的元素。 1234567891011121314struct AreBothSpaces{ bool operator()(char x, char y) const { return x == ' ' &amp;&amp; y == ' '; }};void removeContinuousSpaces(std::string&amp; str){ std::string::iterator last = std::unique(str.begin(), str.end(), AreBothSpaces()); str.erase(last, str.end());} 8.3、用 {make, push, pop}_heap() 实现多路归并题目 用一台 4GiB 内存的机器对磁盘上的单个 100 GB 文件排序标准思路是先分块排序，然后多路归并并输出文件。多路归并用 heap 排序实现，比方说要归并已经按从小到大的顺序排好序的32个文件，可以构造一个32元素的 min heap，每个元素是 std::pair&lt; Recode, FILE* &gt;。然后每次取出堆顶的元素，将其 Record 写入输出文件；如果 FILE* 还可读，就读入一条 Record，再向 heap 中添加 std::pair&lt; Recode, FILE* &gt;。这样当 heap 为空的时候，多路归并就完成了。这个过程中 heap 的大小通常会慢慢变小，因为有可能某个输入文件已经全部读完了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950typedef int Record;typedef std::vector&lt;Record&gt; File;struct Input{ Record value; const File* file; explicit Input(const File* f); bool next(); bool operator&lt;(const Input&amp; rhs) const { // make_heap to build min-heap, for merging return value &gt; rhs.value; }};File mergeN(const std::vector&lt;File&gt;&amp; files){ File output; std::vector&lt;Input&gt; inputs; for(size_t i = 0; i &lt; files.size(); ++i) { Input input(&amp;files[i]); if(input.next()) { inputs.push_back(input); } } std::make_heap(inputs.beigin(), inputs.end()); while(!inputs.empty()) { std::pop_heap(inputs.begin(), inputs.end()); output.push_back(inputs.back().value); if(inputs.back().next()) { std::push_heap(inputs.begin(), inputs.end()); } else { inputs.pop_back(); } } return output;} 8.4、用 partition() 实现重排数组，让奇数位于偶数前面std::partition() 的作用是把符合条件的元素放到区间首部，不符合条件的元素放到区间后部。 123456789101112bool isOdd(int x){ return x % 2 != 0; // x % 2 == 1 is WRONG}void moveOddsBeforeEvens(){ int oddeven[] = { 1, 2, 3, 4, 5, 6 }; std::patition(oddeven, oddeven+6, &amp;isOdd); std::copy(oddeven, oddeven+6, std::ostream_iterator&lt;int&gt;(sdt::cout, ', ')); std::cout &lt;&lt; std::endl;} 如果要求保持原来的数字先后顺序不变，可以用 std::stable_partition()。 8.5、用 lower_bound() 查找 IP 地址所属的城市123456789101112131415161718192021222324252627282930313233343536373839struct IPrange{ uint32_t startIp; // inclusive uint32_t endIp; // inclusive int value; // &gt;= 0 bool operator&lt;(const IPrange&amp; rhs) const { return startIp &lt; rhs.startIp; }};// REQUIRE: ranges is sorted.int findIpValue(const std::vector&lt;IPrange&gt;&amp; ranges, uint32_t ip){ int result = -1; if(!ranges.empty()) { IPrange needle = { ip, 0, 0 }; std::vector&lt;IPrangea&gt;::const_iterator it = std::lower_bound(ranges.begin(), ranges.end(), needle); if(it == ranges.end()) { --it; } else if(it != ranges.begin() &amp;&amp; it-&gt;startIp &gt; ip) { --it; } if(it-&gt;startIp &lt;= ip &amp;&amp; it-&gt;endIp &gt;= ip) { result = it-&gt;value; } } return result;} 8.6、STL algorithm 算法分类 容易，手写一遍的难度跟 strlen() 和 strcpy() 差不多。这类算法基本上是遍历一遍输入区间，对每个元素做些判断或操作，一个 for 循环就可以解决问题。一半左右的 STL algorithm 属于此类，例如 for_each()、transform()、accmulate() 等等。 较难，要写出正确的实现要考虑清楚各种边界条件。例如 merge()、unique()、remove()、random_shuffle()、lower_bound()、partition() 等等。 难，例如 sort()、nth_element()、next_permutation()、inplace_merge() 等等。 参考文章:Linux多线程服务端编程","link":"/post/89b90f5f.html"},{"title":"C++构造函数","text":"构造函数 一、构造函数1.1、禁止对象产生于 heap 之中1、对象被直接实例化2、对象被实例化为 derived class object 内的 base class 成分3、对象被内嵌于其他对象之中 1.2、构造函数语意学1、nontrivial : 有用的2、bitwise : 对每一个 bit 施以 1.3、构造函数为什么不能是虚函数1、构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。而在构造一个对象时，由于对象还未构造成功。编译器无法知道对象的实际类型，是该类本身，还是该类的一个派生类，或是更深层次的派生类。 2、虚函数的执行依赖于虚函数表。而虚函数表在构造函数中进行初始化工作，即初始化 vptr，让他指向正确的虚函数表。而在构造对象期间，虚函数表还没有被初始化，将无法进行。 3、从存储空间角度，虚函数对应一个指向 vtable 虚函数表的指针，这个指向 vtable 的指针其实是存储在对象的内存空间的。问题出来了，如果构造函数是虚的，就需要通过 vtable 来调用，可是对象还没有实例化，也就是内存空间还没有，怎么找 vtable 呢？所以构造函数不能是虚函数。 4、从使用角度，虚函数主要用于在信息不全的情况下，能使重载的函数得到对应的调用。构造函数本身就是要初始化实例，所以构造函数没有必要是虚函数。虚函数的作用在于通过父类的指针或者引用来调用它的时候能够变成调用子类的那个成员函数。而构造函数是在创建对象时自动调用的，不可能通过父类的指针或者引用去调用，因此也就规定构造函数不能是虚函数。 5、构造函数不需要是虚函数，也不允许是虚函数，因为创建一个对象时我们总是要明确指定对象的类型。 6、从实现上看，vtable 在构造函数调用后才建立，因而构造函数不可能成为虚函数。从实际含义上看，在调用构造函数时还不能确定对象的真实类型（因为子类会调父类的构造函数），而且构造函数的作用是提供初始化，在对象生命期只执行一次，不是对象的动态行为，也没有必要成为虚函数。 7、当一个构造函数被调用时，它做的首要的事情之一是初始化它的 vptr。因此，它只能知道它是“当前”类的，而完全忽视这个对象后面是否还有继承者。当编译器为这个构造函数产生代码时，它是为这个类的构造函数产生代码——既不是为基类，也不是为它的派生类（因为类不知道谁继承它）。所以它使用的 vptr 必须是对于这个类的 vtable。而且，只要它是最后的构造函数调用，那么在这个对象的生命期内，vptr 将保持被初始化为指向这个vtable，但如果接着还有一个更晚派生的构造函数被调用，这个构造函数又将设置 vptr 指向它的 vtable，直到最后的构造函数结束。vptr 的状态是由被最后调用的构造函数确定的。这就是为什么构造函数调用是从基类到更加派生类顺序的另一个理由。但是，当这一系列构造函数调用正发生时，每个构造函数都已经设置 vptr 指向它自己的 vtable。如果函数调用使用虚机制，它将只产生通过它自己的 vtable 的调用，而不是最后的 vtable（所有构造函数被调用后才会有最后的 vtable）。 1.4、类成员初始化对类成员进行初始化有两种方式： 构造函数后面跟冒号； 构造函数里面对成员进行赋值。 根据 C++ 的规则，const 类型和引用不可以被赋值，只能被初始化。const 类型和引用必须在声明的时候就初始化，换句话说就是在给 const 和引用类型变量分配内存的时候就初始化。C++ 给类成员初始化的唯一方式就是成员初始化列表，也就是构造函数后面跟冒号的那种形式。 在构造函数里面调用等于号 = 并不是真正意义上的初始化，这个过程相当于： 系统创建成员变量； 创建完后再进行赋值操作。 而在构造函数后面跟冒号，就相当于： 系统创建成员变量并且初始化。也就是系统为成员变量分配了一块内存并且把相应的数据给填了进去。 而构造函数里面调用等于号的方式是分配好后再进行赋值，多了一个步骤。 构造函数后面跟的冒号代码是在进入构造函数并且在括号里面的第一行代码之前被执行。 通俗的讲，构造函数后面的冒号就是初始化，而括号里面的等于号并不是初始化，而是变量生成以后的赋值而已（永远都是2个步骤）。 引用初始化完成后，就永远指向初始化时候的那个变量，无法再改变了。 1.5、C++ 中可以在构造函数中调用另一个构造函数吗？12345678910111213141516171819202122#include &lt;stdlib.h&gt;#include &lt;iostream&gt;using namespace std; struct CLS{ int m_i; CLS( int i ) : m_i(i){} CLS() { CLS(0); }};int main(){ CLS obj; cout &lt;&lt; obj.m_i &lt;&lt; endl; system(\"PAUSE\"); return 0;} 打印结果是不定的，不一定为0。我们知道，当定义一个对象时，会按顺序做2件事情：1、分配好内存（非静态数据成员是未初始化的）2、调用构造函数（构造函数的本意就是初始化非静态数据成员） 显然上面代码中，CLS obj; 这里已经为 obj 分配了内存，然后调用默认构造函数，但是默认构造函数还未执行完，却调用了另一个构造函数，这样相当于产生了一个匿名的临时 CLS 对象，它调用 CLS(int) 构造函数，将这个匿名临时对象自己的数据成员 m_i 初始化为0；但是 obj 的数据成员并没有得到初始化。于是 obj 的 m_i 是未初始化的，因此其值也是不确定的。 由上，归纳如下：1、在 C++ 里，由于构造函数允许有默认参数，使得这种构造函数调用构造函数来重用代码的需求大为减少 2、如果仅仅为了一个构造函数重用另一个构造函数的代码，那么完全可以把构造函数中的公共部分抽取出来定义一个成员函数（推荐为 private），然后在每个需要这个代码的构造函数中调用该函数即可 3、偶尔我们还是希望在类的构造函数里调用另一个构造函数，可以按如下方式做：在构造函数里调用另一个构造函数的关键是让第二个构造函数在第一次分配好的内存上执行，而不是分配新的内存，这个可以用标准库的 placement new 做到 1234inline void *__cdecl operator new(size_t, void *_P){ return (_P); } 正确的方式： 123456789struct CLS{ int m_i; CLS(int i) : m_i(i) {} CLS() { new (this)CLS(0); }}; 若构造函数调用自身，则会出现无限递归调用，是不允许的。 所以，在实际使用的时候，单纯的在构造函数中调用其它的构造函数，只是会产生一个临时的匿名变量。如果仅仅是为了重用代码，可以把重用的代码封装成一个新的函数。 二、拷贝构造2.1、C++ 中拷贝构造函数的定义传参问题在 C++ 中，我们使用拷贝构造函数来实现对象的复制。我们需要注意的是，在定义拷贝构造函数的时候，传入参数不能是传值参数，例如 A(A other)。因为如果是传值函数，就会在拷贝构造函数内将形参复制为实参，而复制的时候又会调用拷贝构造函数，这样就会造成无休止的递归调用，导致栈溢出，因此 C++ 不允许拷贝构造函数传递值参数，最好将拷贝构造函数修改为传递常量引用。 1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt; using namespace std; class A{private: int value;public: A(int n) { value = n; } A(A other) { value = other.value; } void Paint() { cout &lt;&lt; value &lt;&lt; endl; }};// 无法通过编译int main(){ char c; A a = 10; A b = a; b.Paint(); cin &gt;&gt; c; return 0;} 正确的写法，如下所示： 1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt; using namespace std; class A{private: int value;public: A(int n) { value = n; } A(const A&amp; other) { value = other.value; } void Paint() { cout &lt;&lt; value &lt;&lt; endl; }}; int main(){ char c; A a = 10; A b = a; b.Paint(); cin &gt;&gt; c; return 0;} 2.2、C++ 拷贝构造函数(深拷贝，浅拷贝)1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;class CExample {private: int a;public: CExample(int b) { a=b; } void Show() { cout&lt;&lt;a&lt;&lt;endl; }};int main(){ CExample A(100); CExample B=A; B.Show(); return 0;} 运行程序，屏幕输出 100。从以上代码的运行结果可以看出，系统为对象 B 分配了内存并完成了与对象 A 的复制过程。就类对象而言，相同类型的类对象是通过拷贝构造函数来完成整个复制过程的。下面举例说明拷贝构造函数的工作过程。 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;class CExample {private: int a;public: CExample(int b) { a=b;} CExample(const CExample&amp; C) { a=C.a; } void Show () { cout&lt;&lt;a&lt;&lt;endl; }};int main(){ CExample A(100); CExample B=A; B.Show (); return 0;} CExample(const CExample&amp; C) 就是我们自定义的拷贝构造函数。可见，拷贝构造函数是一种特殊的构造函数，函数的名称必须和类名称一致，它的唯一的一个参数是本类型的一个引用变量，该参数是 const 类型，是不可变的。例如：类 X 的拷贝构造函数的形式为 X(X&amp; x)。 当用一个已初始化过了的自定义类类型对象去初始化另一个新构造的对象的时候，拷贝构造函数就会被自动调用。也就是说，当类的对象需要拷贝时，拷贝构造函数将会被调用。以下情况都会调用拷贝构造函数： 一个对象以值传递的方式传入函数体 一个对象以值传递的方式从函数返回 一个对象需要通过另外一个对象进行初始化 如果在类中没有显式地声明一个拷贝构造函数，那么，编译器将会自动生成一个默认的拷贝构造函数，该构造函数完成对象之间的位拷贝。位拷贝又称浅拷贝，后面将进行说明。 自定义拷贝构造函数是一种良好的编程风格，它可以阻止编译器形成默认的拷贝构造函数，提高源码效率。 浅拷贝和深拷贝 在某些状况下，类内成员变量需要动态开辟堆内存，如果实行位拷贝，也就是把对象里的值完全复制给另一个对象，如 A=B。这时，如果 B 中有一个成员变量指针已经申请了内存，那 A 中的那个成员变量也指向同一块内存。这就出现了问题：当 B 把内存释放了（如析构），这时 A 内的指针就是野指针了，出现运行错误。 深拷贝和浅拷贝可以简单理解为：如果一个类拥有资源，当这个类的对象发生复制过程的时候，资源重新分配，这个过程就是深拷贝，反之，没有重新分配资源，就是浅拷贝。下面举个深拷贝的例子。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;class CA{ public: CA(int b, char* cstr) { a=b; str=new char[b]; strcpy(str, cstr); } CA(const CA&amp; C) { a=C.a; str=new char[a]; //深拷贝 if(str!=0) strcpy(str, C.str); } void Show() { cout&lt;&lt;str&lt;&lt;endl; } ~CA() { delete str; } private: int a; char *str;};int main(){ CA A(10, \"Hello!\"); CA B=A; B.Show(); return 0;} 深拷贝和浅拷贝的定义可以简单理解成：如果一个类拥有资源(堆，或者是其它系统资源)，当这个类的对象发生复制过程的时候，这个过程就可以叫做深拷贝，反之对象存在资源，但复制过程并未复制资源的情况视为浅拷贝。 浅拷贝资源后在释放资源的时候会产生资源归属不清的情况导致程序运行出错。 Test(Test &amp;c_t) 是自定义的拷贝构造函数，拷贝构造函数的名称必须与类名称一致，函数的形式参数是本类型的一个引用变量，且必须是引用。 当用一个已经初始化过了的自定义类类型对象去初始化另一个新构造的对象的时候，拷贝构造函数就会被自动调用，如果你没有自定义拷贝构造函数的时候，系统将会提供给一个默认的拷贝构造函数来完成这个过程，上面代码的复制核心语句就是通过 Test(Test &amp;c_t) 拷贝构造函数内的 p1=c_t.p1; 语句完成的。 参考文章C++拷贝构造函数(深拷贝，浅拷贝)","link":"/post/5bf30090.html"},{"title":"数据结构与算法-堆(转载)","text":"堆是生产中非常重要也很实用的一种数据结构，也是求 TopK 等问题的非常热门的考点。 一、堆的定义堆有以下两个特点 堆是一颗完全二叉树，这样实现的堆也被称为二叉堆 堆中节点的值都大于等于（或小于等于）其子节点的值，堆中如果节点的值都大于等于其子节点的值，我们把它称为大顶堆，如果都小于等于其子节点的值，我们将其称为小顶堆。 完全二叉树，它的叶子节点都在最后一层，并且这些叶子节点都是靠左排序的。 从堆的特点可知，下图中，1，2 是大顶堆，3 是小顶堆， 4 不是堆（不是完全二叉树） 从图中也可以看到，一组数据如果表示成大顶堆或小顶堆，可以有不同的表示方式，因为它只要求节点值大于等于（或小于等于）子节点值，未规定左右子节点的排列方式。 堆的底层是如何表示的呢，从以上堆的介绍中我们知道堆是一颗完全二叉树，而完全二叉树可以用数组表示 如图示：给完全二叉树按从上到下从左到右编号，则对于任意一个节点来说，很容易得知如果它在数组中的位置为 i，则它的左右子节点在数组中的位置为 2i，2i + 1，通过这种方式可以定位到树中的每一个节点，从而串起整颗树。 一般对于二叉树来说每个节点是要存储左右子节点的指针，而由于完全二叉树的特点（叶子节点都在最后一层，并且这些叶子节点都是靠左排序的），用数组来表示它再合适不过，用数组来存储有啥好处呢，由于不需要存指向左右节点的指针，在这颗树很大的情况下能省下很多空间！ 二、堆的基本操作堆有两个基本的操作，构建堆（往堆中插入元素）与删除堆顶元素，我们分别来看看这两个操作 1、往堆中插入元素往堆中插入元素后（如下图示），我们需要继续满足堆的特性，所以需要不断调整元素的位置直到满足堆的特点为止（堆中节点的值都大于等于（或小于等于）其子节点的值），我们把这种调整元素以让其满足堆特点的过程称为堆化（heapify）。 由于上图中的堆是个大顶堆，所以我们需要调整节点以让其符合大顶堆的特点。怎么调整？不断比较子节点与父节点，如果子节点大于父节点，则交换，不断重复此过程，直到子节点小于其父节点。来看下上图插入节点 11 后的堆化过程 这种调整方式是先把元素插到堆的最后，然后自下而上不断比较子节点与父节点的值，我们称之为由下而上的堆化。有了以上示意图，不难写出插入元素进行堆化的代码： 12345678910111213141516171819202122232425262728public class Heap { private int[] arr; // 堆是完全二叉树，底层用数组存储 private int capacity; // 堆中能存储的最大元素数量 private int n; // 当前堆中元素数量 public Heap(int count) { capacity = count; arr = new int[capacity+1]; n = 0; } public void insert(int value) { if (n &gt;= capacity) { // 超过堆大小了，不能再插入元素 return; } n++; // 先将元素插入到队尾中 arr[n] = value; int i = n; // 由于我们构建的是一个大顶堆，所以需要不断调整以让其满足大顶堆的条件 while (i/2 &gt; 0 &amp;&amp; arr[i] &gt; arr[i/2]) { swap(arr, i, i/2); i = i / 2; } }} 时间复杂度就是树的高度，所以为 O(logn)。 2、删除堆顶元素由于堆的特点（节点的值都大于等于（或小于等于）其子节点的值），所以其根节点（堆项）要么是所有节点中最大，要么是所有节点中最小的，当删除堆顶元素后，也需要调整子节点，以让其满足堆（大顶堆或小顶堆）的条件。 假设我们要操作的堆是大顶堆，则删除堆顶元素后，要找到原堆中第二大的元素以填补堆顶元素，而第二大的元素无疑是在根节点的左右子节点上，假设是左节点，则用左节点填补堆顶元素之后，左节点空了，此时需要从左节点的左右节点中找到两者的较大值填补左节点…，不断迭代此过程，直到调整完毕，调整过程如下图示： 但是这么调整后，问题来了，如上图所示，在最终调整后的堆中，出现了数组空洞，对应的数组如下 怎么解决？我们可以用最后一个元素覆盖堆顶元素，然后再自上而下地调整堆，让其满足大顶堆的要求，这样即可解决数组空洞的问题。 看了以上示意图，代码实现应该比较简单，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 移除堆顶元素 */public void removeTopElement() { if (n == 0) { // 堆中如果没有元素，也就是不存在移除堆顶元素的情况了 return; } int count = n; arr[1] = arr[count]; --count; heapify(1, count);}/** * 自上而下堆化以满足大顶堆的条件 */public void heapify(int index, int n) { while (true) { int maxValueIndex = index; if (2 * index &lt;= n &amp;&amp; arr[index] &lt; arr[2 * index]) { // 左节点比其父节点大 maxValueIndex = 2 * index; } if (2 * index + 1 &lt;= n &amp;&amp; arr[maxValueIndex] &lt; arr[2 * index + 1]) { // 右节点比左节点或父节点大 maxValueIndex = 2 * index + 1; } if (maxValueIndex == index) { // 说明当前节点值为最大值，无需再往下迭代了 break; } swap(arr, index, maxValueIndex); index = maxValueIndex; }}/** * 交换数组第 i 和第 j 个元素 */public static void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;} 三、堆排序用堆怎么实现排序？我们知道在大顶堆中，根节点是所有节点中最大的，于是我们有如下思路： 假设待排序元素个数为 n（假设其存在数组中），对这组数据构建一个大顶堆，删除大顶堆的元素（将其与数组的最后一个元素进行交换），再对剩余的 n-1 个元素构建大顶堆，再将堆顶元素删除（将其与数组的倒数第二个元素交换），再对剩余的 n-2 个元素构建大顶堆…，不断重复此过程，这样最终得到的排序一定是从小到大排列的，堆排序过程如下图所示： 从以上的步骤中可以看到，重要的步骤就两步，建堆（堆化，构建大顶堆）与排序。 先看下怎么建堆，其实在上一节中我们已经埋下了伏笔，上一节我们简单介绍了堆的基本操作，插入和删除，所以我们可以新建一个数组，遍历待排序的元素，每遍历一个元素，就调用上一节我们定义的 insert(int value) 方法，这个方法在插入元素到堆的同时也会堆化调整堆为大顶堆，遍历完元素后，最终生成的堆一定是大顶堆。 用这种方式生成的大顶堆空间复杂度是多少呢，由于我们新建了一个数组，所以空间复杂度是 O(n)，但其实堆排序是原地排序的（不需要任何额外空间），所以我们重点看下如何在不需要额外空间的情况下生成大顶堆。 其实思路很简单，对于所有非叶子节点，自上而下不断调整使其满足大顶堆的条件（每个节点值都大于等于其左右节点的值）即可，遍历到最后得到的堆一定是大顶堆！同时调整堆的过程中只是不断交换数组里的元素，没有用到额外的存储空间。 那么非叶子节点的范围是多少呢，假设数组元素为 n，则数组下标为 1 到 n/2 的元素是非叶子节点。下标 n/2 + 1 到 n 的元素是叶子节点。 画外音：假设下标 n/2 + 1 的节点不是叶子节点，则其左子节点下标为 (n/2 + 1) * 2 = n + 2，超过了数组元素 n，显然不符合逻辑，由此可以证明 n/2 + 1 开始的元素一定是叶子节点 示意图如下： 如图示：对每个非叶子节点自上而下调整后，最终得到大顶堆。 有了以上思路，不难写出如下代码： 12345678/*** 对 1 到 n/2 的非叶子节点自上而下进行堆化，以构建大顶堆 */public void buildHeap() { for (int i = n/2; i &gt; 0; i--) { heapify(i, n); }} 这样建堆的时间复杂度是多少呢，我们知道对每个元素进行堆化时间复杂度是 O(log n)，那么对 1 到 n/2 个元素进行堆化，则总的时间复杂度显然是 O(nlogn)（实际上如果详细推导，时间复杂度是 O(n)，这里不作展开，有兴趣的同学建议查一下资料看下 O(n) 是怎么来的）。 知道怎么建堆，接下来排序就简单了，对 n 个元素来说，只要移除堆顶元素（将其与最后一个元素交换），再对之前的 n-1 个元素堆化，再移除堆顶元素（将其与倒数第二个元素交换）…，不断重复此过程即可，代码如下: 12345678910111213141516171819/** * 堆排序 */public void heapsort() { // 建堆 buildHeap(); int i = n; while (true) { if (i &lt;= 1) { break; } // 将堆顶元素放到第 i 个位置 swap(arr, 1, i); i--; // 重新对 1 到 i 的元素进行堆化，以让其符合大顶堆的条件 heapify(1, i); }} 时间复杂度上文已经分析过了，就是 O(nlogn)，居然和快排一样快！但堆排序实际在生产中用得并不是很多，Java 默认的数组排序（Arrays.sort()）底层也是用的快排，时间复杂度和快排一样快，为啥堆排序却并不受待见呢。主要有以下三个原因：1、快排在递归排序的过程中，都是拿 pivot 与相邻的元素比较，会用到计算机中一个非常重要的定理：局部性原理，啥叫局部性原理，可以简单理解为当 CPU 读取到某个数据的时候，它认为这个数据附近相邻的数据也有很大的概率会被用到，所以干脆把被读取到数据的附近的数据也一起加载到 Cache 中，这样下次还需要再读取数据进行操作时，就直接从 Cache 里拿数据即可（无需再从内存里拿了），数据量大的话，极大地提升了性能。堆排序无法利用局部性原理，为啥呢，我们知道在堆化的过程中，需要不断比较节点与其左右子节点的大小，左右子节点也需要比较其左右节点。。。 如图示：在对节点 2 自上而下的堆化中，其要遍历数组中 4，5，9，10… 中的元素，这些元素并不是相邻元素，无法利用到局部性原理来提升性能 2、我们知道堆排序的一个重要步骤是把堆顶元素移除，重新进行堆化，每次堆化都会导致大量的元素比较，这也是堆排序性能较差的一个原因。 3、堆排序不是稳定排序，因为我们知道在堆化开始前要先把首位和末位元素进行交换，如果这两元素值一样，就可能改变他们原来在数组中的相对顺序，而快排虽然也是不稳定排序，不过可以改进成稳定排序，这一点也是快排优于堆排序的一个重要的点。 四、堆在生产中应用堆排序虽然不常用，但堆在生产中的应用还是很多的，这里我们详细来看堆在生产中的几个重要应用 1、优先级队列我们知道队列都是先进先出的，而在优先级队列中，元素被赋予了权重的概念，权重高的元素优先执行，执行完之后下次再执行权重第二高的元素…，显然用堆来实现优先级队列再合适不过了，只要用一个大顶堆来实现优先级队列即可，当权重最高的队列执行完毕，将其移除（相当于删除堆顶），再选出优先级第二高的元素（堆化让其符合大顶堆的条件），很方便，实际上我们查看源码就知道，Java 中优先级队列 PriorityQueue 就是用堆来实现的。 2、求 TopK 问题怎样求出 n 个元素中前 K 个最大/最小的元素呢。假设我们要求前 K 个最大的元素，我们可以按如下步骤来做 取 n 个元素的前 K 个元素构建一个小顶堆 遍历第 K + 1 到 n 之间的元素，每一个元素都与小顶堆的堆顶元素进行比较，如果小于堆顶元素，不做任何操作，如果大于堆顶元素，则将堆顶元素替换成当前遍历的元素，再堆化以让其满足小顶的要求，这样遍历完成后此小顶堆的所有元素就是我们要求的 TopK。 每个元素堆化的时间复杂度是 O(logK)，n 个元素时间复杂度是 O(nlogK)，还是相当给力的！ 3、TP99 是生产中的一个非常重要的指标，如何快速计算先来解释下什么是 TP99，它指的是在一个时间段内（如 5 分钟），统计某个接口（或方法）每次调用所消耗的时间，并将这些时间按从小到大的顺序进行排序，取第 99% 的那个值作为 TP99 值，举个例子， 假设这个方法在 5 分钟内调用消耗时间为从 1s 到 100s 共 100 个数，则其 TP99 为 99，这个值为啥重要呢，对于某个接口来说，这个值越低，代表 99% 的请求都是非常快的，说明这个接口性能很好，反之，就说明这个接口需要改进，那怎么去求这个值呢？ 思路如下： 创建一个大顶堆和一个小顶堆，大顶堆的堆顶元素比小顶堆的堆顶元素更小，大顶堆维护 99% 的请求时间，小顶堆维护 1% 的请求时间 每产生一个元素（请求时间），如果它比大顶堆的堆顶元素小，则将其放入到大顶堆中，如果它比小顶堆的堆顶元素大，则将其插入到小顶堆中，插入后当然要堆化以让其符合大小顶堆的要求。 上一步在插入的过程中需要注意一下，可能会导致大顶堆和小顶堆中元素的比例不为 99:1，此时就要做相应的调整，如果在将元素插入大顶堆之后，发现比例大于 99：1，将需将大顶堆的堆顶元素移到小顶堆中，再对两个堆堆化以让其符合大小顶堆的要求，同理，如果发现比例小于 99: 1，则需要将小顶堆的堆顶元素移到大顶堆来，再对两者进行堆化。 以上的大小顶堆调整后，则大顶堆的堆顶元素值就是所要求的 TP99 值。 有人可能会说以上的这些应用貌似用快排或其他排序也能实现，没错，确实能实现，但是我们需要注意到，在静态数据下用快排确实没问题，但在动态数据上，如果每插入/删除一个元素对所有的元素进行快排，其实效率不是很高，由于要快排要全量排序，时间复杂度是 O(nlogn)，而堆排序就非常适合这种对于动态数据的排序，对于每个新添加的动态数据，将其插入到堆中，然后进行堆化，时间复杂度只有 O(logK)。 五、总结堆是一种非常重要的数据结构，在对动态数据进行排序时性能很高，优先级队列底层也是普遍采用堆来管理，所以掌握堆的基本操作十分重要。另外我们也知道了 Java 的优先级队列（PriorityQueue）也是用堆来实现的，所以再次说明了掌握基本的数据结构非常重要，对于理解上层应用的底层实现十分有帮助。 六、拓展C++ 实现堆排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Heap{ // 以大顶堆为例 vector&lt;int&gt; heap; public: Heap(){ heap.push_back(0); // 堆的下标从1开始 // C++类中不能直接初始化vector&lt;int&gt; heap(1); 所以写在构造函数中 } int size(){ return heap.size()-1; } bool empty(){ return size() == 0; } int top(){ return heap[1]; } void push(int value){ heap.push_back(value); // 把新元素插到堆的最后 int index = heap.size()-1; // 新元素的下标 // 将新元素向上浮 while(index/2 &gt; 0 &amp;&amp; heap[index] &gt; heap[index/2]) { // 以大顶堆为例, 比父节点大就交换（小顶堆用&lt;) swap(heap[index], heap[index/2]); index /= 2; } } void pop(){ if(empty()) return; // 用最后一个元素覆盖堆顶元素 int heap_size = heap.size()-1; // 堆的大小(因为堆顶是v[1]，所以要减1) swap(heap[1], heap[heap_size]); // 将堆尾元素移到堆顶 heap.pop_back(); // 删除原来的堆顶元素 heap_size--; // 将堆顶元素向下沉 int index = 1; // 堆顶下标 while(true){ int maxValueIndex = index; // 当前节点和左右子节点这三者中最大者的下标 // 以大顶堆为例，若父节点比子节点小，就与较大的子节点交换 if(2*index &lt;= heap_size &amp;&amp; heap[index] &lt; heap[2*index]) // 左子节点比父节点大（小顶堆用&gt;） maxValueIndex = 2*index; if(2*index+1 &lt;= heap_size &amp;&amp; heap[maxValueIndex] &lt; heap[2*index+1]) // 右节点比左节点和父节点都大（小顶堆用&gt;） maxValueIndex = 2*index+1; if(maxValueIndex == index) // 说明当前节点比两个子节点都大，无需再往下迭代了 break; swap(heap[index], heap[maxValueIndex]); index = maxValueIndex; } }}; 使用示例： 12345678910111213141516171819int main(){ Heap heap; // 大顶堆 int a[] = {3,2,5,4,7,9,6,8}; // 依次入堆 for(int i=0;i&lt;8;i++){ heap.push(a[i]); cout&lt;&lt;heap.top()&lt;&lt;\" \"; } cout&lt;&lt;endl; // 依次出堆(会按降序输出,但这不是堆排序,因为堆排序是在原数组上做的) while(!heap.empty()){ cout&lt;&lt;heap.top()&lt;&lt;\" \"; heap.pop(); } return 0;} 原文链接:五分钟学算法：什么是堆？","link":"/post/261f1c1.html"},{"title":"数据结构与算法-链表","text":"链表 一、判断两个单链表是否相交及找到第一个交点如果两个单链表有共同的节点，那么从第一个共同节点开始，后面的节点都会重叠，直到链表结束。因为两个链表中有一个共同节点，则这个节点里的指针域指向的下一个节点地址一样，所以下一个节点也会相交，依次类推。所以，若相交，则两个链表呈“Y”字形。 使用栈可以从头遍历两个链表。创建两个栈，第一个栈存储第一个链表的节点，第二个栈存储第二个链表的节点。每遍历到一个节点时，就将该节点入栈。两个链表都入栈结束后。则通过 top 判断栈顶的节点是否相等即可判断两个单链表是否相交。因为我们知道，若两个链表相交，则从第一个相交节点开始，后面的节点都相交。若两链表相交，则循环出栈，直到遇到两个出栈的节点不相同，则这个节点的后一个节点就是第一个相交的节点。123456789101112node temp = NULL; // 存第一个相交节点while(!stack1.empty() &amp;&amp; !stack2.empty()) // 两栈都不为空{ temp = stack1.pop(); stack1.pop(); stack2.pop(); if(stack1.top() != stack2.top()) { break; }} 遍历链表记录长度同时遍历两个链表到尾部，记录两个链表的长度。若两个链表最后的一个节点相同，则两个链表相交。有两个链表的长度后，我们就可以知道哪个链表长，设较长的链表长度为 len1，较短的链表长度为 len2。则先让较长的链表向后移动 (len1-len2) 个长度。然后开始从当前位置同时遍历两个链表，当遍历到的链表的节点相同时，则这个节点就是第一个相交的节点。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859struct ListNode{ int val; struct ListNode* next; ListNode(int x) : val(x), next(NULL) {}};// 找出第一个相同的节点ListNode* findFirstNode(ListNode* l1, ListNode* l2){ if(l1 == NULL || l2 == NULL) { return NULL; } ListNode* p1, p2; p1 = l1; p2 = l2; int len1 = 0; int len2 = 0; int diff = 0; while(p1-&gt;next != NULL) { p1 = p1-&gt;next; len1++; } while(p2-&gt;next != NULL) { p2 = p2-&gt;next; len2++; } if(p1 != p2) { return NULL; // 如果最后一个节点不相同，返回 NULL } diff = abs(len1 - len2); // 两个移动指针重新变换指向，p1 总是指向较长的链表头，p2 总是指向较短的链表 if(len1 &gt; len2) { p1 = l1; p2 = l2; } else { p1 = l2; p2 = l1; } for(int i = 0; i &lt; diff; i++) { p1 = p1-&gt;next; } while(p1 != p2) { p1 = p1-&gt;next; p2 = p2-&gt;next; } return p1;}// 指向较长链表的指针先移动 diff 距离，因为多出的部分肯定是在第一个相同节点的前面。 哈希表法既然两个个链表一旦相交，相交节点一定有相同的内存地址，而不同的节点内存地址一定是不同的，那么不妨利用内存地址建立哈希表，如此通过判断两个链表中是否存在内存地址相同的节点判断两个链表是否相交。具体做法是：遍历第一个链表，并利用地址建立哈希表，遍历第二个链表，看看地址哈希值是否和第一个表中的节点地址值有相同即可判断两个链表是否相交。可以采用除留取余法构造哈希函数。构造哈希表可以采用链地址法解决冲突。哈希表冲突指对 key1 != key2，存在 f(key1) = f(key2)，链地址法就是把 key1 和 key2 作为节点放在同一个单链表中，这种表称为同义词子表，在哈希表中只存储同义词子表的头指针。 二、链表中环的入口结点如果链表中环有 n 个结点，指针 P1 在链表上向前移动 n 步，然后两个指针以相同的速度向前移动。当第二个指针指向环的入口结点时，第一个指针已经围绕着环走了一圈又回到了入口结点。所以首先要得到环中结点的数目。 Java 版123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class 链表中环的入口结点 { //找到一快一慢指针相遇处的节点，相遇的节点一定是在环中 public static ListNode meetingNode(ListNode head) { if(head==null) return null; ListNode slow = head.next; if(slow==null) return null; ListNode fast = slow.next; while (slow != null &amp;&amp; fast != null) { if(slow==fast){ return fast; } slow=slow.next; fast=fast.next; /* 有问题的？ if(fast!=slow){ fast=fast.next; } */ } return null; } public ListNode EntryNodeOfLoop(ListNode pHead) { ListNode meetingNode=meetingNode(pHead); if(meetingNode==null) return null;// 得到环中的节点个数 int nodesInLoop=1; ListNode p1=meetingNode; while(p1.next!=meetingNode){ p1=p1.next; ++nodesInLoop; }// 移动p1 p1=pHead; for(int i=0;i&lt;nodesInLoop;i++){ p1=p1.next; }// 移动p1，p2 ListNode p2=pHead; while(p1!=p2){ p1=p1.next; p2=p2.next; } return p1; }} C++ 版1234567891011121314151617181920212223242526272829303132333435363738/*struct ListNode { int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) { }};*/ class Solution {public: ListNode* EntryNodeOfLoop(ListNode* pHead) { if(pHead==NULL || pHead-&gt;next==NULL) return NULL; ListNode* pSlow=pHead; ListNode* pFast=pHead; // detect if the linklist is a circle while(pFast!=NULL &amp;&amp; pFast-&gt;next!=NULL){ pSlow=pSlow-&gt;next; pFast=pFast-&gt;next-&gt;next; if(pSlow==pFast) break; } // if it is a circle if(pFast!=NULL){ pSlow=pHead; while(pSlow!=pFast){ pSlow=pSlow-&gt;next;; pFast=pFast-&gt;next; } } return pFast; }}; 参考文章:1、判断两个单链表是否相交及找到第一个交点2、链表中环的入口结点","link":"/post/3402515c.html"},{"title":"TCP网络编程","text":"Linux 下的 TCP 网络编程 零、序一些关于网络编程方面的问题，你会怎样回答呢？ 大家经常说的四层、七层，分别指的是什么？ TCP 三次握手是什么，TIME_WAIT 是怎么发生的？ CLOSE_WAIT 又是什么状态？ Linux 下的 epoll 解决的是什么问题？如何使用 epoll 写出高性能的网络程序？什么是网络事件驱动模型？Reactor 模式又是什么？ 学习高性能网络编程，掌握两个核心要点就可以了：第一就是理解网络协议，并在这个基础上和操作系统内核配合，感知各种网络 I/O 事件；第二就是学会使用线程处理并发。抓住这两个核心问题，也就抓住了高性能网络编程的“七寸”。 要学好网络编程，需要达到以下三个层次。 第一个层次，充分理解 TCP/IP 网络模型和协议。在这方面，仅仅做到理论上的理解是远远不够的。学会梳理 TCP/IP 模型和网络函数接口之间的联系，并通过实例理解套接字、套接字缓冲区、拥塞控制、数据包和数据流，本地套接字（UNIX 域套接字）等，建立一个全面而具体的知识体系。 第二个层次，结合对协议的理解，增强对各种异常情况的优雅处理能力。比如对 TCP 数据流的处理，半关闭的连接，TCP 连接有效性的侦测，处理各种异常情况等，这些问题决定了程序的健壮性。 第三个层次，写出可以支持大规模高并发的网络处理程序。在这个阶段，可以深入研究 C10K 问题，涉及进程、线程、多路复用、非阻塞、异步、事件驱动等现代高性能网络编程所需要的技术。 一、TCP、IP 和 Linux 历史互联网技术里，有两件事最为重要，一个是 TCP/IP 协议，它是万物互联的事实标准；另一个是 Linux 操作系统，它是推动互联网技术走向繁荣的基石。 1.1、TCP互联网起源于阿帕网（ARPANET）。网络控制协议（Network Control Protocol，缩写 NCP）是阿帕网中连接不同计算机的通信协议。 在构建阿帕网（ARPANET）之后，其他数据传输技术的研究又被摆上案头。NCP 诞生两年后，NCP 的开发者温特·瑟夫（Vinton Cerf）和罗伯特·卡恩（Robert E. Kahn）一起开发了一个阿帕网的下一代协议，并在 1974 年发表了以分组、序列化、流量控制、超时和容错等为核心的一种新型的网络互联协议，一举奠定了 TCP/IP 协议的基础。 TCP/IP 的成功不是偶然的，而是综合了几个因素后的结果： TCP/IP 是免费或者是少量收费的，这样就扩大了使用人群； TCP/IP 搭上了 UNIX 这辆时代快车，很快推出了基于套接字（socket）的实际编程接口；这是最重要的一点，TCP/IP 来源于实际需求，大家都在翘首盼望出一个统一标准，可是在此之前实际的问题总要解决啊，TCP/IP 解决了实际问题，并且在实际中不断完善。 1.2、UNIXUNIX 的各种版本和变体都起源于在 PDP-11 系统上运行的 UNIX 分时系统第 6 版（1976 年）和第 7 版（1979 年），它们通常分别被称为 V6 和 V7。这两个版本是在贝尔实验室以外首先得到广泛应用的 UNIX 系统。 主要从这张图上看 3 个分支： 图上标示的 Research 橘黄色部分，是由 AT&amp;T 贝尔实验室不断开发的 UNIX 研究版本，从此引出 UNIX 分时系统第 8 版、第 9 版，终止于 1990 年的第 10 版（10.5）。这个版本可以说是操作系统界的少林派。天下武功皆出少林，世上 UNIX 皆出自贝尔实验室。 图中最上面所标识的操作系统版本，是加州大学伯克利分校（BSD）研究出的分支，从此引出 4.xBSD 实现，以及后面的各种 BSD 版本。这个可以看做是学院派。在历史上，学院派有力地推动了 UNIX 的发展，包括我们后面会谈到的 socket 套接字都是出自此派。 图中最下面的那一个部分，是从 AT&amp;T 分支的商业派，致力于从 UNIX 系统中谋取商业利润。从此引出了 System III 和 System V（被称为 UNIX 的商用版本），还有各大公司的 UNIX 商业版。 下面这张图也是源自维基百科，将 UNIX 的历史表达得更为详细。 一个基本事实是，网络编程套接字接口，最早是在 BSD 4.2 引入的，这个时间大概是 1983 年，几经演变后，成为了事实标准，包括 System III/V 分支也吸收了这部分能力，在上面这张大图上也可以看出来。 1.3、操作系统对 TCP/IP 的支持下图展示了 TCP/IP 在各大操作系统的演变历史。可以看到，即使是大名鼎鼎的 Linux 以及 90 年代大发光彩的 Windows 操作系统，在 TCP/IP 网络这块，也只能算是一个后来者。 二、客户端 - 服务器网络编程模型拿我们常用的网络购物来说，我们在手机上的每次操作，都是作为客户端向服务器发送请求，并收到响应的例子。（整个过程和 TCP/IP 四次挥手过程有点类似） 当一个客户端需要服务时，比如网络购物下单，它会向服务器端发送一个请求。注意，这个请求是按照双方约定的格式来发送的，以便保证服务器端是可以理解的； 服务器端收到这个请求后，会根据双方约定的格式解释它，并且以合适的方式进行操作，比如调用数据库操作来创建一个购物单； 服务器端完成处理请求之后，会给客户端发送一个响应，比如向客户端发送购物单的实际付款额，然后等待客户端的下一步操作； 客户端收到响应并进行处理，比如在手机终端上显示该购物单的实际付款额，并且让用户选择付款方式。 无论是客户端，还是服务器端，它们运行的单位都是进程（process），而不是机器。一个客户端，比如我们的手机终端，同一个时刻可以建立多个到不同服务器的连接，比如同时打游戏，上知乎，逛天猫；而服务器端更是可能在一台机器上部署运行了多个服务，比如同时开启了 SSH 服务和 HTTP 服务。 2.1、IP 和端口端口号是一个 16 位的整数，最多为 65536。当一个客户端发起连接请求时，客户端的端口是由操作系统内核临时分配的，称为临时端口；然而，服务器端的端口通常是一个众所周知的端口。 一个连接可以通过客户端 - 服务器端的 IP 和端口唯一确定，这叫做套接字对，按照下面的四元组表示： 1(clientaddr:clientport, serveraddr:serverport) 2.2、保留网段国际标准组织在 IPv4 地址空间里面，专门划出了一些网段，这些网段不会用做公网上的 IP，而是仅仅保留作内部使用，我们把这些地址称作保留网段。 2.3、子网掩码第一是网络（network）的概念，直观点说，它表示的是这组 IP 共同的部分，比如在 192.168.1.1~192.168.1.255 这个区间里，它们共同的部分是 192.168.1.0。 第二是主机（host）的概念，它表示的是这组 IP 不同的部分，上面的例子中 1~255 就是不同的那些部分，表示有 255 个可用的不同 IP。 网络地址位数由子网掩码（Netmask）决定，你可以将 IP 地址与子网掩码进行“位与”操作，就能得到网络的值。子网掩码一般看起来像是 255.255.255.0（二进制为 11111111.11111111.11111111.00000000），比如你的 IP 是 192.0.2.12，使用这个子网掩码时，你的网络就会是 192.0.2.12 与 255.255.255.0 所得到的值：192.0.2.0，192.0.2.0 就是这个网络的值。 子网掩码能接受任意个位，而不单纯是上面讨论的 8，16 或 24 个比特而已。所以你可以有一个子网掩码 255.255.255.252（二进制位 11111111.11111111.11111111.11111100），这个子网掩码能切出一个 30 个位的网络以及 2 个位的主机，这个网络最多有四台 host。为什么是 4 台 host 呢？因为变化的部分只有最后两位，所有的可能为 2 的 2 次方，即 4 台 host。注意，子网掩码的格式永远都是二进制格式：前面是一连串的 1，后面跟着一连串的 0。 2.4、全球域名系统全球域名按照从大到小的结构，形成了一棵树状结构。实际访问一个域名时，是从最底层开始写起，例如 www.google.com，www.tinghua.edu.cn 等。 2.5、数据报和字节流TCP，又被叫做字节流套接字（Stream Socket），注意我们这里先引入套接字 socket，套接字 socket 在后面几讲中将被反复提起，因为它实际上是网络编程的核心概念。当然，UDP 也有一个类似的叫法, 数据报套接字（Datagram Socket），一般分别以“SOCK_STREAM”与“SOCK_DGRAM”分别来表示 TCP 和 UDP 套接字。 TCP（Transmission Control Protocol）通过诸如连接管理，拥塞控制，数据流与窗口管理，超时和重传等一系列精巧而详细的设计，提供了高质量的端到端的通信方式。 UDP 在很多场景也得到了极大的应用，比如多人联网游戏、视频会议，甚至聊天室。如果你听说过 NTP，你一定很惊讶 NTP 也是用 UDP 实现的。 使用 UDP 的原因，第一是速度，第二还是速度。 想象一下，一个有上万人的联网游戏，如果要给每个玩家同步游戏中其他玩家的位置信息，而且丢失一两个也不会造成多大的问题，那么 UDP 是一个比较经济合算的选择。 还有一种叫做广播或多播的技术，就是向网络中的多个节点同时发送信息，这个时候，选择 UDP 更是非常合适的。 UDP 也可以做到更高的可靠性，只不过这种可靠性，需要应用程序进行设计处理，比如对报文进行编号，设计 Request-Ack 机制，再加上重传等，在一定程度上可以达到更为高可靠的 UDP 程序。当然，这种可靠性和 TCP 相比还是有一定的距离，不过也可以弥补实战中 UDP 的一些不足。 2.6 思考题 172.16.0.0172.31.255.255，因为 b 类网络的 host 只占最后两个字节，172.16172.31就代表了16个连续的 b 类网络可用。 192.168.0.0~192.168.255.255，因为 c 类网络的 host 只占最后一个字节，所以从192.168.0到192.168.255，就有256个连续的 c 类网络可用。 服务器可以监听的端口有从0到65535，理论上这台服务器的这个端口只要没被占用，你都可以给服务器绑定。 如果是一些默认的服务，服务器绑的也是默认的端口，那么客户端是可以知道的。比如80是给 http 服务，443是给 https 服务，21是给 ftp 服务等。否则的话，就需要服务器开发者告诉客户端应该连接哪个端口。 三、套接字和地址socket 这个英文单词的原意是“插口”“插槽”， 在网络编程中，它的寓意是可以通过插口接入的方式，快速完成网络连接和数据收发。你可以把它想象成现实世界的电源插口，或者是早期上网需要的网络插槽，所以 socket 也可以看做是对物理世界的直接映射。 3.1、socket 到底是什么？ 客户端发起连接请求之前，服务器端必须初始化好。右侧的图显示的是服务器端初始化的过程，首先初始化 socket，之后服务器端需要执行 bind 函数，将自己的服务能力绑定在一个众所周知的地址和端口上，紧接着，服务器端执行 listen 操作，将原先的 socket 转化为服务端的 socket，服务端最后阻塞在 accept 上等待客户端请求的到来。 客户端需要先初始化 socket，再执行 connect 向服务器端的地址和端口发起连接请求，这里的地址和端口必须是客户端预先知晓的。这个过程，就是著名的 TCP 三次握手（Three-way Handshake）。 一旦三次握手完成，客户端和服务器端建立连接，就进入了数据传输过程。 客户端进程向操作系统内核发起 write 字节流写操作，内核协议栈将字节流通过网络设备传输到服务器端，服务器端从内核得到信息，将字节流从内核读入到进程中，并开始业务逻辑的处理，完成之后，服务器端再将得到的结果以同样的方式写给客户端。可以看到，一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是 TCP 的一个显著特性。 当客户端完成和服务器端的交互后，比如执行一次 Telnet 操作，或者一次 HTTP 请求，需要和服务器端断开连接时，就会执行 close 函数，操作系统内核此时会通过原先的连接链路向服务器端发送一个 FIN 包，服务器收到之后执行被动关闭，这时候整个链路处于半关闭状态，此后，服务器端也会执行 close 函数，整个链路才会真正关闭。半关闭的状态下，发起 close 请求的一方在没有收到对方 FIN 包之前都认为连接是正常的；而在全关闭的状态下，双方都感知连接已经关闭。 你可以把整个 TCP 的网络交互和数据传输想象成打电话，顺着这个思路想象，socket 就好像是我们手里的电话机，connect 就好比拿着电话机拨号，而服务器端的 bind 就好比是去电信公司开户，将电话号码和我们家里的电话机绑定，这样别人就可以用这个号码找到你，listen 就好似人们在家里听到了响铃，accept 就好比是被叫的一方拿起电话开始应答。至此，三次握手就完成了，连接建立完毕。 接下来，拨打电话的人开始说话：“你好。”这时就进入了 write，接收电话的人听到的过程可以想象成 read（听到并读出数据），并且开始应答，双方就进入了 read/write 的数据传输过程。 3.2、套接字地址格式1234567/* POSIX.1g 规范规定了地址族为2字节的值. */typedef unsigned short int sa_family_t;/* 描述通用套接字地址 */struct sockaddr{ sa_family_t sa_family; /* 地址族 16-bit */ char sa_data[14]; /* 具体的地址值 112-bit */ }; 在这个结构体里，第一个字段是地址族，它表示使用什么样的方式对地址进行解释和保存，好比电话簿里的手机格式，或者是固话格式，这两种格式的长度和含义都是不同的。地址族在 glibc 里的定义非常多，常用的有以下几种： AF_LOCAL：表示的是本地地址，对应的是 Unix 套接字，这种情况一般用于本地 socket 通信，很多情况下也可以写成 AF_UNIX、AF_FILE； AF_INET：因特网使用的 IPv4 地址； AF_INET6：因特网使用的 IPv6 地址。 这里的 AF_ 表示的含义是 Address Family，但是很多情况下，我们也会看到以 PF_ 表示的宏，比如 PF_INET、PF_INET6 等，实际上 PF_ 的意思是 Protocol Family，也就是协议族的意思。我们用 AF_xxx 这样的值来初始化 socket 地址，用 PF_xxx 这样的值来初始化 socket。我们在 头文件中可以清晰地看到，这两个值本身就是一一对应的。 1234567891011121314/* 各种地址族的宏定义 */#define AF_UNSPEC PF_UNSPEC#define AF_LOCAL PF_LOCAL#define AF_UNIX PF_UNIX#define AF_FILE PF_FILE#define AF_INET PF_INET#define AF_AX25 PF_AX25#define AF_IPX PF_IPX#define AF_APPLETALK PF_APPLETALK#define AF_NETROM PF_NETROM#define AF_BRIDGE PF_BRIDGE#define AF_ATMPVC PF_ATMPVC#define AF_X25 PF_X25#define AF_INET6 PF_INET6 3.3、IPv4 套接字格式地址1234567891011121314151617/* IPV4套接字地址，32bit值. */typedef uint32_t in_addr_t;struct in_addr{ in_addr_t s_addr;}; /* 描述IPV4的套接字地址格式 */struct sockaddr_in{ sa_family_t sin_family; /* 16-bit */ in_port_t sin_port; /* 端口口 16-bit*/ struct in_addr sin_addr; /* Internet address. 32-bit */ /* 这里仅仅用作占位符，不做实际用处 */ unsigned char sin_zero[8];}; 接下来是端口号，我们可以看到端口号最多是 16-bit，也就是说最大支持 2 的 16 次方，这个数字是 65536，所以我们应该知道支持寻址的端口号最多就是 65535。所谓保留端口就是大家约定俗成的，已经被对应服务广为使用的端口，比如 ftp 的 21 端口，ssh 的 22 端口，http 的 80 端口等。一般而言，大于 5000 的端口可以作为我们自己应用程序的端口使用。 123456789101112131415161718192021222324252627282930313233343536373839404142/* Standard well-known ports. */enum { IPPORT_ECHO = 7, /* Echo service. */ IPPORT_DISCARD = 9, /* Discard transmissions service. */ IPPORT_SYSTAT = 11, /* System status service. */ IPPORT_DAYTIME = 13, /* Time of day service. */ IPPORT_NETSTAT = 15, /* Network status service. */ IPPORT_FTP = 21, /* File Transfer Protocol. */ IPPORT_TELNET = 23, /* Telnet protocol. */ IPPORT_SMTP = 25, /* Simple Mail Transfer Protocol. */ IPPORT_TIMESERVER = 37, /* Timeserver service. */ IPPORT_NAMESERVER = 42, /* Domain Name Service. */ IPPORT_WHOIS = 43, /* Internet Whois service. */ IPPORT_MTP = 57, IPPORT_TFTP = 69, /* Trivial File Transfer Protocol. */ IPPORT_RJE = 77, IPPORT_FINGER = 79, /* Finger service. */ IPPORT_TTYLINK = 87, IPPORT_SUPDUP = 95, /* SUPDUP protocol. */ IPPORT_EXECSERVER = 512, /* execd service. */ IPPORT_LOGINSERVER = 513, /* rlogind service. */ IPPORT_CMDSERVER = 514, IPPORT_EFSSERVER = 520, /* UDP ports. */ IPPORT_BIFFUDP = 512, IPPORT_WHOSERVER = 513, IPPORT_ROUTESERVER = 520, /* Ports less than this value are reserved for privileged processes. */ IPPORT_RESERVED = 1024, /* Ports greater this value are reserved for (non-privileged) servers. */ IPPORT_USERRESERVED = 5000 3.4、IPv6 套接字地址格式12345678struct sockaddr_in6{ sa_family_t sin6_family; /* 16-bit */ in_port_t sin6_port; /* 传输端口号 # 16-bit */ uint32_t sin6_flowinfo; /* IPv6 流控信息 32-bit*/ struct in6_addr sin6_addr; /* IPv6 地址128-bit */ uint32_t sin6_scope_id; /* IPv6 域 ID 32-bit */}; 整个结构体长度是 28 个字节，其中流控信息和域 ID 先不用管，这两个字段，一个在 glibc 的官网上根本没出现，另一个是当前未使用的字段。这里的地址族显然应该是 AF_INET6，端口同 IPv4 地址一样，关键的地址从 32 位升级到 128 位，这个数字就大到恐怖了，完全解决了寻址数字不够的问题。 请注意，以上无论 IPv4 还是 IPv6 的地址格式都是因特网套接字的格式，还有一种本地套接字格式，用来作为本地进程间的通信，也就是前面提到的 AF_LOCAL。 1234struct sockaddr_un { unsigned short sun_family; /* 固定为 AF_LOCAL */ char sun_path[108]; /* 路径名 */}; 3.5 几种套接字地址格式比较IPv4 和 IPv6 套接字地址结构的长度是固定的，而本地地址结构的长度是可变的。 3.6、思考题 像 sock_addr 的结构体里描述的那样，几种套接字都要有地址族和地址两个字段。这容易理解，你要与外部通信，肯定要至少告诉计算机对方的地址和使用的是哪一种地址。与远程计算机的通信还需要一个端口号。而本地 socket 的不同之处在于不需要端口号，那么就有了问题2; 本地 socket 本质上是在访问本地的文件系统，所以自然不需要端口。远程 socket 是直接将一段字节流发送到远程计算机的一个进程，而远程计算机可能同时有多个进程在监听，所以用端口号标定要发给哪一个进程。 五、非阻塞 IO非阻塞 I/O 配合 I/O 多路复用，是高性能网络编程中的常见技术。 5.1、阻塞 VS 非阻塞当应用程序调用阻塞 I/O 完成某个操作时，应用程序会被挂起，等待内核完成操作，感觉上应用程序像是被“阻塞”了一样。实际上，内核所做的事情是将 CPU 时间切换给其他有需要的进程，网络应用程序在这种情况下就会得不到 CPU 时间做该做的事情。 当应用程序调用非阻塞 I/O 完成某个操作时，内核立即返回，不会把 CPU 时间切换给其他进程，应用程序在返回后，可以得到足够的 CPU 时间继续完成其他事情。 如果拿去书店买书举例子，阻塞 I/O 对应什么场景呢？你去了书店，告诉老板（内核）你想要某本书，然后你就一直在那里等着，直到书店老板翻箱倒柜找到你想要的书，有可能还要帮你联系全城其它分店。注意，这个过程中你一直滞留在书店等待老板的回复，好像在书店老板这里”阻塞”住了。 那么非阻塞 I/O 呢？你去了书店，问老板有没你心仪的那本书，老板查了下电脑，告诉你没有，你就悻悻离开了。一周以后，你又来这个书店，再问这个老板，老板一查，有了，于是你买了这本书。注意，这个过程中，你没有被阻塞，而是在不断轮询。 但轮询的效率太低了，于是你向老板提议：“老板，到货给我打电话吧，我再来付钱取书。”这就是前面讲到的 I/O 多路复用。 再进一步，你连去书店取书也想省了，得了，让老板代劳吧，你留下地址，付了书费，让老板到货时寄给你，你直接在家里拿到就可以看了。这就是异步 I/O。 这几个 I/O 模型，再加上进程、线程模型，构成了整个网络编程的知识核心。 按照使用场景，非阻塞 I/O 可以被用到读操作、写操作、接收连接操作和发起连接操作上。接下来，我们对它们一一解读。 5.2、非阻塞 I/O读操作 如果套接字对应的接收缓冲区没有数据可读，在非阻塞情况下 read 调用会立即返回，一般返回 EWOULDBLOCK 或 EAGAIN 出错信息。在这种情况下，出错信息需要小心处理，比如后面再次调用 read 操作，而不是直接作为错误直接返回。这就好像去书店买书没买到离开一样，需要不断进行又一次轮询处理。 写操作 在阻塞 I/O 情况下，write 函数返回的字节数，和输入的参数总是一样的。如果返回值总是和输入的数据大小一样，write 等写入函数还需要定义返回值吗？ 在非阻塞 I/O 的情况下，如果套接字的发送缓冲区已达到了极限，不能容纳更多的字节，那么操作系统内核会尽最大可能从应用程序拷贝数据到发送缓冲区中，并立即从 write 等函数调用中返回。可想而知，在拷贝动作发生的瞬间，有可能一个字符也没拷贝，有可能所有请求字符都被拷贝完成，那么这个时候就需要返回一个数值，告诉应用程序到底有多少数据被成功拷贝到了发送缓冲区中，应用程序需要再次调用 write 函数，以输出未完成拷贝的字节。 write 等函数是可以同时作用到阻塞 I/O 和非阻塞 I/O 上的，为了复用一个函数，处理非阻塞和阻塞 I/O 多种情况，设计出了写入返回值，并用这个返回值表示实际写入的数据大小。 非阻塞 I/O 和阻塞 I/O 处理的方式是不一样的。 非阻塞 I/O 需要这样：拷贝→返回→再拷贝→再返回。 而阻塞 I/O 需要这样：拷贝→直到所有数据拷贝至发送缓冲区完成→返回。 12345678910111213141516171819202122232425/* 向文件描述符fd写入n字节数 */ssize_t writen(int fd, const void * data, size_t n){ size_t nleft; ssize_t nwritten; const char *ptr; ptr = data; nleft = n; //如果还有数据没被拷贝完成，就一直循环 while (nleft &gt; 0) { if ( (nwritten = write(fd, ptr, nleft)) &lt;= 0) { /* 这里EAGAIN是非阻塞non-blocking情况下，通知我们再次调用write() */ if (nwritten &lt; 0 &amp;&amp; errno == EAGAIN) nwritten = 0; else return -1; /* 出错退出 */ } /* 指针增大，剩下字节数变小*/ nleft -= nwritten; ptr += nwritten; } return n;} read 和 write 在阻塞模式和非阻塞模式下的不同行为特性： read 总是在接收缓冲区有数据时就立即返回，不是等到应用程序给定的数据充满才返回。当接收缓冲区为空时，阻塞模式会等待，非阻塞模式立即返回 -1，并有 EWOULDBLOCK 或 EAGAIN 错误。 和 read 不同，阻塞模式下，write 只有在发送缓冲区足以容纳应用程序的输出字节时才返回；而非阻塞模式下，则是能写入多少就写入多少，并返回实际写入的字节数。 阻塞模式下的 write 有个特例，就是对方主动关闭了套接字，这个时候 write 调用会立即返回，并通过返回值告诉应用程序实际写入的字节数，如果再次对这样的套接字进行 write 操作，就会返回失败。失败是通过返回值 -1 来通知到应用程序的。 参考文章:网络编程实战","link":"/post/6af8bd79.html"},{"title":"epoll实现原理分析(转载)","text":"epoll 是 Linux 平台下的一种特有的多路复用 IO 实现方式，与传统的 select、poll 相比，epoll 在性能上有很大的提升。 epoll 可以说是和 poll 非常相似的一种 I/O 多路复用技术，有些朋友将 epoll 归为异步 I/O，我觉得这是不正确的。本质上 epoll 还是一种 I/O 多路复用技术， epoll 通过监控注册的多个描述字，来进行 I/O 事件的分发处理。不同于 poll 的是，epoll 不仅提供了默认的 level-triggered（水平触发）机制，还提供了性能更为强劲的 edge-triggered（边缘触发）机制。 一、epoll 的用法使用 epoll 进行网络程序的编写，需要三个步骤，分别是 epoll_create，epoll_ctl 和 epoll_wait。 epoll_create123int epoll_create(int size);int epoll_create1(int flags); 返回值: 若成功返回一个大于0的值，表示 epoll 实例；若返回-1表示出错 epoll_create() 方法创建了一个 epoll 实例，参数 size 是由于历史原因遗留下来的，现在不起作用。从 Linux 2.6.8 开始，参数 size 被自动忽略，但是该值仍需要一个大于 0 的整数。这个 epoll 实例被用来调用 epoll_ctl 和 epoll_wait，如果这个 epoll 实例不再需要，比如服务器正常关机，需要调用 close() 方法释放 epoll 实例，这样系统内核可以回收 epoll 实例所分配使用的内核资源。 epoll_create1() 的用法和 epoll_create() 基本一致，如果 epoll_create1() 的输入 flags 为 0，则和 epoll_create() 一样，内核自动忽略。可以增加如 EPOLL_CLOEXEC 的额外选项。 epoll_ctl12int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 返回值: 若成功返回0；若返回-1表示出错 在创建完 epoll 实例之后，可以通过调用 epoll_ctl 往这个 epoll 实例增加或删除对应文件描述符监控的事件。函数 epll_ctl 有 4 个入口参数。 第一个参数 epfd 是刚刚调用 epoll_create 创建的 epoll 实例描述字，可以简单理解成是 epoll 句柄。 第二个参数表示增加，删除还是修改一个监控事件，它有三个选项可供选择： EPOLL_CTL_ADD：向 epoll 实例注册文件描述符对应的事件； EPOLL_CTL_DEL：向 epoll 实例删除文件描述符对应的事件； EPOLL_CTL_MOD：修改文件描述符对应的事件。 第三个参数是注册的事件的文件描述符，比如一个监听套接字。 第四个参数表示的是注册的事件类型，并且可以在这个结构体里设置用户需要的数据，其中最为常见的是使用联合结构里的 fd 字段，表示事件所对应的文件描述符。 1234567891011typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; 这里 epoll 仍旧使用了基于 mask 的事件类型，我们重点看一下这几种事件类型： EPOLLIN：表示对应的文件描述字可以读； EPOLLOUT：表示对应的文件描述字可以写； EPOLLRDHUP：表示套接字的一端已经关闭，或者半关闭； EPOLLHUP：表示对应的文件描述字被挂起； EPOLLET：设置为 edge-triggered（边缘触发），默认为 level-triggered（水平触发）。 epoll_wait12int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 返回值: 成功返回的是一个大于0的数，表示事件的个数；返回0表示的是超时时间到；若出错返回-1. epoll_wait() 函数类似之前的 poll 和 select 函数，调用者进程被挂起，在等待内核 I/O 事件的分发。 这个函数的第一个参数是 epoll 实例描述字，也就是 epoll 句柄。 第二个参数返回给用户空间需要处理的 I/O 事件，这是一个数组，数组的大小由 epoll_wait 的返回值决定，这个数组的每个元素都是一个需要待处理的 I/O 事件，其中 epoll_event.events 表示具体的事件类型，事件类型取值和 epoll_ctl 可设置的值一样，这个 epoll_event 结构体里的 data 值就是在 epoll_ctl 那里设置的 data，也就是用户空间和内核空间调用时需要的数据。 第三个参数是一个大于 0 的整数，表示 epoll_wait 可以返回的最大事件值。 第四个参数是 epoll_wait 阻塞调用的超时值，如果这个值设置为 -1，表示不超时；如果设置为 0 则立即返回，即使没有任何 I/O 事件发生。 二、epoll 实例实例代码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include \"lib/common.h\"#define MAXEVENTS 128// 旋转字符char rot13_char(char c) { if ((c &gt;= 'a' &amp;&amp; c &lt;= 'm') || (c &gt;= 'A' &amp;&amp; c &lt;= 'M')) return c + 13; else if ((c &gt;= 'n' &amp;&amp; c &lt;= 'z') || (c &gt;= 'N' &amp;&amp; c &lt;= 'Z')) return c - 13; else return c;}int main(int argc, char **argv) { int listen_fd, socket_fd; int n, i; int efd; struct epoll_event event; struct epoll_event *events; listen_fd = tcp_nonblocking_server_listen(SERV_PORT); efd = epoll_create1(0); if (efd == -1) { error(1, errno, \"epoll create failed\"); } event.data.fd = listen_fd; event.events = EPOLLIN | EPOLLET; if (epoll_ctl(efd, EPOLL_CTL_ADD, listen_fd, &amp;event) == -1) { error(1, errno, \"epoll_ctl add listen fd failed\"); } /* Buffer where events are returned */ events = calloc(MAXEVENTS, sizeof(event)); while (1) { n = epoll_wait(efd, events, MAXEVENTS, -1); printf(\"epoll_wait wakeup\\n\"); for (i = 0; i &lt; n; i++) { if ((events[i].events &amp; EPOLLERR) || (events[i].events &amp; EPOLLHUP) || (!(events[i].events &amp; EPOLLIN))) { fprintf(stderr, \"epoll error\\n\"); close(events[i].data.fd); continue; } else if (listen_fd == events[i].data.fd) { struct sockaddr_storage ss; socklen_t slen = sizeof(ss); int fd = accept(listen_fd, (struct sockaddr *) &amp;ss, &amp;slen); if (fd &lt; 0) { error(1, errno, \"accept failed\"); } else { make_nonblocking(fd); event.data.fd = fd; event.events = EPOLLIN | EPOLLET; //edge-triggered if (epoll_ctl(efd, EPOLL_CTL_ADD, fd, &amp;event) == -1) { error(1, errno, \"epoll_ctl add connection fd failed\"); } } continue; } else { socket_fd = events[i].data.fd; printf(\"get event on socket fd == %d \\n\", socket_fd); while (1) { char buf[512]; if ((n = read(socket_fd, buf, sizeof(buf))) &lt; 0) { if (errno != EAGAIN) { error(1, errno, \"read error\"); close(socket_fd); } break; } else if (n == 0) { close(socket_fd); break; } else { for (i = 0; i &lt; n; ++i) { buf[i] = rot13_char(buf[i]); } if (write(socket_fd, buf, n) &lt; 0) { error(1, errno, \"write error\"); } } } } } } free(events); close(listen_fd);} 程序的第 116 行调用 epoll_create1(0) 创建了一个 epoll 实例。 第 121-125 行，调用 epoll_ctl 将监听套接字对应的 I/O 事件进行了注册，这样在有新的连接建立之后，就可以感知到。注意这里使用的是 edge-triggered（边缘触发）。 第 128 行为返回的 event 数组使用 calloc 分配了内存。 主循环调用 epoll_wait 函数分发 I/O 事件，当 epoll_wait 成功返回时，通过遍历返回的 event 数组，就直接可以知道发生的 I/O 事件。 第 134-139 行判断了返回的事件各种错误情况。 第 140-154 行是监听套接字上有事件发生的情况下，调用 accept 获取已建立连接，并将该连接设置为非阻塞，再调用 epoll_ctl 把已连接套接字对应的可读事件注册到 epoll 实例中。这里我们使用了 event_data 里面的 fd 字段，将连接套接字存储其中。 第 156-177 行，处理了已连接套接字上的可读事件，读取字节流，编码后再回应给客户端。 实验启动 epoll 服务器 1234567891011121314151617$./epoll01epoll_wait wakeupepoll_wait wakeupepoll_wait wakeupget event on socket fd == 6epoll_wait wakeupget event on socket fd == 5epoll_wait wakeupget event on socket fd == 5epoll_wait wakeupget event on socket fd == 6epoll_wait wakeupget event on socket fd == 6epoll_wait wakeupget event on socket fd == 6epoll_wait wakeupget event on socket fd == 5 再启动几个 telnet 客户端，可以看到有连接建立情况下，epoll_wait 迅速从挂起状态结束；并且套接字上有数据可读时，epoll_wait 也迅速结束挂起状态，这时候通过 read 可以读取套接字接收缓冲区上的数据。 123456789$telnet 127.0.0.1 43211Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.fasfsafassnfsfnsnf^]telnet&gt; quitConnection closed. edge-triggered VS level-triggered对于 edge-triggered 和 level-triggered，一个是边缘触发，一个是水平触发。也有文章从电子脉冲角度来解读的，总体上，给初学者的带来的感受是理解上有困难。 这里有两个程序，我们用这个程序来说明一下这两者之间的不同。 在这两个程序里，即使已连接套接字上有数据可读，我们也不调用 read 函数去读，只是简单地打印出一句话。 第一个程序我们设置为 edge-triggered，即边缘触发。开启这个服务器程序，用 telnet 连接上，输入一些字符，我们看到，服务器端只从 epoll_wait 中苏醒过一次，就是第一次有数据可读的时候。 1234$./epoll02epoll_wait wakeupepoll_wait wakeupget event on socket fd == 5 12345$telnet 127.0.0.1 43211Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.asfafas 第二个程序我们设置为 level-triggered，即水平触发。然后按照同样的步骤来一次，观察服务器端，这一次我们可以看到，服务器端不断地从 epoll_wait 中苏醒，告诉我们有数据需要读取。 1234567891011$./epoll03epoll_wait wakeupepoll_wait wakeupget event on socket fd == 5epoll_wait wakeupget event on socket fd == 5epoll_wait wakeupget event on socket fd == 5epoll_wait wakeupget event on socket fd == 5... 这就是两者的区别，水平触发的意思是只要满足事件的条件，比如有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。 一般我们认为，边缘触发的效率比条件触发的效率要高，这一点也是 epoll 的杀手锏之一。 三、底层实现分析基本的数据结构在开始研究源代码之前，我们先看一下 epoll 中使用的数据结构，分别是 eventpoll、epitem 和 eppoll_entry。 我们先看一下 eventpoll 这个数据结构，这个数据结构是我们在调用 epoll_create 之后内核侧创建的一个句柄，表示了一个 epoll 实例。后续如果我们再调用 epoll_ctl 和 epoll_wait 等，都是对这个 eventpoll 数据进行操作，这部分数据会被保存在 epoll_create 创建的匿名文件 file 的 private_data 字段中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/* * This structure is stored inside the \"private_data\" member of the file * structure and represents the main data structure for the eventpoll * interface. */struct eventpoll { /* Protect the access to this structure */ spinlock_t lock; /* * This mutex is used to ensure that files are not removed * while epoll is using them. This is held during the event * collection loop, the file cleanup path, the epoll file exit * code and the ctl operations. */ /* 添加、修改或者删除监听 fd 的时候，以及 epoll_wait 返回，向用户空间 * 传递数据时都会持有这个互斥锁，所以在用户空间可以放心的在多个线程 * 中同时执行 epoll 相关的操作，内核级已经做了保护。 */ struct mutex mtx; /* Wait queue used by sys_epoll_wait() */ //这个队列里存放的是执行epoll_wait从而等待的进程队列 wait_queue_head_t wq; /* Wait queue used by file-&gt;poll() */ //这个队列里存放的是该eventloop作为poll对象的一个实例，加入到等待的队列 //这是因为eventpoll本身也是一个file, 所以也会有poll操作 wait_queue_head_t poll_wait; /* List of ready file descriptors */ //这里存放的是事件就绪的fd列表，链表的每个元素是下面的epitem struct list_head rdllist; /* RB tree root used to store monitored fd structs */ //这是用来快速查找fd的红黑树 struct rb_root_cached rbr; /* * This is a single linked list that chains all the \"struct epitem\" that * happened while transferring ready events to userspace w/out * holding -&gt;lock. */ struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ struct user_struct *user; //这是eventloop对应的匿名文件，充分体现了Linux下一切皆文件的思想 struct file *file; /* used to optimize loop detection check */ int visited; struct list_head visited_list_link;#ifdef CONFIG_NET_RX_BUSY_POLL /* used to track busy poll napi_id */ unsigned int napi_id;#endif}; 下图展示了 eventpoll 对象与被监听的文件关系： 每当我们调用 epoll_ctl 增加一个 fd 时，内核就会为我们创建出一个 epitem 实例，并且把这个实例作为红黑树的一个子节点，增加到 eventpoll 结构体中的红黑树中，对应的字段是 rbr。这之后，查找每一个 fd 上是否有事件发生都是通过红黑树上的 epitem 来操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * Each file descriptor added to the eventpoll interface will * have an entry of this type linked to the \"rbr\" RB tree. * Avoid increasing the size of this struct, there can be many thousands * of these on a server and we do not want this to take another cache line. */struct epitem { union { /* RB tree node links this structure to the eventpoll RB tree */ /* rb_node，当使用 epoll_ctl() 将一批 fds 加入到某个 epollfd 时，内核会分配 * 一批的 epitem 与 fds 们对应，而且它们以 rb_tree 的形式组织起来，tree 的 root * 保存在 epollfd，也就是 struct eventpoll 中。 * 在这里使用 rb_tree 的原因我认为是提高查找、插入以及删除的速度。 * rb_tree 对以上3个操作都具有O(logN)的时间复杂度 */ struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; }; /* List header used to link this structure to the eventpoll ready list */ //将这个epitem连接到eventpoll 里面的rdllist的list指针 struct list_head rdllink; /* * Works together \"struct eventpoll\"-&gt;ovflist in keeping the * single linked chain of items. */ struct epitem *next; /* The file descriptor information this item refers to */ //epoll监听的fd struct epoll_filefd ffd; /* Number of active wait queue attached to poll operations */ //一个文件可以被多个epoll实例所监听，这里就记录了当前文件被监听的次数 int nwait; /* List containing poll wait queues */ struct list_head pwqlist; /* The \"container\" of this item */ //当前epollitem所属的eventpoll struct eventpoll *ep; /* List header used to link this item to the \"struct file\" items list */ struct list_head fllink; /* wakeup_source used when EPOLLWAKEUP is set */ struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ /* 当前的 epitem 关心哪些 events，这个数据是调用 epoll_ctl 时从用户态传递过来 */ struct epoll_event event;}; 每次当一个 fd 关联到一个 epoll 实例，就会有一个 eppoll_entry 产生。eppoll_entry 的结构如下： 12345678910111213141516171819/* Wait structure used by the poll hooks *//* poll 所用到的钩子 */struct eppoll_entry { /* List header used to link this structure to the \"struct epitem\" */ struct list_head llink; /* The \"base\" pointer is set to the container \"struct epitem\" */ struct epitem *base; /* * Wait queue item that will be linked to the target file wait * queue head. */ wait_queue_entry_t wait; /* The wait queue head that linked the \"wait\" wait queue item */ wait_queue_head_t *whead;}; epoll_create我们在使用 epoll 的时候，首先会调用 epoll_create 来创建一个 epoll 实例。这个函数是如何工作的呢? 首先，epoll_create 会对传入的 flags 参数做简单的验证。 123456/* Check the EPOLL_* constant for consistency. */BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC);if (flags &amp; ~EPOLL_CLOEXEC) return -EINVAL;/* 接下来，内核申请分配 eventpoll 需要的内存空间。 12345/* Create the internal data structure (\"struct eventpoll\").*/error = ep_alloc(&amp;ep);if (error &lt; 0) return error; 在接下来，epoll_create 为 epoll 实例分配了匿名文件和文件描述字，其中 fd 是文件描述字，file 是一个匿名文件。这里充分体现了 UNIX 下一切都是文件的思想。注意，eventpoll 的实例会保存一份匿名文件的引用，通过调用 fd_install 函数将匿名文件和文件描述字完成了绑定。 最后，这个文件描述字作为 epoll 的文件句柄，被返回给 epoll_create 的调用者。 12345678910111213141516171819202122232425262728293031/* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */fd = get_unused_fd_flags(O_RDWR | (flags &amp; O_CLOEXEC));if (fd &lt; 0) { error = fd; goto out_free_ep;}/* * 这里是创建一个匿名 fd。 * epollfd 本身并不存在一个真正的文件与之对应, 所以内核需要创建一个 * \"虚拟\"的文件，并为之分配真正的 struct file 结构，而且有真正的 fd。 * 这里2个参数比较关键： * eventpoll_fops、fops 就是 file operations，就是当你对这个文件(这里是虚拟的)进行操作(比如读)时， * fops 里面的函数指针指向真正的操作实现，类似 C++ 里面虚函数和子类的概念。 * epoll 只实现了 poll 和 release(就是close) 操作，其它文件系统操作都由 VFS 全权处理了。 * ep、ep 就是 struct epollevent，它会作为一个私有数据保存在 struct file 的 private 指针里面。 * 其实说白了，就是为了能通过 fd 找到 struct file，通过 struct file 能找到 eventpoll 结构。 * 如果懂一点 Linux 下字符设备驱动开发，这里应该是很好理解的，推荐阅读《Linux device driver 3rd》 */file = anon_inode_getfile(\"[eventpoll]\", &amp;eventpoll_fops, ep, O_RDWR | (flags &amp; O_CLOEXEC));if (IS_ERR(file)) { error = PTR_ERR(file); goto out_free_fd;}ep-&gt;file = file;fd_install(fd, file);return fd; epoll_ctl查找 epoll 实例首先，epoll_ctl 函数通过 epoll 实例句柄来获得对应的匿名文件，这一点很好理解，UNIX 下一切都是文件，epoll 的实例也是一个匿名文件。 1234//获得epoll实例对应的匿名文件f = fdget(epfd);if (!f.file) goto error_return; 接下来，获得添加的套接字对应的文件，这里 tf 表示的是 target file，即待处理的目标文件。 123456/* Get the \"struct file *\" for the target file *//* 我们需要监听的fd, 它当然也有个 struct file 结构, 上下2个不要搞混了 *///获得真正的文件，如监听套接字、读写套接字tf = fdget(fd);if (!tf.file) goto error_fput; 再接下来，进行了一系列的数据验证，以保证用户传入的参数是合法的，比如 epfd 真的是一个 epoll 实例句柄，而不是一个普通文件描述符。 123456/* The target file descriptor must support poll *///如果不支持poll，那么该文件描述字是无效的error = -EPERM;if (!tf.file-&gt;f_op-&gt;poll) goto error_tgt_fput;... 如果获得了一个真正的 epoll 实例句柄，就可以通过 private_data 获取之前创建的 eventpoll 实例了。 12345/* * At this point it is safe to assume that the \"private_data\" contains * our own data structure. */ep = f.file-&gt;private_data; 红黑树查找接下来 epoll_ctl 通过目标文件和对应描述字，在红黑树中查找是否存在该套接字，这也是 epoll 为什么高效的地方。红黑树（RB-tree）是一种常见的数据结构，这里 eventpoll 通过红黑树跟踪了当前监听的所有文件描述字，而这棵树的根就保存在 eventpoll 数据结构中。 12/* RB tree root used to store monitored fd structs */struct rb_root_cached rbr; 对于每个被监听的文件描述字，都有一个对应的 epitem 与之对应，epitem 作为红黑树中的节点就保存在红黑树中。 123456789101112/* * Try to lookup the file inside our RB tree, Since we grabbed \"mtx\" * above, we can be sure to be able to use the item looked up by * ep_find() till we release the mutex. *//* 对于每一个监听的fd，内核都有分配一个 epitem 结构， * 而且我们也知道，epoll 是不允许重复添加 fd 的， * 所以我们首先查找该 fd 是不是已经存在了。 * ep_find() 其实就是 RBTREE 查找，跟 C++STL 的 map 差不多一回事，O(logN)的时间复杂度。 */epi = ep_find(ep, tf.file, fd); 红黑树是一棵二叉树，作为二叉树上的节点，epitem 必须提供比较能力，以便可以按大小顺序构建出一棵有序的二叉树。其排序能力是依靠 epoll_filefd 结构体来完成的，epoll_filefd 可以简单理解为需要监听的文件描述字，它对应到二叉树上的节点。 可以看到这个还是比较好理解的，按照文件的地址大小排序。如果两个相同，就按照文件描述字来排序。 123456789101112struct epoll_filefd { struct file *file; // pointer to the target file struct corresponding to the fd int fd; // target file descriptor number} __packed;/* Compare RB tree keys */static inline int ep_cmp_ffd(struct epoll_filefd *p1, struct epoll_filefd *p2){ return (p1-&gt;file &gt; p2-&gt;file ? +1: (p1-&gt;file &lt; p2-&gt;file ? -1 : p1-&gt;fd - p2-&gt;fd));} 在进行完红黑树查找之后，如果发现是一个 ADD 操作，并且在树中没有找到对应的二叉树节点，就会调用 ep_insert 进行二叉树节点的增加。 123456789case EPOLL_CTL_ADD: if (!epi) { epds.events |= POLLERR | POLLHUP; error = ep_insert(ep, &amp;epds, tf.file, fd, full_check); } else error = -EEXIST; if (full_check) clear_tfile_check_list(); break; ep_insertep_insert 首先判断当前监控的文件值是否超过了 /proc/sys/fs/epoll/max_user_watches 的预设最大值，如果超过了则直接返回错误。 123user_watches = atomic_long_read(&amp;ep-&gt;user-&gt;epoll_watches);if (unlikely(user_watches &gt;= max_user_watches)) return -ENOSPC; 接下来是分配资源和初始化动作。 123456789101112131415161718192021222324252627282930313233343536373839/* 从著名的 slab 中分配一个 epitem */if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ INIT_LIST_HEAD(&amp;epi-&gt;rdllink); INIT_LIST_HEAD(&amp;epi-&gt;fllink); INIT_LIST_HEAD(&amp;epi-&gt;pwqlist); epi-&gt;ep = ep; ep_set_ffd(&amp;epi-&gt;ffd, tfile, fd); epi-&gt;event = *event; epi-&gt;nwait = 0; epi-&gt;next = EP_UNACTIVE_PTR; /* Initialize the poll table using the queue callback */ epq.epi = epi; /* 初始化一个 poll_table * 其实就是指定调用 poll_wait(注意不是 epoll_wait) 时的回调函数，和我们关心哪些 events， * ep_ptable_queue_proc() 就是我们的回调，初值是所有 event 都关心。 */ init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc); /* * Attach the item to the poll hooks and get current event bits. * We can safely use the file* here because its usage count has * been increased by the caller of this function. Note that after * this operation completes, the poll callback can start hitting * the new item. */ /* 这一步很关键，也比较难懂，完全是内核的 poll 机制导致的... * 首先，f_op-&gt;poll() 一般来说只是个 wrapper，它会调用真正的 poll 实现， * 拿 UDP 的 socket 来举例，这里就是这样的调用流程: f_op-&gt;poll()、sock_poll()、 * udp_poll()、datagram_poll()、sock_poll_wait()，最后调用到我们上面指定的 * ep_ptable_queue_proc() 这个回调函数...(好深的调用路径...)。 * 完成这一步，我们的 epitem 就跟这个 socket 关联起来了，当它有状态变化时， * 会通过 ep_poll_callback() 来通知. * 最后，这个函数还会查询当前的 fd 是不是已经有什么 event 已经 ready 了，有的话，会将 event 返回。 */ revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt); 再接下来的事情非常重要，ep_insert 会为加入的每个文件描述字设置回调函数。这个回调函数是通过函数 ep_ptable_queue_proc 来进行设置的。这个回调函数是干什么的呢？其实，对应的文件描述字上如果有事件发生，就会调用这个函数，比如套接字缓冲区有数据了，就会回调这个函数。这个函数就是 ep_poll_callback。这里你会发现，原来内核设计也是充满了事件回调的原理。 123456789101112131415161718192021222324252627282930/* * This is the callback that is used to add our wait queue to the * target file wakeup lists. */static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt){ struct epitem *epi = ep_item_from_epqueue(pt); struct eppoll_entry *pwq; if (epi-&gt;nwait &gt;= 0 &amp;&amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) { /* 初始化等待队列，指定 ep_poll_callback 为唤醒时的回调函数， * 当我们监听的 fd 发生状态改变时，也就是队列头被唤醒时， * 指定的回调函数将会被调用。 */ init_waitqueue_func_entry(&amp;pwq-&gt;wait, ep_poll_callback); pwq-&gt;whead = whead; pwq-&gt;base = epi; if (epi-&gt;event.events &amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, &amp;pwq-&gt;wait); else /* 将刚分配的等待队列成员加入到头中, 头是由 fd 持有的 */ add_wait_queue(whead, &amp;pwq-&gt;wait); list_add_tail(&amp;pwq-&gt;llink, &amp;epi-&gt;pwqlist); /* nwait 记录了当前 epitem 加入到了多少个等待队列中， * 我认为这个值最大也只会是1... */ epi-&gt;nwait++; } else { /* We have to signal that an error occurred */ epi-&gt;nwait = -1; }} ep_poll_callbackep_poll_callback 函数的作用非常重要，它将内核事件真正地和 epoll 对象联系了起来。它又是怎么实现的呢？ 首先，通过这个文件的 wait_queue_entry_t 对象找到对应的 epitem 对象，因为 eppoll_entry 对象里保存了 wait_queue_entry_t，根据 wait_queue_entry_t 这个对象的地址就可以简单计算出 eppoll_entry 对象的地址，从而可以获得 epitem 对象的地址。这部分工作在 ep_item_from_wait 函数中完成。一旦获得 epitem 对象，就可以寻迹找到 eventpoll 实例。 12345678910111213141516/* * This is the callback that is passed to the wait queue wakeup * mechanism. It is called by the stored file descriptors when they * have events to report. *//* * 这个是关键性的回调函数，当我们监听的 fd 发生状态改变时，它会被调用。 * 参数 key 被当作一个 unsigned long 整数使用，携带的是events。 */static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key){ int pwake = 0; unsigned long flags; // 从等待队列获取 epitem。需要知道哪个进程挂载到这个设备 struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-&gt;ep; 接下来，进行一个加锁操作。 1spin_lock_irqsave(&amp;ep-&gt;lock, flags); 下面对发生的事件进行过滤，为什么需要过滤呢？为了性能考虑，ep_insert 向对应监控文件注册的是所有的事件，而实际用户侧订阅的事件未必和内核事件对应。比如，用户向内核订阅了一个套接字的可读事件，在某个时刻套接字的可写事件发生时，并不需要向用户空间传递这个事件。 12345678/* * Check the events coming with the callback. At this stage, not * every device reports the events in the \"key\" parameter of the * callback. We need to be able to handle both cases here, hence the * test for \"key\" != NULL before the event match test. */if (key &amp;&amp; !((unsigned long) key &amp; epi-&gt;event.events)) goto out_unlock; 接下来，判断是否需要把该事件传递给用户空间。 123456789101112131415161718192021/* * 这里看起来可能有点费解，其实干的事情比较简单: * 如果该 callback 被调用的同时，epoll_wait() 已经返回了， * 也就是说，此刻应用程序有可能已经在循环获取 events， * 这种情况下，内核将此刻发生 event 的 epitem 用一个单独的链表 * 链起来，不发给应用程序，也不丢弃，而是在下一次 epoll_wait() 时返回给用户。 */if (unlikely(ep-&gt;ovflist != EP_UNACTIVE_PTR)) { if (epi-&gt;next == EP_UNACTIVE_PTR) { epi-&gt;next = ep-&gt;ovflist; ep-&gt;ovflist = epi; if (epi-&gt;ws) { /* * Activate ep-&gt;ws since epi-&gt;ws may get * deactivated at any time. */ __pm_stay_awake(ep-&gt;ws); } } goto out_unlock;} 如果需要，而且该事件对应的 event_item 不在 eventpoll 对应的已完成队列中，就把它放入该队列，以便将该事件传递给用户空间。 12345/* If this file is already in the ready list we exit soon */if (!ep_is_linked(&amp;epi-&gt;rdllink)) { list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake_rcu(epi);} 我们知道，当我们调用 epoll_wait 的时候，调用进程被挂起，在内核看来调用进程陷入休眠。如果该 epoll 实例上对应描述字有事件发生，这个休眠进程应该被唤醒，以便及时处理事件。下面的代码就是起这个作用的，wake_up_locked 函数唤醒当前 eventpoll 上的等待进程。 1234567891011121314151617181920212223/* * Wake up ( if active ) both the eventpoll wait list and the -&gt;poll() * wait list. */if (waitqueue_active(&amp;ep-&gt;wq)) { if ((epi-&gt;event.events &amp; EPOLLEXCLUSIVE) &amp;&amp; !((unsigned long)key &amp; POLLFREE)) { switch ((unsigned long)key &amp; EPOLLINOUT_BITS) { case POLLIN: if (epi-&gt;event.events &amp; POLLIN) ewake = 1; break; case POLLOUT: if (epi-&gt;event.events &amp; POLLOUT) ewake = 1; break; case 0: ewake = 1; break; } } wake_up_locked(&amp;ep-&gt;wq);} 查找 epoll 实例epoll_wait 函数首先进行一系列的检查，例如传入的 maxevents 应该大于 0。 1234567/* The maximum number of event must be greater than zero */if (maxevents &lt;= 0 || maxevents &gt; EP_MAX_EVENTS) return -EINVAL;/* Verify that the area passed by the user is writeable */if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) return -EFAULT; 和前面介绍的 epoll_ctl 一样，通过 epoll 实例找到对应的匿名文件和描述字，并且进行检查和验证。 123456789101112/* Get the \"struct file *\" for the eventpoll file */f = fdget(epfd);if (!f.file) return -EBADF;/* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */error = -EINVAL;if (!is_file_epoll(f.file)) goto error_fput; 还是通过读取 epoll 实例对应匿名文件的 private_data 得到 eventpoll 实例。 12345/* * At this point it is safe to assume that the \"private_data\" contains * our own data structure. */ep = f.file-&gt;private_data; 接下来调用 ep_poll 来完成对应的事件收集并传递到用户空间。 12/* Time to fish for events ... */error = ep_poll(ep, events, maxevents, timeout); ep_poll这里 ep_poll 就分别对 timeout 不同值的场景进行了处理。如果大于 0 则产生了一个超时时间，如果等于 0 则立即检查是否有事件发生。 12345678910111213141516171819202122static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout){int res = 0, eavail, timed_out = 0;unsigned long flags;u64 slack = 0;wait_queue_entry_t wait;ktime_t expires, *to = NULL;if (timeout &gt; 0) { struct timespec64 end_time = ep_set_mstimeout(timeout); slack = select_estimate_accuracy(&amp;end_time); to = &amp;expires; *to = timespec64_to_ktime(end_time);} else if (timeout == 0) { /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. */ timed_out = 1; spin_lock_irqsave(&amp;ep-&gt;lock, flags); goto check_events;} 接下来尝试获得 eventpoll 上的锁： 1spin_lock_irqsave(&amp;ep-&gt;lock, flags); 获得这把锁之后，检查当前是否有事件发生，如果没有，就把当前进程加入到 eventpoll 的等待队列 wq 中，这样做的目的是当事件发生时，ep_poll_callback 函数可以把该等待进程唤醒。 123456789101112131415if (!ep_events_available(ep)) { /* * Busy poll timed out. Drop NAPI ID for now, we can add * it back in when we have moved a socket with a valid NAPI * ID onto the ready list. */ ep_reset_busy_poll_napi_id(ep); /* * We don't have any available event to return to the caller. * We need to sleep here, and we will be wake up by * ep_poll_callback() when events will become available. */ init_waitqueue_entry(&amp;wait, current); __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); 紧接着是一个无限循环，这个循环中通过调用 schedule_hrtimeout_range，将当前进程陷入休眠，CPU 时间被调度器调度给其他进程使用，当然，当前进程可能会被唤醒，唤醒的条件包括有以下四种： 当前进程超时； 当前进程收到一个 signal 信号； 某个描述字上有事件发生； 当前进程被 CPU 重新调度，进入 for 循环重新判断，如果没有满足前三个条件，就又重新进入休眠 对应的 1、2、3 都会通过 break 跳出循环，直接返回。 1234567891011121314151617181920212223242526272829303132333435363738//这个循环里，当前进程可能会被唤醒，唤醒的途径包括//1.当前进程超时//2.当前进行收到一个signal信号//3.某个描述字上有事件发生//对应的1.2.3都会通过break跳出循环//第4个可能是当前进程被CPU重新调度，进入for循环的判断，如果没有满足1.2.3的条件，就又重新进入休眠for (;;) { /* * We don't want to sleep if the ep_poll_callback() sends us * a wakeup in between. That's why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ set_current_state(TASK_INTERRUPTIBLE); /* * Always short-circuit for fatal signals to allow * threads to make a timely exit without the chance of * finding more events available and fetching * repeatedly. */ if (fatal_signal_pending(current)) { res = -EINTR; break; } if (ep_events_available(ep) || timed_out) break; if (signal_pending(current)) { res = -EINTR; break; } spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); //通过调用schedule_hrtimeout_range，当前进程进入休眠，CPU时间被调度器调度给其他进程使用 if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) timed_out = 1; spin_lock_irqsave(&amp;ep-&gt;lock, flags);} 如果进程从休眠中返回，则将当前进程从 eventpoll 的等待队列中删除，并且设置当前进程为 TASK_RUNNING 状态。 123//从休眠中结束，将当前进程从wait队列中删除，设置状态为TASK_RUNNING，接下来进入check_events，来判断是否是有事件发生 __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); __set_current_state(TASK_RUNNING); 最后，调用 ep_send_events 将事件拷贝到用户空间。 123456789101112//ep_send_events将事件拷贝到用户空间/* * Try to transfer events to user space. In case we get 0 events and * there's still timeout left over, we go trying again in search of * more luck. */if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; !timed_out) goto fetch_events;return res; ep_send_eventsep_send_events 这个函数会将 ep_send_events_proc 作为回调函数并调用 ep_scan_ready_list 函数，ep_scan_ready_list 函数调用 ep_send_events_proc 对每个已经就绪的事件循环处理。 ep_send_events_proc 循环处理就绪事件时，会再次调用每个文件描述符的 poll 方法，以便确定确实有事件发生。为什么这样做呢？这是为了确定注册的事件在这个时刻还是有效的。 可以看到，尽管 ep_send_events_proc 已经尽可能的考虑周全，使得用户空间获得的事件通知都是真实有效的，但还是有一定的概率，当 ep_send_events_proc 再次调用文件上的 poll 函数之后，用户空间获得的事件通知已经不再有效，这可能是用户空间已经处理掉了，或者其他什么情形。在这种情况下，如果套接字不是非阻塞的，整个进程将会被阻塞，这也是为什么将非阻塞套接字配合 epoll 使用作为最佳实践的原因。 在进行简单的事件掩码校验之后，ep_send_events_proc 将事件结构体拷贝到用户空间需要的数据结构中。这是通过 __put_user 方法完成的。 123456789101112131415161718//这里对一个fd再次进行poll操作，以确认事件revents = ep_item_poll(epi, &amp;pt);/* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding \"mtx\", so no operations coming from userspace * can change the item. */if (revents) { if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) { list_add(&amp;epi-&gt;rdllink, head); ep_pm_stay_awake(epi); return eventcnt ? eventcnt : -EFAULT; } eventcnt++; uevent++; ep_poll() 函数主要做以下几件事： 判断被监听的文件集合中是否有就绪的文件，如果有就返回。 如果没有就把当前进程添加到 epoll 的等待队列中，并且进入睡眠。 进程会一直睡眠直到有以下几种情况发生：1、被监听的文件集合中有就绪的文件2、设置了超时时间并且超时了3、接收到信号 如果有就绪的文件，那么就调用 ep_send_events() 函数把就绪文件复制到 events 参数中。 返回就绪文件的个数。 最后，我们通过一张图来总结 epoll 的原理： Level-triggered VS Edge-triggered从实现角度来看其实非常简单，在 ep_send_events_proc 函数的最后，针对 level-triggered 情况，当前的 epoll_item 对象被重新加到 eventpoll 的就绪列表中，这样在下一次 epoll_wait 调用时，这些 epoll_item 对象就会被重新处理。 在前面我们提到，在最终拷贝到用户空间有效事件列表中之前，会调用对应文件的 poll 方法，以确定这个事件是不是依然有效。所以，如果用户空间程序已经处理掉该事件，就不会被再次通知；如果没有处理，意味着该事件依然有效，就会被再次通知。 1234567891011121314151617//这里是Level-triggered的处理，可以看到，在Level-triggered的情况下，这个事件被重新加回到ready list里面//这样，下一轮epoll_wait的时候，这个事件会被重新checkelse if (!(epi-&gt;event.events &amp; EPOLLET)) { /* * If this file has been added with Level * Trigger mode, we need to insert back inside * the ready list, so that the next call to * epoll_wait() will check again the events * availability. At this point, no one can insert * into ep-&gt;rdllist besides us. The epoll_ctl() * callers are locked out by * ep_scan_ready_list() holding \"mtx\" and the * poll callback will queue them in ep-&gt;ovflist. */ list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi);} epoll VS poll/select最后，我们从实现角度来说明一下为什么 epoll 的效率要远远高于 poll/select。 首先，poll/select 先将要监听的 fd 从用户空间拷贝到内核空间，然后在内核空间里面进行处理之后，再拷贝给用户空间。这里就涉及到内核空间申请内存，释放内存等等过程，这在大量 fd 情况下，是非常耗时的。而 epoll 维护了一个红黑树，通过对这棵黑红树进行操作，可以避免大量的内存申请和释放的操作，而且查找速度非常快。 下面的代码就是 poll/select 在内核空间申请内存的展示。可以看到 select 是先尝试申请栈上资源，如果需要监听的 fd 比较多, 就会去申请堆空间的资源。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849int core_sys_select(int n, fd_set __user *inp, fd_set __user *outp, fd_set __user *exp, struct timespec64 *end_time){ fd_set_bits fds; void *bits; int ret, max_fds; size_t size, alloc_size; struct fdtable *fdt; /* Allocate small arguments on the stack to save memory and be faster */ long stack_fds[SELECT_STACK_ALLOC/sizeof(long)]; ret = -EINVAL; if (n &lt; 0) goto out_nofds; /* max_fds can increase, so grab it once to avoid race */ rcu_read_lock(); fdt = files_fdtable(current-&gt;files); max_fds = fdt-&gt;max_fds; rcu_read_unlock(); if (n &gt; max_fds) n = max_fds; /* * We need 6 bitmaps (in/out/ex for both incoming and outgoing), * since we used fdset we need to allocate memory in units of * long-words. */ size = FDS_BYTES(n); bits = stack_fds; if (size &gt; sizeof(stack_fds) / 6) { /* Not enough space in on-stack array; must use kmalloc */ ret = -ENOMEM; if (size &gt; (SIZE_MAX / 6)) goto out_nofds; alloc_size = 6 * size; bits = kvmalloc(alloc_size, GFP_KERNEL); if (!bits) goto out_nofds; } fds.in = bits; fds.out = bits + size; fds.ex = bits + 2*size; fds.res_in = bits + 3*size; fds.res_out = bits + 4*size; fds.res_ex = bits + 5*size; ... 第二，select/poll 从休眠中被唤醒时，如果监听多个 fd，只要其中有一个 fd 有事件发生，内核就会遍历内部的 list 去检查到底是哪一个事件到达，并没有像 epoll 一样，通过 fd 直接关联 eventpoll 对象，快速地把 fd 直接加入到 eventpoll 的就绪列表中。 1234567891011121314151617181920212223242526static int do_select(int n, fd_set_bits *fds, struct timespec64 *end_time){ ... retval = 0; for (;;) { unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp; bool can_busy_loop = false; inp = fds-&gt;in; outp = fds-&gt;out; exp = fds-&gt;ex; rinp = fds-&gt;res_in; routp = fds-&gt;res_out; rexp = fds-&gt;res_ex; for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) { unsigned long in, out, ex, all_bits, bit = 1, mask, j; unsigned long res_in = 0, res_out = 0, res_ex = 0; in = *inp++; out = *outp++; ex = *exp++; all_bits = in | out | ex; if (all_bits == 0) { i += BITS_PER_LONG; continue; } if (!poll_schedule_timeout(&amp;table, TASK_INTERRUPTIBLE, to, slack)) timed_out = 1;... 四、总结epoll 流程1、epoll_create()从 slab 缓存中创建一个 eventpoll 对象，并且创建一个匿名的 fd 跟 fd 对应的 file 对象，而 eventpoll 对象保存在 struct file 结构的private 指针中，并且返回。该 fd 对应的 file operations 只是实现了 poll 跟 release 操作。 2、创建 eventpoll 对象的初始化操作获取当前用户信息，是不是 root，最大监听 fd 数目等，并且将这些信息保存到 eventpoll 对象中。然后初始化等待队列，初始化就绪链表，初始化红黑树的头结点。 3、epoll_ctl()将 epoll_event 结构拷贝到内核空间中，并且判断加入的 fd 是否支持 poll 结构(epoll、poll、select，I/O 多路复用必须支持 poll 操作)。并且从 epfd-&gt;file-&gt;privatedata 获取 event_poll 对象，根据 op 区分是添加、删除，还是修改，首先在 eventpoll 结构中的红黑树查找是否已经存在了相对应的 fd，没找到就支持插入操作，否则报重复添加的错误。 插入操作时，会创建一个与 fd 对应的 epitem 结构，并且初始化相关成员，比如保存监听的 fd 跟 file 结构之类的。重要的是指定了调用poll_wait 时的回调函数用于数据就绪时唤醒进程。poll_wait 内部初始化设备的等待队列，将该进程注册到等待队列，完成这一步, 我们的 epitem就跟这个 socket 关联起来了，当它有状态变化时，会通过 ep_poll_callback() 来通知。最后调用加入的 fd 的 file operation-&gt;poll 函数(最后会调用 poll_wait 操作)用于完成注册操作。最后将 epitem 结构添加到红黑树中。 4、epoll_wait()计算睡眠时间(如果有)，判断 eventpoll 对象的链表是否为空，不为空那就干活不睡眠。并且初始化一个等待队列，把自己挂上去，设置自己的进程状态为可睡眠状态。判断是否有信号到来(有的话直接被中断醒来)，如果啥事都没有那就调用 schedule_timeout 进行睡眠，如果超时或者被唤醒，首先从自己初始化的等待队列删除，然后开始拷贝资源给用户空间了。拷贝资源则是先把就绪事件链表转移到中间链表，然后挨个遍历拷贝到用户空间，并且挨个判断其是否为水平触发，是的话再次插入到就绪链表。 epoll 的改进epoll 维护了一棵红黑树来跟踪所有待检测的文件描述字，红黑树的使用减少了内核和用户空间大量的数据拷贝和内存分配，大大提高了性能。 同时，epoll 维护了一个链表来记录就绪事件，内核在每个文件有事件发生时将自己登记到这个就绪事件列表中，通过内核自身的文件 file-eventpoll 之间的回调和唤醒机制，减少了对内核描述字的遍历，大大加速了事件通知和检测的效率，这也为 level-triggered 和 edge-triggered 的实现带来了便利。 通过对比 poll/select 的实现，我们发现 epoll 确实克服了 poll/select 的种种弊端，不愧是 Linux 下高性能网络编程的皇冠。我们应该感谢 Linux 社区的大神们设计了这么强大的事件分发机制，让我们在 Linux 下可以享受高性能网络服务器带来的种种技术红利。 五、拓展延伸epoll 实现特点 等待队列 waitqueue队列头 wait_queue_head_t 往往是资源生产者，队列成员 wait_queue_t 往往是资源消费者，当头的资源 ready 后，会逐个执行每个成员指定的回调函数，来通知它们资源已经 ready 了。 内核的 poll 机制1、被 poll 的 fd，必须在实现上支持内核的 poll 技术，比如 fd 是某个字符设备，或者是个 socket，它必须实现 file_operations 中的 poll 操作，给自己分配有一个等待队列头，主动 poll fd 的某个进程必须分配一个等待队列成员, 添加到 fd 的等待待队列里面去，并指定资源 ready 时的回调函数。2、用 socket 做例子，它必须要实现一个 poll 操作，这个 poll 是发起轮询的代码必须主动调用的，该函数中必须调用 poll_wait()，poll_wait() 会将发起者作为等待队列成员加入到 socket 的等待队列中去，这样 socket 发生状态变化时可以通过队列头逐个通知所有关心它的进程，这一点必须很清楚的理解, 否则会想不明白 epoll 是如何得知 fd 的状态发生变化的。 epollfd 本身也是个 fd，所以它本身也可以被 epoll，可以猜测一下它是不是可以无限嵌套 epoll 下去… 其他部分内核知识点 fd 我们知道是文件描述符，在内核态，与之对应的是 struct file 结构，可以看作是内核态的文件描述符。 spinlock，自旋锁，必须要非常小心使用的锁，尤其是调用 spin_lock_irqsave() 的时候，中断关闭，不会发生进程调度，被保护的资源其它CPU 也无法访问。这个锁是很强力的，所以只能锁一些非常轻量级的操作。 引用计数在内核中是非常重要的概念，内核代码里面经常有些 release、free 释放资源的函数几乎不加任何锁，这是因为这些函数往往是在对象的引用计数变成0时被调用，既然没有进程在使用在这些对象，自然也不需要加锁。struct file 是持有引用计数的。 原文链接31丨性能篇答疑：epoll源码深度剖析 参考文章1、Epoll 实现原理2、epoll源码分析(基于linux-5.1.4) 3、Linux内核笔记：epoll实现原理（一）4、epoll内核源码详解+自己总结的流程","link":"/post/2518bc76.html"},{"title":"C++智能指针的一种实现(转载)","text":"智能指针其实就是 RAII 资源管理功能的自然展现 零、一个资源管理的简单包装类使用智能指针，可以简化资源的管理，从根本上消除资源（包括内存）泄漏的可能性。 12345678910111213141516class shape_wrapper { public: explicit shape_wrapper(shape* ptr = nullptr) : ptr_(ptr) {} ~shape_wrapper() { delete ptr_; } shape* get() const { return ptr_; } private: shape* ptr_;}; 这个类可以完成智能指针的最基本的功能：对超出作用域的对象进行释放。但这个包装类有以下局限： 这个类只适用于 shape 类 该类对象的行为不够像指针 拷贝该类对象会引发程序行为异常 一、模板化和易用性要让这个类能够包装任意类型的指针，我们需要把它变成一个类模板。 12345678910111213141516template &lt;typename T&gt;class smart_ptr {public: explicit smart_ptr(T* ptr = nullptr) : ptr_(ptr) {} ~smart_ptr() { delete ptr_; } T* get() const { return ptr_; } private: T* ptr_;}; 和 shape_wrapper 比较一下，我们就是在开头增加模板声明 template ，然后把代码中的 shape 替换成模板参数 T 而已。这个模板使用也很简单，把原来的 shape_wrapper 改成 smart_ptr&lt; shape &gt; 就行。 目前这个 smart_ptr 的行为还是和指针有点差异的： 它不能用 * 运算符解引用 它不能用 -&gt; 运算符指向对象成员 它不能像指针一样用在布尔表达式里 这些问题也相当容易解决，加几个 operator重载运算符 成员函数就可以： 12345678template &lt;typename T&gt;class smart_ptr {public: … T&amp; operator*() const { return *ptr_; } T* operator-&gt;() const { return ptr_; } operator bool() const { return ptr_; }} 二、拷贝构造和赋值拷贝构造和赋值，我们暂且简称为拷贝，这是个比较复杂的问题了。关键还不是实现问题，而是我们该如何定义其行为。假设有下面的代码： 12smart_ptr&lt;shape&gt; ptr1{create_shape(shape_type::circle)};smart_ptr&lt;shape&gt; ptr2{ptr1}; 对于第二行，究竟应当让编译时发生错误，还是可以有一个更合理的行为？我们来逐一检查一下各种可能性。 最简单的情况显然是禁止拷贝。我们可以使用下面的代码： 123456789template &lt;typename T&gt;class smart_ptr { … smart_ptr(const smart_ptr&amp;) // 禁用拷贝构造 = delete; smart_ptr&amp; operator=(const smart_ptr&amp;) // 禁用赋值构造 = delete; …}; 禁用这两个函数非常简单，但却解决了一种可能出错的情况。否则，smart_ptr ptr2{ptr1}; 在编译时不会出错，但在运行时却会有未定义行为——由于会对同一内存释放两次，通常情况下会导致程序崩溃。 我们是不是可以考虑在拷贝智能指针时把对象拷贝一份？不行，通常人们不会这么用，因为使用智能指针的目的就是要减少对象的拷贝啊。何况，虽然我们的指针类型是 shape，但实际指向的却应该是 circle 或 triangle 之类的对象。在 C++ 里没有像 Java 的 clone 方法这样的约定；一般而言，并没有通用的方法可以通过基类的指针来构造出一个子类的对象来。 我们要么试试在拷贝时转移指针的所有权？大致实现如下： 1234567891011121314151617181920212223242526template &lt;typename T&gt;class smart_ptr { … smart_ptr(smart_ptr&amp; other) { ptr_ = other.release(); } smart_ptr&amp; operator=(smart_ptr&amp; rhs) { smart_ptr(rhs).swap(*this); return *this; } … T* release() { T* ptr = ptr_; ptr_ = nullptr; return ptr; } void swap(smart_ptr&amp; rhs) { using std::swap; swap(ptr_, rhs.ptr_); } …}; 在拷贝构造函数中，通过调用 other 的 release 方法来释放它对指针的所有权。在赋值函数中，则通过拷贝构造产生一个临时对象并调用 swap 来交换对指针的所有权。实现上是不复杂的。 如果你学到的赋值函数还有一个类似于 if (this != &amp;rhs) 的判断的话，那种用法更啰嗦，而且异常安全性不够好——如果在赋值过程中发生异常的话，this 对象的内容可能已经被部分破坏了，对象不再处于一个完整的状态。 上面代码里的这种惯用法（见参考资料 [1]）则保证了强异常安全性：赋值分为拷贝构造和交换两步，异常只可能在第一步发生；而第一步如果发生异常的话，this 对象完全不受任何影响。无论拷贝构造成功与否，结果只有赋值成功和赋值没有效果两种状态，而不会发生因为赋值破坏了当前对象这种场景。 如果你觉得这个实现还不错的话，那恭喜你，你达到了 C++ 委员会在 1998 年时的水平：上面给出的语义本质上就是 C++98 的 auto_ptr 的定义。如果你觉得这个实现很别扭的话，也恭喜你，因为 C++ 委员会也是这么觉得的：auto_ptr 在 C++17 时已经被正式从 C++ 标准里删除了。 上面实现的最大问题是，它的行为会让程序员非常容易犯错。一不小心把它传递给另外一个 smart_ptr，你就不再拥有这个对象了…… 三、移动指针？先简单看一下 smart_ptr 可以如何使用“移动”来改善其行为。 1234567891011121314template &lt;typename T&gt;class smart_ptr { … smart_ptr(smart_ptr&amp;&amp; other) { ptr_ = other.release(); } smart_ptr&amp; operator=(smart_ptr rhs) { rhs.swap(*this); return *this; } …}; 看到修改的地方了吗？改了两个地方： 把拷贝构造函数中的参数类型 smart_ptr&amp; 改成了 smart_ptr&amp;&amp;；现在它成了移动构造函数。 把赋值函数中的参数类型 smart_ptr&amp; 改成了 smart_ptr，在构造参数时直接生成新的智能指针，从而不再需要在函数体中构造临时对象。现在赋值函数的行为是移动还是拷贝，完全依赖于构造参数时走的是移动构造还是拷贝构造。 根据 C++ 的规则，如果我提供了移动构造函数而没有手动提供拷贝构造函数，那后者自动被禁用（记住，C++ 里那些复杂的规则也是为方便编程而设立的）。于是，我们自然地得到了以下结果： 123456smart_ptr&lt;shape&gt; ptr1{create_shape(shape_type::circle)};smart_ptr&lt;shape&gt; ptr2{ptr1}; // 编译出错smart_ptr&lt;shape&gt; ptr3;ptr3 = ptr1; // 编译出错ptr3 = std::move(ptr1); // OK，可以smart_ptr&lt;shape&gt; ptr4{std::move(ptr3)}; // OK，可以 这也是 C++11 的 unique_ptr 的基本行为。 四、子类指针向基类指针的转换不知道你注意到没有，一个 circle* 是可以隐式转换成 shape* 的，但上面的 smart_ptr&lt; circle &gt; 却无法自动转换成 smart_ptr&lt; shape &gt;。这个行为显然还是不够“自然”。 不过，只需要额外加一点模板代码，就能实现这一行为。在我们目前给出的实现里，只需要增加一个构造函数即可——这也算是我们让赋值函数利用构造函数的好处了。 12345template &lt;typename U&gt;smart_ptr(smart_ptr&lt;U&gt;&amp;&amp; other){ ptr_ = other.release();} 这样，我们自然而然利用了指针的转换特性：现在 smart_ptr&lt; circle &gt; 可以移动给 smart_ptr&lt; shape &gt;，但不能移动给 smart_ptr&lt; triangle &gt;。不正确的转换会在代码编译时直接报错。 需要注意，上面这个构造函数不被编译器看作移动构造函数，因而不能自动触发删除拷贝构造函数的行为。如果我们想消除代码重复、删除移动构造函数的话，就需要把拷贝构造函数标记成 = delete 了。不过，更通用的方式仍然是同时定义标准的拷贝 / 移动构造函数和所需的模板构造函数。下面的引用计数智能指针里我们就需要这么做。 至于非隐式的转换，因为本来就是要写特殊的转换函数的，我们留到这一讲的最后再讨论。 五、引用计数unique_ptr 算是一种较为安全的智能指针了。但是，一个对象只能被单个 unique_ptr 所拥有，这显然不能满足所有使用场合的需求。一种常见的情况是，多个智能指针同时拥有一个对象；当它们全部都失效时，这个对象也同时会被删除。这也就是 shared_ptr 了。 unique_ptr 和 shared_ptr 的主要区别如下图所示： 多个不同的 shared_ptr 不仅可以共享一个对象，在共享同一对象时也需要同时共享同一个计数。当最后一个指向对象（和共享计数）的 shared_ptr 析构时，它需要删除对象和共享计数。我们下面就来实现一下。 我们先来写出共享计数的接口： 1234567class shared_count {public: shared_count(); void add_count(); long reduce_count(); long get_count() const;}; 这个 shared_count 类除构造函数之外有三个方法：一个增加计数，一个减少计数，一个获取计数。注意上面的接口增加计数不需要返回计数值；但减少计数时需要返回计数值，以供调用者判断是否它已经是最后一个指向共享计数的 shared_ptr 了。由于真正多线程安全的版本需要用到我们目前还没学到的知识，我们目前先实现一个简单化的版本： 12345678910111213141516171819class shared_count {public: shared_count() : count_(1) {} void add_count() { ++count_; } long reduce_count() { return --count_; } long get_count() const { return count_; }private: long count_;}; 现在我们可以实现我们的引用计数智能指针了。首先是构造函数、析构函数和私有成员变量： 12345678910111213141516171819202122232425template &lt;typename T&gt;class smart_ptr {public: explicit smart_ptr(T* ptr = nullptr) : ptr_(ptr) { if (ptr) { shared_count_ = new shared_count(); } } ~smart_ptr() { if (ptr_ &amp;&amp; !shared_count_ -&gt;reduce_count()) { delete ptr_; delete shared_count_; } }private: T* ptr_; shared_count* shared_count_;}; 构造函数跟之前的主要不同点是会构造一个 shared_count 出来。析构函数在看到 ptr_ 非空时（此时根据代码逻辑，shared_count 也必然非空），需要对引用数减一，并在引用数降到零时彻底删除对象和共享计数。原理就是这样，不复杂。 当然，我们还有些细节要处理。为了方便实现赋值（及其他一些惯用法），我们需要一个新的 swap 成员函数： 1234567void swap(smart_ptr&amp; rhs){ using std::swap; swap(ptr_, rhs.ptr_); swap(shared_count_, rhs.shared_count_);} 赋值函数可以跟前面一样，保持不变，但拷贝构造和移动构造函数是需要更新一下的： 12345678910111213141516171819202122232425262728293031smart_ptr(const smart_ptr&amp; other){ ptr_ = other.ptr_; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; }}template &lt;typename U&gt;smart_ptr(const smart_ptr&lt;U&gt;&amp; other){ ptr_ = other.ptr_; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; }}template &lt;typename U&gt;smart_ptr(smart_ptr&lt;U&gt;&amp;&amp; other){ ptr_ = other.ptr_; if (ptr_) { shared_count_ = other.shared_count_; other.ptr_ = nullptr; }} 除复制指针之外，对于拷贝构造的情况，我们需要在指针非空时把引用数加一，并复制共享计数的指针。对于移动构造的情况，我们不需要调整引用数，直接把 other.ptr_ 置为空，认为 other 不再指向该共享对象即可。 不过，上面的代码有个问题：它不能正确编译。编译器会报错，像： 1fatal error: ‘ptr_’ is a private member of ‘smart_ptr’ 错误原因是模板的各个实例间并不天然就有 friend 关系，因而不能互访私有成员 ptr_ 和 shared_count_。我们需要在 smart_ptr 的定义中显式声明： 12template &lt;typename U&gt;friend class smart_ptr; 此外，我们之前的实现（类似于单一所有权的 unique_ptr ）中用 release 来手工释放所有权。在目前的引用计数实现中，它就不太合适了，应当删除。但我们要加一个对调试非常有用的函数，返回引用计数值。定义如下： 123456789long use_count() const{ if (ptr_) { return shared_count_ -&gt;get_count(); } else { return 0; }} 这就差不多是一个比较完整的引用计数智能指针的实现了。我们可以用下面的代码来验证一下它的功能正常： 12345678910111213141516171819202122232425class shape {public: virtual ~shape() {}};class circle : public shape {public: ~circle() { puts(\"~circle()\"); }};int main(){ smart_ptr&lt;circle&gt; ptr1(new circle()); printf(\"use count of ptr1 is %ld\\n\", ptr1.use_count()); smart_ptr&lt;shape&gt; ptr2; printf(\"use count of ptr2 was %ld\\n\", ptr2.use_count()); ptr2 = ptr1; printf(\"use count of ptr2 is now %ld\\n\", ptr2.use_count()); if (ptr1) { puts(\"ptr1 is not empty\"); }} 这段代码的运行结果是： use count of ptr1 is 1use count of ptr2 was 0use count of ptr2 is now 2ptr1 is not empty~circle() 六、指针类型转换对应于 C++ 里的不同的类型强制转换： static_cast reinterpret_cast const_cast dynamic_cast 智能指针需要实现类似的函数模板。实现本身并不复杂，但为了实现这些转换，我们需要添加构造函数，允许在对智能指针内部的指针对象赋值时，使用一个现有的智能指针的共享计数。如下所示： 123456789101112template &lt;typename U&gt;smart_ptr(const smart_ptr&lt;U&gt;&amp; other, T* ptr){ ptr_ = ptr; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; }} 这样我们就可以实现转换所需的函数模板了。下面实现一个 dynamic_pointer_cast 来示例一下： 12345678template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; dynamic_pointer_cast( const smart_ptr&lt;U&gt;&amp; other){ T* ptr = dynamic_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);} 在前面的验证代码后面我们可以加上： 1234smart_ptr&lt;circle&gt; ptr3 = dynamic_pointer_cast&lt;circle&gt;(ptr2);printf(\"use count of ptr3 is %ld\\n\", ptr3.use_count()); 编译会正常通过，同时能在输出里看到下面的结果： use count of ptr3 is 3 最后，对象仍然能够被正确删除。这说明我们的实现是正确的。 七、代码列表为了方便你参考，下面我给出了一个完整的 smart_ptr 代码列表： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172#include &lt;utility&gt; // std::swapclass shared_count {public: shared_count() noexcept : count_(1) {} void add_count() noexcept { ++count_; } long reduce_count() noexcept { return --count_; } long get_count() const noexcept { return count_; }private: long count_;};template &lt;typename T&gt;class smart_ptr {public: template &lt;typename U&gt; friend class smart_ptr; explicit smart_ptr(T* ptr = nullptr) : ptr_(ptr) { if (ptr) { shared_count_ = new shared_count(); } } ~smart_ptr() { if (ptr_ &amp;&amp; !shared_count_ -&gt;reduce_count()) { delete ptr_; delete shared_count_; } } smart_ptr(const smart_ptr&amp; other) { ptr_ = other.ptr_; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; } } template &lt;typename U&gt; smart_ptr(const smart_ptr&lt;U&gt;&amp; other) noexcept { ptr_ = other.ptr_; if (ptr_) { other.shared_count_-&gt;add_count(); shared_count_ = other.shared_count_; } } template &lt;typename U&gt; smart_ptr(smart_ptr&lt;U&gt;&amp;&amp; other) noexcept { ptr_ = other.ptr_; if (ptr_) { shared_count_ = other.shared_count_; other.ptr_ = nullptr; } } template &lt;typename U&gt; smart_ptr(const smart_ptr&lt;U&gt;&amp; other, T* ptr) noexcept { ptr_ = ptr; if (ptr_) { other.shared_count_ -&gt;add_count(); shared_count_ = other.shared_count_; } } smart_ptr&amp; operator=(smart_ptr rhs) noexcept { rhs.swap(*this); return *this; } T* get() const noexcept { return ptr_; } long use_count() const noexcept { if (ptr_) { return shared_count_ -&gt;get_count(); } else { return 0; } } void swap(smart_ptr&amp; rhs) noexcept { using std::swap; swap(ptr_, rhs.ptr_); swap(shared_count_, rhs.shared_count_); } T&amp; operator*() const noexcept { return *ptr_; } T* operator-&gt;() const noexcept { return ptr_; } operator bool() const noexcept { return ptr_; }private: T* ptr_; shared_count* shared_count_;};template &lt;typename T&gt;void swap(smart_ptr&lt;T&gt;&amp; lhs, smart_ptr&lt;T&gt;&amp; rhs) noexcept{ lhs.swap(rhs);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; static_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = static_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; reinterpret_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = reinterpret_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; const_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = const_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);}template &lt;typename T, typename U&gt;smart_ptr&lt;T&gt; dynamic_pointer_cast( const smart_ptr&lt;U&gt;&amp; other) noexcept{ T* ptr = dynamic_cast&lt;T*&gt;(other.get()); return smart_ptr&lt;T&gt;(other, ptr);} 如果你足够细心的话，你会发现我在代码里加了不少 noexcept。这对这个智能指针在它的目标场景能正确使用是十分必要的。 八、内容小结这一讲我们从 shape_wrapper 出发，实现了一个基本完整的带引用计数的智能指针。这个智能指针跟标准的 shared_ptr 比，还缺了一些东西（见参考资料 [2]），但日常用到的智能指针功能已经包含在内。现在，你应当已经对智能指针有一个较为深入的理解了。 九、拓展延伸shared_ptr() 一种简单实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182typename&lt;T&gt;class shared_ptr { // 指针成员 T* _ptr = nullptr; // 用指针，一般是 new 出来的话，这样在进程的堆区，那么这样其实也就实现了计数共享 uint32_t* _count = 0; // 拷贝构造 shared_ptr(const shared_ptr&amp; other) { _ptr = other-&gt;_ptr; count = other-&gt;_count; ++(*_count); } shared_ptr(T* ptr) { _ptr = ptr; if(ptr) { _count = new uint32_t(); _count = 0; } } // 赋值构造 shared_ptr operator = (const shared_ptr&amp; other) { if(_ptr == this) { // 如果是自赋值，则不处理 } else { // 要变更管理的指针对象了 // 如果当前不为空，说明有管理的指针 if(this != nullptr) { --(*_count); if(*_count == 0) { delete _ptr; delete _count; } } // 否则未初始化的，则进行赋值 else { _ptr = other-&gt;_ptr; _count = other-&gt;_count; ++(*_count); } } } // 析构函数 ~shared_ptr() { if(_ptr) { // 共享技术是正值 if(*_count &gt; 0) { --(*_count); } // 计数减少为0了 else { delete _ptr; delete _count; } } }};typename&lt;T&gt;shared_ptr&lt;T&gt; make_shared(){ return ret(new T());} weak_ptr() 和 shared_ptr() 另一种简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111// 指针表template&lt;typename T&gt;class ptr_table{ protected: static std::unordered_map&lt;T*, size_t&gt; table_;};// 初始化template&lt;typename T&gt;std::unordered_map&lt;T*, size_t&gt; ptr_table&lt;T&gt;::table_;// shared_ptr 实现template&lt;typename T&gt;class shared_ptr : public ptr_table&lt;T&gt; {private: T* ptr_; using ptr_table&lt;T&gt;::table_;public: explicit shared_ptr( T* ptr = nullptr ) noexcept : ptr_(ptr) { table_[ptr] = 1u; } void reset( T* ptr = nullptr ) noexcept { if(--table_[ptr_] == 0u){ table_.erase(ptr_); delete ptr_; } ptr_ = ptr; table_[ptr] = 1u; } ~shared_ptr() noexcept { if(--table_[ptr_] == 0u){ table_.erase(ptr_); delete ptr_; } } shared_ptr&lt;T&gt;&amp; operator=(shared_ptr&lt;T&gt; const&amp; other) noexcept { if(--table_[ptr_] == 0u){ table_.erase(ptr_); delete ptr_; } ptr_ = other.ptr_; ++table_[ptr_]; return *this; } shared_ptr&lt;T&gt;&amp; operator=(shared_ptr&lt;T&gt;&amp;&amp; other) noexcept { std::swap(ptr_, other.ptr_); return *this; } operator bool() const noexcept { return ptr_ == nullptr; } T* get() const noexcept { return ptr_; } T operator*() const noexcept { return *ptr_; } T* operator-&gt;() const noexcept { return ptr_; } size_t use_count() const noexcept { return table_[ptr_]; } bool unique() const noexcept { return table_[ptr_] == 1u; } void swap(shared_ptr&lt;T&gt;&amp; other) noexcept { std::swap(ptr_, other.ptr_); } };// weak_ptr 实现template &lt;typename T&gt;class weak_ptr : public ptr_table&lt;T&gt; {private: T* ptr_; using ptr_table&lt;T&gt;::table_;public: explicit weak_ptr( shared_ptr&lt;T&gt; const&amp; other = shared_ptr&lt;T&gt;() ) noexcept : ptr_(other.get()) {} void reset( shared_ptr&lt;T&gt; const&amp; other = shared_ptr&lt;T&gt;() ) noexcept { ptr_ = other.get(); } ~weak_ptr() noexcept = default; weak_ptr&amp; operator=(weak_ptr&lt;T&gt; const&amp; other) noexcept { ptr_ = other.ptr_; return *this; } weak_ptr&amp; operator=(shared_ptr&lt;T&gt; const&amp; other) noexcept { ptr_ = other.get(); return *this; } weak_ptr&amp; operator=(weak_ptr&lt;T&gt;&amp;&amp; other) noexcept { std::swap(ptr_,other.ptr_); return *this; } size_t use_count() const noexcept { return table_[ptr_]; } bool expired() const noexcept { return table_.find(ptr_) == table_.end(); } shared_ptr&lt;T&gt; lock() const noexcept { return shared_ptr&lt;T&gt;(ptr_); } void swap(weak_ptr&lt;T&gt;&amp; other) noexcept { std::swap(ptr_,other.ptr_); }}; 一种 shared_ptr 的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207#pragma once#include &lt;functional&gt;// 模仿shared_ptr实现一个智能指针template &lt;typename T&gt;class smart_ptr{public: smart_ptr(); explicit smart_ptr(T*); smart_ptr(const smart_ptr&amp;); smart_ptr(T*, std::function&lt;void(T*)&gt;); smart_ptr&amp; operator=(const smart_ptr&amp;); T&amp; operator*() const; T* operator-&gt;() const; ~smart_ptr(); // 向bool的类型转换 explicit operator bool() const; bool unique(); void reset(); void reset(T*); void reset(T*, std::function&lt;void(T*)&gt;); T* release(); T* get() const;private: // 默认的deleter static std::function&lt;void(T*)&gt; default_del;private: unsigned* m_p_use_count = nullptr; T* m_pobject = nullptr; std::function&lt;void(T*)&gt; m_del = default_del;};template &lt;typename T&gt;std::function&lt;void(T*)&gt; smart_ptr&lt;T&gt;::default_del = [](T*p) {delete p; p = nullptr; };template &lt;typename T, typename... Args&gt;smart_ptr&lt;T&gt; make_smart(Args&amp;&amp;... args){ smart_ptr&lt;T&gt; sp(new T(std::forward&lt;Args&gt;(args)...)); return sp;}template &lt;typename T&gt;smart_ptr&lt;T&gt;::smart_ptr() :m_pobject(nullptr), m_p_use_count(new unsigned(1)){}template &lt;typename T&gt;smart_ptr&lt;T&gt;::smart_ptr(T *p) :m_pobject(p), m_p_use_count(new unsigned(1)){}template &lt;typename T&gt;smart_ptr&lt;T&gt;::smart_ptr(T *p, std::function&lt;void(T*)&gt; del) :m_pobject(p), m_p_use_count(new unsigned(1)), m_del(del){}template &lt;typename T&gt;smart_ptr&lt;T&gt;::smart_ptr(const smart_ptr&amp; rhs) :m_pobject(rhs.m_pobject), m_p_use_count(rhs.m_p_use_count), m_del(rhs.m_del){ (*m_p_use_count)++;}template &lt;typename T&gt;smart_ptr&lt;T&gt;&amp; smart_ptr&lt;T&gt;::operator =(const smart_ptr &amp;rhs){ // 使用rhs的deleter m_del = rhs.m_del; // 递增右侧运算对象的引用计数 ++(*rhs.m_p_use_count); // 递减本对象的引用计数 if (--(*m_p_use_count) == 0) { // 如果管理的对象没有其他用户了，则释放对象分配的成员 m_del(m_pobject); delete m_p_use_count; } m_p_use_count = rhs.m_p_use_count; m_pobject = rhs.m_pobject; return *this; // 返回本对象}template &lt;typename T&gt;T&amp; smart_ptr&lt;T&gt;::operator*() const{ return *m_pobject;}template &lt;typename T&gt;T* smart_ptr&lt;T&gt;::operator-&gt;() const{ return &amp;this-&gt;operator*();}template &lt;typename T&gt;smart_ptr&lt;T&gt;::~smart_ptr(){ if (--(*m_p_use_count) == 0) { m_del(m_pobject); m_pobject = nullptr; delete m_p_use_count; m_p_use_count = nullptr; }}template &lt;typename T&gt;bool smart_ptr&lt;T&gt;::unique(){ return *m_p_use_count == 1;}template &lt;typename T&gt;void smart_ptr&lt;T&gt;::reset(){ (*m_p_use_count)--; if (*m_p_use_count == 0) { m_del(m_pobject); } m_pobject = nullptr; *m_p_use_count = 1; m_del = default_del;}template &lt;typename T&gt;void smart_ptr&lt;T&gt;::reset(T* p){ (*m_p_use_count)--; if (*m_p_use_count == 0) { m_del(m_pobject); } m_pobject = p; *m_p_use_count = 1; m_del = default_del;}template &lt;typename T&gt;void smart_ptr&lt;T&gt;::reset(T *p, std::function&lt;void(T*)&gt; del){ reset(p); m_del = del;}template &lt;typename T&gt;T* smart_ptr&lt;T&gt;::release(){ (*m_p_use_count)--; if (*m_p_use_count == 0) { *m_p_use_count = 1; } auto p = m_pobject; m_pobject = nullptr; return p;}template &lt;typename T&gt;T* smart_ptr&lt;T&gt;::get() const{ return m_pobject;}template &lt;typename T&gt;smart_ptr&lt;T&gt;::operator bool() const{ return m_pobject != nullptr;} unique_ptr() 一种简单实现1、几个基本成员函数的作用 1234u.reset(); // 释放 u 指向的对象u.reset(q); // 如果提供了内置指针 q，就令 u 指向这个对象 u.reset(nullptr); // 将 u 置为空u.release(); // u 放弃对指针的控制权，返回指针，并将 u 置为空 2、一些规则 某个时刻只能有一个 unique_ptr 指向一个给定的对象。当它销毁时，它所指向的对象也会被销毁。 初始化 unique_ptr 只能采用直接初始化的方式（explicit 关键字） 不支持复制构造与赋值操作 在创建或者是 reset 一个具有删除器的 unique_ptr 时，必须提供删除器 不支持拷贝与赋值的规则有一个例外，那就是我们可以拷贝或者赋值一个将要被销毁的 unique_ptr（右值引用）12345678910/* 从函数返回一个unique_ptr */unique_ptr&lt;int&gt; clone(int p ){ return unique_ptr&lt;int&gt;(new int(p));}/* 返回一个局部对象的拷贝 */unique_ptr&lt;int&gt; clone(int p ){ unique_ptr&lt;int&gt; ret(new int (p)); return ret;} 3、unique_ptr 使用场景 1、为动态申请的资源提供异常安全保证2、返回函数内动态申请资源的所有权3、在容器中保存指针4、管理动态数组5、作为 auto_ptr 的替代品 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 /*unique_ptr.h 文件 */#ifndef _UNIQUE_PTR_H#define __UNIQUE_Hclass Delete { public: template&lt;typename T&gt; void operator()(T *p) const { delete p; }};template&lt;typename T,typename D = Delete &gt;class unique_ptr {public: explicit unique_ptr(T *pp = nullptr ,const D &amp;dd= D() ) :un_ptr(pp),del(dd) { } ~unique_ptr() { del(un_ptr); } /* 不支持拷贝与赋值 */ unique_ptr(const unique_ptr&amp;) = delete ; unique_ptr&amp; operator=(const unique_ptr&amp; ) = delete ; /*可以拷贝或者赋值一个将要被销毁的 unique_ptr（右值引用）*/ unique_ptr( unique_ptr&amp;&amp; right_value): un_ptr(right_value.un_ptr),del(std::move(right_value.del)) { right_value.un_ptr = nullptr ; } unique_ptr&amp; operator=( unique_ptr&amp;&amp; right_value ) noexcept { if(this != &amp;right_value ){ std::cout &lt;&lt; \"operator &amp;&amp; right_value \" &lt;&lt; std::endl ; del(*this); un_ptr = right_value.un_ptr; del = std::move(right_value.del); right_value.un_ptr = nullptr ; } return *this ; } //u.release() u 放弃对指针的控制权，返回指针，并将 u 置为空 T* release(){ T *tmp = un_ptr ; un_ptr = nullptr ; return tmp ; } /* u.reset() 释放u指向的对象 u.reset(q) 如果提供了内置指针q，就令u指向这个对象 u.reset(nullptr) 将 u 置为空 */ void reset(){ del(un_ptr); } void reset(T* q ){ if( un_ptr ){ del(un_ptr) ; un_ptr = q ; } else un_ptr = nullptr ; } void swap(unique_ptr &amp;other ) noexcept { using std::swap ; swap( un_ptr,other.un_ptr ); swap(del,other.del) ; } T* get() { return un_ptr ; } D&amp; get_deleter(){ return del ; } T&amp; operator*() { return *un_ptr ; } T* operator-&gt;() { return un_ptr ; }private: T *un_ptr = nullptr ; D del ;};#endif 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 /* main.cpp 文件 */#include &lt;iostream&gt;#include &lt;string&gt;//#include\"shared_ptr.h\"#include \"unique_ptr.h\"#include\"DebugDelete.h\"#include &lt;assert.h&gt;struct Foo { Foo() { std::cout &lt;&lt; \"Foo()\\n\"; } ~Foo() { std::cout &lt;&lt; \"~Foo()\\n\"; } Foo(const Foo&amp;) { std::cout &lt;&lt; \"Foo copy ctor\\n\"; } Foo(Foo&amp;&amp;) { std::cout &lt;&lt; \"Foo move ctor\\n\"; }};struct Fooo { Fooo(int n = 0) noexcept : bar(n) { std::cout &lt;&lt; \"Fooo: constructor, bar = \" &lt;&lt; bar &lt;&lt; '\\n'; } ~Fooo() { std::cout &lt;&lt; \"Fooo: destructor, bar = \" &lt;&lt; bar &lt;&lt; '\\n'; } int GetBar() const noexcept { return bar; }private: int bar;};struct D { void bar() { std::cout &lt;&lt; \"Call deleter D::bar()...\\n\"; } void operator()(Foo* p) const { std::cout &lt;&lt; \"Call delete from function object...\\n\"; delete p; }};using namespace std ;int main(){ unique_ptr&lt;string&gt; p1(new string(\"Shengxi-Liu\")); cout &lt;&lt; *p1 &lt;&lt; endl ; { std::cout &lt;&lt; \"======================\\nunique_ptr constructor:\\n\"; unique_ptr&lt;Foo&gt; up1; unique_ptr&lt;Foo&gt; up1b(nullptr); unique_ptr&lt;Foo&gt; up2(new Foo); DebugDelete d; unique_ptr&lt;Foo, DebugDelete&gt; up3(new Foo, d); unique_ptr&lt;Foo, DebugDelete&amp;&gt; up3b(new Foo, d); unique_ptr&lt;Foo, DebugDelete&gt; up4(new Foo, DebugDelete()); unique_ptr&lt;Foo&gt; up5b(std::move(up2)); unique_ptr&lt;Foo, DebugDelete&gt; up6b(std::move(up3)); unique_ptr&lt;Foo&gt; up7 = std::move(up5b); Foo* fp = up7.release(); assert(up7.get() == nullptr); delete fp; up6b.reset(new Foo()); up6b.reset(nullptr); unique_ptr&lt;Fooo&gt; up71(new Fooo(1)); unique_ptr&lt;Fooo&gt; up72(new Fooo(2)); up71.swap(up72); std::cout &lt;&lt; \"up71-&gt;val:\" &lt;&lt; up71-&gt;GetBar() &lt;&lt; std::endl; std::cout &lt;&lt; \"up72-&gt;val:\" &lt;&lt; (up72.get())-&gt;GetBar() &lt;&lt; std::endl; unique_ptr&lt;Foo, D&gt; up8(new Foo(), D()); D&amp; del = up8.get_deleter(); del.bar(); }} 参考资料[1] Stack Overflow, GManNickG’s answer to “What is the copy-and-swap idiom?”. https://stackoverflow.com/a/3279550/816999[2] cppreference.com, “std::shared_ptr”. https://en.cppreference.com/w/cpp/memory/shared_ptr 原文链接:自己动手，实现C++的智能指针C++ 之实现自己的 unique_ptr","link":"/post/3095e612.html"},{"title":"值语义与数据抽象","text":"值语义与数据抽象 一、什么是值语义值语义是指对象的拷贝与原对象无关，就像拷贝 int 一样。C++ 的内置类型 (bool/int/double/char) 都是值语义，标准库里的 complex&lt;&gt;、pari&lt;&gt;、vector&lt;&gt;、map&lt;&gt;、string 等等类型也都是值语义，拷贝之后就与原对象脱离关系。Java 语言的 基本类型（primitive types） 也是值语义。 二、什么是对象语义对象语义指的是面向对象意义下的对象，对象拷贝是禁止的。例如 muduo 里的 Thread 是对象语义，拷贝 Thread 是无意义的，也是被禁止的。因为 Thread 代表线程，拷贝一个 Thread 对象并不能让系统增加一个一模一样的线程。同样的，拷贝一个 Employee 对象也是没有意义的，一个雇员不会变成两个雇员，他也不会领两份薪水。拷贝 TcpConnection 对象也没有意义，系统中只有一个 TCP 连接，拷贝 TcpConnection 对象不会让我们拥有两个连接。Printer 也是不能拷贝的，系统只连接了一个打印机，拷贝 Printer 并不能凭空增加打印机。 Java 中的 class 对象都是对象语义/引用意义 12ArrayList&lt;Integer&gt; a = new ArrayList&lt;Integer&gt;();ArrayList&lt;Integer&gt; b = a; a 和 b 指向的是同一个 ArrayList 对象，修改 a 同时也会影响 b。 值语义与 immutable 无关。Java 有 value object 一说，它实际上是 immutable object，例如 String、Integer、BigInteger、joda.time.DataTime等等(因为 Java 没有办法实现真正的值语义 class，只好用 immutable object 来模拟)。 C++ 中的值语义对象也可以是 mutable，比如 complex&lt;&gt;、pari&lt;&gt;、vector&lt;&gt;、map&lt;&gt;、string 都是可以修改的。 值语义的对象不一定是 POD，例如 string 就不是 POD，但它是值语义的。 值语义的对象不一定小，例如 vector 的元素可多可少，但它始终是值语义的。 三、值语义与生命期值语义的对象要么是 stack object，要么直接作为其他 object 的成员，因此不用担心它的生命期(一个函数使用自己 stack 上的对象，一个成员函数使用自己的数据成员对象)。相反，对象语义的 object 由于不能拷贝，因此我们只能通过指针或引用来使用它。 一旦使用指针和引用来操作对象，那么就要担心所指的对象是否已被释放，这一度是 C++ 程序 bug 的一大来源。由于 C++ 只能通过指针或引用来获得多态性，在 C++ 里基于继承和多态的面向编程有其本质的困难—对象生命期管理(资源管理)。 考虑一个简单的对象建模—家长与子女：a Parent has a Child, a Child knows its Parent。Java 中不用担心内存泄露，也不用担心空悬指针。 123456789public class Parent{ private Child myChild;}public class Child{ private Parent myParent;} C++ 的写法如下： 1234567891011class Child;class Parent : boost::noncopyable{ Child* myChild;};class Child : boost::noncopyable{ Parent* myParent;}; C++ 可以借助 smart pointer 把对象语义转换为值语义，从而轻松解决对象生命期问题：让 Parent 持有 Child 的 smart pointer，同时让 Child 持有 Parent 的 smart pointer。其中一个 smart pointer 应该是 smart pointer 应该是 week reference，否则会出现循环引用，导致内存泄露。 如果 Parent 拥有 Child，Child 的生命期由其 Parent 控制，Child 的生命期小于 Parent。 1234567891011121314151617181920212223class Parent;class Child : boost::noncopyable{ public: explicit Child(Parent* myParent_) : myParent(myParent_) { } private: Parent* myParent;};class Parent : boost::noncopyable{ public: Parent() : myChild(new Child(this)) { } private: boost::scoped_ptr&lt;Child&gt; myChild;}; 上面的设计中，Child 的指针不能泄露给外界，否则仍然有可能出现空悬指针。 如果 Parent 与 Child 的生命期相互独立 12345678910111213141516171819202122232425262728293031323334353637class Parent;typedef boost::scoped_ptr&lt;Parent&gt; ParentPtr;class Child : boost::noncopyable{ public: explicit Child(const ParentPtr&amp; myParent_) : myParent(myParent_) { } private: boost::scoped_ptr&lt;Parent&gt; myParent;};typedef boost::scoped_ptr&lt;Child&gt; ChildPtr;class Parent : public boost::enable_shared_from_this&lt;Parent&gt;, private boost::noncopyable{ public: Parent() { } void addChild() { myChild.reset(new Child(shared_from_this())); } private: ChildPtr myChild;};int main(){ ParentPtr p(new Parent); p-&gt;addChild();} 考虑一个稍微复杂一点的对象模型：“a Child has parents: mom and dad; a Parent has one or more Child(ren); a Parent knows his/her spouse.” 123456789101112// Java 实现public class Parent{ private Parent mySpouse; private ArrayList&lt;Child&gt; myChildren;}public class Child{ private Parent myMom; private Parent myDad;} 如果用 C++ 来实现，如何才能避免出现空悬指针，同时避免出现内存泄露呢？借助 shared_ptr 把裸指针转换为值语义。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Parent;typedef boost::shared_ptr&lt;Parent&gt; ParentPtr;class Child : boost::noncopyable{ public: explicit Child(const ParentPtr&amp; myMom_, const ParentPtr&amp; myDad_) : myMom(myMom_) , myDad(myDad_) { } private: boost::weak_ptr&lt;Parent&gt; myMom; boost::week_ptr&lt;Parent&gt; myDad; };typedef boost::shared_ptr&lt;Child&gt; ChildPtr;class Parent : boost::noncopyable{ public: Parent() { } void setSpouse(const ParentPtr&amp; spouse) { mySpouse = spouse; } void addChild(const ChildPtr&amp; child) { myChildren.push_back(child); } private: boost::weak_ptr&lt;Parent&gt; mySpouse; std::vector&lt;ChildPtr&gt; myChildren;};int main(){ ParentPtr mom(new Parent); ParentPtr dad(new Parent); mom-&gt;setSpouse(dad); dad-&gt;setSpouse(mom); { ChildPtr child(new Child(mom, dad)); mom-&gt;addChild(child); dad-&gt;addChild(child); } { ChildPtr child(new Child(mom, dad)); mom-&gt;addChild(child); dad-&gt;addChild(child); }} 四、值语义与标准库C++ 要求凡是能放入标准容器的类型必须具有值语义。type 必须是 SGIAssignable concept 的 model。但是，由于 C++ 编译器会为 class 默认提供 copy constructor 和 assignment operator，因此除非明确静止，否则 class 总是可以作为标准库的元素类型—尽管程序可以编译通过，但是隐藏了资源管理方面的 bug。 在现代 C++ 中，一般不需要自己编写 copy constructor 或 assignment operator，因为只要每个数据成员都具有值语义的话，编译器自动生成的 member-wise copying &amp; assigning 就能正常工作；如果以 smart ptr 为成员来持有其他对象，那么就能自动启用或禁用 copying &amp; assigning。 五、值语义与C++语言值语义是 C++ 语言的三大约束之一，C++ 的设计初衷是让用户自定义的类型 (class) 能像内置类型 (int) 一样工作，具有同等地位。 class 的 layout 与 C struct 一样，没有额外的开销。定义一个“只包含一个 int 成员的 class” 的对象开销和定义一个 int 一样。 甚至 class data member 都默认是 uninitialized，因为函数局部的 int 也是如此。 class 可以在 stack 上创建，也可以在 heap 上创建。因为 int 可以是 stack variable。 class 的数组就是一个个 class 对象挨着，没有额外的 indirection。因为 int 数组就是这样的。因此派生类数组的指针不能安全转换为基类指针。 编译器会为 class 默认生成 copy constructor 和 assignment operator。其他语言没有 copy constructor 一说，也不允许重载 assignment operator。C++ 的对象默认是可以拷贝的。 当 class type 传入函数时，默认是 make a copy (除非参数声明为 reference)。因为把 int 传入函数时 make a copy。C++ 的函数调用比其他语言复杂之处在于参数传递和返回值传递。C、Java 等语言都是传值，复制几个字节的内存就行了。但是 C++ 对象是值语义，如果以 pass-by-value 方式把对象传入函数，会涉及拷贝构造。代码里看到一句简单的函数调用，实际背后发生的可能是一长串对象构造操作，因此减少无谓的临时对象是 C++ 代码优化的关键之一。 当函数返回一个 class type 时，只能通过 make a copy (C++ 不得不定义 RVO 来解决性能问题)。因为函数返回 int 时是 make a copy。 以 class type 为成员时，数据成员是嵌入的。例如 pair&lt; complex, size_t &gt; 的 layout 就是 complex&lt; double &gt; 挨着 size_t。 六、什么是数据抽象数据抽象 (data abstraction) 是与面向对象 (object-oriented) 并列的一种编程范式。 C++ is a general-purpose programming language with a bias towards systems programming that is a better C supports data abstraction supports object-oriented programming supports generic programming 数据抽象是用来描述(抽象)数据结构的。数据抽象就是 ADT。一个 ADT 主要表现为它支持的一些操作，比如 stack::push()、stack::pop()，这些操作应该具有明确的时间和空间复杂度。另外，ADT 可以隐藏其实现细节，例如 stack 既可以用动态数组实现，又可以用链表实现。ADT 通常是值语义，而 object-based 是对象语义。ADT class 是可以拷贝的，拷贝之后的 instance 与原 instance 脱离关系。 1234stack&lt;int&gt; a;a.push(10);stack&lt;int&gt; b = a;b.pop(); 栈 a 里元素10还在。 C++标准库中的数据抽象 vector 是动态数组，它的主要操作有 size()、begin()、end()、push_back()等等。list 是链表，map 是有序关联数组，set 是有序集合、stack 是 FILO 栈、queue 是 FIFO 队列。 数据抽象与面向对象的区别 面向对象（object-oriented）有三大特征：封装、继承、多态。基于对象（object-based）则只有封装，没有继承和多态，即只有具体类，没有抽象接口。它们两个都是对象语义。 面向对象的核心思想是消息传递（messaging）。数据抽象不是对象语义，而是值语义。比方说 muduo 里的 TcpConnection 和 Buffer 都是具体类，但前者是基于对象的（object-based），而后者是数据抽象。 如果一个 class 代表了其他资源（文件、员工、打印机、账号），那么它通常就是 object-based 或 object-oriented，而不是数据抽象。ADT class 可以作为 Object-based/object-oriented class 的成员，但反过来不成立。 七、数据抽象所需的语言设施支持数据聚合 数据聚合即 data aggregation，或者叫 value aggregation。即定义 C-style struct，把有关数据放到同一个 struct 里。这种数据聚合 struct 是 ADT 的基础，struct list、struct HashTable 等能把链表和哈希表结构的数据放到一起，而不是用几个零散的变量来表示它。 全局函数与重载 定义了 complex，可以同时定义 complex sin(const complex&amp; x) 和 complex exp(const complex&amp; x) 等等全局函数来实现复数的三角函数和指数运算。sin() 和 exp() 不是 complex 的成员，而是全局函数 double sin(double) 和 double exp(double) 的重载。这样能让 double a = sin(b); 和 complex a = sin(b); 具有相同的代码形式，而不必写成 complex a = b.sin();。 成员函数与private数据 数据声明为 private，可以防止外界意外修改。不是每个 ADT 都适合把数据声明为 private，例如 complex、Point、pari&lt;&gt; 这样的 ADT 使用 public data 更加合理。 要能够在 struct 里定义操作，而不是只能用全局函数来操作 struct。比方说 vector 有 push_back() 操作，push_back() 是 vector 的一部分，它必须直接修改 vector 的 private data members，因此无法定义为全局函数。 拷贝控制（copy control） copy data 是拷贝 stack a; stack b = a; 和赋值 stack b; b = a; 的合称。 C++ class 是值语义，copy control 是实现深拷贝的必要手段，而且 ADT 用到的资源只涉及动态分配的内存，所以深拷贝是可行的。相反，object-based 编程风格中的 class 往往代表某样真实的事物（Employee、Accout、File 等等），深拷贝无意义。 C 语言没有 copy control，也没有办法防止拷贝。File* 可以随意拷贝，但是主要关闭其中一个 copy，其他 copy 也都失效了。整个 C 语言对待资源（malloc() 得到的内存，open() 打开的文件，socket() 打开的连接）都是这样的，用整数或指针来代表（即句柄）。而整数和指针类型的的句柄是可以随意拷贝的，很容易造成重复释放、遗漏释放、使用已经释放的资源等常见错误。 操作符重载 如果写动态数组，能像使用内置数组一样使用它，比如支持下标操作。C++ 可以重载 operator[] 来做到这一点。如果要写复数，能像使用内置的 double 一样使用它，比如支持加减乘除。C++ 可以重载 operator+ 等操作符来做到这一点。如果要写日期与时间，希望它能直接用大于或小于号来比较先后，用 == 来判断是否相等。C++ 可以重载 operator&lt; 来做到这一点。这要求语言能重载成员与全局操作符。 如果没有操作符重载，那么用户定义的 ADT 与内置类型用起来不一样了（有的语言要区分 == 和 equals）。Java 里有 BigInteger，但是 BigInteger 用起来和普通的 int/long 大不相同。 12345678public static BigInteger mean(BigInteger x, BigInteger y) { BigInteger two = BigInteger.valueOf(2); return x.add(y).divide(two);}public static long mean(long x, long y) { return (x + y) / 2;} 效率无损 在 C++ 中，提高抽象的层次并不会降低效率。 模板与泛型 写了个 IntVetcor，不想为 double 和 string 再实现一遍同样的代码。应该把 vector 写成 template，然后用不同的类型来具现化它，从而得到 vector&lt; int &gt;、vector&lt; double &gt;、vector&lt; complex &gt;、vector&lt; string &gt; 等具体类型。","link":"/post/722035e8.html"},{"title":"C++面向对象和虚函数","text":"C++面向对象和虚函数 反思C++面向对象和虚函数朴实的C++设计C++ 基于对象的风格，就是具体类加全局函数。 定义并使用清晰一致的接口很重要，但接口不一定非得是抽象基类，一个类的成员函数就是它的接口。一个进程内部的解耦意义不大；相反，函数调用是最直接有效的通信方式了。或许采用接口类/实现类的一个可能的好处是依赖注入，便于单元测试。 确定性析构是 C++ 区别其他主流开发语言(Java/C#/C/动态脚本语言)的主要特性。 程序库的二进制兼容性二进制兼容性是在升级(也可能是 bug fix)库文件的时候，不必重新编译使用了这个库的可执行文件或其他库文件，并且程序的功能不被破坏。 open 函数的原型如下，其中 flags 的取值有三个：O_RDONLY、O_WRONLY、O_RDWR。 1int open(const char *pathname, int flags); 这几个值不满足按位或(bitwise-OR)的关系，即 (O_RDONLY | O_WRONLY) != O_RDWR。因为它们的值分别是0、1、2。 操作系统的 system call 可以看成 Kernel 与 User space 的 interface，kernel 在这个意义下也可以当成 shared library，可以把内核从2.6.30升级到2.6.35，而不需要重新编译所有用户态的程序。 破坏库的ABI的情况C++ 编译器 ABI 的主要内容包括以下几个方面： 函数参数传递的方式，比如 x86-64 用寄存器来传函数的前4个整数参数； 虚函数的调用方式，通常是 vptr/vtbl 机制，然后用 vtbl[offset] 来调用； struct 和 class 的内存布局，通过偏移量来访问数据成员； name mangling; RTTI 和异常处理的实现。 一个修改动态库导致二进制不兼容的例子。比如原来动态库里定义了 non-virtual 函数 void foo(int)，新版的库把参数写成了 double。那么现有的可执行文件就无法启动，会发生 undefined symbol 错误，因为这两个函数的 mangled name 不同。但是对于 virtual 函数 foo(int)，修改其参数类型并不会导致加载错误，而是会发生诡异的运行时错误。因为虚函数的决议(resolution)是靠偏移量，并不是靠符号名。 常见的一些源代码兼容但是二进制代码不兼容的例子： 给函数增加默认参数，现有的可执行文件无法传这个额外的参数。 增加虚函数，会造成 vtbl 里排列变化。(不要考虑只在末尾增加这种取巧行为，因为你的 class 可能被继承。) 增加默认模板类型参数，比方说 Foo 改为 Foo&lt;T, Alloc=alloc &gt;，这会改变 name mangling。 改变 enum 的值，把 enum Color { Red = 3 }; 改为 Red = 4。这会造成错位。由于 enum 自动排列取值，添加 enum 项也是不安全的(在末尾添加除外)。 给 class Bar 增加数据成员，造成 sizeof(Bar) 变大，以及内部数据成员的 offset 变化。通常不是安全的，但也有例外。 如果客户代码里有 new Bar，肯定不安全。因为 new 的字节数不够装下新 Bar 对象。相反，如果 library 通过 factory 返回 Bar*(并通过 factory 来销毁对象)或者直接返回 shared_ptr，客户端不需要用到 sizeof(Bar)，那么可能是安全的。 如果客户代码里有 Bar* pBar; pBar-&gt;memberA = xx;，那么肯定不安全。因为 menberA 的新 Bar 的编译可能会变。相反，如果只是通过成员函数来访问对象的数据成员，客户端不需要用到 data member 的 offsets，那么可能是安全的。 如果客户调用 pBar-&gt;setMemberA(xx);，而 Bar::setMemberA() 是个 inline function，那么肯定不安全，因为偏移量已经被 inline 到客户的二进制代码里了。如果 setMemberA() 是 outline function，其实现位于 shared library 中，会随着 Bar 的更新而更新，那么可能是安全的。 多半是安全的做法 增加新的 class。 增加 non-virtual 成员函数或 static 成员函数。 修改数据成员的名称，因为生产的二进制代码是按偏移量来访问的。但是这会造成源码级的不兼容。 以只包含虚函数的 class(interface class) 作为程序库的接口，一旦发布，无法修改。Windows 下，Visual C++ 编译的时候要选择 Release 或 Debug 模式，而且 Debug 模式编译出来的 library 通常不能在 Release binary 中使用(反之亦然)，这也是因为两种模式下的 CRT 二进制不兼容(主要是内存分配方面，Debug 有自己的簿记(bookkeeping))。Linux 可以混用。 解决方法采用静态链接不是指使用(.a)，而是指完全从源码编译出可执行文件。在分布式系统里，采用静态链接也带来部署上的好处，只要把可执行文件放到机器上就能运行，不用考虑它依赖的 libraries。 通过动态库的版本管理来控制兼容性比如 1.0.x 版本系列之间做到二进制兼容，1.1.x 版本系列之间做到二进制兼容，而 1.0.x 和 1.1.x 不必二进制兼容。 用pimpl技法，编译器防火墙在头文件中只暴露 non-virtual 接口，并且 class 的大小固定为 sizeof(Impl*)，这样可以随意更新库文件而不影响可执行文件。这么做增加了一道间接性，可能有一定的性能损失。 避免使用虚函数作为库的接口接口表示一个广义的接口，即一个库的代码界面；用英文 interface 表示狭义的接口，即只包含 virtual function 的 class，这类 class 通常没有 data member，在 Java 里有一个专门的关键字 interface 来表示它。 程序库作者的生存环境如果打算新写一个 C++ library，通常要做如下几个决策： 以什么方式发布？动态库还是静态库？ 以什么方式暴露库的接口？可选的做法有：以全局(含 namespace 级别)函数为接口、以 class 的 non-virtual 成员函数为接口、以 virtual 函数为接口。 在作出上面两个决策之前，考虑两个基本假设： 代码会有 bug，库也不例外。将来可能会发布 bug fixes。 会有新的功能需求。 如果需要 hot fix，那么只能用动态库；否则，在分布式系统中使用静态库更容易部署，动态库比静态库节约内存这种优势现在已不是太重要。 要选择一种可扩展的(extensible)接口风格，让库的升级变得更轻松。升级有两层意思： 对于 bug fix only 的升级，二进制库文件的替换应该兼容现有的二进制可执行文件。 对于新增功能的升级，应该对客户代码友好。 虚函数作为接口的两大用途 调用，也就是库提供一个什么功能(比如绘图 Graphics)，以虚函数为接口方式暴露给客户端代码。客户端代码一般不需要继承这个 interface，而是直接调用其 member function。 回调，也就是事件通知，比如网络库的连接建立、数据到达、连接断开等等。客户端代码一般会继承这个 interface，然后把对象实体注册到库里边，等库来回调自己。一般来说客户端不会自己去调用这些 member function，除非是为了写单元测试模板库的行为。 混合，一个 class 既可以被客户端代码继承用作回调，又可以被客户端直接调用。 对于回调方式，现代 C++ 有 boost::function + boost::bind。举一个虚构的图形库说明问题。 12345678910111213141516171819202122struct Point{ int x; int y;};class Graphics{ virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(Point p, int r);};// 客户端使用方法Graphics* g = getGraphics();g-&gt;drawLine(0, 0, 100, 200);releaseGraphics(g); 虚函数作为接口的弊端C++ 以 vtable[offset] 方式实现虚函数调用，而 offset 又是根据虚函数声明的位置隐式确定的。增加 drawLine(double x0, double y0, double x1, double y1)，造成 vtable 的排列发生了变化，现有的二进制可执行文件无法再用旧的 offset 调用到正确的函数。有种不太优雅的做法，可以直接把新的虚函数放到 interface 的末尾。如果 Graphics 被继承，那么新增虚函数会改变派生类中的 vtable offset 变化，同样不是二进制兼容的。 有两种似乎安全的做法： 通过链式继承来扩展现有的 interface1234567891011121314151617181920212223class Graphics{ virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(Point p, int r);};class Graphics2 : public Graphics{ using Graphics::drawLine; using Graphics::drawRectangle; using Graphics::drawArc; // added in version 2 virtual void drawLine(double x0, double y0, double x1, double y1); virtual void drawRectangle(double x0, double y0, double x1, double y1); virtual void drawArc(double x, double y, double r);}; 通过多重继承来扩展现有的 interface123456789101112131415161718192021222324252627282930313233class Graphics{ virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(Point p, int r);};class Graphics2{ virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawLine(double x0, double y0, double x1, double y1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(double x0, double y0, double x1, double y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(double x, double y, double r); virtual void drawArc(Point p, int r);};// 在实现中采用多重接口继承class GraphicsImpl : public Graphics, // version1 public Graphics2, // version2{} 假如Linxu系统调用以COM接口方式实现Linux kernal 给每一个 system call 赋予一个终身不变的数字代号，等于把虚函数表的排列固定下来。 动态库接口的推荐做法 其一，如果动态库的使用范围比较窄。 其二，如果库的使用范围很广，用户很多，各家的 release cycle 不尽相同，那么推荐 pimpl 技法，并考虑多采用 non-menber non-friend function in namespace 作为接口。 暴露的接口里边不要有虚函数，要显式声明构造函数、析构函数、并且不能 inline。另外 sizeof(Graphics) == sizeof(Graphics::Impl*)。12345678910111213141516171819class Graphics{ public: Graphics(); // outline ctor ~Graphics(); // outline dtor virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(Point p, int r); private: class Impl; // 头文件只放声明 boost::scope_ptr&lt;Impl&gt; impl;}; 在库的实现中把调用转发(forward)给实现 Graphics::Impl，这部分代码位于 .so/.dll中，随库的升级一起变化。1234567891011121314151617181920212223242526272829303132333435#include &lt;graphics.h&gt;class Graphics::Impl{ public: virtual void drawLine(int x0, int y0, int x1, int y1); virtual void drawLine(Point p0, Point p1); virtual void drawRectangle(int x0, int y0, int x1, int y1); virtual void drawRectangle(Point p0, Point p1); virtual void drawArc(int x, int y, int r); virtual void drawArc(Point p, int r);};Graphics::Graphics() : impl(new Impl){}Graphics::~Graphics(){}void Graphics::drawLine(int x0, int y0, int x1, int y1){ impl-&gt;drawLine(x0, y0, x1, y1);}void Graphics::drawLine(Point p0, Point p1){ impl-&gt;drawLine(p0, p1);} 如果要加入新的功能，不必通过继承来扩展，可以原地修改，并且很容易保持二进制兼容性。 采用 pimpl 多了一道 explicit forward 的手续，带来的好处是可扩展性与二进制兼容性。pimpl 扮演了编译器防火墙的作用。 为什么 non-virtual 函数比 vitual 函数更健壮？因为 virtual function 是 bind-by-vtable-offset，而 non-virtual function 是 bind-by-name。加载器(loader)会在程序启动时做决议(resolution)，通过 mangled name 把可执行文件和动态库链接到一起。就像使用 Internet 域名比使用 IP 地址更能适应变化一样。用 free function 有时候更好。 以boost::function和boost::bind取代虚函数用继承树这种方式来建模，确实是基于概念分类的思想。分类是西方哲学一早就有的思想，可以上溯到古希腊时期。 比如电影，可以分为科幻片、爱情片、伦理片、战争片、灾难片、恐怖片等等。 比如生物，可以分为动物和植物，动物又可以分为有脊椎动物和无脊椎动物，有脊椎动物又分为鱼类、两栖类、爬行类、鸟类、哺乳类等。 比如技术书籍分为电子类、通信类、计算机类等等，计算机书籍又可分为编程语言、操作系统、数据结构、数据库、网络技术等等。 Ruby 的 duck typing 和 Google Go 的无继承都可以看作以 tag 取代分类(层次化的类型)的代表。一个 object 只要提供了相应的 operations，就能当作某种东西来用，不需要显式地继承或实现某个接口。 在传统的 C++ 程序中，事件回调是通过虚函数进行的。网络库往往会定义一个或几个抽象基类(Handler class)，其中声明了一些(纯)虚函数，如 onConnect()、onDisconnect()、onMessage()、onTimer()等等。使用者需要继承这些基类，并覆写(override)这些虚函数，以获得事件回调通知。C++ 的动态绑定只能通过指针和引用实现，使用者必须把派生类(MyHandler)对象的指针或引用隐式转换为基类(Handler)的指针或引用，再注册到网络库中。MyHandler 对象通常是动态创建的，位于堆上，用完后需要 delete。网络库调用基类的虚函数，通过动态绑定机制实际调用的是用户在派生类中 override 的虚函数，这也是各种 OO framework 的通行做法。 std::function + std::bind 这种方式的一个优点是不必担心对象的生存期。这种借口方式对用户代码的 class 类没有限制(不必从特定的基类派生)，对成员函数名也没有限制，只对函数签名有部分限制。这样也解决了空悬指针的难题，因为传给网络库的都是具有值语义的 boost::function 对象。 基本用途boost::function 就像 C# 里的 delegate，可以指向任何函数，包括成员函数。当用 bind 把某个成员函数绑到某个对象上时，就得到了一个 closure(闭包)。 123456789101112131415161718192021222324252627282930313233343536class Foo{ public: void methodA(); void methodInt(int a); void methodString(const string&amp; str);};class Bar{ public: void methodB();};boost::function&lt;void()&gt; f1; // 无参数，无返回值Foo foo;f1 = boost::bind(&amp;Foo::methodA, &amp;foo);f1(); // 调用 foo.methodA();Bar bar;f1 = boost::bind(&amp;Bar::methodB, &amp;bar);f1(); // 调用 bar.methodB();f1 = boost::bind(&amp;Foo::methodInt, &amp;foo, 42);f1(); // 调用 foo.methodInt(42);f1 = boost::bind(&amp;Foo::methodString, &amp;foo, \"hello\");f1(); // 调用 foo.methodString(\"hello\"); // bind 拷贝的是实参类型(const char*)，不是形参类型(string) // 这里形参中的 string 对象的构造发生在调用 f1 的时候，而非 bind 的时候，因此要留意 bind 的实参(const char*)的生命期， // 必要时可通过 bind(&amp;Foo::methodString, &amp;Foo, string(aTempBuf))来保证安全。boost::function&lt;void(int)&gt; f2; // int 参数，无返回值f2 = boost::bind(&amp;Foo::methodInt, &amp;foo, _1);f2(53); // 调用 foo.methodInt(53); 有了 bind，同一个类的不同对象可以 delegate 给不同的实现，从而实现不同的行为。 对程序库的影响继承是第二强的一种耦合(最强耦合的是友元)。 1. 线程库常规OO设计 写一个 Thread base class，含有(纯)虚函数 Thread::run()，然后应用程序派生一个 derived class，覆写 run()。程序里的每一种线程对应一个 Thread 的派生类。缺点：如果一个 class 的三个 method 需要在三个不同的线程中执行，就得写 helper class(es)并玩一些 OO 把戏。 基于boost::function的设计 令 Thread 是一个具体类，其构造函数接受 ThreadCallback 对象。应用程序只需提供一个能转换为 ThreadCallback 的对象(可以是函数)，即可创建一份 Thread 实体，然后调用 Thread::start()即可。 12345678910111213141516171819202122232425262728293031323334353637class Thread{ public: typedef boost::function&lt;void()&gt; ThreadCallback; Thread(ThreadCallback cb) : cb_(cb) { } void start() { // some magic to call run() in new created thread } private: void run(); { cb_(); } ThreadCallback cb_; // ...};// 使用方式class Foo // 不需要继承{ public: void runInThread(); void runInAnotherThread();};Foo foo;Thread thread1(boost::bind(&amp;Foo::runInThread, &amp;foo));Thread thread2(boost::bind(&amp;Foo::runInAnotherThread, &amp;foo, 43));thread1.start(); // 在两个线程中分别运行两个成员函数thread2.start(); 2. 网络库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Connection;class NetServer : boost::noncopyable{ public: typedef boost::function&lt;void (Connection*)&gt; ConnectionCallback; typedef boost::function&lt;void (Connection*, const void*, int len)&gt; MessageCallback; NetServer(uint16_t port); ~NetServer(); void registerConnectionCallback(const ConnectionCallback&amp;); void registerMessageCallback(const MessageCallback&amp;); void sendMessage(Connection*, const void* buf, int len); private: // ...};class EchoService{ public: // 符合 NetServer::sendMessage 的原型 typedef boost::function&lt;void (Connection*, const void*, int)&gt; SendMessageCallback; EchoService(const SendMessageCallback&amp; sendMsgCb) : sendMessageCb_(sendMsgCb) // 保存 boost::funtion { } // 符合 NetServer::MessageCallback 的原型 void onMessage(Connection* conn, const void* buf, int size) { printf(\"Received Msg from Connection %d: %.*s\\n\", conn-&gt;id(), size, (const char*)buf); sendMessageCb_(conn, buf, size); // echo back } // 符合 NetServer::ConnectionCallback 的原型 void onConnection(Connection* conn) { printf(\"Connection from %s:%d is %s\\n\", conn-&gt;ipAddr(), conn-&gt;port(), conn-&gt;connected() ? \"UP\" : \"DOWN\"); } private: SendMessageCallback sendMessageCb_;};// 扮演上帝的角色，把各部分拼起来int main(){ NetServer server(7); EchoService echo(bind(&amp;NetService::sendMessage, &amp;server, _1, _2, _3)); server.registerMessageCallback( bind(&amp;EchoService::onMessage, &amp;echo, _1, _2, _3)); ) server.registerConnectionCallback( bind(&amp;EchoService::onConnection, &amp;echo, _1)); ) server.run();} 对面向对象程序设计的影响面向对象的三要素是封装、继承和多态。继承和多态不仅规定了函数的名称、参数、返回类型，还规定了类的继承关系。在现代的 OO 编程语言里，借助反射和 attribute/annotation，已经大大放宽了限制。JUnit3.x 是用反射，找出派生类里的名字符合 void test*() 的函数来执行的。 对面向对象设计模式的影响 既然虚函数能用 closeure 代替，那么很多 OO 设计模式，尤其是行为模式，就失去了存在的必要。既然没有继承体系，那么很多创建型模式似乎也没用了(比如 Factory Method 可以用 boost::function&lt;Base* ()&gt; 替代)。 依赖注入与单元测试 EchoService 可算是依赖注入的例子。EchoServcie 需要一个什么东西来发送消息，它对这个东西的要求只是函数原型满足 SendMessageCallback，而并不关心数据到底发到网络上还是发到控制台。在正常使用的时候，数据应该发给网络；而在做单元测试的时候，数据应该发给某个 DataSink。 什么时候使用继承 如果是指 OO 中的 public 继承，即为了接口与实现分离。则在派生类的数目和功能完全确定的情况下使用。如果是功能继承，则会考虑继承 boost::noncopyable 或 boost::enable_shared_from_this。例如，IO multiplexing 在不同的操作系统下有不同的推荐实现，最通用的 select()、POSIX 的 poll()、Linux 的 epoll()、FreeBSD 的 kqueue() 等，数目固定，功能也完全确定，不用考虑扩展，那么设计一个 NetLoop base class 加若干具体 classes 就是不错的解决办法。用多态来代替 switch-case 以达到简化代码的目的。 基于接口的设计 不会飞的企鹅(Penguin)究竟应不应该继承自鸟(Bird)，如果 Bird 定义了 virtual function fly() 的话。可以把具体的行为提出来，作为 interface，比如 Flyable(能飞的)，Runnable(能跑的)，然后让企鹅实现 Runnable，麻雀实现 Flyable 和 Runable。interface 的粒度应该足够小，或许一个 method 就够了，那么 interface 实际上退化成了给类型打的标签(tag)。这种情况下，完全可以使用 boost::function 来代替。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Penguin // 企鹅能游泳，也能跑{ public: void run(); void swim();};class Sparrow // 麻雀能飞，也能跑{ public: void fly(); void run();};// 以 boost::function 作为接口typedef boost::function&lt;void()&gt; FlyCallback;typedef boost::function&lt;void()&gt; RunCallback;typedef boost::function&lt;void()&gt; SwimCallback;// 一个既用到 run，也用到 fly 的客户 classclass Foo{ public: Foo(FlyCallback flyCb, RunCallback runCb) : flyCb_(flyCb), runCb_(runCb) { } private: FlyCallback flyCb_; RunCallback runCb_;};// 一个既用到 run，也用到 swim 的客户 classclass Bar{ public: Bar(SwimCallback swimCb, RunCallback runCb) : swimCb_(swimCb), runCb_(runCb) { } private: SwimCallback swimCb_; RunCallback runCb_;};int main(){ Sparrow s; Penguin p; // 装配起来，Foo 要麻雀，Bar 要企鹅 Foo foo(bind(&amp;Sparrow::fly, &amp;s), bind(&amp;Sparrow::run, &amp;s)); Bar bar(bind(&amp;Penguin::swim, &amp;p), bind(&amp;Penguin::run, &amp;p));}","link":"/post/9d2bfddd.html"},{"title":"C/C++编译模型","text":"C++ 语言的三大约束：与 C 兼容、零开销(zero overhead)原则、值语义。 C语言编译模型 In general, C++ implementations obey the zero-overhead principle: What you don’t use, you don’t pay for [Stroustrup, 1994]. And further: What you do use, you couldn’t hand code any better. 123#include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socket_len addrlen); C++ 编译器必须能理解头文件 sys/socket.h 中 struct sockaddr 的定义，生成与 C 编译器完全相同的 layout(包括采用相同的对齐 (alignment) 算法)，遵循 C 语言的函数调用约定(参数传递、返回值传递、栈帧管理等等)。 笼统地说把 .cc 文件编译为可执行文件，指的的是 preprocessor/compiler/assembler/linker 这四个步骤。 预编译，预编译的时候做一些简单的文本替换，比如宏替换，而不进行语法的检查； 编译，在编译阶段，编译器将检查一些语法错误，但是，如果使用的函数事先没有定义这种情况，不再这一阶段检查，编译后，得到 .s 文件； 汇编，将 C/C++ 代码变为汇编代码，得到 .o 或者 .obj 文件； 链接，将所用到的外部文件链接在一起，在这一阶段，就会检查使用的函数有没有定义，链接过后，形成可执行文件 .exe。 C++ 没有模块机制，不能像其他现代编程语言那样用 import 或 using 来引入当前源文件用到的库，而必须用 include 头文件的方式来机械地将库的接口声明以文本替换的方式载入，再重新 parse 一遍。这也带来了一些隐患，部分原因是因为头文件包含具有传递性，引入不必要的依赖；另一个原因是头文件是在编译时使用，动态库文件是在运行时使用，二者的时间差可能带来不匹配，导致二进制兼容性方面的问题。 隐式函数声明(implicit declaration of function)代码在使用前文未定义的函数时，编译器不需要也不检查函数原型：既不检查参数个数，也不检查参数类型与返回值类型。编译器认为未声明的函数都返回 int，并且能接受任意个数的 int 型参数。而且早期的 C 语言甚至不严格区分指针和 int，而是认为两者可以相互赋值转换。 12345678910111213141516171819202122232425int main() # 这个程序没有引用任何头文件{ printf(\"hello C.\\n\"); # 隐式声明 int printf(...); return 0;}$ gcc hello.c -Wall # 用 gcc 可以编译运行通过ubuntu@VM-0-9-ubuntu:~$ gcc hello.c -Wallhello.c: In function ‘main’:hello.c:3:5: warning: implicit declaration of function ‘printf’ [-Wimplicit-function-declaration] printf(\"hello C.\\n\"); ^~~~~~hello.c:3:5: warning: incompatible implicit declaration of built-in function ‘printf’hello.c:3:5: note: include ‘&lt;stdio.h&gt;’ or provide a declaration of ‘printf’$ g++ hello.c -Wall # 用 g++ 则会报错ubuntu@VM-0-9-ubuntu:~$ g++ hello.c -Wallhello.c: In function ‘int main()’:hello.c:3:5: error: ‘printf’ was not declared in this scope printf(\"hello C.\\n\"); ^~~~~~hello.c:3:5: note: suggested alternative: ‘int’ printf(\"hello C.\\n\"); ^~~~~~ int 如果 C 程序用到了某个没有定义的函数(可能错误拼写了函数名)，实际造成的是链接错误 (undefined reference)，而非编译错误。 1234567891011121314int main(){ helloworld(); # 隐式声明 helloworld return 0;}$ gcc undefined.c -Wallubuntu@VM-0-9-ubuntu:~$ gcc undefined.c -Wallundefined.c: In function ‘main’:undefined.c:3:5: warning: implicit declaration of function ‘helloworld’ [-Wimplicit-function-declaration] helloworld(); ^~~~~~~~~~/tmp/ccQUxJ5b.o: In function `main':undefined.c:(.text+0xa): undefined reference to `helloworld'collect2: error: ld returned 1 exit status # 真正报错的是 ld，不是 cc1 #include 完成文件内容替换，#define 只支持定义宏常量，不支持定义宏函数。早期的头文件里只放 struct 定义、外部变量的声明、宏常量。 C 语言是按单遍编译 (one pass) 来设计： C 语言要求结构体必须先定义，才能访问其成员，否则编译器不知道结构体成员的类型和偏移量，无法立刻生成目标代码。 局部变量也必须先定义再使用，如果把定义放在后面，编译器在第一次看到一个局部变量时并不知道它的类型和在 stack 中的位置，无法立刻生成代码，只能报错退出。 为了方便编译器分配 stack 空间，C 语言要求局部变量只能在语句块的开始处定义。 对于外部变量，编译器只需要知道它的类型和名字，不需要知道它的地址，因此需要先声明后使用。在生成的目标代码中，外部变量的地址是个空白，留给链接器填上。 当编译器看到一个函数调用时，按隐式函数规则，编译器可以立刻生成调用函数的汇编代码(函数参数入栈、调用、获取返回值)，这里唯一尚不能确定的是函数的实际地址，编译器可以留下一个空白给链接器去填。 C++编译模型单遍编译编译器只能根据目前看到的代码做出决策，读到后面的代码也不会影响前面做出的决定。 名字查找C++ 的名字有类型名、函数名、变量名、typedef 名、template 名等。1Foo&lt;T&gt; a; # Foo、T、a 这三个名字都不是 macro 如果不知道 Foo、T、a 这三个名字代表什么，编译器就无法进行语法分析。有如下三种可能：1、Foo 是个 template class Foo；T 是 type，那么这句话以 T 为模板类型参数类型具现化了 Foo 类型，并定义了变量 a。2、Foo 是个 template class Foo；T 是 const int 变量，那么这句话以 T 为非类型模板参数具现化了 Foo 类型，并定义了变量 a。3、Foo、T、a 都是 int，这句话没有任何意义。 C++ 编译器的符号表至少要保存目前已看到的每个名字的含义，包括 class 的成员定义、已声明的变量、已知的函数原型等，才能正确解析源代码。如果考虑 template，编译 template 的难度是很大的。编译器还要正确处理作用域嵌套引发的名字的含义变化：内层作用域中的名字有可能遮住 (shadow) 外层作用域中的名字。建议用 g++ 的 -Wshadow 选项来编译代码。(muduo 的代码都是 -Wall -Wextra -Werror -Wconversion -Wshadow 编译的)。 函数重载决议当 C++ 编译器读到一个函数调用语句时，它必须(也只能)从目前已看到的同名函数中选出最佳函数。如果交换两个 namespace 级的函数定义在源代码中的位置，有可能改变程序的行为。12345678910111213141516171819void foo(int){ printf(\"foo(int);\\n\");}void bar(){ foo('a'); // 调用 foo(int)}void foo(char){ printf(\"foo(char);\\n\");}int main(){ bar();} 如果在重构代码的时候把 void bar() 的定义挪到 void foo(char) 之后，程序的输出就不一样了。 前向声明使用前向声明可以减少编译期依赖。如果代码里调用了 foo()，C++ 编译期 parse 此处函数调用时，需要生成函数调用的目标代码。为了完成语法检查并生成调用函数的目标代码，编译期需要知道函数的参数个数和类型以及函数的返回值类型，它并不需要知道函数体的实现(除非要做 inline 展开)。因此通常把函数原型放到头文件里。 12345678910// in foo.hvoid foo(int); // 原型声明// in foo.cc#include \"foo.h\"void foo(int, bool) // 在定义的时候把参数列表和返回类型抄一遍{ // 有抄错的可能，也可能将来改了一处，忘了改另一处 // do something} 编译上述代码不会出错，编译器会认为 foo 有两个重载。但是链接整个程序会报错：找不到 void foo(int) 的定义。这是 C++ 的一种典型缺陷，即一样东西区分声明和定义，代码放到不同的文件中，这就有可能出现不一致。 编译器通常能查出参数列表不同，但不一定能查出返回类型不同，也可能参数类型相同，但是顺序调换了。 12draw(int height, int width)，定义的时候写成 draw(int width, int height)编译器无法查出此类错误，因为原型声明中的变量名是无用的。 其他语言似乎没有这个问题。Java 不需要使用函数原型，一个成员函数的参数列表只需要在代码里出现一次。Java 编译器也不受单遍编译的约束，调整成员函数的顺序不会影响代码语义。Java 没有头文件包含机制，而是基于 package 的模块化机制。 class 的前向声明 对于 class Foo，以下几种使用不需要看见其完整定义： 定义或声明 Foo* 和 Foo&amp;，包括用于函数参数、返回类型、局部变量、类成员变量等等。这是因为 C++ 的内存模型是 flat 的，Foo 的定义无法改变 Foo 的指针或引用的含义。 声明一个以 Foo 为参数或返回类型的函数，Foo bar() 或 void bar(Foo f)，代码里调用这个函数就需要知道 Foo 的定义，因为编译器需要使用 Foo 的拷贝构造函数和析构函数，因此至少要看到它们的声明(虽然构造函数没有参数，但是有可能位于 private 区)。 不能重载 &amp;&amp;、||、，(逗号)、一元 operator&amp; (取地址操作符)，重载 operator&amp;，这个 class 就不能用前向声明了。 123456class Foo; // 前向声明void bar(Foo&amp; foo){ Foo *p = &amp;foo; // 这是取 foo 的地址，但是如果重载了 &amp;，意思就变了。} C++ 比 C 链接模型增加了两项内容： 函数重载，需要类型安全的链接，即 name mangling vague linkage，即同一个符号有多份互不冲突的定义。C 语言一个符号在程序中只能有一处定义，否则就会重复定义。C++ 编译器在处理单个源文件的时候并不知道某些符号是否应该在本编译单元定义。只能在每个目标文件生成一份弱定义，而依赖链接器去选择一份作为最终的定义，这就是 vague linkage。 C++链接函数重载C++ 编译器普遍采用名字改编 (name mangling)，为每个重载函数生成独一无二的名字，这样在链接的时候就能找到正确的重载版本。 12345678910111213141516171819// foo.ccint foo(bool x){ return 42;}int foo(int x){ return 100;}ubuntu@VM-0-9-ubuntu:~$ g++ -c foo.cc ubuntu@VM-0-9-ubuntu:~$ nm foo.o # foo.o 定义了两个 external linkage 函数0000000000000000 T _Z3foob0000000000000010 T _Z3fooiubuntu@VM-0-9-ubuntu:~$ c++filt _Z3foob _Z3fooi # unmangle 这两个函数名foo(bool) # 注意，mangled name 里没有返回类型foo(int) 普通 non-template 函数的 mangled name 不包含返回类型。返回类型不参与函数重载。如果一个源文件用到了重载函数，但它看到的函数原型声明的返回类型是错的(违反了 ODR)，链接器无法捕捉这样的错误。 123456789101112131415// main.ccvoid foo(bool);int main(){ foo(true);}ubuntu@VM-0-9-ubuntu:~$ g++ -c main.ccubuntu@VM-0-9-ubuntu:~$ nm main.o # 目标文件依赖 _Z3foob 这个符号 U _GLOBAL_OFFSET_TABLE_0000000000000000 T main U _Z3foobubuntu@VM-0-9-ubuntu:~$ g++ main.o foo.o # 能正常生成 ./a.out inline函数如果编译器无法 inline 展开的话，每个编译单元都会生成 inline 函数的目标代码，然后链接器会从多份实现中任选一份保留，其余的则丢弃(vague linkage)。如果编译器能够展开 inline 函数，那就不必单独为之生成目标代码了(除非使用函数指针指向它)。 如何判断一个 C++ 可执行文件是 debug build 还是 release build？即如何判断一个可执行文件是 -O0 编译还是 -O2 编译？一个方法就是看 class template 的短成员函数有没有被 inline 展开。 123456789101112131415161718// vec.cc#include &lt;vector&gt;#include &lt;stdio.h&gt;int main(){ std::vector&lt;int&gt; vi; printf(\"%zd\\n\", vi.size()); # 这里调用了 inline 函数 size()}ubuntu@VM-0-9-ubuntu:~$ g++ -Wall vec.cc # non-optimized buildubuntu@VM-0-9-ubuntu:~$ nm ./a.out | grep size | c++filt 0000000000000906 W std::vector&lt;int, std::allocator&lt;int&gt; &gt;::size() const// vector&lt;int&gt;::size() 没有 inline 展开，目标文件中出现了函数(弱)定义。ubuntu@VM-0-9-ubuntu:~$ nm ./a.out | grep size | c++filt ubuntu@VM-0-9-ubuntu:~$ // 没有输出，因为 vector&lt;int&gt;::size() 被 inline 展开了。 编译器自动生成 class 析构函数也是 inline 函数，有时候要故意 out-line，防止代码膨胀或出现编译错误。 1234567891011121314// printer.h#include &lt;boost/scoped_ptr.hpp&gt;class Printer{ public: Printer(); ~Printer(); // make it out-line // other member functions private: class Impl; // forward declaration only boost::scoped_ptr&lt;Impl&gt; impl_;} 1234567891011121314#include \"printer.h\"class Printer::Impl{ // members};Printer::Printer() : impl_(new Impl) // 现在编译器看到了 Impl 的定义，这句能编译通过{}Printer::~Printer() // 析构函数是空的，也必须放到这里定义。否则编译器{ // 在将隐式声明的 ~Printer() inline 展开的时候无法看到} // Impl::~Impl() 的声明，会报错。见 boost::check_delete 模板C++ 模板包括函数模板和类模板，与链接相关的话题包括： 函数定义，包括具现化后的函数模板、类模板的成员函数、类模板的静态成员函数等。 变量定义，包括函数模板的静态数据变量、类模板的静态数据成员、类模板的全局对象等。 模板编译链接的不同之处在于，以上具有 external linkage 的对象通常会在多个编译单元被定义。链接器必须进行重复代码消除，才能正确生成可执行文件。 template 和 inline 函数会不会导致代码膨胀？ 123456789101112131415161718192021222324252627282930template&lt;int Size&gt;class Buffer{ public: Buffer() : index_(0) {} void append(const void* data, int len) { ::memcpy(buffer_ + index_, data, len); index_ += len; } void clear() { index_ = 0; } // other members private: char buffer_[Size]; // Size 是模板参数 int index_;};int main(){ Buffer&lt;256&gt; b1; b1.append(\"hello\", 5); // Buffer&lt;256&gt;::append() b1.clear(); // Buffer&lt;256&gt;::clear() Buffer&lt;1024&gt; b2; b2.append(\"template\", 8); // Buffer&lt;1024&gt;::append() b2.clear(); // Buffer&lt;1024&gt;::clear()} 编译器会为每一个用到的类模板成员函数具现化一份实体。 123456789101112131415ubuntu@VM-0-9-ubuntu:~$ g++ buffer.ccubuntu@VM-0-9-ubuntu:~$ nm a.out0000000000000870 W _ZN6BufferILi1024EE5clearEv0000000000000818 W _ZN6BufferILi1024EE6appendEPKvi00000000000007fe W _ZN6BufferILi1024EEC1Ev00000000000007fe W _ZN6BufferILi1024EEC2Ev00000000000007e4 W _ZN6BufferILi256EE5clearEv000000000000078c W _ZN6BufferILi256EE6appendEPKvi0000000000000772 W _ZN6BufferILi256EEC1Ev0000000000000772 W _ZN6BufferILi256EEC2Evubuntu@VM-0-9-ubuntu:~$ g++ -O2 buffer.ccubuntu@VM-0-9-ubuntu:~$ nm a.out | c++filt | grep Bufferubuntu@VM-0-9-ubuntu:~$# 没有输出，Buffer 的成员函数都被 inline 展开了，没有生成函数定义。 如果想限制模板的具现化，比如限制 Buffer 只能有64、256、1024、4096这几个长度，除了可以用 static_assert 来制造编译期错误，还可以用只声明、不定义的办法来制造链接错误。C++ 教材中指出模板的定义要放到头文件中，否则会有编译错误，其实是链接错误。 12345678910111213141516171819202122232425262728template&lt;typename T&gt;void foo(const T&amp;); // 只声明而没有定义template&lt;typename T&gt;T bar(const T&amp;); // 只声明而没有定义int main(){ foo(0); foo(1.0); bar('c');}ubuntu@VM-0-9-ubuntu:~$ g++ main.cc # 注意是链接报错，不是编译器报错/tmp/cc5rGP5E.o: In function `main':main.cc:(.text+0x26): undefined reference to `void foo&lt;int&gt;(int const&amp;)'main.cc:(.text+0x3f): undefined reference to `void foo&lt;double&gt;(double const&amp;)'main.cc:(.text+0x4f): undefined reference to `char bar&lt;char&gt;(char const&amp;)'collect2: error: ld returned 1 exit statusubuntu@VM-0-9-ubuntu:~$ g++ -c main.cc # 可以单独编译为目标文件ubuntu@VM-0-9-ubuntu:~$ nm main.o # 目标文件里引用了未定义的模板函数， U _GLOBAL_OFFSET_TABLE_ # 注意这次函数 mangled name 包含返回类型0000000000000000 T main U __stack_chk_fail U _Z3barIcET_RKS0_ # char bar&lt;char&gt;(char const&amp;) U _Z3fooIdEvRKT_ # void foo&lt;double&gt;(double const&amp;) U _Z3fooIiEvRKT_ # void foo&lt;int&gt;(int const&amp;) 其实是可以在头文件里只放声明的，前提是你要知道模板会有哪些具现化类型，并事先显示(或隐式)具现化出来。 1234567891011121314151617181920212223template&lt;typename T&gt;void foo(const T&amp;){}template&lt;typename T&gt;T bar(const T&amp; x){ return x;}template void foo(const int&amp;); # 显示具现化template void foo(const double&amp;); # 如果漏了这几行，仍然会有链接错误template char bar(const char&amp;);ubuntu@VM-0-9-ubuntu:~$ g++ -c foobar.cc ubuntu@VM-0-9-ubuntu:~$ nm foobar.o # foobar.o 包含模板函数的定义0000000000000000 W _Z3barIcET_RKS0_0000000000000000 W _Z3fooIdEvRKT_0000000000000000 W _Z3fooIiEvRKT_ubuntu@VM-0-9-ubuntu:~$ g++ main.o foobar.o # 可以成功生成 a.out 对于 private 成员函数模板，也不用在头文件中给出定义，因为用户代码不能调用它，也就无法随意具现化它，所以不会造成链接错误。 1234567891011121314151617class PrintRequest{ public: int getUserId() const { return userId_; } // other members private: int userId_;};class ScanRequest{ public: int getUserId() const { return userId_; } // other members private: int userId_;}; PrintRequest 和 ScanRequest 有一些共同的成员，但是没有共同的基类。写一个 Printer class，能同时处理这两种请求，为了避免代码重复，用一个函数模板来解析 request 的公共部分。 1234567891011121314151617class PrintRequest;class ScanRequest;class Printer : boost::noncopyable // Printer 不是模板{ public: void onRequest(const PrintRequest&amp;); void onRequest(const ScanRequest&amp;); private: template&lt;typename REQ&gt; void decodeRequest(const REQ&amp;); void processRequest(); int currentRequestUserId_;}; decodeRequest 是模板，但不必把实现暴露在头文件中，因为只有 onRequest 会调用它。可以把这个成员函数模板的实现放到源文件中。这样的好处之一是 Printer 的用户看不到 decodeRequest 函数模板的定义，可以加快编译速度。 12345678910111213141516171819202122#include \"Printer.h\"#include \"Request.h\"template&lt;typename REQ&gt;void Printer::decodeRequest(const REQ&amp; req){ currentRequestUserId_ = req.getUserId(); // decode other parts}// 现在编译器能看到 decodeRequest 的定义，也就能自动具现化它void Printer::onRequest(const PrintRequest&amp; req){ decodeRequest(req); processRequest();}void Printer::onRequest(const ScanRequest&amp; req){ decodeRequest(req); processRequest();} C++11 新增了 extern template 特性，可以阻止隐式模板具现化。g++ 很早就支持这个特性，g++ 的 C++ 标准库就使用了这个办法，使得使用 std::string 和 std::iostream 的代码不受代码膨胀之苦。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() // 用到了 iostream 和 string 两个大模板{ string name; cin &gt;&gt; name; cout &lt;&lt; \"Hello，\" &lt;&lt; name &lt;&lt; \"\\n\";}ubuntu@VM-0-9-ubuntu:~$ size a.out # 生成的可执行文件很小 text data bss dec hex filename 3348 720 576 4644 1224 a.outubuntu@VM-0-9-ubuntu:~$ nm a.out | grep ' [TW] ' # 并没有具现化那些巨大的类模板0000000000202000 W data_start0000000000000d74 T _fini0000000000000a18 T _init0000000000000d70 T __libc_csu_fini0000000000000d00 T __libc_csu_init0000000000000bea T main0000000000000ae0 T _startubuntu@VM-0-9-ubuntu:~$ nm a.out | grep -o ' U .*' # 而是引用了标准库中的实现 U __cxa_atexit@@GLIBC_2.2.5 U __gxx_personality_v0@@CXXABI_1.3 U __libc_start_main@@GLIBC_2.2.5 U __stack_chk_fail@@GLIBC_2.4 U _Unwind_Resume@@GCC_3.0 U _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1Ev@@GLIBCXX_3.4.21 U _ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev@@GLIBCXX_3.4.21 U _ZNSt8ios_base4InitC1Ev@@GLIBCXX_3.4 # 这两个是 string 的构造函数与析构函数 U _ZNSt8ios_base4InitD1Ev@@GLIBCXX_3.4 U _ZStlsIcSt11char_traitsIcESaIcEERSt13basic_ostreamIT_T0_ES7_RKNSt7__cxx1112basic_stringIS4_S5_T1_EE@@GLIBCXX_3.4.21 U _ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc@@GLIBCXX_3.4 # 这三个是输入输出操作符 U _ZStrsIcSt11char_traitsIcESaIcEERSt13basic_istreamIT_T0_ES7_RNSt7__cxx1112basic_stringIS4_S5_T1_EE@@GLIBCXX_3.4.21 虚函数虚函数的动态调用(动态绑定、运行期决议)是通过虚函数表 (vtable) 进行的，每个多态 class 都应该有一份 vtable。定义或继承了虚函数的对象中会有一个指向 vtable 的指针，即 vptr。在构造和析构对象的时候，编译器生成的代码会修改这个 vptr 成员。有时看到的链接错误不是找不到某个虚函数的定义，而是找不到虚函数表的定义。 1234567891011121314151617class Base{ public: virtual ~Base(); virtual void doIt();};int main(){ Base* b = new Base(); b-&gt;doIt();}ubuntu@VM-0-9-ubuntu:~$ g++ virt.cc /tmp/ccfVRhyo.o: In function `Base::Base()':virt.cc:(.text._ZN4BaseC2Ev[_ZN4BaseC5Ev]+0xb): undefined reference to `vtable for Base'collect2: error: ld returned 1 exit status 头文件使用原则为了使用某个 struct 或者某个库函数而包含了一个头文件，那么这个头文件中定义的其他名字 (struct、函数、宏) 也被引入当前编译单元。 头文件的害处 传递性。头文件可以再包含其他头文件。一方面造成编译缓慢；另一方面，任何一个头文件改动一点点代码都会需要重新编译所有直接或间接包含它的源文件。 顺序性。通常的做法是把头文件分为几类，然后分别按顺序包含这几类头文件，相同类的头文件按文件名的字母排序。一般避免每次在 #include 列表的末尾添加新的头文件。 差异性。内容差异造成不同源文件看到的头文件不一致，时间差异造成头文件与库文件内容不一致。如果两个源文件编译时的宏定义选项不一致，可能造成二进制代码不兼容，整个程序应该用统一的编译选项。 现代编程语言使用模块化的做法： 对于解释性语言，import 的时候直接对对应模块的源文件解析 (parse) 一遍(不再是简单地把源文件包含进来)。 对于编译型语言，编译出来的目标文件(如 Java .class 文件)里直接包含了足够的元数据，import 的时候只需要读目标文件的内容，不需要读源文件。 头文件的使用规则 将文件间的编译依赖降至最小。 将定义式之间的依赖关系降至最小。避免循环依赖。 让 class 名字、头文件名字、源文件名字直接相关。这样方便源代码的定位。 令头文件自给自足。为了验证 TcpServer.h 的自足性(self-contained)，TcpServer.cc 第一个包含的头文件是它。 总是在头文件内写内部 #include guard(护套)，不要在源文件写外部护套。这是因为现在的预处理对这种通用做法有特别的优化，GNU cpp 在第二次 #include 同一个文件时甚至不会去读这个文件，而是直接跳过。 #include guard 用的宏的名字应该包含文件的路径全名(从版本管理器的角度)，必要的话还要加上项目名称(如果每个项目有自己的代码仓库)。 如果编写程序库，公开的头文件应该表达模块的接口，必要的时候可以把实现细节放到内部头文件中。一个查找头文件包含的小技巧，比如有一个程序只包含了 ，但是却能使用 std::string，可以在当前目录创建一个 string 文件，然后制造编译错误。12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;int main(){ std::string s = \"muduo\";}ubuntu@VM-0-9-ubuntu:~$ cat &gt; string # 创建一个只有一行内容的 string 文件#error error^Cubuntu@VM-0-9-ubuntu:~$ g++ -M -I . hello.cc # 用 g++ 查出包含路径，原来是 locale_classes.hIn file included from /usr/include/c++/7/bits/locale_classes.h:40:0, from /usr/include/c++/7/bits/ios_base.h:41, from /usr/include/c++/7/ios:42, from /usr/include/c++/7/ostream:38, from /usr/include/c++/7/iostream:39, from hello.cc:1:./string:1:2: error: #error error #error error ^~~~~In file included from /usr/include/c++/7/stdexcept:39:0, from /usr/include/c++/7/system_error:41, from /usr/include/c++/7/bits/ios_base.h:46, from /usr/include/c++/7/ios:42, from /usr/include/c++/7/ostream:38, from /usr/include/c++/7/iostream:39, from hello.cc:1:./string:1:2: error: #error error #error error ^~~~~ 工程项目中库文件的组织原则改动程序本身或它依赖的库之后应该重新测试，否则测试通过的版本和实际运行的版本根本就是两个东西。对于脚本语言，除了库之外，解释器的版本(Python2.5/2.6/2.7)也会影响程序的行为，因此有 Python virtualenv 和 Ruby rbenv 这样的工具，允许一台机器同时安装多个解释器版本。 还有一种依赖是外部进程的依赖，例如 app 程序依赖某些数据源(运行在别的机器上的进程)，会在运行的时候通过某种网络协议从这些数据源定期或不定期读取数据。数据源可能会升级，其行为也可能变化。 另外一个需要考虑的是 C++ 标准库(libstdc++) 的版本与 C 标准库(glibc)的版本。C++ 标准库的版本跟 C++ 编译器直接关联，C 标准库的版本跟 Linux 操作系统的版本直接相关。Linux 的共享库(shared library)比 Windows 的动态链接库在 C++ 编程方面要好用得多，对应用程序来说基本可算是透明的，和使用静态库无区别。主要体现在： 一致的内存管理。Linux 动态库与应用程序共享一个 heap，因此动态库分配的内存可以交给应用程序去释放，反之亦然。 一致的初始化。动态库里的静态对象(全局对象、namespace 级的对象等等)的初始化和程序其他地方的静态对象一样，不用特别区分对象的位置。 在动态库的接口中可以放心地使用 class、STL、boost(如果版本相同)。 没有 dllimport/dllexport 的累赘。直接 include 头文件就能使用。 DLL HELL 的问题也小得多，因为 Linux 允许多个版本的动态库并存，而且每个符号可以有多个版本。 DLL HELL 指的是安装新的软件的时候更新了某个公用的 DLL，破坏了其他已有软件的功能。 一个 C++ 库的发布方式有三种：动态库(.so)、静态库(.a)、源码库(.cc)。 动态库 静态库 源码库 库的发布方式 头文件 + .so 文件 头文件 + .a 文件 头文件 + .cc 文件 程序编译时间 短 短 长 查询依赖 ldd 查询 编译期信息 编译期信息 部署 可执行文件 + 动态库 单一可执行文件 单一可执行文件 主要时间差 编译时 &lt;==&gt; 运行时 编译库 &lt;==&gt; 编译应用程序 无 这里动态库只包括编译时就链接动态库的那种常规用法，不包括运行期动态加载(dlopen())的用法。如果要在多台 Linux 机器上运行程序，先要把程序部署到那些机器上。如果程序只依赖操作系统本身提供的库(包括可以通过 package 管理软件安装的第三方库)，那么只要把可执行文件拷贝到目标机器上就能运行。这是静态库和源码库在分布式环境下突出优点之一。传统的观点，动态库比静态库节省磁盘空间和内存空间，并且具备动态更新的能力(hot fix bug)。 动态库的不足在发布动态库的 bug fix 之前无法做到充分测试所有受影响的应用程序。动态库的使用面宅，只有两三个程序用到它，测试的成本较低，那么它作为动态库的优势就不明显。一个动态库的使用面宽，有几十个程序用到它，动态库的优势明显，测试和更新的成本也相应很高。有一种做法是把动态库的更新先发布到 QA 环境，正常运行一段时间之后再发布到生产环境。这么做也有另外的问题：在测试下一版 app1.1 的时候，该用 QA 环境的动态库版本还是用生产环境的动态库版本？ 静态库的不足静态库相比动态库的主要有几点好处： 依赖管理在编译期决定，不用担心日后它用的库会变。调试 core dump 不会遇到库更新导致 debug 符号失效的情况。 运行速度可能更快，因为没有 PLT(过程查找表)，函数的调用的开销更小。 发布方便，只要把单个可执行文件拷贝到模板机器上。 静态库的作者把源文件编译成 .a 库文件，连同头文件一起打包发布。应用程序的作者用库的头文件编译自己的代码，并链接到 .a 库文件，得到可执行文件。这里有一个编译的时间差：编译库文件比编译可执行文件要早，这就可能造成编译应用程序时看到的头文件与编译静态库时不一样。应用程序在使用静态库的时候必须要采用完全相同的开发环境(更底层的库、编译器版本、编译器选项)。 静态库把库之间的版本依赖完全放到编译期，可能会遇到的情况： 迫使升级高版本。 重复链接。 版本冲突。 源码编译每个应用程序自己选择要用到的库，并自行编译为单个可执行文件。彻底避免头文件与库文件之间的时间差，确保整个项目的源文件采用相同的编译选项，也不用为库的版本搭配操心。但是编译时间会长。 最好能和源码版本工具配合，让应用程序只需指定用哪个库，build 工具能自动帮我们 check out 库的源码。这样库的作者只需要维护少数几个 branch，发布库的时候不需要把头文件和库文件打包供人下载，只要 push 到特定的 branch 即可。这个 build 工具最好还能解析库的 Makefile(或等价的 build script)，自动帮我们解决库的传递性依赖，就像 Apache Ivy。接近这一点的有 Chromjum 的 gyp 和腾讯的 typhoon-blade，其他 Scons、CMake、Premake、Waf 等等工具仍然是以库的思路来搭建项目。","link":"/post/2829de4.html"},{"title":"C++网络编程","text":"网络编程设个术语的范围比较广，这里指用 Sockets API 开发基于 TCP/IP 的网络应用程序。 一、网络编程网络编程设个术语的范围比较广，这里指用 Sockets API 开发基于 TCP/IP 的网络应用程序。 1.1、网络编程是什么？TCP 网络编程，核心是处理三个半事件。程序员的主要工作是在事件处理函数中实现业务逻辑。 1.2、学习网络编程有用吗？程序代码直接面对从 TCP 或 UDP 收到的数据以及构造数据包发出去。实际工作中，另一种常见的情况是通过各种 client library 来与服务端打交道。比如用 libmemcached 与 memcached 打交道，使用 libpa 来与 PostgreSQL 打交道，编写 Servlet 来响应 HTTP 请求，使用某种 RPC 与其他进程通信等等。这些过程都会发生网络通信，但不一定算作网络编程。 熟悉 TCP/IP 协议、会用 tcpdump 也非常有助于分析解决线上网络服务问题。至少在 troubleshooting 的时候有用。 1.3、网络编程的各种任务角色 开发网络设备，编写防火墙、交换机、路由器的固件(firmwave)。 开发或移植网卡的驱动。 移植或维护 TCP/IP 协议栈（特别是在嵌入式系统上）。 开发或维护标准的网络协议程序，HTTP、FTP、DNS、SMTP、POP3、NFS。 开发标准网络协议的附加品，比如 HAProxy、squid、varnish 等 Web load balancer。 开发标准或非标准网络服务的客户端库，比如 ZooKeeper 客户端库、memcached 客户端库。 开发与公司业务直接相关的网络服务程序，比如即时聊天软件的后台服务器、网游服务器、金融交易系统、互联网企业用的分布式海量存储、微博发帖的内部广播通知等等。 客户端程序中涉及网络的部分，比如邮件客户端中的 POP3、SMTP 通信的部分，以及网游的客户端程序中与服务器通信的部分。 1.4、面向业务的网络编程的特点业务逻辑比较复杂，而且时常变化 以即时聊天工具的后台服务器为例，可能第一版只支持在线聊天；几个月之后发布第二版，支持离线消息；又过了几个月，第三版支持隐身聊天；随后，第四版支持上传头像；等等。 不一定需要遵循公认的通信协议标准 网游服务器就没什么协议标准，可以绕开一些性能难点。比方说，对于多线程的服务程序，如果用短连接 TCP 协议，为了优化性能通常要精心设计 accept 新连接的机制，避免惊群并减少上下文切换。但是如果改用长连接，用最简单的单线程 accept 就行了。 程序结构没有定论 对于高并发大吞吐的标准网络服务，一般采用单线程事件驱动的方式开发，比如 HAProxy、lighttpd 等都是这个模式。目前 one loop per thread 是通用性较高的一种程序结构，能发挥多核的优势。 性能评判的标准不同 如果开发 httpd 这样的通用服务，必然会和开源的 Nginx、lighttpd 等高性能服务器比较，程序员要投入相当的精力去优化程序。而面向业务的专用网络程序不一定是 IO bound，也不一定有开源的实现以供对比行性能，优化方向也可能不同。程序员通常更加注重功能的稳定性与开发的便捷性。 网络编程起到支撑作用，但不处于主导地位 程序的性能瓶颈不一定在网络上，瓶颈有可能是 CPU、Disk IO、数据库等，这时优化网络方面的代码并不能提高整体性能。 1.5、几个术语网络服务器 到底是服务于网络本身的机器（交换机、路由器、防火墙、NAT），还是利用网络为其他人或程序提供服务的机器（打印服务器、文件服务器、邮件服务器）？ 客户端？服务端？ 在 TCP 网络编程中，客户端和服务端很容易区分，主动发起连接的是客户端，被动接受连接的是服务端。这个客户端本身也可能是个后台服务程序，HTTP proxy 对 HTTP server 来说就是个客户端。 客户端编程？服务端编程？ Web crawler，它会主动发起大量连接，扮演的是 HTTP 客户端的角色，但似乎应该归入服务端编程。又比如写一个 HTTP proxy，它既会扮演客户端–被动接受 Web browser 发起的链接，也会扮演客户端–主动向 HTTP server 发起连接。 服务端网络编程指的是编写没有用户界面的长期运行的网络程序，程序默默地运行在一台服务器上、通过网络与其他程序打交道，而不必和人打交道。与之对应的是客户端网络程序，要么是短时间运行，比如 wget；要么是有用户界面（无论是字符界面还是图形界面）。 1.6、7 × 24 重要吗？内存碎片可怕吗？分布式系统的可靠性重要的不是 7 × 24，而是在程序不必做到 7 × 24 的情况下也能达到足够高的可用性。既然不要求 7 × 24，那么也不必害怕内存碎片： 64-bit 系统的地址空间足够大，不会出现没有足够的连续空间这种情况。 现在的内存分配器（malloc 及其第三方实现）今非昔比，除了 memcached 这种纯以内存为卖点的程序需要自己设计分配器之外，其他网络程序大可使用系统自带的 malloc 或者某个第三方实现。重新发明 memmory pool 似乎已经不流行了。 Linux Kernal 也大量用到了动态分配内存。 1.7、协议设计是网络编程的核心以网游为例，到底是连接服务器主动连接逻辑服务器，还是逻辑服务器主动连接“连接服务器”，似乎没有定论。一般可以按照“依赖 -&gt; 被依赖”的关系来设计发起连接的方向。 比起新建连接难的是关闭连接。在传统的网络服务中（特别是短连接服务），不少是服务端主动关闭连接，比如 daytime、HTTP 1.0。也有少部分是客户端主动关闭连接，通常是些长连接服务，比如 echo、chargen 等。 服务端主动关闭连接的缺点之一是会多占用服务器资源。服务端主动关闭连接之后会进入 TIME_WAIT 状态，在一段时间之内持有（hold）一些内核资源。如果并发访问量很高，就会影响服务端的处理能力。 比连接的建立与断开更重要的是设计消息协议。消息格式好办，XML、JSON、Protobuf 都是很好的选择。难的是消息内容，一个消息应该包含哪些内容？多个程序相互通信如何避免 race condtion？外部事件发生时，网络消息应该发 snapshot 还是 delta？新增功能时，各个组件如何平滑升级？ 1.8、网络编程的三个层次 读过教程和文档，做过练习； 熟悉本系统的 TCP/IP 协议栈的脾气； 自己写过一个简单的 TCP/IP stack。 第一个层次是基本要求，读过《UNIX 网络编程》、《TCP/IP 详解》并基本理解 TCP/IP 协议，读过本系统的 manpage。 第二个层次，熟悉本系统的 TCP/IP 协议栈参数设置与优化是开发高性能网络程序的必备条件。拿 Linux 的 TCP/IP 协议栈来说： 有可能出现 TCP 自连接（self-connection），程序应该有所准备。 Linux 的内核会有 bug，比如某种 TCP 拥塞控制算法正经出现 TCP window clamping（窗口箝位）bug，导致吞吐量暴跌，可以选用其他拥塞控制方法来绕开（work around）这个问题。 编写可靠的网络程序的关键是熟悉各种场景下的 error code（文件描述符用完了如何？本地 ephemeral port 暂时用完，不能发起新连接怎么办？服务端新建并发连接太快，backlog 用完了，客户端 connect 会返回什么错误？），有的在 manpage 里有描述，有的要通过实践或阅读源码获得。 第三个层次，通过自己写一个简单的 TCP/IP 协议栈，能打打加深对 TCP/IP 的理解，更能明白 TCP 为什么要这么设计，有哪些因素制约，每一步操作的代价是什么。实现 TCP/IP 只需要操作系统提供三个接口函数：一个函数，两个回调函数。分别是：send_packet()、on_receive_packet()、on_timer()。 1.9、TCP 的可靠性有多高IP header 和 TCP header 的 checksum 是一种非常弱的 16-bit check sum 算法，其把数据当成反码表示的 16-bit integers，再加到一起。由于是简单的加法，遇到和（sum）不变的情况情况就无法检查出错误（比如交换两个 16-bit 整数，加法满足交换律，checksum 不变）。以太网的 CRC32 只能保证同一个网段上的通信不会出错（两台机器的网线插到同一个交换机上，这时候以太网的 CRC 是有用的）。但是，如果两台机器之间经过了多级路由器呢？ 二、三本必看的书谈到 Unix 编程和网络编程，W.Richard Stevens 写了6本书，即 APUE、两卷《UNIX 网络编程》、三卷《TCP/IP 详解》。 第一本：《TCP/IP IIustrated, Vol.1: The Protocols》 作者以 tcpdump 为工具，对 TCP 协议抽丝剥茧、娓娓道来。TCP 作为一个可靠的传输协议，其核心有三点： Positive acknowledgement with retransmission; Flow control using sliding window（包括 Nagle 算法等）; Congestion control（包括 slow start、congestion avoidance、fast retransmit 等）。 第一点足以满足可靠性要求；第二点是为了提高吞吐量，充分利用链路层带宽；第三点是防止过载造成丢包。换言之，第二点是避免发得太慢，第三点是避免发得太快，二者相互制约。从反馈控制的角度看，TCP 像是一个自适应的节流阀，根据管道的拥堵情况自动调整阀门的流量。 第二本：《Unix Network Programming, Vol.1: Networking API》 UNP 是 Sockets API 的权威指南。 第三本：《Effective TCP/IP Programming》 三、关于 TCP 并发连接的几个思考题与试验思考题一 有一台机器，它有一个 IP，上面运行了一个 TCP 服务程序，程序只侦听一个端口，问：从理论上讲（只考虑 TCP/IP 这一层面，不考虑 IPv6）这个服务程序可以支持多少并发 TCP 连接？这个问题等价于：有一个 TCP 服务程序的地址是 1.2.3.4:8765，问它从理论上能接受多少个并发连接？ 思考题二 一台被测试机器 A，功能同上，同一交换机上还接有一台机器 B，如果允许 B 的程序直接收发以太网 frame，问：让 A 承担10万个并发 TCP 连接需要用多少 B 的资源？100万个呢？ 一个 TCP 连接要占用多少系统资源呢？ 在现在的 Linux 操作系统上，如果用 socket() 或 accept() 来创建 TCP 连接，那么每个连接至少要占用一个文件描述符（file descriptor）。为什么说至少？因为文件描述符可以复制，比如 dup()；也可以被继承，比如 fork()；这样可能出现系统中同一个 TCP 连接有多个文件描述符与之对应。 TCP/IP 协议中的三路握手中 TCP 连接是虚拟的连接，不是电路连接。维持 TCP 连接理论上不占用网络资源（会占用两头程序的系统资源）。只要连接的双方认为 TCP 连接存在，并且可以互相发送 IP packet，那么 TCP 连接就一直存在。 对于问题1，向一个 TCP 服务程序发起一个连接，客户端（faketcp 客户端）只需要三件事情（三路握手）：1a. 向 TCP 服务程序发一个 IP packet，包含 SYN 的 TCP segment;1b. 等待对方返回一个包含 SYN 和 ACK 的 TCP segment;1c. 向对方发送一个包含 ACK 的 segment。 对于问题2，为了让一个 TCP 客户端程序认为连接已建立，faketcp 服务端也只需要做三件事情：2a. 等待客户端发来的 SYN TCP segment;2b. 发送一个包含 SYN 和 ACK 的 TCP segment;2c. 忽视对方发来的包含 ACK 的 segment。 faketcp 服务端在做完头两件事情（收一个 SYN、发一个 SYN+ACK）之后，TCP 客户端程序会认为连接已建立。而做这三件事情并不占用 facktcp 服务端的资源。换句话说，facktcp 服务端可以一直重复做这三件事，接受不计其数的 TCP 连接，而 facktcp 服务端自己毫发无损。 第一题的答案：在只考虑 IPv4 的情况下，并发数的理论上限了248。实际的限制是操作系统的全局文件描述符的数量，以及内存大小。一个 TCP 连接有两个 end point 已经固定，每个 end point 是 {ip, port}，题目说其中一个 end point 已经固定，那么留下一个 end point 的自由度，即248。客户端 IP 的上限是232，每个客户端 IP 发起连接的上限是216，乘到一起得到理论上限。","link":"/post/57227f14.html"},{"title":"Mysql中MyISAM和InnoDB的区别","text":"InnoDB 和 MyISAM 是许多人在使用 MySQL 时最常用的两个表类型，这两个表类型各有优劣，可以根据业务需求选择使用。 一、区别 InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。 InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败。 InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快。 InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。 如果用 InnoDB 必须要有主键，主键建议用自增的 id 而不用 uuid，用 uuid 会使索引变慢。 InnoDB 是聚簇索引(叶子节点存数据)，MyISAM 是非聚簇索引(叶子节点存指针)。 InnoDB 和 MyISAM 都是 B+ 数的结构，但是它们的实现有点不一样，如下图所示： 二、如何选择 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM。 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果有读写也挺频繁，请使用 InnoDB。 系统奔溃后，MyISAM 恢复起来更困难，能否接受，不能接受就选 InnoDB。 MySQL5.5版本开始 Innodb 已经成为 Mysql 的默认引擎(之前是 MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用 InnoDB，至少不会差。 参考文章:1、Mysql 中 MyISAM 和 InnoDB 的区别有哪些？2、InnoDB和MyISAM的区别3、高性能MySQL01-MyISAM和InnoDB的区别","link":"/post/a82c6dfe.html"},{"title":"B+Tree索引","text":"每当我们执行某个 SQL 发现很慢时，都会下意识地反应是否加了索引，那么大家是否有想过加了索引为啥会使数据查找更快呢，索引的底层一般又是用什么结构存储的呢，相信大家看了标题已经有答案了，没错！B+ 树！那么它相对于一般的链表，哈希等有何不同，为何多数存储引擎都选择使用它呢，今天我就来揭开 B+ 树的面纱，相信看了此文，B+ 树不再神秘，对你理解以下高频面试题会大有帮助！ 为啥索引常用 B+ 树作为底层的数据结构 除了 B+ 树索引，你还知道什么索引 为啥推荐自增 id 作为主键，自建主键不行吗 什么是页分裂，页合并 怎么根据索引查找行记录 本文将会从以下几个方面来讲解 B+ 树 定义问题 几种常见的数据结构对比 页分裂与页合并 一、定义问题要知道索引底层为啥使用 B+ 树，得看它解决了什么问题，我们可以想想，日常我们用到的比较多的 SQL 有哪些呢。假设我们有一张以下的用户表： 1234567CREATE TABLE `user` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL COMMENT '姓名', `idcard` varchar(20) DEFAULT NULL COMMENT '身份证号', `age` tinyint(10) DEFAULT NULL COMMENT '年龄', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='用户信息'; 一般我们会有如下需求： 1、根据用户 id 查用户信息 1select * from user where id = 123; 2、根据区间值来查找用户信息 1select * from user where id &gt; 123 and id &lt; 234; 3、按 id 逆序排列，分页取出用户信息 1select * from user where id &lt; 1234 order by id desc limit 10; 从以上的几个常用 SQL 我们可以看到索引所用的数据结构必须满足以下三个条件 根据某个值精确快速查找 根据区间值的上下限来快速查找此区间的数据 索引值需要排好序，并支持快速顺序查找和逆序查找 接下来我们以主键索引（id 索引）为例来看看如何用相应的数据结构来构造它 二、几种常见的数据结构对比接下来我们想想有哪些数据结构满足以上的条件 1、散列表 散列表（也称哈希表）是根据关键码值(key，value)而直接进行访问的数据结构，它让码值经过哈希函数的转换映射到散列表对应的位置上，查找效率非常高。哈希索引就是基于散列表实现的，假设我们对名字建立了哈希索引，则查找过程如下图所示： 对于每一行数据，存储引擎都会对所有的索引列（上图中的 name 列）计算一个哈希码（上图散列表的位置），散列表里的每个元素指向数据行的指针，由于索引自身只存储对应的哈希值，所以索引的结构十分紧凑，这让哈希索引查找速度非常快！但是哈希索引也有它的劣势，如下： 针对哈希索引，只有精确匹配索引所有列的查询才有效，比如我在列（A，B）上建立了哈希索引，如果只查询数据列 A，则无法使用该索引。 哈希索引并不是按照索引值顺序存存储的，所以也就无法用于排序，也就是说无法根据区间快速查找 哈希索引只包含哈希值和行指针，不存储字段值，所以不能使用索引中的值来避免读取行，不过，由于哈希索引多数是在内存中完成的，大部分情况下这一点不是问题 哈希索引只支持等值比较查询，包括 =、IN()，不支持任何范围的查找，如 age &gt; 17 综上所述，哈希索引只适用于特定场合， 如果用得对，确实能再带来很大的性能提升，如在 InnoDB 引擎中，有一种特殊的功能叫「自适应哈希索引」，如果 InnoDB 注意到某些索引列值被频繁使用时，它会在内存基于 B+ 树索引之上再创建一个哈希索引，这样就能让 B+ 树也具有哈希索引的优点，比如快速的哈希查找。 2、链表 双向链表支持顺序查找和逆序查找，如图下 但显然不支持我们说的按某个值或区间的快速查找，另外我们知道表中的数据是要不断增加的，索引也是要及时插入更新的，链表显然也不支持数据的快速插入，所以能否在链表的基础上改造一下，让它支持快速查找、更新，删除。有一种结构刚好能满足我们的需求，这里引入跳表的概念。什么是跳表？简单地说，跳表是在链表之上加上多层索引构成的。如下图所示 假设我们现在要查找区间 7- 13 的记录，再也不用从头开始查找了，只要在上图中的二级索引开始找即可，遍历三次即可找到链表的区间位置，时间复杂度是 O(log2n)，非常快，这样看来，跳表是能满足我们的需求的，实际上它的结构已经和 B+ 树非常接近了，只不过 B+ 树是从平衡二叉查找树演化而来的而已，接下来我们一步步来看下如何将平衡二叉查找树改造成 B+ 树。先来看看什么是平衡二叉查找树，平衡二叉查找树具有如下性质： 若左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若右子树不空，则右子树上所有节点的值均大于或等于它的根节点的值； 每个非叶子节点的左右子树的高度之差的绝对值（平衡因子）最多为1。 下图就是一颗平衡二叉查找树 从其特性就可以看到平衡二叉查找树查找节点的时间复杂度是 O(log2n)现在我们将其改造成 B+ 树 可以看到主要区别就是所有的节点值都在最后叶节点上用双向链表连接在了一起，仔细和跳表对比一下 ，是不是很像，现在如果我们要找15 ~ 27 这个区间的数只要先找到 15 这个节点（时间复杂度 log2n = 3 次）再从前往后遍历直到 27 这个节点即可找到这区间的节点，这样它完美地支持了我们提的三个需求：快速查找值，区间查找，顺序逆序查找。假设有 1 亿个节点，每个节点要查询多少次呢，显然最多为 log2(1亿) = 27 次，如果这 1 亿个节点都在内存里，那 27 次显然不是问题，可以说是非常快了，但一个新的问题出现了，这 1 亿个节点在内存大小是多少呢，我们简单算一下，假设每个节点 16 byte，则 1 亿个节点大概要占用 1.5G 内存！对于内存这么宝贵的资源来说是非常可怕的空间消耗，这还只是一个索引，一般我们都会在表中定义多个索引，或者库中定义多张表，这样的话内存很快就爆满了！所以在内存中完全装载一个 B+ 树索引显然是有问题的，如何解决呢。内存放不下， 我们可以把它放到磁盘嘛，磁盘空间比内存大多了，但新的问题又来了，我们知道内存与磁盘的读取速度相差太大了，通常内存是纳秒级的，而磁盘是毫秒级的，读取同样大小的数据，两者可能相差上万倍，于是上一步我们计算的 27 次查询如果放在磁盘中来看就非常要命了（查找一个节点可以认为是一次磁盘 IO，也就是说有 27 次磁盘 IO！），27 次查询是否可以优化？可以很明显地观察到查询次数和树高有关，那树高和什么有关，很明显和每个节点的子节点个数有关，即 N 叉树中的 N，假设现在有 16 个数，我们分别用二叉树和五叉树来构建，看下树高分别是多少。 可以看到如果用二叉树，要遍历 5 个节点，如果用五叉树，只要遍历 3 次，一下少了两次磁盘 IO，回过头来看上文的一亿个节点，如果我们用 100 叉树来构建，需要几次 IO 呢？ 可以看到，最多遍历五次！（实际上根节点一般存在内存里的，所以可以认为是 4 次）磁盘 IO 一下从 27 减少到了 5！性能可以说是大大提升了，有人说 5 次还是太多，是不是可以把 100 叉树改成 1000 或 10000 叉树呢，这样 IO 次数不就就能进一步减少了。这里我们就需要了解页（page）的概念，在计算机里，无论是内存还是磁盘，操作系统都是按页的大小进行读取的（页大小通常为 4 KB），磁盘每次读取都会预读，会提前将连续的数据读入内存中，这样就避免了多次 IO，这就是计算机中有名的局部性原理，即我用到一块数据，很大可能这块数据附近的数据也会被用到，干脆一起加载，省得多次 IO 拖慢速度， 这个连续数据有多大呢，必须是操作系统页大小的整数倍，这个连续数据就是 MySQL 的页，默认值为 16 KB，也就是说对于 B+ 树的节点，最好设置成页的大小（16 KB），这样一个 B+ 树上的节点就只会有一次 IO 读。那有人就会问了，这个页大小是不是越大越好呢，设置大一点，节点可容纳的数据就越多，树高越小，IO 不就越小了吗，这里要注意，页大小并不是越大越好，InnoDB 是通过内存中的缓存池（pool buffer）来管理从磁盘中读取的页数据的。页太大的话，很快就把这个缓存池撑满了，可能会造成页在内存与磁盘间频繁换入换出，影响性能。通过以上分析，相信我们不难猜测出 N 叉树中的 N 该怎么设置了，只要选的时候尽量保证每个节点的大小等于一个页（16 KB）的大小即可。 三、页分裂与页合并现在我们来看看开头的问题， 为啥推荐自增 id 作为主键，自建主键不行吗，有人可能会说用户的身份证是唯一的，可以用它来做主键，假设以身份证作主键，会有什么问题呢？B+ 树为了维护索引的有序性，每插入或更新一条记录的时候，会对索引进行更新。假设原来基于身份证作索引的 B+ 树如下（假设为二叉树 ，图中只列出了身份证的前四位） 现在有一个开头是 3604 的身份证对应的记录插入 DB ，此时要更新索引，按排序来更新的话，显然这个 3604 的身份证号应该插到左边节点 3504 后面（如下图示，假设为二叉树） 如果把 3604 这个身份证号插入到 3504 后面的话，这个节点的元素个数就有 3 个了，显然不符合二叉树的条件，此时就会造成页分裂，就需要调整这个节点以让它符合二叉树的条件 这种由于页分裂造成的调整必然导致性能的下降，尤其是以身份证作为主键的话，由于身份证的随机性，必然造成大量的随机结点中插入，进而造成大量的页分裂，进而造成性能的急剧下降，那如果是以自增 id 作为主键呢，由于新插入表中生成的 id 比索引中所有的值都大，所以它要么合到已存在的节点（元素个数未满）中，要么放入新建的节点中（如下图示）所以如果是以自增 id 作为主键，就不存在页分裂的问题了，推荐！ 有页分裂就必然有页合并，什么时候会发生页合并呢，当删除表记录的时候，索引也要删除，此时就有可能发生页合并，如图示 当我们删除 id 为 7，9 对应行的时候，上图中的索引就要更新，把 7，9 删掉，此时 8，10 就应该合到一个节点，不然 8，10 分散在两个节点上，可能造成两次 IO 读，势必会影响查找效率！ 那什么时候会发生页合并呢，我们可以定个阈值，比如对于 N 叉树来说，当节点的个数小于 N/2 的时候就应该和附近的节点合并，不过需要注意的是合并后节点里的元素大小可能会超过 N，造成页分裂，需要再对父节点等进行调整以让它满足 N 叉树的条件。 四、怎么根据索引查找行记录相信大家看完以上的 B+ 树索引的介绍应该还有个疑惑，怎么根据对应的索引值查找行记录呢，其实相应的行记录就放在最后的叶子节点中，找到了索引值，也就找到了行记录。如图示 可以看到，非叶子节点只存了索引值，只在最后一行才存放了行记录，这样极大地减小了索引了大小，而且只要找到索引值就找到了行记录，也提升了效率，这种在叶节点存放一整行记录的索引被称为聚簇索引，其他的就称为非聚簇索引。 五、关于 B+ 树的总结综上所述，B+ 树有以下特点： 每个节点中子节点的个数不能超过 N，也不能小于 N/2（不然会造成页分裂或页合并） 根节点的子节点个数可以不超过 m/2，这是一个例外 m 叉树只存储索引，并不真正存储数据，只有最后一行的叶子节点存储行数据。 通过链表将叶子节点串联在一起，这样可以方便按区间查找 六、总结本文由日常中常用的 SQL 由浅入深地总结了 B+ 树的特点，相信大家应该对 B+ 树索引有了比较清晰地认识，所以说为啥我们要掌握底层原理，学完了 B+ 树，再看开头提的几个问题，其实也不过如此，深挖底层，有时候确实能让你以不变应万变。 原文链接:拜托，别再问我什么是B+树 了","link":"/post/4347273b.html"},{"title":"进程间通信方式与线程间通信方式","text":"进程间通信方式与线程间通信方式 零、进程通信的应用场景 数据传输：一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几兆字节之间。 共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到。 通知事件：一个进程需要向另一个或一组进程发送消息，通知它(它们)发生了某种事件(如进程终止时要通知父进程)。 资源共享：多个进程之间共享同样的资源。需要内核提供锁和同步机制。 进程控制：有些进程希望完全控制另一个进程的执行(如 Debug 进程)，此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。 一、进程间通信方式1.1、管道(pipe)管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用，进程间的亲缘关系通常是指父子进程关系。如通过 fork 操作生成的两个进程。 1.1.1、通信管道是由内核管理的一个缓冲区，相当于放入内存中的一个纸条。管道的一端连接一个进程的输出，这个进程会向管道中放入信息。管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。缓冲区不要太大，设计成为环形的数据结构。当管道中没有消息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。当管道被放满消息时，尝试放入消息的进程会等待，直到另一端的进程取出消息。当两个进程都终结的时候，管道也自动消失。(有点类似 Golang 的 Channel，但是 Channel 是可以主动 Close 的)。 1.1.2、创建管道利用 fork 机制建立，从而让两个进程可以连接到同一个 PIPE 上。 在 Linux 中，管道借助了文件系统的 file 结构和 VFS 的索引节点 inode。通过将两个 file 结构指向同一个临时的 VFS 索引节点，而这个 VFS 索引节点又指向一个物理页面实现的。 1.1.3、读写管道读函数 pipe_read() 和 管道写函数 pipe_write()。写函数通过将字节复制到 VFS 索引节点指向的物理内存而写入数据，读函数则通过复制物理内存中的字节而读出数据。内核必须利用一定的机制同步对管道的访问，如锁、等待队列、信号。写入函数必须检查 VFS 索引节点中的信息，需要同时满足如下条件，才能进行实际的内存复制工作： 内存中有足够的空间可容纳所有要写入的数据； 内存没有被读程序锁定 写入函数首先锁定内存，然后从写进程的地址空间中复制数据到内存。否则，写入进程就休眠在 VFS 索引节点的等待队列中，接下来，内核讲调用调度程序，而调度程序会选择其他进程运行。写入进程实际处于可中断的等待状态，当内存中有足够的空间可以容纳写入数据，或内存被解锁时，读取进程会唤醒写入进程，这时，写入进程将接收到信号。当数据写入内存之后，内存被解锁，而所有休眠在索引节点的读取进程会被唤醒。 管道的读取过程和写入过程类似，但是，进程可以在没有数据或内存被锁定时立即返回错误信息，而不是阻塞该进程，这依赖于文件或管道的打开模式。反之，进程可以休眠在索引节点的等待队列中等待写入进程写入数据。当所有的进程完成了管道操作之后，管道的索引节点被丢弃，而共享数据页被释放。 1.1.4、程序实例函数原型 123#include &lt;unistd.h&gt;int pipe(int filedes[2]); filedes[0]用于读出数据，读取时必须关闭写入端，即 close(filedes[1]);filedes[1]用于写入数据，写入时必须关闭读取端，即 close(filedes[0]); 123456789101112131415161718192021222324252627282930int main(void){ int n; int fd[2]; pid_t pid; char line[MAXLINE]; if(pipe[fd] == 0) // 先建立管道得到一对文件描述符 { exit(0); } if((pid = fork()) == 0) // 父进程把文件描述符复制给子进程 { exit(1); } else if(pid &gt; 0) // 父进程写 { close(fd[0]); // 关闭读描述符 write(fd[1], \"\\nhello world\\n\", 14); } else // 子进程读 { // 关闭写端 close(fd[1]); n = read(fd[0], line, MAXLINE); write(STDOUT_FILENO, line, n); } exit(0);} 1.2、命名管道(named pipe/FIFO)命名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 函数原型 12345#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;int mkinfo(const char *filename, mode_t mode);int mknod(const char *filename, mode_t mode | S_IFIFO, (dev_t)0); filename 是被创建的文件名称，mode 表示将在文件上设置的权限位和被创建的文件类型，dev 是当创建设备特殊文件时使用的一个值。 程序实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt; #include &lt;stdlib.h&gt;#include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #include &lt;string.h&gt; #include &lt;sys/stat.h&gt; #include &lt;sys/types.h&gt; using namespace std; #define FIFO_PATH \"/root/fifo\" int main() { if (mkfifo(FIFO_PATH, 0666) &lt; 0 &amp;&amp; errno != EEXIST) { cout&lt;&lt;\"create fifo failed.\"&lt;&lt;endl; return -1; } if (fork() == 0) { int readfd = open(FIFO_PATH, O_RDONLY); cout&lt;&lt;\"child open fifo success.\"&lt;&lt;endl; char buf[256]; read(readfd, buf, sizeof(buf)); cout&lt;&lt;\"receive message from pipe: \"&lt;&lt;buf&lt;&lt;endl; close(readfd); exit(0); } sleep(3); int writefd = open(FIFO_PATH, O_WRONLY); cout&lt;&lt;\"parent open fifo success.\"&lt;&lt;endl; char *temp = \"hello world\"; write(writefd, temp, strlen(temp) + 1); close(writefd); } 1.3、信号量(semaphore)信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一个锁机制，防止某进程在访问共享资源时，其他进程也访问此资源。主要作为进程间以及同一进程内不同线程之间的同步手段。 1.3.1、工作原理由于信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv) P(sv)：如果 sv 的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行 V(sv)：如果有其他进程因等待 sv 而被挂起，就让它恢复运行，如果没有进程因等待 sv 而挂起，就给它加1 1.3.2、信号量机制semget函数 1int semget(key_t key, int num_sems, int sem_flags); 第一个参数 key 是整数值（唯一非零），不相关的进程可以通过它访问一个信号量，它代表程序可能要使用的某个资源，程序对所有信号量的访问都是间接的，程序先通过调用 semget 函数并提供一个键，再由系统生成一个相应的信号标识符（semget函数的返回值），只有 semget 函数才直接使用信号量键，所有其他的信号量函数使用由 semget 函数返回的信号量标识符。如果多个程序使用相同的 key 值，key 将负责协调工作。 第二个参数 num_sems 指定需要的信号量数目，它的值几乎总是1。 第三个参数 sem_flags 是一组标志，当想要当信号量不存在时创建一个新的信号量，可以和值 IPC_CREAT 做按位或操作。设置了 IPC_CREAT 标志后，即使给出的键是一个已有信号量的键，也不会产生错误。而 IPC_CREAT | IPC_EXCL 则可以创建一个新的、唯一的信号量，如果信号量已存在，返回一个错误。 semop函数它的作用是改变信号量的值 1int semop(int sem_id, struct sembuf *sem_opa, size_t num_sem_ops); sem_id 是由 semget 返回的信号量标识符，sembuf 结构的定义如下： 123456struct sembuf{ short sem_num; //除非使用一组信号量，否则它为0 short sem_op; //信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即P（等待）操作，一个是+1，即V（发送信号）操作。 short sem_flg; //通常为SEM_UNDO，使操作系统跟踪信号，并在进程没有释放该信号量而终止时，操作系统释放信号量 }; semctl函数 1int semctl(int sem_id, int sem_num, int command, ...); 如果有第四个参数，它通常是一个 union semum 结构 123456union semun{ int val; struct semid_ds *buf; unsigned short *arry; }; command 通常是下面两个值中的其中一个 SETVAL：用来把信号量初始化为一个已知的值。p 这个值通过 union semun 中的 val 成员设置，其作用是在信号量第一次使用前对它进行设置。 IPC_RMID：用于删除一个已经无需继续使用的信号量标识符。 1.4、消息队列(message queue)消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号量传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。包括 Posix 消息队列 system V 消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。 结构 msg_queue 用来描述消息队列头，存在于系统空间： 1234567891011121314struct msg_queue { struct kern_ipc_perm q_perm; time_t q_stime; /* last msgsnd time */ time_t q_rtime; /* last msgrcv time */ time_t q_ctime; /* last change time */ unsigned long q_cbytes; /* current number of bytes on queue */ unsigned long q_qnum; /* number of messages in queue */ unsigned long q_qbytes; /* max number of bytes on queue */ pid_t q_lspid; /* pid of last msgsnd */ pid_t q_lrpid; /* last receive pid */ struct list_head q_messages; struct list_head q_receivers; struct list_head q_senders;}; 结构 msqid_ds 用来设置或返回消息队列的信息，存在于用户空间： 123456789101112131415struct msqid_ds { struct ipc_perm msg_perm; struct msg *msg_first; /* first message on queue,unused */ struct msg *msg_last; /* last message in queue,unused */ __kernel_time_t msg_stime; /* last msgsnd time */ __kernel_time_t msg_rtime; /* last msgrcv time */ __kernel_time_t msg_ctime; /* last change time */ unsigned long msg_lcbytes; /* Reuse junk fields for 32 bit */ unsigned long msg_lqbytes; /* ditto */ unsigned short msg_cbytes; /* current number of bytes on queue */ unsigned short msg_qnum; /* number of messages in queue */ unsigned short msg_qbytes; /* max number of bytes on queue */ __kernel_ipc_pid_t msg_lspid; /* pid of last msgsnd */ __kernel_ipc_pid_t msg_lrpid; /* last receive pid */}; 1.4.1、消息队列与内核的联系 从上图可以看出，全局数据结构 struct ipc_ids msg_ids 可以访问到每个消息队列头的第一个成员 struct kern_ipc_perm；而每个 struct kern_ipc_perm 能够与具体的消息队列对应起来，因为在该结构中，有一个 key_t 类型成员 key，而 key 则唯一确定一个消息队列。 12345678910struct kern_ipc_perm{ //内核中记录消息队列的全局数据结构 msg_ids 能够访问到该结构；key_t key; //该键值则唯一对应一个消息队列uid_t uid;gid_t gid;uid_t cuid;gid_t cgid;mode_t mode;unsigned long seq;}; 1.4.2、消息队列的操作 打开或创建消息队列消息队列的内核持续性要求每个消息队列都在系统范围内对应唯一的键值，所以要获得一个消息队列的描述字，只需提供该消息队列的键值即可；消息队列描述字是由在系统范围内唯一的键值生成的，而键值可以看作对应系统内的一条路经。 读写操作 12345struct msgbuf{long mtype;char mtext[1];}; mtype 成员代表消息类型，从消息队列中读取消息的一个重要依据就是消息的类型；mtext 是消息内容，当然长度不一定为1。因此，对于发送消息来说，首先预置一个 msgbuf 缓冲区并写入消息类型和内容，调用相应的发送函数即可；对读取消息来说，首先分配这样一个 msgbuf 缓冲区，然后把消息读入该缓冲区即可。 获得或设置消息队列属性消息队列的信息基本上都保存在消息队列头中，因此，可以分配一个类似于消息队列头的结构，来返回消息队列的属性，同样可以设置该数据结构。 1.5、信号(signal)信号是一种比较复杂的通信方式，用于通知接受进程某个事件已经发生。 信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。 信号是进程间通信机制中唯一的异步通信机制，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。信号机制经过 POSIX 实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。 1.5.1、信号来源、种类信号事件的发生有两个来源 硬件来源(比如我们按下了键盘或者其它硬件故障)； 软件来源，最常用发送信号的系统函数是 kill, raise, alarm 和 setitimer 以及 sigqueue 函数，软件来源还包括一些非法运算等操作。 1.5.2、信号种类可以从两个不同的分类角度对信号进行分类： 可靠性方面：可靠信号与不可靠信号； 与时间的关系上：实时信号与非实时信号。 不可靠信号 Linux 信号机制基本上是从 Unix 系统中继承过来的。早期 Unix 系统中的信号机制比较简单和原始，后来在实践中暴露出一些问题，因此，把那些建立在早期机制上的信号叫做“不可靠信号”，信号值小于 SIGRTMIN (Red hat 7.2中，SIGRTMIN=32，SIGRTMAX=63)的信号都是不可靠信号。这就是“不可靠信号”的来源。它的主要问题是： 进程每次处理信号后，就将对信号的响应设置为默认动作。在某些情况下，将导致对信号的错误处理；因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用 signal()，重新安装该信号。 信号可能丢失。因此，早期 unix 下的不可靠信号主要指的是进程可能对信号做出错误的反应以及信号可能丢失。 Linux 支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，Linux 下的不可靠信号问题主要指的是信号可能丢失。 可靠信号 随着时间的发展，实践证明了有必要对信号的原始机制加以改进和扩充，力图实现“可靠信号”。由于原来定义的信号已有许多应用，不好再做改动，最终只好又新增加了一些信号，并在一开始就把它们定义为可靠信号，这些信号支持排队，不会丢失。 信号值位于 SIGRTMIN 和 SIGRTMAX 之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。Linux 在支持新版本的信号安装函数sigation() 以及信号发送函数 sigqueue() 的同时，仍然支持早期的 signal() 信号安装函数，支持信号发送函数 kill()。 注意：可靠信号是指后来添加的新信号（信号值位于 SIGRTMIN 及 SIGRTMAX 之间）；不可靠信号是信号值小于 SIGRTMIN 的信号。信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。 实时信号与非实时信号 非实时信号都不支持排队，都是不可靠信号，编号是1-31，0是空信号；实时信号都支持排队，都是可靠信号。 进程对信号的响应 忽略信号，即对信号不做任何处理，其中，有两个信号不能忽略：SIGKILL 及 SIGSTOP； 捕捉信号，定义信号处理函数，当信号发生时，执行相应的处理函数； 执行缺省操作，Linux 对每种信号都规定了默认操作 注意：进程对实时信号的缺省反应是进程终止。 信号的发送和安装 发送信号的主要函数有：kill()、raise()、sigqueue()、alarm()、setitimer() 以及 abort()。 如果进程要处理某一信号，那么就要在进程中安装该信号。安装信号主要用来确定信号值及进程针对该信号值的动作之间的映射关系，即进程将要处理哪个信号；该信号被传递给进程时，将执行何种操作。 注意： linux 主要有两个函数实现信号的安装：signal()、sigaction()。其中 signal() 在可靠信号系统调用的基础上实现，是库函数。它只有两个参数，不支持信号传递信息，主要是用于前32种非实时信号的安装；而 sigaction() 是较新的函数（由两个系统调用实现：sys_signal以及sys_rt_sigaction），有三个参数，支持信号传递信息，主要用来与 sigqueue() 系统调用配合使用，当然，sigaction() 同样支持非实时信号的安装。sigaction() 优于 signal() 主要体现在支持信号带有参数。 1.6、共享内存(shared memory)共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往和其他通信方式(如信号量)配合使用来实现进程间的同步和通信。 1.6.1、系统V共享内存原理进程间需要共享的数据被放在一个叫做 IPC 共享内存区域的地方，所有需要访问该共享区域的进程都要把该共享区域映射到本进程的地址空间中去。系统 V 共享内存通过 shmget 获得或创建一个 IPC 共享内存区域，并返回相应的标识符。内核在保证 shmget 获得或创建一个共享内存区，初始化该共享内存区相应的 shmid_kernel 结构体的同时，还将在特殊文件系统 shm 中，创建并打开一个同名文件，并在内存中建立起该文件的相应 dentry 及inode 结构，新打开的文件不属于任何一个进程（任何进程都可以访问该共享内存区）。所有这一切都是系统调用 shmget 完成的。 1.6.2、系统V共享内存APIshmget() 用来获得共享内存区域的 ID，如果不存在指定的共享区域就创建相应的区域。shmat() 把共享内存区域映射到调用进程的地址空间中去，这样，进程就可以方便地对共享区域进行访问操作。shmdt() 调用用来解除进程对共享内存区域的映射。shmctl() 实现对共享内存区域的控制操作。 1.7、套接字(socket)套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备间的进程通信。 1.8、全双工管道共享内存、信号量、消息队列、管道和命名管道只适用于本地进程间通信，套接字和全双工管道可用于远程通信，因此可用于网络编程。 二、线程间通信2.1、锁机制包括互斥锁、条件变量、读写锁。 2.2、互斥锁提供了以排他方式防止数据结构被并发修改的方法。 2.3、读写锁允许多个线程同时共享数据，而对写操作是互斥的。 2.4、条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 2.5、信号量机制(Semaphore)包括无名线程信号量和命名进程信号量。 无名信号量一般用于线程间同步或互斥，而有名信号量一般用于进程间同步或互斥。它们的区别和管道及命名管道的区别类似，无名信号量则直接保存在内存中，而有名信号量要求创建一个文件。 信号量广泛用于进程或线程间的同步和互斥，信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问。 编程时可根据操作信号量值的结果判断是否对公共资源有访问的权限，当信号量值大于0时，则可以访问，否则将阻塞。PV 原语是对信号量的操作，一次 P 操作使信号量减1，一次 V 操作使信号量加1。 信号量主要用于进程或线程间的同步和互斥这两种典型情况。 信号量用于互斥： 信号量用于同步： 无名信号量基本操作： 需包含的头文件 1#include &lt;semaphore.h&gt; 注意：编译信号量操作函数时，编译选项需加上参数 -lpthread 。 信号量数据类型为：sem_t 。 1）初始化信号量 1int sem_init(sem_t *sem, int pshared, unsigned int value); 功能： 创建一个信号量并初始化它的值。一个无名信号量在被使用前必须先初始化。 参数： sem：信号量的地址。 pshared：等于0，信号量在线程间共享(常用)；不等于0，信号量在进程间共享。 value：信号量的初始值。 返回值： 成功：0；失败：-1 2）信号量 P 操作(减 1) 1int sem_wait(sem_t *sem); 功能： 将信号量的值减1。操作前，先检查信号量 sem 的值是否为0，若信号量为0，此函数会阻塞，直到信号量大于0时才进行减1操作。 参数： sem：信号量的地址。 返回值： 成功：0；失败：-1 1int sem_trywait(sem_t *sem); 以非阻塞的方式来对信号量进行减1操作。若操作前，信号量的值等于0，则对信号量的操作失败，函数立即返回。 3）信号量 V 操作(加 1) 1int sem_post(sem_t *sem); 功能： 将信号量的值加1并发出信号唤醒等待线程(sem_wait())。 参数： sem：信号量的地址。 返回值： 成功：0；失败：-1 4）获取信号量的值 1int sem_getvalue(sem_t *sem, int *sval); 功能： 获取 sem 标识的信号量的值，保存在 sval 中。 参数： sem：信号量地址。 sval：保存信号量值的地址。 返回值： 成功：0；失败：-1 5）销毁信号量 1int sem_destroy(sem_t *sem); 功能： 删除 sem 标识的信号量。 参数： sem：信号量地址。 返回值： 成功：0；失败：-1 互斥实例: >folded sem1.cpp12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;#include &lt;semaphore.h&gt; sem_t sem; //信号量 void printer(char *str){ sem_wait(&amp;sem);//减一 while(*str) { putchar(*str); fflush(stdout); str++; sleep(1); } printf(\"\\n\"); sem_post(&amp;sem);//加一} void *thread_fun1(void *arg){ char *str1 = \"hello\"; printer(str1);} void *thread_fun2(void *arg){ char *str2 = \"world\"; printer(str2);} int main(void){ pthread_t tid1, tid2; sem_init(&amp;sem, 0, 1); //初始化信号量，初始值为 1 //创建 2 个线程 pthread_create(&amp;tid1, NULL, thread_fun1, NULL); pthread_create(&amp;tid2, NULL, thread_fun2, NULL); //等待线程结束，回收其资源 pthread_join(tid1, NULL); pthread_join(tid2, NULL); sem_destroy(&amp;sem); //销毁信号量 return 0;} 同步实例: >folded sem2.cpp1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;semaphore.h&gt; sem_t sem_g, sem_p; //定义两个信号量char ch = 'a'; void *pthread_g(void *arg) //此线程改变字符ch的值{ while(1) { sem_wait(&amp;sem_g); ch++; sleep(1); sem_post(&amp;sem_p); }} void *pthread_p(void *arg) //此线程打印ch的值{ while(1) { sem_wait(&amp;sem_p); printf(\"%c\",ch); fflush(stdout); sem_post(&amp;sem_g); }} int main(int argc, char *argv[]){ pthread_t tid1,tid2; sem_init(&amp;sem_g, 0, 0); //初始化信号量 sem_init(&amp;sem_p, 0, 1); pthread_create(&amp;tid1, NULL, pthread_g, NULL); pthread_create(&amp;tid2, NULL, pthread_p, NULL); pthread_join(tid1, NULL); pthread_join(tid2, NULL); return 0;} 2.6、信号机制(signal)类似进程间的信号处理 参考文章:1、进程间通信方式+线程间通信方式2、Linux系统编程——线程同步与互斥：POSIX无名信号量3、记一次面试：进程之间究竟有哪些通信方式？ —- 告别死记硬背4、Linux进程间的通信方式和原理","link":"/post/10267b43.html"},{"title":"Golang构造结构体对象new方法和取地址符&的区别","text":"面向对象的语言一般都有构造函数，用来在创建对象时初始化对象，即为对象成员变量赋初始值。但是Golang里面没有构造函数，在初始化结构体对象时可以使用new操作符，也可以使用&amp;操作符，两者具体区别在哪里呢？ 一、构造函数与复合语义(Constructors and composite literals)在go官方文档 effective_go 中的 Constructors and composite literals 章节部分指出： 12As a limiting case, if a composite literal contains no fields at all, it creates a zero value for the type. The expressions new(File) and &amp;File{} are equivalent. 也就是说，如果在构造结构体时，复合文本中没有包含任何字段，则它将为类型创建一个零值。此时表达式 new(File) 和 &amp;File{} 是等价的。 有时候零值初始化并不够好，所以构造函数还是有必要的，看 package os 包中的一个例子: 1234567891011func NewFile(fd int, name string) *File { if fd &lt; 0 { return nil } f := new(File) f.fd = fd f.name = name f.dirinfo = nil f.nepipe = 0 return f} 这种类似早期 C++ 生成对象的写法，看着有点繁琐，而且有时候也容易遗漏某些字段。可以使用复合语义来简化，而且每次调用时都是不同的实例。 1234567func NewFile(fd int, name string) *File { if fd &lt; 0 { return nil } f := File{fd, name, nil, 0} return &amp;f} 与 C、C++ 不同，go 语言可以返回局部变量的地址，变量相关联的存储在函数返回后继续存在。合并上述代码的最后两行，进一步简化。 1return &amp;File{fd, name, nil, 0} 复合文本的字段按顺序排列，并且必须全部存在。但是，通过将元素显式标记为 field:value 对，初始化器可以以任何顺序出现。未出现的字段，则使用对应类型的零值初始化。 1return &amp;File{fd: fd, name: name} 二、在赋值语句方面的不同使用new 12345678910111213141516171819202122232425262728package mainimport ( \"fmt\")type Drink struct { Name string Flavour string}func main() { a := new(Drink) a.Name = \"Maaza\" a.Flavour = \"Mango\" b := a fmt.Println(&amp;a) fmt.Println(&amp;b) b.Name = \"Frooti\" fmt.Println(a.Name)}// output0xc0000060280xc000006030FrootiProcess finished with exit code 0 在赋值 = 操作时，虽然 a、b 的地址不同，但是修改了 b 对象的 Name 字段值，a 对象的 Name 字段也改变了。 使用取地址符&amp;1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\")type Drink struct { Name string Flavour string}func main() { a := Drink{ Name: \"Maaza\", Flavour: \"Mango\", } b := a fmt.Println(&amp;a) fmt.Println(&amp;b) b.Name = \"Froti\" fmt.Println(a.Name)}// output&amp;{Maaza Mango}&amp;{Maaza Mango}MaazaProcess finished with exit code 0 这里改变 b 变量 Name 字段的值，不会对 a 变量 Name 字段造成影响。若讲赋值语句修改为 b := &amp;a，即将 b 指向了 a 变量的地址，此时修改 b 的 Name 字段，实际也是在修改 a 变量的 Name 字段。","link":"/post/63e034ab.html"},{"title":"分布式之数据库和缓存双写一致性方案解析(转载)","text":"在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。 引言为什么写这篇文章？首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，都是按照下图的流程来进行业务操作。 文章结构本文由以下三个部分组成1、讲解缓存更新策略2、对每种策略进行缺点分析3、针对缺点给出改进方案 正文先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。 在这里，我们讨论三种更新策略：1、先更新数据库，再更新缓存2、先删除缓存，再更新数据库3、先更新数据库，再删除缓存 (1)先更新数据库，再更新缓存这套方案，大家是普遍反对的。为什么呢？有如下两点原因。 原因一(线程安全角度) 同时有请求A和请求B进行更新操作，那么会出现（1）线程 A 更新了数据库（2）线程 B 更新了数据库（3）线程 B 更新了缓存（4）线程 A 更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。 原因二(业务场景角度) 有如下两点：（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致数据压根还没读到，缓存就被频繁的更新，浪费性能。 （2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。 接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。 (2)先删缓存，再更新数据库该方案会导致不一致的原因是同时有一个请求 A 进行更新操作，另一个请求 B 进行查询操作。那么会出现如下情形：（1）请求 A 进行写操作，删除缓存（2）请求 B 查询发现缓存不存在（3）请求 B 去数据库查询得到旧值（4）请求 B 将旧值写入缓存（5）请求 A 将新值写入数据库 上述情况就会导致不一致。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 那么，如何解决呢？采用延时双删策略 伪代码如下 123456public void write(String key, Object data) { redis.delKey(key); db.updateData(data); Thread.sleep(1000); redis.delKey(key); } 转化为中文描述就是（1）先淘汰缓存（2）再写数据库（这两步和原来一样）（3）休眠1秒，再次淘汰缓存 这么做，可以将1秒内所造成的缓存脏数据，再次删除。 那么，这个1秒怎么确定的，具体该休眠多久呢？ 针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百 ms 即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 如果你用了mysql的读写分离架构怎么办？ ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求 A 进行更新操作，另一个请求 B 进行查询操作。（1）请求 A 进行写操作，删除缓存（2）请求 A 将数据写入数据库了（3）请求 B 查询缓存发现，缓存没有值（4）请求 B 去从库查询，这时，还没有完成主从同步，因此查询到的是旧值（5）请求 B 将旧值写入缓存（6）数据库完成主从同步，从库变为新值 上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百 ms。 采用这种同步淘汰策略，吞吐量降低怎么办？ ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，可以加大吞吐量。 第二次删除，如果删除失败怎么办？ 这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求 A 进行更新操作，另一个请求 B 进行查询操作，为了方便，假设是单库:（1）请求 A 进行写操作，删除缓存（2）请求 B 查询发现缓存不存在（3）请求 B 去数据库查询得到旧值（4）请求 B 将旧值写入缓存（5）请求 A 将新值写入数据库（6）请求 A 试图去删除请求 B 写入缓存的值，结果失败了 ok，这也就是说，如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。 如何解决呢？ 具体解决方案，且看第(3)种更新策略的解析。 (3)先更新数据库，再删缓存首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中就指出 失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从 cache 中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 另外，知名社交网站 facebook 也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。 这种情况不存在并发问题么？ 不是的。假设这会有两个请求，一个请求 A 做查询操作，一个请求 B 做更新操作，那么会有如下情形产生：（1）缓存刚好失效（2）请求A查询数据库，得一个旧值（3）请求B将新值写入数据库（4）请求B删除缓存（5）请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据。 然而，发生这种情况的概率又有多少呢？ 发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。假设，有人非要抬杠，有强迫症，一定要解决怎么办？ 如何解决上述并发问题？ 首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。 还有其他造成不一致的原因么？ 有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。 如何解决？ 提供一个保障的重试机制即可，这里给出两套方案。 方案一： 流程如下所示（1）更新数据库数据（2）缓存因为种种问题删除失败（3）将需要删除的key发送至消息队列（4）自己消费消息，获得需要删除的key（5）继续重试删除操作，直到成功 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的 binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。 方案二： 流程如下图所示：（1）更新数据库数据（2）数据库会将操作信息写入 binlog 日志当中（3）订阅程序提取出所需要的数据以及 key（4）另起一段非业务代码，获得该信息（5）尝试删除缓存操作，发现删除失败（6）将这些信息发送至消息队列（7）重新从消息队列中获得该数据，重试操作 备注说明：上述的订阅 binlog 程序在 mysql 中有现成的中间件叫 canal，可以完成订阅 binlog 日志的功能。至于 oracle 中，目前不知道有没有现成中间件可以使用。另外，重试机制，采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。 总结本文其实是对目前互联网中已有的一致性方案，进行了一个总结。对于先删缓存，再更新数据库的更新策略，还有方案提出维护一个内存队列的方式，看了一下，觉得实现异常复杂，没有必要，因此没有在文中给出。最后，希望大家有所收获。 参考文献1、主从DB与cache一致性2、缓存更新的套路 原文1、【原创】分布式之数据库和缓存双写一致性方案解析","link":"/post/b41fd8e8.html"},{"title":"博客-配置问题记录","text":"博客配置、主题配置过程中偶尔会出现问题，这里记录一些对应的解决方法。 博客目前采用的是在icarus主题基础上修改的amazing主题。 一、主题配置gitalk评论系统之前提交百度收录博客时，一级域名提交的是带http协议头的。这样每次浏览博客时，浏览器会提示与此网站的连接不安全，为了消除这个提示，需要采用加密的https协议头来访问网站URL。如下所示，只需要在网站仓库的GitHub Pages设置里勾选上Enforce HTTPS即可让网站采用加密的https方式访问了。 123[√]Enforce HTTPS HTTPS provides a layer of encryption that prevents others from snooping on or tampering with traffic to your site.When HTTPS is enforced, your site will only be served over HTTPS. Learn more. 主题_config.yml下的评论设置选项如下所示，配置完后，可以初始化评论，这样其他浏览的用户就可以参与评论了。 1234567891011comment: type: gitalk owner: xxx # (required) GitHub user name repo: xxx # (required) GitHub repository name client_id: xxx # (required) OAuth application client id client_secret: xxx # (required) OAuth application client secret admin: xxx #此账户一般为用户名 GitHub user name 文章中能创建issue需要此用户登录才可以，点了创建issue后刷新一遍才能看到！！！！ create_issue_manually: true distraction_free_mode: true has_hot_recommend: true # 是否有热门推荐 has_latest_comment: true #是否有最新评论 但是当启用hppts访问后，博客的gitalk评论系统出现了不能更新文章Issue的情况。原因如下图所示： 提示是未授权，如下图所示，为了解决这个问题，只需要将协议头改为https即可。 amazing主题碎碎念在宽屏浏览日期显示不全的问题碎碎念在宽屏浏览时，会出现评论框覆盖日期框的问题。如下图所示： 在主题配置css布局的base.styl中有碎碎念的设置。 amazing/source/css/base.styl:116412345678910111213// ============self-talking start.content .gt-container .gt-comment-header { font-size: 0.875em; position: relative; display: inline-block; left: -3%; margin-bottom: 10px; padding: 0 10% 0 32px; height: 32px; line-height: 32px; border-radius: 0 3px 3px 0; background-color: #deeafb;} 依次调试了几个选项，发现修改left可以使日期框显示完整，之前left参数的值是-6%，现改成了-3%。 给主题增加天气显示想着给博客页面增加一个天气显示的框，可能最近老是下雨，晴雨不定。在网上搜索到一篇博客美化的文章，里面天气的样式，是自己需要的。如下图所示： 二、博客配置Github和Coding双线绑定自定义域名为了能让博客网站的站点地图被百度爬取，需要双线解析部署。之前PING博客域名时，是github服务器的ip。如下所示，在Coding部署后，就能显示是coding的服务器ip了。 12345678910正在 Ping beyondhxl.com [124.156.193.111] 具有 32 字节的数据:来自 124.156.193.111 的回复: 字节=32 时间=75ms TTL=49来自 124.156.193.111 的回复: 字节=32 时间=72ms TTL=49来自 124.156.193.111 的回复: 字节=32 时间=72ms TTL=49来自 124.156.193.111 的回复: 字节=32 时间=72ms TTL=49124.156.193.111 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 72ms，最长 = 75ms，平均 = 72ms 双线部署，可以参考Hexo 双线部署到 Coding Pages 和 GitHub Pages 并实现全站 HTTPS这篇博文，或者这篇Github博客同步到Coding,自定义域名双线解析博文。 中间可能会申请SSL证书，需要暂时在DNS域名管理控制台那里将github解析停止。原因见这篇Hexo瞎折腾系列(7) - Coding Pages申请SSL/TLS证书错误博文。同时在SSL开启之前，不要开启https的跳转，如果有cdn，先直接解析到源服务器。 参考1、Hexo博客百度收录","link":"/post/36cef32a.html"},{"title":"博客-提交百度站点收录","text":"目前Github是禁止百度爬虫的，对于部署在 github pages 服务上的博客，需要主动推送站点信息给百度，这样可以提高网站的关键词排名以及博客文章的曝光度。 一、检测网站是否被百度收录在百度搜索框输入：site:域名 查看网站域名是否被百度收录。如下图所示： 二、百度站长平台提交链接提交网站一级域名如下所示，需要提交一级域名，协议头建议采用https，这种方式有加密处理，安全性更高。 验证站点主要有三种验证方式，文件验证、HTML标签验证、CNAME验证，通过验证用来确认提交链接的用户是否是网站的所有者。 这里选择CNAME验证，注意主机记录是第一个点号”.”前面的部分。然后登陆网站域名解析提供商，增加如下所示一条域名解析记录。等待TTL时间后，再去验证。 链接提交百度站长平台的链接提交方式分为自动提交和手动提交两种。自动提交又包含主动推送(实时)、自动推送、sitemap站点地图三种。主动推送是每次在博客发布之时，生成对应文章的链接。自动推送则需要安装百度提供的JS代码到网页。sitemap则是将生成的站点地图推送给百度，站点地图里面包含了网站的所有有效链接地址。这里叙述主动推送(实时)方式。 安装百度主动推送插件： 1npm install hexo-baidu-url-submit --save 修改站点配置文件_config.yml，增加百度提交配置，添加内容如下： 12345baidu_url_submit: count: 50 # 提交最新的多少个链接 host: www.beyondhxl.com # 在百度站长平台中添加的域名 token: your_token # 秘钥 path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档 your_token可以在百度站长平台主动推送页面找到。 查看站点配置_config.yml文件中的URL是否与在百度站长提交的链接一致。 1234# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://www.beyondhxl.comroot: / 最后需要在站点配置_config.yml中新增一种百度deploy方式，如下所示： 123456789# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: git repository: github: git@github.com:beyondhxl/beyondhxl.github.io.git coding: git@e.coding.net:persis/persis.git branch: master- type: baidu_url_submitter 主动推送的实现原理如下: hexo generate 会产生一个文本文件，里面包含最新的链接 hexo deploy 会从上述文件中读取链接，提交至百度搜索引擎 注意点站点配置的URL切记一定要和提交到百度站长的链接一致，否则会出现如下所示问题： 1234567891011Branch 'master' set up to track remote branch 'master' from 'git@e.coding.net:persis/persis.git'.INFO Deploy done: gitINFO Deploying: baidu_url_submitterINFO Submitting urlshttps://beyondhxl.github.io/post/540fc464.htmlhttps://beyondhxl.github.io/post/4d0a2d54.htmlhttps://beyondhxl.github.io/post/1d3a59e7.htmlhttps://beyondhxl.github.io/post/93582398.htmlhttps://beyondhxl.github.io/post/b08db376.html{\"remain\":3000,\"success\":0,\"not_same_site\":[\"https://beyondhxl.github.io/post/540fc464.html\",\"https://beyondhxl.github.io/post/4d0a2d54.html\",\"https://beyondhxl.github.io/post/1d3a59e7.html\",\"https://beyondhxl.github.io/post/93582398.html\",\"https://beyondhxl.github.io/post/b08db376.html\"]}INFO Deploy done: baidu_url_submitter 百度推送反馈说明 字段 是否必选 参数类型 说明 success 是 int 成功推送的url条数 remain 是 int 当天剩余的可推送url条数 not_same_site 否 array 由于不是本站url而未处理的url列表 not_valid 否 array 不合法的url列表 对比发现，not_same_site数组不为空，说明提交的不是本站的URL，例如https://beyondhxl.github.io/post/540fc464.html这个就缺少了www前缀。修改后再次提交，如下图所示，说明提交成功了。 1234567891011Branch 'master' set up to track remote branch 'master' from 'git@e.coding.net:persis/persis.git'.INFO Deploy done: gitINFO Deploying: baidu_url_submitterINFO Submitting urlshttps://www.beyondhxl.com/post/540fc464.htmlhttps://www.beyondhxl.com/post/4d0a2d54.htmlhttps://www.beyondhxl.com/post/1d3a59e7.htmlhttps://www.beyondhxl.com/post/93582398.htmlhttps://www.beyondhxl.com/post/b08db376.html{\"remain\":2995,\"success\":5}INFO Deploy done: baidu_url_submitter 参考文章:1、Hexo博客提交百度和Google收录2、《SEO实战密码》","link":"/post/27dac0a0.html"},{"title":"Goland常用快捷键","text":"Goland常用快捷键记录，以及使用中遇到的问题记录。 一、快捷键文件相关 CTRL+E，打开最近浏览过的文件 CTRL+SHIFT+E，打开最近更改的文件 CTRL+N，可以快速打开struct结构体 CTRL+SHIFT+N，可以快速打开文件 代码格式化 CTRL+ALT+T，可以把代码包在一个块内，例如if{…}else{…} CTRL+ALT+L，格式化代码 CTRL+空格，代码提示 CTRL+/，单行注释。CTRL+SHIFT+/，进行多行注释 CTRL+B，快速打开光标处的结构体或方法（跳转到定义处） CTRL+“+/-”，可以将当前方法进行展开或折叠 查找和定位 CTRL+R，替换文本 CTRL+F，查找文本 CTRL+SHIFT+F，进行全局查找 CTRL+G，快速定位到某行 代码编辑 ALT+Q，可以看到当前方法的声明 CTRL+Backspace，按单词进行删除 SHIFT+ENTER，可以向下插入新行，即使光标在当前行的中间 Ctrl+Alt+Enter：当前行的上方插入空行 CTRL+X，删除当前光标所在行 CTRL+D，复制当前光标所在行 ALT+SHIFT+UP/DOWN，可以将光标所在行的代码上下移动 CTRL+SHIFT+U，可以将选中内容进行大小写转化 函数操作 CTRL+ALT+L，转到函数定义处 ALT+”&lt;-“，回退到上一次查看函数定义处 二、问题记录git revert后如何恢复之前的本地修改使用Goland提交本地修改时，发现commit注释信息与提交内容不符，然后不小心使用git revert命令将本地代码都回退了。 Goland右上角有个git提交历史记录，可以查看过往提交信息。 由于回退的内容还比较多，也没有备份，通过搜索相关问题，发现Goland有本地历史记录，而且可以恢复指定日期的历史记录。 右键项目，显示下拉菜单，选择Local History。 选择需要恢复的一个日期，右键弹出revert选项，点击即可恢复。 参考文章:Goland常用快捷键","link":"/post/540fc464.html"},{"title":"面向对象思想概念","text":"面向对象三大特性，封装、继承、多态。这些特性将事物抽象成对象，给对象赋一些属性和方法，外部就可以通过公开方法访问对象了。 一、设计原则依赖倒置原则 在面向对象设计中有一个重要的原则是依赖倒置（Dependence Inversion Principle），主要作用是解耦，让对象与对象之间松耦合。定义如下：高层模块不应该依赖底层模块，他们都应该依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。要针对接口编程，不要对实现编程。 依赖倒置原则基于这样一个事实：相对于细节的多变性，抽象的东西要稳定的多。 抽象指的是接口或者抽象类，细节就是具体的实现类，使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成。 实例任天堂 Switch 一经推出，就获得了玩家的一致好评。其上运行的《塞尔达传说：旷野之息》，是一款优秀的开放世界动作冒险游戏，值得品玩。有如下关于 Switch 的代码： 12345678910111213type Player struct {}func (p *Player) PlayZelda(s *Switch) { s.Play()}type Switch struct {}func (s *Switch) Play() { fmt.Print(\"Play Zelda by Switch\")} 上述书写的代码，只能让玩家在 Switch 主机上玩塞尔达。开发者以后可能会将游戏移植到电脑、手机端，为了让玩家也可以在电脑、手机上玩塞尔达，需要引入一个 IPlay 玩的接口，任何只要实现了这个接口的平台或者硬件，就可以让玩家在上面玩塞尔达。 1234// 游戏type IPlay interface { Play()} 因此 Player 类与 IPlay 就有了依赖关系，而电脑、手机这些都属于玩塞尔达的硬件或者平台，各自实现 IPlay 接口即可，这样就符合依赖倒置原则了。最终实现代码如下： main.go >folded123456789101112131415161718192021222324252627282930313233343536// 游戏type IPlay interface { Play()}// 电脑type PC struct {}func (pc *PC) Play() { fmt.Print(\"Play by PC \\n\")}// 手机type Phone struct {}func (ph *Phone) Play() { fmt.Print(\"Play by Phone \\n\")}// 玩家type Player struct {}func (p *Player) PlayZelda(play IPlay) { play.Play()}func main() { pc := &amp;PC{} ph := &amp;Phone{} player := new(Player) player.PlayZelda(pc) player.PlayZelda(ph)} 总结 低层模块尽量都要有抽象类或接口，或者两者都有。 变量的声明类型尽量是抽象类或接口。 使用继承时遵循里氏替换原则。依赖倒置原则的核心就是要我们面向接口编程，理解了面向接口编程，也就理解了依赖倒置原则。 参考文章:依赖倒置原则(Dependence Inversion Principle)","link":"/post/4d0a2d54.html"},{"title":"博客-配置RSS订阅","text":"一、什么是RSS？RSS（简易信息聚合，也叫Really Simple Syndication、聚合RSS、聚合内容），是一种消息来源格式规范，用以聚合经常发布更新数据的网站，例如博客文章、新闻、音频或视频的网摘。通常在时效性比较强的内容上使用RSS订阅能更快速获取信息，网站提供RSS输出，有利于让用户获取网站内容的最新更新。网络用户可以在客户端借助于支持RSS的聚合工具软件（例如SharpReader、NewzCrawler、FeedDemon），在不打开网站内容页面的情况下阅读支持RSS输出的网站内容。 二、为什么需要RSS？网络上的信息铺天盖地，个人的时间和精力有限，无法面面俱到。RSS可以主动推送用户关注的信息，这样也提高了阅读体验。 三、将博客RSS配置成可订阅的最近更换了博客主题，新主题有一个可以让浏览网站的用户邮件订阅博客RSS的挂件。 需要通过Google FeedBurner配置，进而获得注册后的feedburner_id，然后在主题配置文件下打开对应的订阅RSS开关即可。 四、配置步骤登录 http://www.feedburner.com 注册一个用户，将博客的RSS/ATOM地址注册，同时选取一个在feedburner上的发布地址，形如：http://feeds.feedburner.com/abc， 其他用户就可以使用这个地址订阅你博客的RSS/ATOM了。 配置完成后，就可以看到博客的feed了。 最后在feed发布页签，开启邮件订阅功能，博客更新了，订阅的用户就会在第一时间收到最新内容。 后记博客文章更新后，邮箱确实收到了提醒邮件，说明订阅RSS的设置是成功的。 参考Icarus用户指南 - 挂件","link":"/post/93582398.html"},{"title":"leetcode-外观数列","text":"一、题目「外观数列」是一个整数序列，从数字 1 开始，序列中的每一项都是对前一项的描述。前五项如下： 1 11 21 1211 1112211 被读作 “one 1” (“一个一”) , 即 11。11 被读作 “two 1s” (“两个一”）, 即 21。21 被读作 “one 2”, “one 1” （”一个二” , “一个一”) , 即 1211。 给定一个正整数 n（1 ≤ n ≤ 30），输出外观数列的第 n 项。 注意：整数序列中的每一项将表示为一个字符串。 示例 1: 输入: 1输出: “1”解释：这是一个基本样例。 示例 2: 输入: 4输出: “1211”解释：当 n = 3 时，序列是 “21”，其中我们有 “2” 和 “1” 两组，”2” 可以读作 “12”，也就是出现频次 = 1 而 值 = 2；类似 “1” 可以读作 “11”。所以答案是 “12” 和 “11” 组合在一起，也就是 “1211”。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/count-and-say 二、思路理论推导 数列的第n项中的结果是由其前一项第n-1项的表达式决定的，第n项中表达式中的数字序列应该是每两个作为一组描述组合a1a2，表示前一项中对应位置是a1个a2(数字是从右往左排列)。 由此，第6项读第5项111221，3个1，2个2，1个1，推导出第6项就是312211。 规律与结论通过上述理论，总结出一些规律： 数列中每一项数字的个数一定是2的倍数，因为每一项都是对前一项的描述，而每一组描述都需要两个字符来完成，把数字中每一个数位上的数字看作字符，最终的总字符一定是偶数。 如果第n项数字序列是a1a2a3…am共m个数字，其中不重复的有k个，(如第5项111221中数字一共有6个，不重复数字是1、2，k等于2），要表示前一项的k个不重复数字，后一项至少需要2k个字符。 由此得出的结论： 如果数列第n项是An=a1a2a3a4a5a6…an-1an，则可以知道前一项An-1是由a2a4a6…an组成，因此a2≠a4，a4≠a6，以此类推，否则矛盾。例如111321131221中偶数位置数字分别是1、3、1、3、2、1，相邻的两个数字一定不相等，否则如果是111121131221，则前面四个数1111表示前一项对应的两个数字就是11，而又由描述组合的规则来看，要表示这两个数，下一项应该要用21来表示，而不是1111，所以就会矛盾，所以可知每一项的数字序列中，最多会连续出现相同的数字的数目是3个，不会有连续四个数字相同。 任何一项的数字序列中，只能由1、2、3三个字符中的若干个排列组成 三、代码实现>folded main.go123456789101112131415161718192021222324252627282930313233343536// 递归解法func countAndSay(n int) string { // 基础情况 if n == 1 { return \"1\" } // 得到第n-1项的字符串 pstr := countAndSay(n - 1) return say(pstr)}func say(prev string) string { if len(prev) == 0 { return \"\" } // 获取字符的重复个数 n := getCharCount(prev) // 递归调用 return strconv.Itoa(n) + string(prev[0]) + say(prev[n:])}func getCharCount(str string) int { count := 1 ch := str[0] for i := 1; i &lt; len(str); i++ { if str[i] == ch { count++ } else { break } } return count} 参考Leetcode#String 外观数列","link":"/post/b08db376.html"},{"title":"leetcode-两数相除","text":"一、题目给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。 返回被除数 dividend 除以除数 divisor 得到的商。 整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2 示例 1: 输入: dividend = 10, divisor = 3输出: 3解释: 10/3 = truncate(3.33333..) = truncate(3) = 3示例 2: 输入: dividend = 7, divisor = -3输出: -2解释: 7/-3 = truncate(-2.33333..) = -2 提示： 被除数和除数均为 32 位有符号整数。 除数不为 0。 假设我们的环境只能存储 32 位有符号整数，其数值范围是 [−231, 231 − 1]。本题中，如果除法结果溢出，则返回 231 − 1。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/divide-two-integers 二、思路二分法递归，被除数每次都减去除数的两倍，直到被除数的数值小于除数的数值，不够减为止。这个迭代过程的次数，即是商。 十进制竖列式方法计算两个数的除法 二进制除法 三、代码实现>folded main.go123456789101112131415161718192021222324252627282930313233343536373839404142func divide(dividend int, divisor int) int { if divisor == 0 { return math.MaxInt32 } signdived, signdivor := 1, 1 if dividend &lt; 0 { dividend = -dividend signdived = -1 } if divisor &lt; 0 { divisor = -divisor signdivor = -1 } res, _ := div(dividend, divisor, 1) if signdived != signdivor { res = -res } if res &lt; math.MinInt32 || res &gt; math.MaxInt32 { return math.MaxInt32 } return res}func div(m, n, count int) (quo, rem int) { switch { case m &lt; n: return 0, m case m &gt;= n &amp;&amp; m &lt; n+n: return count, m - n default: quo, rem = div(m, n+n, count+count) if rem &gt;= n { return quo + count, rem - n } return }}","link":"/post/87df3eb0.html"},{"title":"leetcode-合并K个排序链表","text":"一、题目合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 示例: 输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/merge-k-sorted-lists 二、思路一分治法两两合并 将k个链表配对并将同一对中的链表合并 第一轮合并后，k个链表被合并成了$\\frac{k}{2}$ 个链表，平均长度为$\\frac{2n}{k}$，总共n个元素。然后是$\\frac{k}{4}$个链表，$\\frac{k}{8}$个链表等等 重复这个过程，直到不能再合并 代码实现>folded main.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } return merge(lists)}func merge(lists []*ListNode) *ListNode { llen := len(lists) mid := llen / 2 if llen == 1 { return lists[0] } if llen == 2 { l1, l2 := lists[0], lists[1] res, cur := &amp;ListNode{}, &amp;ListNode{} if l1 == nil { return l2 } if l2 == nil { return l1 } if l1.Val &lt; l2.Val { res = l1 cur.Next = l1 l1 = l1.Next } else { res = l2 cur.Next = l2 l2 = l2.Next } cur = cur.Next for l1 != nil &amp;&amp; l2 != nil { if l1.Val &lt; l2.Val { cur.Next = l1 l1 = l1.Next } else { cur.Next = l2 l2 = l2.Next } cur = cur.Next } if l1 != nil { cur.Next = l1 } if l2 != nil { cur.Next = l2 } return res } return mergeKLists([]*ListNode{mergeKLists(lists[mid:]), mergeKLists(lists[:mid])})} 三、思路二优先队列建立优先队列(大根堆或者小根堆均可)，每次让链表头元素入队，一轮比较后，如果该元素被弹出，对应的链表则后移，后面的元素再入队。 代码实现>folded main.go12345678910111213141516171819202122232425262728func mergeKLists2(lists []*ListNode) *ListNode { if lists == nil || len(lists) == 0 { return nil } // golang容器中的heap var h MinHeap heap.Init(&amp;h) for _, l := range lists { if l != nil { heap.Push(&amp;h, l) } } dummy := &amp;ListNode{} p := dummy for h.Len() &gt; 0 { min := heap.Pop(&amp;h).(*ListNode) p.Next = min p = p.Next if min.Next != nil { heap.Push(&amp;h, min.Next) } } return dummy.Next}","link":"/post/a2af3058.html"},{"title":"leetcode-整数转罗马数字及罗马数字转整数","text":"罗马数字是欧洲在阿拉伯数字（实际上是印度数字）传入之前使用的一种数码，是古罗马使用的记数系统。它的产生晚于中国甲骨文中的数码，更晚于埃及人的十进制数字。但是，它的产生标志着一种古代文明的进步。 整数转罗马数字一、题目罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。 罗马数字与阿拉伯数字对应表 罗马数字 阿拉伯数字 M 1000 CM 900 D 500 CD 400 C 100 XC 90 L 50 XL 40 X 10 IX 9 V 5 IV 4 I 1 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。 示例 1: 输入: 3输出: “III”示例 2: 输入: 4输出: “IV”示例 3: 输入: 9输出: “IX”示例 4: 输入: 58输出: “LVIII”解释: L = 50, V = 5, III = 3.示例 5: 输入: 1994输出: “MCMXCIV”解释: M = 1000, CM = 900, XC = 90, IV = 4. 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/integer-to-roman 二、思路一暴力匹配 题目限制输入的数字在1 ~ 3999之间，所以数字最多有四位，分别是千、百、十、个位。转换时，从左到右依次转换。 三、代码实现123456789// 解法一 暴力匹配func intToRoman(num int) string { // 将每个数位枚举出 M := []string{\"\", \"M\", \"MM\", \"MMM\"} // 1000, 2000, 3000 对应的是阿拉伯数字千分位 C := []string{\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"} // 100 ~ 900 X := []string{\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"} // 10 ~ 90 I := []string{\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"} // 1 ~ 9 return M[num/1000] + C[(num/100)%10] + X[(num/10)%10] + I[(num%10)]} 四、思路二贪心法 可以构造一个字典，将阿拉伯数字和罗马数字对应起来。每次都从罗马数字中，选取一个最大的罗马数字，去分解这个整数，目的就是让分解的整数的个数尽可能的少。 五、代码实现12345678910111213// 解法二 贪心法func intToRoman1(num int) string { digits := []int{1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1} romans := []string{\"M\", \"CM\", \"D\", \"CD\", \"C\", \"XC\", \"L\", \"XL\", \"X\", \"IX\", \"V\", \"IV\", \"I\"} res := \"\" for i := 0; i &lt; len(digits); i++ { for num &gt;= digits[i] { num -= digits[i] res += romans[i] } } return res} 参考 LeetCode–整数转罗马数字 贪心算法（贪心算法的有效性未证明） 罗马数字转整数一、思路转换时是从最低位开始，从左到右转换，把一个小值放在大值的左边，就是做减法，否则做加法。 罗马数字由 I、V、X、L、C、D、M 构成； 当小值在大值的左边，则减小值，如 IV=5-1=4 当小值在大值的右边，则加小值，如 VI=5+1=6 二、代码实现1234567891011121314151617181920212223242526272829func romanToInt(s string) int { // 一个hashmap或者map存储罗马数字与对应阿拉伯数字的对应关系 res := 0 hashmap := map[byte]int{ 'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000, } // 从右往左遍历字符转换 pre := 0 for i := len(s) - 1; i &gt;= 0; i-- { cur := hashmap[s[i]] sign := 1 // 如果小数在大数的旁边，需减去小数，如IV if cur &lt; pre { sign = -1 } res += sign * cur pre = cur } return res} 参考 用时 99.93%，内存98.73%，简单解法","link":"/post/17854e07.html"},{"title":"leetcode-回文数","text":"一、题目判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 示例 1: 输入: 121输出: true示例 2: 输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。示例 3: 输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。进阶: 你能不将整数转为字符串来解决这个问题吗？ 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/palindrome-number 二、思路一反转一半数字回文的特点是首尾是一样的，利用这个特性，只需要反转一半数字。在循环内原数字不断迭代处理后如果大于等于新数字时循环就退出。 三、代码实现1234567891011121314151617// 反转一半数字func isPalindrome1(x int) bool { // 负数不是回文数 // 如果数字最后一位是0，只有数字0满足回文特征，因为多位整数不可能是0开头的 if x &lt; 0 || (x%10 == 0 &amp;&amp; x != 0) { return false } revertnum := 0 for x &gt; revertnum { revertnum = revertnum*10 + x%10 x = x / 10 } // 数字长度是奇数时，中间的数字不影响回文的，如12321 return x == revertnum || x == revertnum/10} 四、思路二转换为字符串用两个游标从转换后的字符串首尾向中间移动，每移动一步就比较对应的两个字符是否相等，循环结束条件是首尾游标位置相遇。 五、代码实现12345678910111213141516// 解法二// 转换为字符串func isPalindrome2(x int) bool { if x &lt; 0 || (x%10 == 0 &amp;&amp; x != 0) { return false } s := strconv.Itoa(x) for i, j := 0, len(s)-1; i &lt; j; i, j = i+1, j-1 { if s[i] != s[j] { return false } } return true}","link":"/post/f1e8e850.html"},{"title":"leetcode-Z字形变换","text":"一、题目将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 4 时，排列如下： L D R E O E I I E C I H N T S G之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。 请你实现这个将字符串进行指定行数变换的函数： string convert(string s, int numRows);示例 1: 输入: s = “LEETCODEISHIRING”, numRows = 3输出: “LCIRETOESIIGEDHN”示例 2: 输入: s = “LEETCODEISHIRING”, numRows = 4输出: “LDREOEIIECIHNTSG”解释: L D R E O E I I E C I H N T S G来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/zigzag-conversion 二、思路一将字符对应的索引显示，以numRows=3为例，行优先打印出字符 0| 1 5 9 13 1| 2 4 6 8 10 12 14 16 2| 3 7 11 15每一行右边的字符的索引值都是其左边的字符的索引值加上它下面剩余行数的两倍或上面行数的两倍(具体看两个字符所在的行) 因为两个字符目前在同一行，所以左边的字符是经过从上到下的，然后斜着从左到右到右边的字符，或者相反。例如： 4 == 2(左边的索引) + 2(两倍) * 1(4的下面有一行) 7 == 3(左边的索引) + 2(两倍) * 2(3的上面有两行) 三 、代码实现>folded main.go1234567891011121314151617181920212223func convert1(s string, numRows int) string { if numRows &lt;= 1 || len(s) &lt;= numRows { return s } var res []byte for i := 0; i &lt; numRows; i++ { count := 0 // 计数 upline := i // 上方的行数 downline := numRows - 1 - i // 下方的行数 for j := i; j &lt; len(s); { if count%2 == 0 &amp;&amp; downline != 0 { res = append(res, s[j]) j += 2 * downline } else if count%2 != 0 &amp;&amp; upline != 0 { res = append(res, s[j]) j += 2 * upline } count++ } } return string(res)} 四、思路二对原字符串进行分块处理，找到每块中数字在Z形变化后的对应关系。 L D R E O E I I E C I H N T S G将上图分成块[L E E T C O] [D E I S H I] [R I N G]，每块的数量等于行数的二倍减2。每块的头元素相距2*4-2=6个元素。 五、代码实现>folded main.go12345678910111213141516171819202122232425262728293031323334353637func convert2(s string, numRows int) string { // 从上到下、然后从左到右遍历字符串 // 需要算出有多少列？ if numRows == 1 || len(s) &lt;= numRows { return s } res := bytes.Buffer{} // 步长 // 因为计算两个位置索引差时，没有包含当前行，所以是2*(numRows-1)==numRows*2-2 step := numRows*2 - 2 // 首行 for i := 0; i &lt; len(s); i += step { res.WriteByte(s[i]) } // 中间行 for j := 1; j &lt;= numRows-2; j++ { // 每行的第一个元素 res.WriteByte(s[j]) for k := step; k-j &lt; len(s); k += step { res.WriteByte(s[k-j]) if k+j &lt; len(s) { res.WriteByte(s[k+j]) } } } // 末行 for l := numRows - 1; l &lt; len(s); l += step { res.WriteByte(s[l]) } return res.String()}","link":"/post/d2e4e456.html"},{"title":"leetcode-无重复字符的最长子串","text":"一、题目给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。 示例 1: 输入: “abcabcbb”输出: 3解释: 因为无重复字符的最长子串是 “abc”，所以其长度为 3。示例 2: 输入: “bbbbb”输出: 1解释: 因为无重复字符的最长子串是 “b”，所以其长度为 1。示例 3: 输入: “pwwkew”输出: 3解释: 因为无重复字符的最长子串是 “wke”，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，”pwke” 是一个子序列，不是子串。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-substring-without-repeating-characters 二、分析 设置 start 标志位，从前往后依次遍历字符位置 map 每次出现的字母，都缓存其最后一次出现的索引 如果当前字母的的 lastidx 大于或者等于 start，则 start 标志位移动到 lastidx 的前面一位，否则 start 标志不移动 每次遍历都更新 lastidx 和 maxlength，maxlength= 当前遍历位置 -start+1，即当前位置和 start 的距离 三、代码实现1234567891011121314151617181920package problem0003func lengthOfLongestSubstring(s string) int {s var ( start = 0 maxlength = 0 charlocation = make(map[rune]int) // 缓存每次出现的字符及位置索引 ) for i, ch := range []rune(s) { if lastidx, ok := charlocation[ch]; ok &amp;&amp; lastidx &gt;= start { start = lastidx + 1 } if i-start+1 &gt; maxlength { maxlength = i - start + 1 } charlocation[ch] = i } return maxlength}","link":"/post/f74735c.html"},{"title":"leetcode-两数相加","text":"一、题意给出两个非空的链表用来表示两个非负的整数。其中，它们各自的位数是按照逆序的方式存储的，并且它们的每个节点只能存储一位数字。 如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。 您可以假设除了数字0之外，这两个数都不会以0开头。 示例： 输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 0 -&gt; 8原因：342 + 465 = 807 题目来源：leetcode-两数相加 二、分析 整数的各个位置通过链表逆序连接起来，求和与笔算求和的顺序刚好相反。计算时需要考虑进位的情况。 两个链表的长度可能不同，遍历完其中一个链表后，直接将未走到终点的链表链接到尾部。这个多出来的结点就是多出来的位数。 三、代码实现>folded main.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode { // Val值逆序存储 // 要考虑进位 res := &amp;ListNode{} cur := res carry := 0 // 进位 for l1 != nil &amp;&amp; l2 != nil { sum := l1.Val + l2.Val + carry val := sum % 10 carry = sum / 10 lnode := &amp;ListNode{Val: val} cur.Next = lnode cur = cur.Next l1 = l1.Next l2 = l2.Next } // 最后无进位 if carry == 0 { // l1比l2长 if l1 != nil { cur.Next = l1 } else { cur.Next = l2 } } else { for l1 != nil { sum := l1.Val + carry val := sum % 10 carry = sum / 10 node := &amp;ListNode{Val: val} cur.Next = node cur = cur.Next l1 = l1.Next } for l2 != nil { sum := l2.Val + carry val := sum % 10 carry = sum / 10 node := &amp;ListNode{Val: val} cur.Next = node cur = cur.Next l2 = l2.Next } for carry != 0 { val := carry % 10 carry = carry / 10 node := &amp;ListNode{Val: val} cur.Next = node cur = cur.Next } } return res.Next} 四、测试代码>folded test.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package problem007import ( \"fmt\" \"testing\" \"github.com/stretchr/testify/assert\")func createList(vals []int) *ListNode { if len(vals) == 0 { return nil } res := &amp;ListNode{ Val: vals[0], } cur := res for i := 1; i &lt; len(vals); i++ { cur.Next = &amp;ListNode{ Val: vals[i], } cur = cur.Next } return res}func printList(l *ListNode) { for l != nil { val := l.Val l = l.Next if l == nil { fmt.Printf(\"%d\", val) } else { fmt.Printf(\"%d --&gt; \", val) } }}func Test_addTwoNumbers(t *testing.T) { ast := assert.New(t) l1 := createList([]int{2, 4, 3}) l2 := createList([]int{5, 6, 4}) ans := createList([]int{7, 0, 8}) res := addTwoNumbers(l1, l2) ast.Equal(ans, res) fmt.Printf(\"输入：(\") printList(l1) fmt.Printf(\") + (\") printList(l2) fmt.Println(\")\") fmt.Printf(\"输出：\") printList(res) fmt.Println()}// 输出如下：=== RUN Test_addTwoNumbers输入：(2 --&gt; 4 --&gt; 3) + (5 --&gt; 6 --&gt; 4)输出：7 --&gt; 0 --&gt; 8--- PASS: Test_addTwoNumbers (0.00s)PASSProcess finished with exit code 0 五、总结与思考本题和合并两个排序的链表类似，在构造链表时，都是顺序遍历两个链表。两数之和每次都是将两个链表对应的结点的值域相加，合并链表则是每次取其中值较大或者较小者。 六、C++ 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution{ public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { // 为什么不初始化为0？初始化为1，就可以假定两个参数至少有一个节点，但是这样也不是完全的边界情况啊？ // 还是要判断下两个头结点是不是空？ if(l1 == NULL &amp;&amp; l2 == NULL) { //return &amp;ListNode{0}; // golang 的写法，在这里是不对的 return NULL; // 直接返回一个空 } else if(l1 == NULL &amp;&amp; l2 != NULL) { return l2; } else if(l2 == NULL &amp;&amp; l1 != NULL) { return l1; } int len1 = 1; int len2 = 1; ListNode* p = l1; ListNode* q = l2; while(p-&gt;next != NULL) { ++len1; p = p-&gt;next; } while(q-&gt;next != NULL) { ++len2; q = q-&gt;next; } if(len1 &gt; len2) // l1较长，在l2末尾补上0 { for(int i = 1; i &lt;= len1-len2; ++i) { q-&gt;next = new ListNode(0); q = q-&gt;next; } } if(len1 &lt; len2) // l2较长，在l1处末尾补0 { for(int i = 1; i &lt;= len2-len1; ++i) { p-&gt;next = new ListNode(0); p = p-&gt;next; } } // 相等则不处理 // 又回到两个链表的开头，因为此时两个链表的长度肯定是相等的 p = l1; q = l2; bool carry = false; // 进位 ListNode* res = new ListNode(-1); // 结果指针 ListNode* cur = res; // 移动指针 int sum = 0; // 相加结果 while(p != NULL &amp;&amp; q != NULL) { sum = p-&gt;val + q-&gt;val + carry; // bool值 false=0、true=1 cur-&gt;next = new ListNode(sum%10); // 生成一个新的节点保存余数 carry = sum &gt;= 10 ? true : false; // 都移动到下个节点 cur = cur-&gt;next; p = p-&gt;next; q = q-&gt;next; } if(carry != 0) // 如果还有进位 { cur-&gt;next = new ListNode(1); cur = cur-&gt;next; } return res-&gt;next; }};","link":"/post/e847425f.html"},{"title":"剑指offer-求1+2+...+n","text":"一、题意求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句(A?B:C) 二、分析不能使用乘除法就意味着不能使用公式，循环和条件判断也不能用，就不能通过遍历累加得到结果，所以只能用递归，递归的终止条件用逻辑与来终止(短路特性)，即当n为0时，不再递归直接返回结果。 三、代码实现12345678910111213141516171819202122232425package mainimport ( \"fmt\" \"math\")// 利用公式1+2+...+n = (n+1)*n/2func sumSolution(n int) int { return (int(math.Pow(float64(n), 2)) + n) &gt;&gt; 1}func main() { n := 3 res := sumSolution(n) fmt.Printf(\"当n=%d，1+2+...+n的值是%d\", n, res)}// 输出如下：--------------------------------------当n=3，1+2+...+n的值是6Process finished with exit code 0--------------------------------------","link":"/post/9504833b.html"},{"title":"剑指offer-圆圈中最后剩下的数","text":"一、题意0，1，…，n-1这n个数字排成一个圆圈，从数字0开始每次从这个圆圈里删除第m个数字。求这个圆圈里剩下的最后一个数字。如0、1、2、3、4这5个数字组成的圆圈，从数字0开始每次删除第3个数字，则删除的前四个数字分别是2、0、4、1，因此最后剩下的数字是3。 二、分析 输入的序列在删除一个元素后，序列的长度会改变，如果索引在被删除的元素位置开始计算，那么每删除一个元素，序列的长度减一而索引会完全改变。如果能找到改变前的索引和新索引的对应关系，那么该问题就容易解决了。 定义一个函数f(n，m)，表示每次在n个数字0，1，2，3，…，n-1中每次删除第m个数字后剩下的数字。那么第一个被删除的数字的索引是(m-1)%n。删除该索引元素后，剩下的n-1个数字为0，1，2，…，k-1，k+1，…，n-1。下次删除数字是从k+1位置开始，于是可以把序列看作k+1，…，n-1，0，1，…，k-1。该序列最后剩下的序列也是f的函数。但该函数和第一个函数不同，存在映射关系，使用f’来表示，于是有：f(n，m) = f’(n-1，m)。 123456789k+1 --&gt; 0..k+2 --&gt; 1n-1 --&gt; n-k-2..0 --&gt; n-k-1k-1 --&gt; n-2 将映射定义为函数p，则p(x) = (x-k-1)%n，它表示如果映射前的数字是x，那么映射后的数字是(x-k-1)%n。对应的逆映射是p’(x) = (x+k+1)%n。由于映射之后的序列和最初的序列具有同样的形式，即都是从0开始的连续序列，仍然可以用函数f表示，记为f(n-1，m)。映射之前的序列中最后剩下的数字f’(n-1，m) = p’[f(n-1，m)] = [f(n-1, m)+k+1]%n代入得到f(n，m) = f’(n-1，m) = [f(n-1，m)+m]%n。 经过分析，终于得到一个递归公式。要得到n个数字的序列中最后剩下的数字，只需要得到n-1个数字的序列中最后剩下的数字，以此类推…。当n = 1时，也就是序列中开始只有一个数字0，那么最后剩下的数字就是0 $$ f(x) = \\left\\{ \\begin{array}{lr} 0 & : n=0\\\\ [f(n-1,m)+m] \\%n & : n > 1 \\end{array} \\right. $$ 三、代码实现123456789101112131415161718192021222324package mainimport \"fmt\"// n个数字从0、1、2、...、n-1开始编号，每次从其中删除第m个数字func CycleNumber(n, m int) int { if n &lt; 1 || m &lt; 1 { return -1 } else if n == 1 { return 0 } else { return (CycleNumber(n-1, m) + m) % n }}func main() { last := CycleNumber(5, 3) fmt.Printf(\"5个数字编号0、1、2、3、4，每次删除第3个数字，剩下的数字：%d\", last)}// 输出如下:5个数字编号0、1、2、3、4，每次删除第3个数字，剩下的数字：3Process finished with exit code 0","link":"/post/cb8c7ea6.html"},{"title":"剑指offer-n个骰子的点数","text":"一、题意把n个骰子扔在地上，所有骰子朝上一面的点数之和为s。输入n，打印出s的所有可能的值出现的概率。 二、解法一现在考虑如何统计每一个点数出现的次数。要想求出n个骰子的点数和，可以先把n个骰子分为两堆：第一堆只有一个，另一堆有n-1个。单独的那一个骰子可能出现从1到6的点数。我们需要计算从1到6的每一种点数和剩下的 n-1个骰子来计算点数和。接下来把剩下的n-1个骰子还是分成两堆，第一堆只有一个，第二堆有n-2个。我们把上一轮单独骰子的点数和这一轮单独骰子的点数相加，再和n-2个骰子来计算点数和。分析到这里，我们不难发现这是一种递归的思路，递归结束的条件就是最后只剩下一个骰子。 三、解法二可以换一个思路来解决这个问题，我们可以考虑用两个数组来存储骰子点数的每一个总数出现的次数。在一次循环中，第一个数组中的第n个数字表示骰子和为n出现的次数。在下一轮循环中，我们加上一个新的骰子，此时和为n的骰子出现的次数应该等于上一次循环中骰子点数和为n-1、n-2、n-3、n-4、n-5与n-6的次数的总和，所以把另一个数组的第n个数字设为前一个数组对应的第n-1、n-2、n-3、n-4、n-5与n-6之和。 四、代码实现>folded main.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( \"fmt\" \"math\")// 动态规划解法const gmax = 6func printProbability(n int) (result []float64) { var ( i, j, k int total = math.Pow(float64(gmax), float64(n)) flag = 0 probabilities = make([][]int, 2) ) probabilities[0] = make([]int, n*gmax+1) probabilities[1] = make([]int, n*gmax+1) // 初始掷第一枚骰子 for i = 1; i &lt;= gmax; i++{ probabilities[flag][i] = 1 } for k = 2; k &lt;= n; k++ { for i = 0; i &lt; k; i++ { probabilities[1-flag][i] = 0 } for i = k; i &lt;= k*gmax; i++ { // 使用i个骰子最小点数为i，最大点数6*i probabilities[1-flag][i] = 0 for j = 1; i-j &gt;= 0 &amp;&amp; j &lt;= gmax; j++ { // 第j个骰子的6种情况 probabilities[1-flag][i] += probabilities[flag][i-j] } } flag = 1 - flag } result = make([]float64, gmax*n-n+1) for i = n; i &lt;= gmax*n; i++ { result[i-n] = float64(probabilities[flag][i]) / total } return result}func main() { result := printProbability(3) for i := 0; i &lt; len(result); i++ { fmt.Println(result[i]) }}// 输出如下：--------------------------------0.0046296296296296290.0138888888888888880.0277777777777777760.0462962962962962940.069444444444444450.097222222222222220.115740740740740740.1250.1250.115740740740740740.097222222222222220.069444444444444450.0462962962962962940.0277777777777777760.0138888888888888880.004629629629629629--------------------------------Process finished with exit code 0 参考文章:1、面试题60n个骰子的点数","link":"/post/1deb282a.html"},{"title":"剑指offer-数组中只出现一次的数字","text":"一、题意一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。 二、思路 题目一直在强调一个(或两个)数字只出现一次，其他的出现两次。可以联想到异或运算。异或的一个性质是：任何一个数字异或它自己都等于0。如果我们从头到尾依次异或数组中的每一个数字，那么最终的结果刚好是那个只出现一次的数字。 那么如何在一个数组中找到两个只出现一次的数字呢？如果可以将原始数组分成两个子数组，使得每个子数组包含一个只出现一次的数字，而其他数字都成对出现。就可以用上述方法找到出现一次的数字。 从头到尾一次异或数组中的每一个数字，那么最终得到的结果就是两个只出现一次的数组的异或结果。因为其他数字都出现了两次，在异或中全部抵消了。由于两个数字肯定不一样，那么异或的结果肯定不为0，也就是说这个结果数组的二进制表示至少有一个位为1。我们在结果数组中找到第一个为1的位的位置，记为第n位。现在我们以第n位是不是1为标准把元数组中的数字分成两个子数组，第一个子数组中每个数字的第n位都是1，而第二个子数组中每个数字的第n位都是0。 三、代码实现1234567891011121314151617181920212223242526272829303132333435363738package mainimport \"fmt\"func oneNumber(nums []int) []int { xor := 0 // 遍历数组进行异或操作 for _, v := range nums { xor ^= v } // 取xor从右往左第一位为1的位 // 与自身的负数相与 // 负数的补码：符号位为1，其余位为该数绝对值的原码按位取反，然后再加1 // 2=0010 -2=1101+1=1110 0010&amp;1110=0010 // 用来判断xor是不是2的N次方 lowbit := xor &amp; -xor one, two := 0, 0 for _, v := range nums{ if lowbit&amp;v == 0 { one ^= v } else { two ^= v } } return []int{one, two}}func main() { test := []int{2, 4, 3, 6, 3, 2, 5, 5} result := oneNumber(test) fmt.Print(result)}// 输出如下：[4 6]Process finished with exit code 0","link":"/post/b9b525c6.html"},{"title":"剑指offer-数字在排序数组中出现的次数","text":"一、题目统计一个数字在排序数组中出现的次数。例如输入排序数组{1，2，3，3，3，3，4，5}和数字3，由于3在这个数组中出现了4次，因此输出4。 二、思路一运用二分查找 既然输入的数组是排序的，那么我们很自然地就能想到用二分查找算法。在题目给出的例子中，我们可以先用二分查找算法找到一个3。由于3可能出现多次，因此我们找到的3的左右两边可能都有3，于是我们在找到的3的左右两边顺序扫描，分别找出第一个3和最后一个3。 因为要查找的数字在长度为n的数组中有可能出现O(n)次，所以顺序扫描的时间复杂度是O(n)。因此这种算法的效率和直接从头到尾顺序扫描整个数组统计3出现的次数的方法是一样的。 三、思路二改进的二分查找 在前面的算法中时间主要消耗在如何确定重复出现的数字的第一个k和最后一个k的位置上，有没有可能用二分查找算法直接找到第一个k及最后一个k呢？ 我们先分析如何用二分查找算法在数组中找到第一个k。二分查找算法总是先拿数组中间的数字和k作比较。如果中间的数字比k大，那么k只有可能出现在数组的前半段，下一轮我们只在数组的前半段查找就可以了。如果中间的数字比k小，那么k只有可能出现在数组的后半段，下一轮我们只在数组的后半段查找就可以了。如果中间的数字和k相等呢？我们先判断这个数字是不是第一个k。如果位于中间数字的前面一个数字不是k，此时中间的数字刚好就是第一个k。如果中间数字的前面一个数字也是k，也就是说第一个k肯定在数组的前半段，下一轮我们仍然需要在数组的前半段查找。 四、代码实现>folded main.go12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport \"fmt\"func numberCount(nums []int, target int) int { // 二分查找初始化游标 left, right := 0, len(nums)-1 var mid int for left &lt; right { mid = (left + right) / 2 // 中间元素与查找对象相等，继续在它两边查找 if nums[mid] == target { // right在末尾，与中间元素不等，则往前面查找 for nums[mid] != nums[right] { right-- } // left在头部，与中间元素不等，则往后顺序查找 for nums[mid] != nums[left] { left++ } break } if nums[mid] &gt; target { // 中间元素比目标值大，则在数组的前半段去查找 right = mid - 1 } else { // 中间元素比目标值大，则在数组的后半段去查找 left = mid + 1 } } if left &lt; right { return right-left+1 } return -1}func main() { test := []int{1, 2, 3, 3, 3, 3, 4, 5} count := numberCount(test, 3) fmt.Println(\"Count 3 in \", test, \": \", count)}// 输出如下：Count 3 in [1 2 3 3 3 3 4 5] : 4Process finished with exit code 0","link":"/post/633aec21.html"},{"title":"剑指offer-数组中的逆序对","text":"一、题意题目描述 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。样例：输入：[7，5，6，4]输出：5 二、思路一顺序扫描整个数组。每扫描到一个数字的时候，逐个比较该数字和它后面的数字的大小。如果后面的数字比它小，则这两个数字就组成了一个逆序对。假设数组中含有n个数字。由于每个数字都要和O(n)个数字作比较，因此这个算法的时间复杂度是O(n^2)。 三、思路二可以利用归并排序的思想，在排序过程中统计逆序对的个数。一个排序好的数组逆序对数为0。所以从排序角度来看，我们只要将每一个逆序对转换为正序，最后数组则是有序的。问题转换为如何利用排序统计逆序数。将一个逆序变为正序，只需交换两者即可，如果仅仅这样统计交换次数是不够的。比如5432，对于(5，2)这对逆序数，交换(5，2)后，数组序列变为2435，这样会丢失中间(4，2)和(3，2)的逆序对。所以必须基于相邻元素来统计交换次数。那么基于交换相邻元素的排序算法有冒泡排序，插入排序和归并排序（两个子数组合并可看做2个相邻交换，只不过需要特殊处理）。插入排序的复杂度为O(n^2)，归并排序可以达到O(nlogn)。 四、代码实现>folded main.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package mainimport \"fmt\"func InverseParis(nums []int) int { // 存储排序好的数组 tmp := make([]int, len(nums)) // 合并两个排序好的数组 var merge func (start, mid, end int) int merge = func (start, mid, end int) int { // 匿名函数 if start &gt;= end { return 0 } p1, p2 := mid, end k, count := 0, 0 for p1 &gt;= start &amp;&amp; p2 &gt;= mid+1 { // 第一个数组中的数字不大于第二个数组中的数字，则进行下一轮的比较 if nums[p1] &lt;= nums[p2] { tmp[k] = nums[p2] p2-- k++ } else { // 两个数组合并时已排好序，对于num[p1]而言，至少有(p2-mid)个逆序对 tmp[k] = nums[p1] count += p2 - mid p1-- k++ } } // p1指向的数字此时都不大于p2指向的数字 for p1 &gt;= start { tmp[k] = nums[p1] p1-- k++ } for p2 &gt;= mid+1 { tmp[k] = nums[p2] p2-- k++ } for i := 0; i &lt;= k-1; i++ { nums[end-i] = tmp[i] } return count } var sort func (start, end int) int sort = func (start, end int) int { count := 0 if start &lt; end { // 每次排序都从中间分割 mid := (start+end)/2 count += sort(start, mid) count += sort(mid+1, end) count += merge(start, mid, end) } return count } return sort(0, len(nums)-1)}func main() { test := []int{7, 5, 6, 4} pairs := InverseParis(test) fmt.Println(\"样例：\") for i := 0; i &lt; len(test); i++ { fmt.Println(test[i]) } fmt.Printf(\"逆序对个数：%d\", pairs)}// 输出如下：样例：4567逆序对个数：5Process finished with exit code 0 参考链接： 1、[剑指offer] 数组中的逆序对2、剑指Offer（三十五）：数组中的逆序对","link":"/post/6d820329.html"},{"title":"剑指offer-二叉搜索树与双向链表","text":"一、题意题目描述 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 二、分析 二叉排序树的每个节点均由两个指针指向其两个孩子，双向链表中每个节点又都有两个指针指向其前驱和后继 二叉排序树的左节点的值 &lt; 根结点的值 &lt; 右子节点的值，其中序遍历就是一个排序好的信息串 对应两种方法实现： 中序遍历来实现二叉搜索树向双向链表的转换，访问过程需修改为链接操作 把左子树和右子树都转换成排序的双向链表之后再和根节点链接起来，整棵二叉搜索树就转换成了排序的双向链表 中序遍历 中序遍历中当前结点的前一个节点： 要么是当前结点的左子树的的最右孩子 要么是当前结点其前一个节点的右孩子 三、代码实现(采用递归)>folded main.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( \"fmt\")type TreeNode struct { Val int Left *TreeNode Right *TreeNode}var tail *TreeNode = nil// 中序遍历：左--中--右func ConvertRecursion(root *TreeNode) *TreeNode { if root == nil { return nil } // 如果左子树为空，则根结点root为双向链表的头结点 head := ConvertRecursion(root.Left) if head == nil { head = root } // 连接当前结点root和当前链表的尾结点tail root.Left = tail if tail != nil { tail.Right = root } tail = root // 遍历当前结点的右子树 ConvertRecursion(root.Right) return head}func main() { // 4 // 3 5 // 2 node2 := &amp;TreeNode{2, nil, nil} node3 := &amp;TreeNode{3, node2, nil} node5 := &amp;TreeNode{5, nil, nil} node4 := &amp;TreeNode{4, node3, node5} head := ConvertRecursion(node4) for head != nil { fmt.Println() fmt.Printf(\"curval: %d\", head.Val) head = head.Right } for tail != nil { fmt.Println() fmt.Printf(\"curval: %d\", tail.Val) tail = tail.Left }}// 输出如下：curval: 2curval: 3curval: 4curval: 5curval: 5curval: 4curval: 3curval: 2Process finished with exit code 0 四、总结与思考 ConvertRecursion函数的功能。1、输入：输入一个二叉搜索树的根节点。2、过程：将其转化为一个有序的双向链表。3、输出：返回该链表的头节点。 tail节点的作用1、用于记录当前链表的末尾节点。 递归过程1、按照中序遍历，将整个树分解成了无数的小树，然后将他们分别转化成一小段一小段的双向链表。再利用tail节点记录总的链表的末尾，然后将这些小段链表一个接一个地加到末尾。所以tail节点要定义成全局的。 参考剑指Offer–027-二叉搜索树与双向链表","link":"/post/600b78b.html"},{"title":"剑指offer-复杂链表的复制","text":"一、题意题目描述 请实现函数ComplexListNode Clone(ComplexListNode head)，复制一个复杂链表。在复杂链表中，每个结点除了有一个Next指针指向下一个结点外，还有一个Sibling指向链表中的任意结点或者NULL。 二、题解借助辅助空间的O(n)解法 第一步复制原始链表上的每个结点N创建N’，然后把这些创建出来的结点用Next链接起来。同时把(N，N’)配对信息放到一个哈希表中，节点数量不多的话，用普通map也可以。 第二步设置复制链表上每个结点的sibling兄弟节点。由于有了哈希表，可以用O(1)的时间根据sibling找到sibling’。 三、代码实现>folded main.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( \"fmt\")type ComplexListNode struct { Val int // 值 Next *ComplexListNode // 下一个节点 Sibling *ComplexListNode // 随机的兄弟节点}func CloneComplexList(head *ComplexListNode) *ComplexListNode { if head == nil { return nil } m := make(map[*ComplexListNode]*ComplexListNode) cur := head for cur != nil { if _, ok := m[cur]; !ok { m[cur] = &amp;ComplexListNode{cur.Val, nil, nil} } if cur.Next != nil { if _, ok := m[cur.Next]; !ok { m[cur.Next] = &amp;ComplexListNode{cur.Next.Val, nil, nil} } m[cur].Next = m[cur.Next] } if cur.Sibling != nil { if _, ok := m[cur.Sibling]; !ok { m[cur.Sibling] = &amp;ComplexListNode{cur.Sibling.Val, nil, nil} } m[cur].Sibling = m[cur.Sibling] } cur = cur.Next } return m[head]}func printList(head *ComplexListNode){ for head != nil{ fmt.Printf(\"当前节点: %d 兄弟节点: %d \\t\", head.Val, head.Sibling.Val) head = head.Next }}func main() { // 构造链表 l3 := &amp;ComplexListNode{3, nil, nil} l2 := &amp;ComplexListNode{2, l3, nil} l1 := &amp;ComplexListNode{1, l2, nil} l1.Sibling = l3 l2.Sibling = l2 l3.Sibling = l1 fmt.Println(\"复制前 --------- \") printList(l1) fmt.Println() fmt.Println(\"复制后 --------- \") printList(CloneComplexList(l1))}// 测试输出如下：复制前 --------- 当前节点: 1 兄弟节点: 3 当前节点: 2 兄弟节点: 2 当前节点: 3 兄弟节点: 1 复制后 --------- 当前节点: 1 兄弟节点: 3 当前节点: 2 兄弟节点: 2 当前节点: 3 兄弟节点: 1 Process finished with exit code 0","link":"/post/68dc24ea.html"},{"title":"历史","text":"一、1935年，站在未完工的金门大桥上的工人 二、1960s, Black men combating the psychological degradation of white people calling them “boy” 三、1969年，伍德斯托克音乐节 四、1964年，奥黛丽赫本 五、穆罕默德·阿里 六、1909年巴黎大皇宫，世界初次航展 七、1901年的日本商人 八、1934，纽约，晒衣服 九、1910年，巴黎大洪水掉落在街上的图书馆里的书 十、1926年洛杉矶，禁酒时期一位官员在运木车里闻到酒精气味 十一、1930年，经济大萧条，排队找工作的人 十二、1925年，印第安妇女电话接线员 十三、1886年，Bertha Benz，奔驰先生的妻子在驾驶奔驰车 十四、哥斯拉的扮演者拍摄间隙抽支烟 十五、马丁路德金移除烧毁的十字架，旁边是他儿子 十六、1990年，莫斯科第一家麦当劳，排队买麦当劳的人们 十七、广岛原子弹轰炸的幸存者Shigeki Tanak 赢得了1951年波士顿马拉松，人群一片静寂 十八、1948年，旧金山，Drive-In Theatre，汽车剧院 十九、The Beatles，最后一张成员合照 二十、1956年，弗雷德·阿斯泰尔和奥黛丽赫本在拍摄Funny face 二十一、1973年7月31日，李小龙葬礼 二十二、1939年的汽油价格 二十三、1936年7月30日，希特勒宣布柏林奥运会开幕 二十四、1960年11月14日，Ruby Bridges成为第一个上白人小学的african american 二十五、The London underground Now and then 二十六、1972 Toyota RV-2 Concept 二十七、1946年7月25日，美国空军拍摄的比基尼环礁上进行的十字路口试核行动 二十八、地铁里听着Walkman的4个人 二十九、1918，法国，一共只有二十台的German Panzerkampfwagen A7V heavy tank 奔赴战场 三十、1967，慕尼黑，施瓦辛格炫耀肌肉 三十一、1964，Elvis and Ann-Margret 三十二、1948年，第一次在电器店看到电视的男孩 三十三、1937年，两岁的达赖喇嘛 三十四、1921，The first Miss America Pageant 三十五、1945，东京湾，日本投降时的密苏里号 三十六、在空军一号上穿着厚运动裤的里根 三十七、1960，Jean-Paul Sartre, Simone de Beauvoir and Che Guevara in Cuba 三十八、李小龙单手俯卧撑，只用两根手指 三十九、1931年，在移动屏幕前看最新的米老鼠电影的伦敦人 四十、1943年，丘吉尔，Victory手势 四十一、1944年6月6日，霸王行动 横竖图 横图 竖图","link":"/post/53410.html"},{"title":"剑指offer-二叉树中和为某一值的路径","text":"一、题意题目描述 输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径 二、分析 由于路径是从根结点出发到叶结点，也就是说路径总是以根结点为起始点，因此我们首先需要遍历根结点。在树的前序、中序、后序三种遍历方式中，只有前序遍历是首先访问根结点的。 当用前序遍历的方式访问到某一结点时，我们把该结点添加到路径上，并累加该结点的值。如果该结点为叶结点并且路径中结点值的和刚好等于输入的整数，则当前的路径符合要求，我们把它打印出来。 如果当前结点不是叶结点，则继续访问它的子结点。当前结点访问结束后，递归函数将自动回到它的父结点。 因此我们在函数退出之前要在路径上删除当前结点并减去当前结点的值，以确保返回父结点时路径刚好是从根结点到父结点的路径。 三、参考Leetcode原题113. Path Sum II 四、代码实现>folded main.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package mainimport ( \"fmt\")type TreeNode struct { Data int Left *TreeNode Right *TreeNode}func FindPath(root *TreeNode, sum int) { if root == nil || root.Data == 0 || root.Left == nil || root.Right == nil { return } var path []int cursum := 0 findPath(root, sum, path, cursum) fmt.Println(\"------\") fmt.Println(path) fmt.Println(cursum)}func findPath(root *TreeNode, sum int, path []int, cursum int) { cursum += root.Data path = append(path, root.Data) // 如果是叶子节点，且路径上节点的和等于输入的值 // 打印出这条路径 leaf := root.Left == nil &amp;&amp; root.Right == nil if cursum == sum &amp;&amp; leaf { fmt.Print(\"a path is found: \") for i := 0; i &lt; len(path); i++ { fmt.Printf(\"%d --&gt; \", path[i]) } fmt.Println() } // 如果不是叶子节点，则遍历它的子节点 if root.Left != nil { findPath(root.Left, sum, path, cursum) } if root.Right != nil { findPath(root.Right, sum, path, cursum) } // 在返回到父节点之前，在路径上删除当前节点， // 并在cursum中减去当前节点的值 cursum -= root.Data path = path[:len(path)-1] fmt.Println(cursum) fmt.Println(path)}func main() { node4 := &amp;TreeNode{4, nil, nil} node7 := &amp;TreeNode{7, nil, nil} node5 := &amp;TreeNode{5, node4, node7} node12 := &amp;TreeNode{12, nil, nil} node10 := &amp;TreeNode{10, node5, node12} FindPath(node10, 22)}// 输出19[10 5 4]a path is found: 10 --&gt; 5 --&gt; 7 --&gt; 22[10 5 7]15[10 5]a path is found: 10 --&gt; 12 --&gt; 22[10 12]10[10]------[]0Process finished with exit code 0","link":"/post/36527.html"},{"title":"剑指offer-最小栈","text":"一、题意题目描述 定义栈的数据结构，请在该类型中实现一个能够得到栈最小元素的min函数。在该栈中，调用min、push以及pop的时间复杂度都是O(1)。 二、分析 实现当前栈的最小值，因为出栈也可能是最小元素出栈，所以需要辅助栈来保存每次元素入栈时的最小值 如果入栈的元素是最小值，则辅助栈保存当前元素；如果入栈的元素不是最小值，则辅助栈重复保存其栈顶的最小元素。 三、参考Leetcode原题LeetCode 155. Min Stack 四、代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657type MinStack struct { data utils.Stack // 数据栈 help utils.Stack // 辅助栈}func (m *MinStack) Push(val int) { top, _ := m.data.Top() if m.help.IsEmpty() == true || val &lt;= top.(int) { m.help.Push(val) } else { m.help.Push(top.(int)) } m.data.Push(val)}func (m *MinStack) Pop() { if m.data.IsEmpty() == true || m.help.IsEmpty() == true { return } m.data.Pop() m.help.Pop()}func (m *MinStack) Top() int { if m.data.IsEmpty() { return 0 } top, _ := m.data.Top() return top.(int)}func (m *MinStack) Min() int { if m.help.IsEmpty() { return 0 } min, _ := m.help.Top() return min.(int)}func main() { m := MinStack{nil, nil} m.Push(5) m.Push(2) m.Push(3) fmt.Print(\"数据栈 --&gt; \", m.data, \"\\n\") fmt.Print(\"辅助栈 --&gt; \", m.help, \"\\n\") fmt.Print(\"栈顶元素 --&gt; \", m.Top(), \"\\n\") fmt.Print(\"栈最小元素 --&gt; \", m.Min(), \"\\n\")}// 输出如下数据栈 --&gt; [5 2 3]辅助栈 --&gt; [5 2 2]栈顶元素 --&gt; 3栈最小元素 --&gt; 2Process finished with exit code 0","link":"/post/16270.html"},{"title":"剑指offer-顺时针打印矩阵","text":"一、题意给定一个包含 n x m 个元素的矩阵（n 行，m 列），请按照顺时针螺旋顺序，返回矩阵中的所有元素。例如，如果输入如下矩阵：输入:[ [1, 2, 3, 4], [5, 6, 7, 8], [9,10,11,12]]输出: [1, 2, 3, 4, 8, 12, 11, 10, 9, 5, 6, 7] 二、参考Leetcode原题LeetCode 54. Spiral Matrix 三、代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package mainimport \"fmt\"func PrintMatrix(matrix [][]int) []int { var res []int // 行数 n := len(matrix) if n == 0 { return res } // 列数 m := len(matrix[0]) // 计算元素个数 nm := n * m // 初始化层 layer := 0 // 初始化边界 startN, endN, startM, endM := 0, 0, 0, 0 // 从外围到内部顺时针遍历 for nm &gt; 0 { startN, endN = layer, n-layer-1 startM, endM = layer, m-layer-1 // 从左到右（行号不变） for i := startM; i &lt;= endM &amp;&amp; nm &gt; 0; i++ { res = append(res, matrix[startN][i]) nm-- } // 从上到下（列号不变） for i := startN+1; i &lt;= endN &amp;&amp; nm &gt; 0; i++ { res = append(res, matrix[i][endM]) nm-- } // 从右到左（行号不变） for i := endM-1; i &gt;= startM &amp;&amp; nm &gt; 0; i-- { res = append(res, matrix[endN][i]) nm-- } // 从下到上（列号不变） for i := endN-1; i &gt;= startN+1 &amp;&amp; nm &gt; 0; i-- { res = append(res, matrix[i][startM]) nm-- } // 层数递增 layer++ } return res}func main() { var matrix [][]int = [][]int {{1, 2}, {4, 5}, {7, 8}} res := PrintMatrix(matrix) fmt.Print(res)}// 输出如下[1 2 5 8 7 4]Process finished with exit code 0","link":"/post/54334.html"},{"title":"设计模式-享元模式","text":"一、定义 享元模式(Flyweight Pattern)：运用共享技术有效地支持大量细粒度对象的复用。系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次复用。由于享元模式要求能够共享的对象必须是细粒度对象，因此它又称为轻量级模式，它是一种对象结构型模式。 二、代码实现基本对象 12345678910111213141516// 享元对象type ObjFlyweight struct { data string // 数据}// 构造func NewObjFlyweight(objname string) *ObjFlyweight { data := fmt.Sprintf(\"data %s\", objname) return &amp;ObjFlyweight{ data: data, }}func (o *ObjFlyweight) Data() string { return o.data} 对象管理器(对象工厂) 123456789101112131415161718192021222324func (f *ObjFlyweightFactory) Get(objname string) *ObjFlyweight { obj := f.maps[objname] // 取对象，没有就New一个 if obj == nil { obj = NewObjFlyweight(objname) f.maps[objname] = obj } return obj}type ObjFlyweightFactory struct { maps map[string]*ObjFlyweight}var g_ObjFactory *ObjFlyweightFactoryfunc GetObjFlyweightFactory() *ObjFlyweightFactory { if g_ObjFactory == nil { g_ObjFactory = &amp;ObjFlyweightFactory{ maps: make(map[string]*ObjFlyweight), } } return g_ObjFactory} 显示对象 1234567891011121314type ObjDisplay struct { *ObjFlyweight}func NewObjDisplay(objname string) *ObjDisplay { obj := GetObjFlyweightFactory().Get(objname) return &amp;ObjDisplay{ ObjFlyweight: obj, }}func (odisp *ObjDisplay) Display() { fmt.Printf(\"Display: %s\\n\", odisp.Data())} 三、测试用例1234567891011121314151617181920212223242526272829303132333435363738// 样例输出测试func ExampleFlyweight() { odisp := NewObjDisplay(\"obj1\") odisp.Display() // Output: // Display: data obj1}// 结果显示如下：=== RUN ExampleFlyweight--- PASS: ExampleFlyweight (0.00s)PASSProcess finished with exit code 0------------------------------------------------------// 对象测试func TestFlyweight(t *testing.T) { odisp1 := NewObjDisplay(\"obj1\") odisp2 := NewObjDisplay(\"obj2\") odisp3 := NewObjDisplay(\"obj1\") if odisp1.ObjFlyweight != odisp2.ObjFlyweight { t.Fail() } if odisp3.ObjFlyweight == odisp1.ObjFlyweight { t.Log(\"Pass\") }}// 结果输出如下:=== RUN TestFlyweight TestFlyweight: flyweight_test.go:24: Pass--- FAIL: TestFlyweight (0.00s)FAILProcess finished with exit code 1","link":"/post/1701.html"},{"title":"剑指offer-打印1到最大的N位数","text":"一、题目描述输入数字n，按顺序打印出从1到最大的n位十进制数。例如输入3，则打印1、2、3 … 一直到最大的3位数999. 二、题解设置一个N位数的数组，使用全排列给数组赋值即可。因为个位数要不断变化，所以个位数的赋值应该在递归的最底层。一种递归实现如下所示。 12345678910111213141516171819202122232425262728293031323334353637func Print1ToMaxDigits(n int) { if n &lt;= 0 { return } number := make([]int, n) for i := 0; i &lt; 10; i++ { number[0] = i Print1ToMaxDigitsRecursively(number, n, 0) }}func Print1ToMaxDigitsRecursively(number []int, length int, index int) { if index == length-1 { printNumber(number) return } for i := 0; i &lt; 10; i++ { number[index+1] = i Print1ToMaxDigitsRecursively(number, length, index+1) }}func printNumber(number []int) { var isBeginning0 = true length := len(number) for i := 0; i &lt; length; i++ { if isBeginning0 &amp;&amp; number[i] != 0 { isBeginning0 = false } if !isBeginning0 { fmt.Printf(\"%d\", number[i]) if i == length-1 { fmt.Println() // 换行操作 } } }}","link":"/post/14807.html"},{"title":"剑指offer-使用两个栈实现队列，使用两个队列实现栈","text":"一、使用两个栈实现队列题目描述 用两个栈来实现一个队列，完成队列的Push和Pop操作。 二、分析两个栈，s1作为存储空间，入队先压栈到s1，s2作为元素出栈缓冲区，元素出栈在s2。 入队时，将元素压入s1。 出队时，判断s2是否为空，如不为空，则直接弹出栈顶元素；如为空，则将s1的元素逐个压入s2，把最后一个元素弹出并出队。这种思路，避免了反复压栈到缓冲栈，仅在需要时才压入一次。 三、go语言实现123456789101112131415161718192021222324252627282930313233343536type Queue struct { in common.Stack out common.Stack}// 判空func (que *Queue) IsEmpty() bool { return que.in.IsEmpty() &amp;&amp; que.out.IsEmpty()}// 入队func (que *Queue) Push(value interface{}) { qu.in.Push(value)}// 出队func (que *Queue) Pop() (interface{}, error) { if que.IsEmpty() { return nil, errors.New(\"Queue is empty\") } var value interface{} if !que.out.IsEmpty() { value, _ = que.out.Pop() return value, nil } for !que.in.IsEmpty() { value, _ = que.in.Pop() que.out.Push(value) } value, _ = que.out.Pop() return value, nil} 四、使用两个队列实现栈题目描述 用两个队列来实现一个栈，完成栈的Push压栈操作和Pop出栈操作。 五、分析 压栈时，将元素直接加入到一个不为空的一个队列中，如果都为空，任选一个即可。 出栈时，将不为空的队列除最后一个元素依次取出放入到另一个队列中，然后将最后一个元素出队即可。 六、go语言实现1234567891011121314151617181920212223242526272829303132333435363738394041type Stack struct { in Queue out Queue}// 入栈func (s *Stack) Push(value interface{}) { if s.in.IsEmpty() == false { s.in.Push(value) } else { s.out.Push(value) }}// 出栈func (s *Stack) Pop() (interface{}, error) { if s.in.IsEmpty() == false { inlen := s.in.Size() var val interface{} for i := 0; i &lt; inlen; i++ { val, _ = s.in.Pop() if i == inlen-1 { return val, nil } else { s.out.Push(val) } } } else if s.out.IsEmpty() == false { outlen := s.out.Size() var val interface{} for i := 0; i &lt; outlen; i++ { val, _ = s.out.Pop() if i == outlen-1 { return val, nil } else { s.in.Push(val) } } } return nil, nil}","link":"/post/59749.html"}],"tags":[{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"C++11","slug":"C-11","link":"/tags/C-11/"},{"name":"initializer_list","slug":"initializer-list","link":"/tags/initializer-list/"},{"name":"初始化列表","slug":"初始化列表","link":"/tags/%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8/"},{"name":"IDE","slug":"IDE","link":"/tags/IDE/"},{"name":"构造函数","slug":"构造函数","link":"/tags/%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"MyISAM","slug":"MyISAM","link":"/tags/MyISAM/"},{"name":"InnoDB","slug":"InnoDB","link":"/tags/InnoDB/"},{"name":"主从复制","slug":"主从复制","link":"/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"OS","slug":"OS","link":"/tags/OS/"},{"name":"WSL","slug":"WSL","link":"/tags/WSL/"},{"name":"字符串","slug":"字符串","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"二分查找","slug":"二分查找","link":"/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"分治","slug":"分治","link":"/tags/%E5%88%86%E6%B2%BB/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"回文数","slug":"回文数","link":"/tags/%E5%9B%9E%E6%96%87%E6%95%B0/"},{"name":"哈希表","slug":"哈希表","link":"/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"双指针","slug":"双指针","link":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"滑动窗口","slug":"滑动窗口","link":"/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"子序列","slug":"子序列","link":"/tags/%E5%AD%90%E5%BA%8F%E5%88%97/"},{"name":"math","slug":"math","link":"/tags/math/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"二叉搜索树","slug":"二叉搜索树","link":"/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"双向链表","slug":"双向链表","link":"/tags/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/"},{"name":"二叉树","slug":"二叉树","link":"/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"栈","slug":"栈","link":"/tags/%E6%A0%88/"},{"name":"队列","slug":"队列","link":"/tags/%E9%98%9F%E5%88%97/"},{"name":"递归","slug":"递归","link":"/tags/%E9%80%92%E5%BD%92/"},{"name":"全排列","slug":"全排列","link":"/tags/%E5%85%A8%E6%8E%92%E5%88%97/"},{"name":"数组","slug":"数组","link":"/tags/%E6%95%B0%E7%BB%84/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"矩阵","slug":"矩阵","link":"/tags/%E7%9F%A9%E9%98%B5/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"SEO","slug":"SEO","link":"/tags/SEO/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"配置","slug":"配置","link":"/tags/%E9%85%8D%E7%BD%AE/"},{"name":"历史","slug":"历史","link":"/tags/%E5%8E%86%E5%8F%B2/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"无锁队列","slug":"无锁队列","link":"/tags/%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"代码推送","slug":"代码推送","link":"/tags/%E4%BB%A3%E7%A0%81%E6%8E%A8%E9%80%81/"},{"name":"对象模型","slug":"对象模型","link":"/tags/%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"享元模式","slug":"享元模式","link":"/tags/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","link":"/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"面向对象","slug":"面向对象","link":"/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"B+树","slug":"B-树","link":"/tags/B-%E6%A0%91/"},{"name":"索引","slug":"索引","link":"/tags/%E7%B4%A2%E5%BC%95/"},{"name":"string","slug":"string","link":"/tags/string/"},{"name":"thread","slug":"thread","link":"/tags/thread/"},{"name":"线程","slug":"线程","link":"/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"网络编程","slug":"网络编程","link":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"ping","slug":"ping","link":"/tags/ping/"},{"name":"ifconfig","slug":"ifconfig","link":"/tags/ifconfig/"},{"name":"netstat","slug":"netstat","link":"/tags/netstat/"},{"name":"lsof","slug":"lsof","link":"/tags/lsof/"},{"name":"tcpdump","slug":"tcpdump","link":"/tags/tcpdump/"},{"name":"数据抽象","slug":"数据抽象","link":"/tags/%E6%95%B0%E6%8D%AE%E6%8A%BD%E8%B1%A1/"},{"name":"值语义","slug":"值语义","link":"/tags/%E5%80%BC%E8%AF%AD%E4%B9%89/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"一致性","slug":"一致性","link":"/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"channel","slug":"channel","link":"/tags/channel/"},{"name":"通道","slug":"通道","link":"/tags/%E9%80%9A%E9%81%93/"},{"name":"LRU","slug":"LRU","link":"/tags/LRU/"},{"name":"遍历","slug":"遍历","link":"/tags/%E9%81%8D%E5%8E%86/"},{"name":"先序","slug":"先序","link":"/tags/%E5%85%88%E5%BA%8F/"},{"name":"中序","slug":"中序","link":"/tags/%E4%B8%AD%E5%BA%8F/"},{"name":"后序","slug":"后序","link":"/tags/%E5%90%8E%E5%BA%8F/"},{"name":"TIME_WAIT","slug":"TIME-WAIT","link":"/tags/TIME-WAIT/"},{"name":"游戏开发","slug":"游戏开发","link":"/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"游戏服务器","slug":"游戏服务器","link":"/tags/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"架构","slug":"架构","link":"/tags/%E6%9E%B6%E6%9E%84/"},{"name":"new","slug":"new","link":"/tags/new/"},{"name":"malloc","slug":"malloc","link":"/tags/malloc/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"行为树","slug":"行为树","link":"/tags/%E8%A1%8C%E4%B8%BA%E6%A0%91/"},{"name":"控制反转","slug":"控制反转","link":"/tags/%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC/"},{"name":"依赖注入","slug":"依赖注入","link":"/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"name":"进程","slug":"进程","link":"/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"内存","slug":"内存","link":"/tags/%E5%86%85%E5%AD%98/"},{"name":"虚函数","slug":"虚函数","link":"/tags/%E8%99%9A%E5%87%BD%E6%95%B0/"},{"name":"三次握手","slug":"三次握手","link":"/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"},{"name":"四次挥手","slug":"四次挥手","link":"/tags/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"name":"数据库理论","slug":"数据库理论","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA/"},{"name":"堆","slug":"堆","link":"/tags/%E5%A0%86/"},{"name":"跳跃表","slug":"跳跃表","link":"/tags/%E8%B7%B3%E8%B7%83%E8%A1%A8/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"编译","slug":"编译","link":"/tags/%E7%BC%96%E8%AF%91/"},{"name":"STL","slug":"STL","link":"/tags/STL/"},{"name":"vector","slug":"vector","link":"/tags/vector/"},{"name":"list","slug":"list","link":"/tags/list/"},{"name":"map","slug":"map","link":"/tags/map/"},{"name":"set","slug":"set","link":"/tags/set/"},{"name":"智能指针","slug":"智能指针","link":"/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"CodeStyle","slug":"CodeStyle","link":"/tags/CodeStyle/"},{"name":"代码风格","slug":"代码风格","link":"/tags/%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC/"},{"name":"tcp","slug":"tcp","link":"/tags/tcp/"},{"name":"select","slug":"select","link":"/tags/select/"},{"name":"poll","slug":"poll","link":"/tags/poll/"},{"name":"epoll","slug":"epoll","link":"/tags/epoll/"},{"name":"IO多路复用","slug":"IO多路复用","link":"/tags/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"name":"红黑树","slug":"红黑树","link":"/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"服务端","slug":"服务端","link":"/tags/%E6%9C%8D%E5%8A%A1%E7%AB%AF/"},{"name":"通信","slug":"通信","link":"/tags/%E9%80%9A%E4%BF%A1/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"非阻塞IO","slug":"非阻塞IO","link":"/tags/%E9%9D%9E%E9%98%BB%E5%A1%9EIO/"},{"name":"LT","slug":"LT","link":"/tags/LT/"},{"name":"ET","slug":"ET","link":"/tags/ET/"},{"name":"互斥","slug":"互斥","link":"/tags/%E4%BA%92%E6%96%A5/"},{"name":"同步","slug":"同步","link":"/tags/%E5%90%8C%E6%AD%A5/"}],"categories":[{"name":"C++","slug":"C","link":"/categories/C/"},{"name":"开发工具","slug":"开发工具","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"C++11","slug":"C/C-11","link":"/categories/C/C-11/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"IDE","slug":"开发工具/IDE","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/IDE/"},{"name":"leetcode","slug":"leetcode","link":"/categories/leetcode/"},{"name":"构造函数","slug":"Golang/构造函数","link":"/categories/Golang/%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"initializer_list","slug":"C/C-11/initializer-list","link":"/categories/C/C-11/initializer-list/"},{"name":"主从复制","slug":"MySQL/主从复制","link":"/categories/MySQL/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"WSL","slug":"操作系统/WSL","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/WSL/"},{"name":"剑指offer","slug":"剑指offer","link":"/categories/%E5%89%91%E6%8C%87offer/"},{"name":"字符串","slug":"leetcode/字符串","link":"/categories/leetcode/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"链表","slug":"leetcode/链表","link":"/categories/leetcode/%E9%93%BE%E8%A1%A8/"},{"name":"二分查找","slug":"leetcode/二分查找","link":"/categories/leetcode/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"分治","slug":"leetcode/分治","link":"/categories/leetcode/%E5%88%86%E6%B2%BB/"},{"name":"博客","slug":"博客","link":"/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"数学","slug":"leetcode/数学","link":"/categories/leetcode/%E6%95%B0%E5%AD%A6/"},{"name":"历史","slug":"历史","link":"/categories/%E5%8E%86%E5%8F%B2/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"无锁队列","slug":"操作系统/无锁队列","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97/"},{"name":"github","slug":"github","link":"/categories/github/"},{"name":"对象模型","slug":"C/对象模型","link":"/categories/C/%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"面向对象","slug":"面向对象","link":"/categories/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"数组","slug":"leetcode/数组","link":"/categories/leetcode/%E6%95%B0%E7%BB%84/"},{"name":"事务","slug":"分布式/事务","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1/"},{"name":"动态规划","slug":"剑指offer/动态规划","link":"/categories/%E5%89%91%E6%8C%87offer/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"二叉搜索树","slug":"剑指offer/二叉搜索树","link":"/categories/%E5%89%91%E6%8C%87offer/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"二叉树","slug":"剑指offer/二叉树","link":"/categories/%E5%89%91%E6%8C%87offer/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"栈","slug":"剑指offer/栈","link":"/categories/%E5%89%91%E6%8C%87offer/%E6%A0%88/"},{"name":"递归","slug":"剑指offer/递归","link":"/categories/%E5%89%91%E6%8C%87offer/%E9%80%92%E5%BD%92/"},{"name":"链表","slug":"剑指offer/链表","link":"/categories/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"},{"name":"数组","slug":"剑指offer/数组","link":"/categories/%E5%89%91%E6%8C%87offer/%E6%95%B0%E7%BB%84/"},{"name":"位运算","slug":"剑指offer/位运算","link":"/categories/%E5%89%91%E6%8C%87offer/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"数学","slug":"剑指offer/数学","link":"/categories/%E5%89%91%E6%8C%87offer/%E6%95%B0%E5%AD%A6/"},{"name":"矩阵","slug":"剑指offer/矩阵","link":"/categories/%E5%89%91%E6%8C%87offer/%E7%9F%A9%E9%98%B5/"},{"name":"markdown","slug":"博客/markdown","link":"/categories/%E5%8D%9A%E5%AE%A2/markdown/"},{"name":"SEO","slug":"博客/SEO","link":"/categories/%E5%8D%9A%E5%AE%A2/SEO/"},{"name":"回文数","slug":"leetcode/数学/回文数","link":"/categories/leetcode/%E6%95%B0%E5%AD%A6/%E5%9B%9E%E6%96%87%E6%95%B0/"},{"name":"RSS订阅","slug":"博客/RSS订阅","link":"/categories/%E5%8D%9A%E5%AE%A2/RSS%E8%AE%A2%E9%98%85/"},{"name":"配置","slug":"博客/配置","link":"/categories/%E5%8D%9A%E5%AE%A2/%E9%85%8D%E7%BD%AE/"},{"name":"照片","slug":"历史/照片","link":"/categories/%E5%8E%86%E5%8F%B2/%E7%85%A7%E7%89%87/"},{"name":"二叉搜索树","slug":"数据结构与算法/二叉搜索树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"链表","slug":"数据结构与算法/链表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/"},{"name":"代码推送","slug":"github/代码推送","link":"/categories/github/%E4%BB%A3%E7%A0%81%E6%8E%A8%E9%80%81/"},{"name":"简单对象模型、表格驱动模型、C++对象模型","slug":"C/对象模型/简单对象模型、表格驱动模型、C-对象模型","link":"/categories/C/%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/%E7%AE%80%E5%8D%95%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E3%80%81%E8%A1%A8%E6%A0%BC%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E3%80%81C-%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/"},{"name":"享元模式","slug":"设计模式/享元模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"设计模式/单例模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"概念","slug":"面向对象/概念","link":"/categories/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/%E6%A6%82%E5%BF%B5/"},{"name":"幂","slug":"leetcode/数学/幂","link":"/categories/leetcode/%E6%95%B0%E5%AD%A6/%E5%B9%82/"},{"name":"索引","slug":"数据库/索引","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%B4%A2%E5%BC%95/"},{"name":"String","slug":"C/String","link":"/categories/C/String/"},{"name":"构造函数","slug":"C/构造函数","link":"/categories/C/%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"},{"name":"线程","slug":"C/线程","link":"/categories/C/%E7%BA%BF%E7%A8%8B/"},{"name":"网络编程","slug":"C/网络编程","link":"/categories/C/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"面向对象","slug":"Golang/面向对象","link":"/categories/Golang/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"数据抽象","slug":"C/数据抽象","link":"/categories/C/%E6%95%B0%E6%8D%AE%E6%8A%BD%E8%B1%A1/"},{"name":"缓存","slug":"数据库/缓存","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%BC%93%E5%AD%98/"},{"name":"通道channel","slug":"Golang/通道channel","link":"/categories/Golang/%E9%80%9A%E9%81%93channel/"},{"name":"LRU","slug":"数据结构与算法/LRU","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/LRU/"},{"name":"二分查找","slug":"数据结构与算法/二分查找","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"二叉树","slug":"数据结构与算法/二叉树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"对象成员布局","slug":"C/对象模型/对象成员布局","link":"/categories/C/%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E8%B1%A1%E6%88%90%E5%91%98%E5%B8%83%E5%B1%80/"},{"name":"游戏开发","slug":"游戏开发","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"内存","slug":"C/内存","link":"/categories/C/%E5%86%85%E5%AD%98/"},{"name":"网络工具命令","slug":"计算机网络/网络工具命令","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E5%91%BD%E4%BB%A4/"},{"name":"设计原则","slug":"设计模式/设计原则","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"name":"进程","slug":"操作系统/进程","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B/"},{"name":"一致性","slug":"数据库/缓存/一致性","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%BC%93%E5%AD%98/%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"遍历","slug":"数据结构与算法/二叉树/遍历","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/%E9%81%8D%E5%8E%86/"},{"name":"TCP","slug":"计算机网络/TCP","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP/"},{"name":"游戏服务器","slug":"游戏开发/游戏服务器","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"内存分配","slug":"C/内存/内存分配","link":"/categories/C/%E5%86%85%E5%AD%98/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"},{"name":"AI","slug":"游戏开发/AI","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/AI/"},{"name":"控制反转与依赖注入","slug":"设计模式/设计原则/控制反转与依赖注入","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC%E4%B8%8E%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"name":"内存布局","slug":"操作系统/进程/内存布局","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B/%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"},{"name":"TIME_WAIT","slug":"计算机网络/TCP/TIME-WAIT","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP/TIME-WAIT/"},{"name":"架构","slug":"游戏开发/游戏服务器/架构","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9E%B6%E6%9E%84/"},{"name":"malloc、new","slug":"C/内存/内存分配/malloc、new","link":"/categories/C/%E5%86%85%E5%AD%98/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/malloc%E3%80%81new/"},{"name":"行为树","slug":"游戏开发/AI/行为树","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/AI/%E8%A1%8C%E4%B8%BA%E6%A0%91/"},{"name":"虚函数","slug":"C/虚函数","link":"/categories/C/%E8%99%9A%E5%87%BD%E6%95%B0/"},{"name":"三次握手 四次挥手","slug":"计算机网络/TCP/三次握手-四次挥手","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"name":"读书笔记","slug":"Golang/读书笔记","link":"/categories/Golang/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"数据库理论","slug":"数据库/数据库理论","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA/"},{"name":"堆","slug":"数据结构与算法/堆","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%A0%86/"},{"name":"跳跃表","slug":"数据结构与算法/跳跃表","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E8%B7%B3%E8%B7%83%E8%A1%A8/"},{"name":"编译","slug":"C/编译","link":"/categories/C/%E7%BC%96%E8%AF%91/"},{"name":"概念","slug":"C/内存/概念","link":"/categories/C/%E5%86%85%E5%AD%98/%E6%A6%82%E5%BF%B5/"},{"name":"STL","slug":"C/STL","link":"/categories/C/STL/"},{"name":"智能指针","slug":"C/智能指针","link":"/categories/C/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"},{"name":"经验谈","slug":"C/经验谈","link":"/categories/C/%E7%BB%8F%E9%AA%8C%E8%B0%88/"},{"name":"游戏服务器","slug":"Golang/游戏服务器","link":"/categories/Golang/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"编程风格","slug":"C/编程风格","link":"/categories/C/%E7%BC%96%E7%A8%8B%E9%A3%8E%E6%A0%BC/"},{"name":"网络编程","slug":"计算机网络/网络编程","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"IO多路复用","slug":"计算机网络/IO多路复用","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"name":"红黑树","slug":"数据结构与算法/红黑树","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"服务端","slug":"游戏开发/服务端","link":"/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/%E6%9C%8D%E5%8A%A1%E7%AB%AF/"},{"name":"进程线程","slug":"操作系统/进程线程","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B/"},{"name":"Google Style","slug":"C/编程风格/Google-Style","link":"/categories/C/%E7%BC%96%E7%A8%8B%E9%A3%8E%E6%A0%BC/Google-Style/"},{"name":"通信","slug":"操作系统/进程线程/通信","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B/%E9%80%9A%E4%BF%A1/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"epoll","slug":"Linux/epoll","link":"/categories/Linux/epoll/"},{"name":"多线程","slug":"操作系统/多线程","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"同步互斥","slug":"操作系统/多线程/同步互斥","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/"},{"name":"epoll","slug":"C/epoll","link":"/categories/C/epoll/"},{"name":"区别","slug":"操作系统/进程线程/区别","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B/%E5%8C%BA%E5%88%AB/"},{"name":"游戏服务器","slug":"C/游戏服务器","link":"/categories/C/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]}